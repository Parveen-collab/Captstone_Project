job_id,job_title,company_name,location,workplace_type,employment_type,industry,job_description,seniority_level,experience_required,skills,salary_range
4249936426,Machine Learning Engineer,IntraEdge,"Pune, Maharashtra, India (Remote)",Remote,Full-time,,"About the job Website http://www.intraedge.com Machine Leaning Engineer Experience-6+Years Notice period-max 15 days Location -Pune/Remote Job Summary: Job Overview Machine Learning Engineer (Python, AWS) We are seeking an experienced Machine Learning Engineer with 5+ years of hands-on experience in developing and deploying ML solutions. The ideal candidate will have strong Python programming skills and a proven track record working with AWS services for machine learning. Responsibilities: Design, develop, and deploy scalable machine learning models. Implement and optimize ML algorithms using Python. Leverage AWS services (e.g., Sagemaker, EC2, S3, Lambda) for ML model training, deployment, and monitoring. Collaborate with data scientists and other engineers to bring ML solutions to production. Ensure the performance, reliability, and scalability of ML systems. Qualifications: Bachelor's or Master's degree in Computer Science, Engineering, or a related field. 5+ years of professional experience as a Machine Learning Engineer. Expertise in Python programming for machine learning. Strong experience with AWS services for ML (SageMaker, EC2, S3, Lambda, etc.). Solid understanding of machine learning algorithms and principles. Experience with MLOps practices is a plus.",,,"Python, Machine Learning",
4256402684,Jr. Generative AI Engineer,Crystal Group,Mumbai Metropolitan Region (On-site),On-site,Full-time,,"About the job Job Title: AI Generalist – Junior / Technical Assistant Location: Goregaon East Experience: Fresher / 0–1 year Type: Full-time About the Role We’re looking for a smart, curious generalist with a beginner-to-intermediate understanding of AI tools and workflows. You don’t need to be an ML engineer — but you do need to understand how AI tools like ChatGPT, LLM APIs, image models, or automation platforms can be used to solve real-world problems. This is a hands-on, utility-first role: you’ll be experimenting, testing tools, building small workflows, and helping non-technical teams apply AI effectively. Responsibilities Research and test AI tools, APIs, and open-source projects Assist in building simple AI-based workflows (chatbots, summarizers, auto-taggers, etc.) Write prompts, test outputs, and improve AI response quality Help connect AI tools with existing systems (via Zapier, Python, Google Sheets, etc.) Create basic documentation and explainers for internal teams Stay updated with new tools, releases, and use-cases What We’re Looking For Basic working knowledge of generative AI (LLMs, vision models, etc.) Familiarity with tools like OpenAI, Gemini, Claude, Hugging Face, LangChain, or similar Knows how to use Python or no-code/low-code tools to connect things Logical thinker who can break down problems and test solutions Hungry to learn, experiment, and grow with minimal supervision Bonus: familiarity with prompt engineering or basic model fine-tuning Ideal Background Recent graduate or final-year student (any stream – CS, engineering, design, business, etc.) Completed an AI/ML course, bootcamp, or hands-on project Portfolio, GitHub, or personal projects using AI? Even better. What You’ll Get Exposure to cutting-edge tools and real-world problems Mentorship from cross-functional teams Room to grow into ops, product, data, or engineering roles A low-bureaucracy, high-initiative environment",,,Python,
4253104049,"Software Development Engineer-Finance AI and ML Dev, PXT Finance - ML Forecasting and Core Engineering",Amazon,"Bengaluru, Karnataka, India",,Full-time,,"About the job Description Amazon Finance Tech team leads innovation to combine data-driven finance with the AI approach driving accuracy, next gen forecasting capabilities, speed, efficiency, and reliability by exploring new techniques in ML and GenAI and building full stack services in AWS. This AI-First Finance builders team will lead AI Application Architecture, designs for predicting outcomes, forecasting values with high degree of automation and ML Ops for existing science pipelines and frameworks. Key job responsibilities As an software engineer on the team, you will own components of an integrated system. You will design and develop these components using AI builder tools, AWS and serverless infrastructure in the cloud that will need to be deployed for use by our financial stakeholders. You will work on a secured data management service that will allow the storage and usage of financial data with the highest standard of privacy. You will create a system that will allow the team to monitor the efficiencies of the designs. You will utilize GenAI-assisted software development on a daily basis that integrates with artificial intelligence tools like Amazon Q Developer into builder workflows to generate & optimize code, build tests, explain unfamiliar code, and learn new languages or APIs, effectively boosting your team’s productivity and code quality. Throughout the software development lifecycle, you will deploy AI tools, agents, use Model Context Protocol (MCP) and large language models (LLMs) to assist in multiple phases - from requirements analysis to coding and testing. You will be execute AI tools on Claude and Nova models for vibe coding and testing. We are looking for individuals who thrive in a collaborative environment where they will have a high level of independence, autonomy, and ownership in what they deliver. The right candidate will wear many hats and work in a highly collaborative environment that is more startup than big company. You will work on cutting edge technology not legacy. As a Software Development Engineer, you will work with a team of talented engineers to build low-latency solutions for frontend, middle tier and backend as well as identify and evaluate new technology options for the challenges we are trying to solve. You will work with a variety of core languages, microservices, and technologies including Java, Javascript, Python, Dynamo DB, Lambda, SQS, SNS and many other AWS services. We are looking for a smart engineer who can effectively deal with ambiguity and work independently to clarify requirements, build prototypes and deliver results quickly. Come join a team in which builders build software and delight customers! You will learn, have fun, and make a positive impact for our customers. A day in the life You Will Design and develop scalable financial systems using distributed computing technologies while collaborating with cross-functional teams Write and review high-quality code for mission-critical applications that process millions of transactions and impact customers globally Participate in daily agile ceremonies including stand-ups, sprint planning, and retrospectives while managing rapid development cycles Debug, optimize, and maintain complex distributed systems to ensure fault tolerance, performance, and reliability at massive scale Create and contribute to technical documentation, architecture designs, and implementation strategies while mentoring junior team members and participating in code reviews Partner closely with customers, product leaders, and stakeholders to understand business requirements, influence product roadmap decisions, and deliver innovative solutions that drive business value Basic Qualifications 3+ years of non-internship professional software development experience 2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience 3+ years of computer science fundamentals (object-oriented design, data structures, algorithm design, problem solving and complexity analysis) experience Experience programming with at least one software programming language Preferred Qualifications 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience Bachelor's degree in computer science or equivalent Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI - Karnataka Job ID: A3011439",,,Python,
4245431841,Engineer II - Data Engg & AI,Anblicks,"Hyderabad, Telangana, India",,Full-time,,"About the job We are seeking a highly skilled and experienced Senior AI Engineer to lead the design, development, and deployment of advanced AI systems. You will work on cutting-edge machine learning models, natural language processing, computer vision, and AI infrastructure to solve real-world problems and drive innovation across our products and services. Key Responsibilities Design, develop, and deploy scalable AI/ML models for production environments. Lead end-to-end AI project lifecycles from data collection and preprocessing to model training, evaluation, and deployment. Collaborate with cross-functional teams including data scientists, software engineers, and product managers. Optimize model performance and ensure robustness, fairness, and explainability. Stay current with the latest research and advancements in AI and machine learning. Mentor junior engineers and contribute to building a strong AI engineering culture. Required Qualifications Bachelor’s or Master’s degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field (PhD preferred). 5+ years of experience in AI/ML engineering with a strong portfolio of deployed models. Proficiency in Python and ML libraries such as TensorFlow, PyTorch, Scikit-learn, etc. Experience with cloud platforms (AWS, Azure) and MLOps tools. Strong understanding of data structures, algorithms, and software engineering principles. Excellent problem-solving and communication skills. Preferred Qualifications Experience with LLMs, RAG, or agentic AI (Crew AI) systems. Familiarity with vector databases, prompt engineering, and AI safety practices. Contributions to open-source AI projects or published research papers. Experience with real-time inference systems and edge AI.",manager,,"Python, Machine Learning",
4248004749,Senior Machine Learning Operations Engineer,Onclusive,"Navi Mumbai, Maharashtra, India (Hybrid)",Hybrid,Full-time,,"About the job About the Role: As a Machine Learning Operation Engineer, you will work on deploying, scaling, and optimizing backend algorithms, robust and scalable data ingestion pipelines, machine learning services, and data platforms to support analysis on vast amounts of text and analytics data. You will apply your technical knowledge and Big Data analytics on Onclusive’s billions of online content data points to solve challenging marketing problems. ML Ops Engineers are integral to the success of Onclusive. Your responsibilities: Design and build scalable machine learning services and data platforms. Utilize benchmarks, metrics, and monitoring to measure and improve services. Manage system currently processing data on the order of tens of millions of jobs per day. Research, design, implement and validate cutting-edge algorithms to analyze diverse sources of data to achieve targeted outcomes. Work with data scientists and machine learning engineers to implement ML, AI, and NLP techniques for article analysis and attribution. Deploy, manage, and optimize inference services on autoscaling fleets with GPUs and specialized inference hardware. Who you are: A degree (BS, MS, or Ph.D.) in Computer Science or a related field, accompanied by hands-on experience. Minimum of 2 years experience of working with Kubernetes / Terraform Proficiency in Python, showcasing your understanding of Object-Oriented Programming (OOP) principles. Solid knowledge of containerisation (Docker preferable) Experience working with Kubernetes. Experience in Infrastructure as Code (IAC) for AWS, with a preference for Terraform. Knowledge of Version Control Systems (VCS), particularly Git and GitHub, alongside familiarity with CI/CD, preferably GitHub Actions. Understanding of release management, embracing rigorous testing, validation, and quality assurance protocols. Good understanding of ML principles Data Engineering experience (airflow, dbt, meltano) is highly desired. Exposure to deep learning tech-stacks like Torch / Tensorflow, and Transformers. What we can offer: We are a global fast growing company which offers a variety of opportunities for you to develop your skill set and career. In exchange for your contribution, we can offer you: Competitive salary and benefits Hybrid working in a team that is passionate about the work we deliver and supporting the development of those that we work with A company focus on wellbeing and work life balance including initiative’s such as flexible working and mental health support We want the best talent available, regardless of race, religion, gender, gender reassignment, sexual orientation, marital status, pregnancy, disability or age.",,2 years experience,"Python, Machine Learning",
4223540297,Data Engineer,Virtusa,"Andhra Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job Sr Developer with special emphasis and experience of 8 to 10 years on Python and Pyspark along with hands on experience on AWS Data components like AWS Glue, Athena etc.,. Also have good knowledge on Data ware house tools to understand the existing system. Candidate should also have experience on Datalake, Teradata and Snowflake. Should be good at terraform. 8-10 years of experience in designing and developing Python and Pyspark applications Creating or maintaining data lake solutions using Snowflake,taradata and other dataware house tools. Should have good knowledge and hands on experience on AWS Glue , Athena etc., Sound Knowledge on all Data lake concepts and able to work on data migration projects. Providing ongoing support and maintenance for applications, including troubleshooting and resolving issues. Expertise in practices like Agile, Peer reviews and CICD Pipelines. Desired Skills and Experience PySpark, Snowflake, UNIX, AWS Glue, Python, CI & CD",,,Python,
4253251481,Data Research Engineer-AI/ML,Uplers,Greater Lucknow Area (Remote),Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - Forbes Advisor) What do you need for this opportunity? Must have skills required: TensorFlow, PyTorch, rag, LangChain Forbes Advisor is Looking for: Location - Remote (For candidate's from Chennai or Mumbai it's hybrid) Forbes Advisor is a new initiative for consumers under the Forbes Marketplace umbrella that provides journalist- and expert-written insights, news and reviews on all things personal finance, health, business, and everyday life decisions. We do this by providing consumers with the knowledge and research they need to make informed decisions they can feel confident in, so they can get back to doing the things they care about most. At Marketplace, our mission is to help readers turn their aspirations into reality. We arm people with trusted advice and guidance, so they can make informed decisions they feel confident in and get back to doing the things they care about most. We are an experienced team of industry experts dedicated to helping readers make smart decisions and choose the right products with ease. Marketplace boasts decades of experience across dozens of geographies and teams, including Content, SEO, Business Intelligence, Finance, HR, Marketing, Production, Technology and Sales. The team brings rich industry knowledge to Marketplace’s global coverage of consumer credit, debt, health, home improvement, banking, investing, credit cards, small business, education, insurance, loans, real estate and travel. The Data Extraction Team is a brand-new team who plays a crucial role in our organization by designing, implementing, and overseeing advanced web scraping frameworks. Their core function involves creating and refining tools and methodologies to efficiently gather precise and meaningful data from a diverse range of digital platforms. Additionally, this team is tasked with constructing robust data pipelines and implementing Extract, Transform, Load (ETL) processes. These processes are essential for seamlessly transferring the harvested data into our data storage systems, ensuring its ready availability for analysis and utilization. A typical day in the life of a Data Research Engineer will involve coming up with ideas regarding how the company/team can best harness the power of AI/LLM, and use it not only simplify operations within the team, but also to streamline the work of the research team in gathering/retrieving large sets of data. The role is that of a leader who sets a vision for the future of AI/LLM’s use within the team and the company. They think outside the box and are proactive in engaging with new technologies and developing new ideas for the team to move forward in the AI/LLM field. The candidate should also at least be willing to acquire some basic skills in scraping and data pipelining. Responsibilities: Develop methods to leverage the potential of LLM and AI within the team. Proactive at finding new solutions to engage the team with AI/LLM, and streamline processes in the team. Be a visionary with AI/LLM tools and predict how the use of future technologies could be harnessed early on so that when these technologies come out, the team is ahead of the game regarding how it could be used. Assist in acquiring and integrating data from various sources, including web crawling and API integration. Stay updated with emerging technologies and industry trends. Explore third-party technologies as alternatives to legacy approaches for efficient data pipelines. Contribute to cross-functional teams in understanding data requirements. Assume accountability for achieving development milestones. Prioritize tasks to ensure timely delivery, in a fast-paced environment with rapidly changing priorities. Collaborate with and assist fellow members of the Data Research Engineering Team as required. Leverage online resources effectively like StackOverflow, ChatGPT, Bard, etc., while considering their capabilities and limitations. Skills And Experience Bachelor's degree in Computer Science, Data Science, or a related field. Higher qualifications is a plus. Think proactively and creatively regarding the next AI/LLM technologies and how to use them to the team’s and company’s benefits. “Think outside the box” mentality. Experience prompting LLMs in a streamlined way, taking into account how the LLM can potentially “hallucinate” and return wrong information. Experience building agentic AI platforms with modular capabilities and autonomous task execution. (crewai, lagchain, etc.) Proficient in implementing Retrieval-Augmented Generation (RAG) pipelines for dynamic knowledge integration. (chromadb, pinecone, etc) Experience managing a team of AI/LLM experts is a plus: this includes setting up goals and objectives for the team and fine-tuning complex models. Strong proficiency in Python programming Proficiency in SQL and data querying is a plus. Familiarity with web crawling techniques and API integration is a plus but not a must. Experience in AI/ML engineering and data extraction Experience with LLMs, NLP frameworks (spaCy, NLTK, Hugging Face, etc.) Strong understanding of machine learning frameworks (TensorFlow, PyTorch) Design and build AI models using LLMs Integrate LLM solutions with existing systems via APIs Collaborate with the team to implement and optimize AI solutions Monitor and improve model performance and accuracy Familiarity with Agile development methodologies is a plus. Strong problem-solving and analytical skills with attention to detail. Creative and critical thinking. Ability to work collaboratively in a team environment. Good and effective communication skills. Experience with version control systems, such as Git, for collaborative development. Ability to thrive in a fast-paced environment with rapidly changing priorities. Comfortable with autonomy and ability to work independently. Perks: Day off on the 3rd Friday of every month (one long weekend each month) Monthly Wellness Reimbursement Program to promote health well-being Monthly Office Commutation Reimbursement Program Paid paternity and maternity leaves How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience TensorFlow, PyTorch, rag, LangChain",,,"Python, SQL, Machine Learning",
4257575937,"Software Engineer, Integrations",Relyance AI,"Bengaluru, Karnataka, India",,Full-time,,"About the job Senior Software Engineer - AI Backend As Relyance AI’s Senior Software Engineer, AI Backend , you will strategize, drive, and execute on the core initiatives connecting output of NLP (Natural Language Processing) and AI models with the Relyance product. You will partner with cross-functional stakeholders to design and build a flexible, powerful, and robust NLP backend that scales the impact of AI for our customers. Given that you are constructing the foundation for a system with complex data that rapidly evolves over time, you need to pay close attention to detail, anticipate and welcome constant change, maintain a forward-thinking outlook, all while being fast and scrappy enough to address present needs. As a Senior Software Engineer - AI Backend, your role will include: Strategy: using your experience and understanding of how complex backends and data evolve over time, you will create and execute a roadmap for a system that enables high velocity AI development while creating stability on the product side Execution: make customer-centric prioritization decisions to balance between immediate impact and long-term bets and partner with the team manager to drive alignment and collaboration with other engineering teams Design: deeply understand how everything fits together; architect systems to balance scrappiness for the current needs with a forward-thinking outlook to improve and scale our infrastructure; continuously look for opportunities to automate and build tools to lower operational barriers Hands-on: being a key member of the team solving its most complex problems with the simple, pragmatic solutions Learning: in this role, you will have ample opportunities to become a hands-on AI/ML engineer by learning practical use of AI technologies such as LLMs (Large Language Models, e.g. ChatGPT and GPT-4), smaller models like BERT and T5, frameworks like PyTorch and TensorFlow, model training and data curation workflows, etc. This role could be a fit for you if you bring: 7+ years of experience with a track record of being a key member of teams building complex backends, especially backends that deal with complex data Expert level proficiency in Python Strong data structures, algorithms, and OO software design and implementation skills Ability to learn and operate across full stack, from ML and NLP, to cloud infrastructure, to UI frontend Experience as a creative and strategic thinker with mindset to build powerful, robust, and flexible systems A “get stuff done” attitude and enjoy being hands-on and working alongside the team to solve its most pressing problems in a fast-paced, collaborative environment A track record of successfully influencing product direction through a strong perspective that motivates engineers to develop simple, pragmatic solutions to complex problems Skills in communicating with clear and concise, active listening and empathy skills, and a respectful, collaborative approach that earns the trust of your peers Bonus points for: Experience with ML and NLP in particular Experience with a privacy technology Startup Experience An advanced technical degree",manager,,Python,
4255441821,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4243617163,Artificial Intelligence Engineer,Tata Consultancy Services,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Dear Associate Greetings from TATA Consultancy Services!! Thank you for expressing your interest in exploring a career possibility with the TCS Family. We have a job opportunity for AIML Engineer at Tata Consultancy Services at 14th June 2025. Hiring For : AIML Engineer Mandatory Skills: Python AI ML, MlOPs, Spark, Hadoop,PyTorch, TensorFlow,Matplotlib, Seaborn, Tableau, Power BI,scikit-learn, TensorFlow, XGBoost,AWS,Azure , AWS, Databricks,Pyspark, Python,SQL, Snowflake, Walk in Location: Pune Experience : 5-15 years Mode of interview: in-person walk in drive Date of interview: 14 June 2025 Venue : Zone 3 Auditorium, Tata Consultancy Services, Sahyadri Park, Rajiv Gandhi Infotech Park, Hinjewadi Phase 3, Pune – 411057 If you are interested in this exciting opportunity, Please share your updated resume on archana.parmeshwar@tcs.com along with the additional information mentioned below: Name: Preferred Location: Contact No: Email id: Highest Qualification: Current Organization Total Experience: Relevant Experience: Current CTC: Expected CTC: Notice Period: Gap Duration: Gap Details: Attended interview with TCS in past(details): Please share your I begin portal EP id if already registered: Willing to attend walk in on 14th June: (Yes/No) Note: only Eligible candidates with Relevant experience will be contacted further Thanks & Regards, Archana",Associate,,"Python, SQL, Tableau, Power BI",
4258457073,Computer Scientist,Recruin,"Kanpur, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job TDMM Artificial Intelligence team is looking for a passionate, talented, and inventive Computer Scientist with a strong applied mathematics background, to build industry-leading technology with Foundation models including multimodal systems and the opportunity to contribute to our AI initiatives and drive innovation in financial services. Key job responsibilities: Leverage TDMM diverse multimodel financial data sets along with large-scale computing resources to fast-track advancements in LLMs, and multimodal systems, ensuring our model team stays at the forefront of innovation in science and help our clients. Work with large teams, including external collaborators Present research findings Basic Qualifications: PhD, or Master's degree and 3+ years of applied research experience 3+ years of building machine learning models for business application experience Experience programming in Python or related language Experience with neural deep learning methods and machine learning Experience with neural deep learning methods and machine learning Experience with data-driven model development, time series analytics, stochastic optimisation, predictive analytics, uncertainty quantification, and more. Preferred Qualifications: PhD in Computer Science, Mathematics or related field Experience with LLMs or vision-based transformers and multimodal architectures Thorough understanding of AI/ML technology stack Experience in CNN, Transformer and Graph Neural Network. Experience with basic Reinforcement Learning algorithms Experience with generative deep learning models applicable to the creation of synthetic data like CNNs, GANs, VAEs, etc. Experience with large-scale machine learning systems such as profiling and debugging and understanding of system performance and scalability Experience with cross-domain/multi-task model training including datasets from diverse sources, balancing many axes of measurement in evaluation, and deploying to multiple products. Experience in publications at top-tier peer-reviewed conferences or journal Basic Qualifications Bachelor's degree and 3+ years of applied research experience 3+ years of building machine learning models for business application experience Experience programming in Python or related language Experience with data-driven model development, LLMs, fine-tuning LLMs Experience with API, application developments with AI models",,,"Python, Machine Learning",
4189290088,Software Architect (AI/ML),Celigo,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Celigo, a fast-growing Silicon Valley startup, is revolutionizing the cloud-based application integration landscape with our integrator.io iPaaS platform. We are looking for a talented engineer to help lead our internal AI/ML initiatives, and drive innovation throughout our integration platform. Responsibilities Help lead the charge at Celigo evaluating, implementing and deploying some of the hottest AI/ML frameworks like OpenAI, LangChain, Pinecone, Spacy, Hugging Face, etc… Develop and refine NLP models using the OpenAI platform to meet specific use cases and requirements. Utilize machine learning techniques to analyze and interpret data. Architect, implement and deploy Python microservices at AWS via containers/K8s delivered via fully automated CI/CD pipeline. Collaborate with software engineers to accelerate integrating more and more AI/ML capabilities into our products, ensuring seamless functionality and user experience. Work closely with product managers and business stakeholders to understand their requirements and develop AI/ML solutions that meet their needs, balancing technical feasibility with business objectives. Help ensure the security and privacy of user data by implementing appropriate safeguards, and staying informed on industry best practices. Qualifications 15+ years of total experience in software product development, with at least 4 years of relevant technical expertise in architecting solutions around AI/ML, NLP, data science, deep learning, etc… Multiple years experience building and supporting multi tenant SaaS applications at scale. A postgraduate degree with strong experience in research, or equivalent job experiences with a proven track record of successful outcomes. Hands-on experience developing AI/ML models in real-world environments and integrating AI/ML using cloud-native or hybrid technologies into large-scale enterprise applications is a plus Expertise with Python, comfortability with Node.js. Good with both SQL and NoSQL databases and technologies. Why You’ll Love Working At Celigo Solving complex integration challenges As an AI architect at Celigo, you will be part of a team that is tackling one of the most difficult problems faced by businesses worldwide: integrating cloud applications. You will be at the forefront of creating innovative solutions that help our customers automate their business processes. Automation expertise Celigo is the only iPaaS (Integration Platform as a Service) provider that offers prebuilt integrations to automate business processes across multiple cloud applications. You will have the opportunity to develop your skills in automation and leverage the latest AI technologies to build intelligent solutions. Values that guide our mission At Celigo, we have a set of guiding principles and beliefs that shape our work environment and culture. We are committed to fostering a workplace that promotes teamwork, creativity, and learning. A Company That Stands For Something Celigo's Taking a Stand initiative is our commitment to promoting diversity, equity, and inclusion. We believe that a diverse and inclusive workplace is essential to our success, and we are dedicated to making a positive impact in our community. Work-life balance We believe that a healthy work-life balance is critical to our team's happiness and productivity. As part of our commitment to this, we offer our employees three weeks of vacation and holidays from their first year, so they can recharge and spend time with loved ones. Great Benefits And Perks Celigo offers a comprehensive benefits package, including a tech stipend, pre-tax commuter expense reimbursement, and recognition opportunities. Our goal is to create an environment where our employees feel supported and valued, with opportunities for growth and development.",manager,,"Python, SQL, Machine Learning",
4252887638,Artificial Intelligence/Machine Learning Engineer - LLM Models,iAI Solution,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Job Title : AI/ML Engineer & Large Language Models (LLM) Location : Bengaluru, India Experience : 1 - 3 years Position Summary We are looking for an AI/ML Engineer with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, open source model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications. Key Responsibilities Develop, fine-tune, and deploy AI models using Python and Django frameworks. Apply prompt engineering techniques to optimize model outputs and improve accuracy. Utilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models. Work on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently. Collaborate with research teams to translate cutting-edge AI research into scalable solutions. Implement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions. Stay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects. Document and share findings, best practices, and solutions across the engineering team. An Ideal Candidate Will Have Strong proficiency in Python and Flask/FastAPI. Experience in prompt engineering and fine-tuning AI models. Extensive experience with HuggingFace libraries and similar AI/ML tools. Strong experience in AI Agentic Architecture Hands-on experience with cloud platforms such as AWS SageMaker for training and deploying models. Proficiency in Databases like MongoDB or PostgreSQL, as well as vector databases such as FAISS, Qdrant, or Elasticsearch Hands-on experience with Docker and Git for version control. Background in AI/ML research, with a preference for candidates from research institutes. Demonstrated experience in training and deploying machine learning models in real-world applications. Solid understanding of object-oriented programming and problem-solving skills. Strong analytical skills and the ability to work independently or in a team environment. Excellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders. Must Have Skills Python Object-Oriented Programming (OOP) Prompt engineering HuggingFace libraries and similar AI/ML tools Open Source Model fine-tuning AI Agentic Architecture such as LangGraph and CrewA Docker and Git for version control. Databases like MongoDB or PostgreSQL, as well as vector databases such as FAISS, Qdrant, or Elasticsearch Good To Have Deep Learning and Machine Learning AWS SageMaker or similar services for training AI models Previous experience in academic or industrial research, with published work in AI/ML. Proven track record of successful AI model deployments and optimizations. Experience with databases like MongoDB or PostgreSQL, as well as vector databases such as FAISS, Qdrant, or Elasticsearch. Perks & Benefits Work on groundbreaking AI/ML projects in a collaborative and innovative environment. Access to state-of-the-art tools and cloud platforms. Opportunities for professional development and continuous learning. Competitive salary. (ref:hirist.tech)",,,"Python, Machine Learning",
4227315563,Cloud Machine Learning LLM Serving Engineer,Qualcomm,"Bengaluru, Karnataka, India",,Full-time,,"About the job Company Qualcomm India Private Limited Job Area Engineering Group, Engineering Group > Software Engineering General Summary JD for Cloud Machine Learning LLM Serving engineer Job Overview The Qualcomm Cloud Computing team is developing hardware and software for Machine Learning solutions spanning the data center, edge, infrastructure, automotive market. We are seeking ambitious, bright, and innovative engineers with experience in machine learning framework development. Job activities span the whole product life cycle from early design to commercial deployment. The environment is fast-paced and requires cross-functional interaction daily so good communication, planning and execution skills are a must. Key Responsibilities Improve and optimize key Deep Learning models on Qualcomm AI 100. Build deep learning framework extensions for Qualcomm AI 100 in upstream open-source repositories. Implement Kernels for AI workloads Collaborate and interact with internal teams to analyze and optimize training and inference for deep learning. Build software tools and ecosystem around AI SW Stack. Work on vLLM, Triton, ExecuTorch, Inductor, TorchDynamo to build abstraction layers for inference accelerator. Optimize workloads for both scale-up (multi-SoC) and scale-out (multi-card) systems. Optimize the entire deep learning pipeline including graph compiler integration. Apply knowledge of software engineering best practices. Desirable Skills And Aptitudes Deep Learning experience or knowledge – LLMs, Natural Language Processing, Vision, Audio, Recommendation systems. Knowledge of the structure and function of different components of Pytorch, TensorFlow software stacks. Excellent C/C++/Python programming and software design skills, including debugging, performance analysis, and test design. Ability to work independently, define requirements and scope, and lead your own development effort. Well versed with open-source development practices. Strong developer with a research mindset – strives to innovate. Avid problem solver – should be able to find solutions to key engineering and domain problems. Knowledge of tiling and scheduling a Machine learning operator is a plus. Experience in using C++ 14 (advanced features) Experience of profiling software and optimization techniques Hands on experience writing SIMD and/or multi-threaded high-performance code is a plus. Experience of ML compiler, Auto-code generation (using MLIR) is a plus. Experiences to run workloads on large scale heterogeneous clusters is a plus. Hands-on experience with CUDA, CUDNN is a plus. Qualifications Bachelor's / Masters/ PHD degree in Engineering, Machine learning/ AI, Information Systems, Computer Science, or related field. 2+ years Software Engineering or related work experience. 2+ years’ experience with Programming Language such as C++, Python. Minimum Qualifications Bachelor's degree in Engineering, Information Systems, Computer Science, or related field. Applicants : Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here . Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries). Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law. To all Staffing and Recruiting Agencies : Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications. If you would like more information about this role, please contact Qualcomm Careers . 3075070",,,"Python, Machine Learning",
4241897720,GCP Data Engineer,Vista Applied Solutions Group Inc,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Role: GCP Data Engineer Fulltime with Perficient India Pvt Ltd Location: Bengaluru or Chennai (Hybrid) Notice Period : Immediate - 2 weeks Job Description: * Experience as a Data Engineer with expertise in GCP technologies such as BigQuery, Data Flow, etc. * Strong understanding of SQL concepts including joins, aggregations, filtering, etc. * Proficiency in writing efficient Python code for data processing tasks.",Manager,,"Python, SQL",
4250646294,"Software Development Engineer, Alexa Customer Journeys",Amazon,"Hyderabad, Telangana, India",,Full-time,"(supporting title Development, Release, or Live Ops) experience Experience programming with at least one software programming language Preferred Qualifications 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience Bachelor's degree in computer science or equivalent Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI HYD 13 SEZ Job ID: A3008497 Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company Amazon 34,483,838 followers Follow Software Development 10,001+ employees 735,395 on LinkedIn Amazon is guided by four principles: customer obsession rather than competitor focus, passion for invention, commitment to operational excellence, and long-term thinking. We are driven by the excitement of building technologies, inventing products, and providing services that change lives. We embrace new ways of doing things, make decisions quickly, and are not afraid to fail. We have the scope and capabilities of a large company, and the spirit and heart of a small one. Together, Amazonians research and develop new technologies from Amazon Web Services to Alexa on behalf of our customers: shoppers, sellers, content creators, and developers around the world. Our mission is to be Earth's most customer-centric company. Our actions, goals, projects, programs, and inventions begin and end with the customer top of mind. You'll also hear us say that at Amazon, it's always ""Day 1.""​ What do we mean? That our approach remains the same as it was on Amazon's very first day - to make smart, fast decisions, stay nimble, invent, and focus on delighting our customers. … show more Commitments Career growth and learning We offer a variety of career mobility and development opportunities that are designed to help employees move into higher-paying roles at Amazon or elsewhere. Our ten upskilling programs offer employees access to pre-paid education, technical and non-technical skills training, industry certifications, virtual and on-the-job learning and more to help them grow their skills. These programs, as well as career development opportunities like mentoring, internal transfers and promotions, are just one of the one we strive to be Earth's best employer. … Show more Diversity, equity, and inclusion Amazon’s ability to innovate on behalf of our customers relies on the perspectives and knowledge of people from all backgrounds. We actively recruit people from diverse backgrounds to build a","About the job Description Are you passionate about inventing experiences that help customers discover ways to incorporate Generative AI in their daily lives? Do you want to work in a fast paced environment surrounded by the smartest and most customer obsessed product, engineering, marketing, and data science leaders on the planet, where the future is still to be defined? Alexa Customer Journeys team is looking for a Software Development Engineer in the mission to make Alexa an expert on itself, providing useful information and experiences to customers seeking to take advantage of all of their devices’ features and capabilities. You will be building solutions and systems working with Large Language Model (LLM) and other generative technologies. You will be working with an interdisciplinary team of Software Development Engineers, Data Scientists and Quality Assurance Engineers, and working with Product Managers to design customer-facing experiences with Alexa, and building solutions to make Alexa an expert in itself. Key job responsibilities As a SDE, you will be responsible for designing, developing, testing, and deploying distributed machine learning systems and large-scale solutions for our world-wide customer base. In this, you will collaborate closely with a team of Data/Applied scientists to influence our overall strategy and define the team’s roadmap. You will also drive the system architecture, spearhead best practices that enable a quality product, and help coach and develop junior engineers. A successful candidate will have an established background in engineering large scale software systems, a strong technical ability, great communication skills, and a motivation to achieve results in a fast paced environment. We are a growing multi-disciplinary team addressing everyday customer needs through a combination of software engineering, web development and applied research. About The Team The Alexa Customer Journeys team builds products and technology that simplifies customers lives. Our products are used by millions of customer, across Amazon devices, WW. Our teams invent on behalf of our customers and have a ton of fun along the way! Basic Qualifications 3+ years of non-internship professional software development experience 2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience 3+ years of Video Games Industry (supporting title Development, Release, or Live Ops) experience Experience programming with at least one software programming language Preferred Qualifications 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience Bachelor's degree in computer science or equivalent Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI HYD 13 SEZ Job ID: A3008497",Manager,,Machine Learning,
4173687324,Data Engineer,Virtusa,"Andhra Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job Skill: Data Engineer Role: T2, T1 Key Responsibility Data Engineer Must have 9+ years of experience in below mentioned skills. Must Have: Big Data Concepts , Python(Core Python- Able to write code), SQL, Shell Scripting, AWS S3 Good to Have: Event-driven/AWA SQS, Microservices, API Development, Kafka, Kubernetes, Argo, Amazon Redshift, Amazon Aurora Desired Skills and Experience Amazon Redshift",,,"Python, SQL",
4253250554,Data Research Engineer-AI/ML,Uplers,"Kanpur, Uttar Pradesh, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - Forbes Advisor) What do you need for this opportunity? Must have skills required: TensorFlow, PyTorch, rag, LangChain Forbes Advisor is Looking for: Location - Remote (For candidate's from Chennai or Mumbai it's hybrid) Forbes Advisor is a new initiative for consumers under the Forbes Marketplace umbrella that provides journalist- and expert-written insights, news and reviews on all things personal finance, health, business, and everyday life decisions. We do this by providing consumers with the knowledge and research they need to make informed decisions they can feel confident in, so they can get back to doing the things they care about most. At Marketplace, our mission is to help readers turn their aspirations into reality. We arm people with trusted advice and guidance, so they can make informed decisions they feel confident in and get back to doing the things they care about most. We are an experienced team of industry experts dedicated to helping readers make smart decisions and choose the right products with ease. Marketplace boasts decades of experience across dozens of geographies and teams, including Content, SEO, Business Intelligence, Finance, HR, Marketing, Production, Technology and Sales. The team brings rich industry knowledge to Marketplace’s global coverage of consumer credit, debt, health, home improvement, banking, investing, credit cards, small business, education, insurance, loans, real estate and travel. The Data Extraction Team is a brand-new team who plays a crucial role in our organization by designing, implementing, and overseeing advanced web scraping frameworks. Their core function involves creating and refining tools and methodologies to efficiently gather precise and meaningful data from a diverse range of digital platforms. Additionally, this team is tasked with constructing robust data pipelines and implementing Extract, Transform, Load (ETL) processes. These processes are essential for seamlessly transferring the harvested data into our data storage systems, ensuring its ready availability for analysis and utilization. A typical day in the life of a Data Research Engineer will involve coming up with ideas regarding how the company/team can best harness the power of AI/LLM, and use it not only simplify operations within the team, but also to streamline the work of the research team in gathering/retrieving large sets of data. The role is that of a leader who sets a vision for the future of AI/LLM’s use within the team and the company. They think outside the box and are proactive in engaging with new technologies and developing new ideas for the team to move forward in the AI/LLM field. The candidate should also at least be willing to acquire some basic skills in scraping and data pipelining. Responsibilities: Develop methods to leverage the potential of LLM and AI within the team. Proactive at finding new solutions to engage the team with AI/LLM, and streamline processes in the team. Be a visionary with AI/LLM tools and predict how the use of future technologies could be harnessed early on so that when these technologies come out, the team is ahead of the game regarding how it could be used. Assist in acquiring and integrating data from various sources, including web crawling and API integration. Stay updated with emerging technologies and industry trends. Explore third-party technologies as alternatives to legacy approaches for efficient data pipelines. Contribute to cross-functional teams in understanding data requirements. Assume accountability for achieving development milestones. Prioritize tasks to ensure timely delivery, in a fast-paced environment with rapidly changing priorities. Collaborate with and assist fellow members of the Data Research Engineering Team as required. Leverage online resources effectively like StackOverflow, ChatGPT, Bard, etc., while considering their capabilities and limitations. Skills And Experience Bachelor's degree in Computer Science, Data Science, or a related field. Higher qualifications is a plus. Think proactively and creatively regarding the next AI/LLM technologies and how to use them to the team’s and company’s benefits. “Think outside the box” mentality. Experience prompting LLMs in a streamlined way, taking into account how the LLM can potentially “hallucinate” and return wrong information. Experience building agentic AI platforms with modular capabilities and autonomous task execution. (crewai, lagchain, etc.) Proficient in implementing Retrieval-Augmented Generation (RAG) pipelines for dynamic knowledge integration. (chromadb, pinecone, etc) Experience managing a team of AI/LLM experts is a plus: this includes setting up goals and objectives for the team and fine-tuning complex models. Strong proficiency in Python programming Proficiency in SQL and data querying is a plus. Familiarity with web crawling techniques and API integration is a plus but not a must. Experience in AI/ML engineering and data extraction Experience with LLMs, NLP frameworks (spaCy, NLTK, Hugging Face, etc.) Strong understanding of machine learning frameworks (TensorFlow, PyTorch) Design and build AI models using LLMs Integrate LLM solutions with existing systems via APIs Collaborate with the team to implement and optimize AI solutions Monitor and improve model performance and accuracy Familiarity with Agile development methodologies is a plus. Strong problem-solving and analytical skills with attention to detail. Creative and critical thinking. Ability to work collaboratively in a team environment. Good and effective communication skills. Experience with version control systems, such as Git, for collaborative development. Ability to thrive in a fast-paced environment with rapidly changing priorities. Comfortable with autonomy and ability to work independently. Perks: Day off on the 3rd Friday of every month (one long weekend each month) Monthly Wellness Reimbursement Program to promote health well-being Monthly Office Commutation Reimbursement Program Paid paternity and maternity leaves How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience TensorFlow, PyTorch, rag, LangChain",,,"Python, SQL, Machine Learning",
4245290661,GCP Data Engineer,TELUS Digital,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job About Us : At TELUS Digital, we enable customer experience innovation through spirited teamwork, agile thinking, and a caring culture that puts customers first. TELUS Digital is the global arm of TELUS Corporation, one of the largest telecommunications service providers in Canada. We deliver contact center and business process outsourcing (BPO) solutions to some of the world's largest corporations in the consumer electronics, finance, telecommunications and utilities sectors. With global call center delivery capabilities, our multi-shore, multi-language programs offer safe, secure infrastructure, value-based pricing, skills-based resources and exceptional customer service - all backed by TELUS, our multi-billion dollar telecommunications parent. Required Skills : 5+ years of industry experience in data engineering, business intelligence, or a related field with experience in manipulating, processing, and extracting value from datasets. Expertise in architecting, designing, building, and deploying internal applications to support technology life cycle management, service delivery management, data, and business intelligence. Experience in developing modular code for versatile pipelines or complex ingestion frameworks aimed at loading data into Cloud SQL and managing data migration from multiple on-premises sources. Strong collaboration with analysts and business process owners to translate business requirements into technical solutions. Proficiency in coding with scripting languages (Shell scripting, Python, SQL). Deep understanding and hands-on experience with Google Cloud Platform (GCP) technologies, especially in data migration and warehousing, including Database Migration Service (DMS), Cloud SQL, BigQuery, Dataflow, Data Catalog, Cloud Composer, Google Cloud Storage (GCS), IAM, Compute Engine, Cloud Data Fusion, and optionally Dataproc. Adherence to best development practices including technical design, solution development, systems configuration, test documentation/execution, issue identification and resolution, and writing clean, modular, self-sustaining code. Familiarity with CI/CD processes using GitHub, Cloud Build, and Google Cloud SDK. Qualifications: Bachelor's degree in Computer Science or a related technical field, or equivalent practical experience. GCP Certified Data Engineer (preferred). Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams, and business audiences.",,,"Python, SQL",
4255442803,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4254382130,Data Engineer - Data and Generative AI,Advisor360°,"Bengaluru, Karnataka, India",,Full-time,,"About the job At Advisor360°, we build technology that transforms how wealth management firms operate, scale, and serve their clients. As a leading SaaS platform in the fintech space, we’re trusted by some of the largest independent broker-dealers and RIAs to power the full advisor and client experience—from portfolio construction and reporting to compliance and client engagement. What sets us apart? It's not just the tech (though it's best-in-class). It's the people, the purpose, and the passion behind everything we do. We’re a team of builders, thinkers, and doers who believe that great companies are defined by the stories they tell and the experiences they create—internally and externally. We bring deep industry expertise, a collaborative spirit, and a commitment to innovation as we reshape what’s possible in wealth management. As we grow, we’re looking for teammates who are ready to roll up their sleeves, think big, and help elevate our brand in a way that reflects the bold ambitions we have for our company and the clients we serve. Join us, and be part of a company that's not only moving fast—but making it count. We hire people with all kinds of awesome experiences, backgrounds, and perspectives. We like it that way. So even if you don’t meet every single requirement, please consider applying if you like what you see. Key Responsibilities Acts as a technical leader by making significant technical contributions to the planning and implementation of mid- to large-scale projects from conception to completion. Demonstrates versatility of knowledge and applies strong technical skill sets to architect and implement cloud-based data solutions. Validates requirements, performs business and technical analysis, designs cloud-native applications, writes optimized PySpark-based data pipelines, and contributes to end-to-end application development. Ensures compliance with coding standards and best practices for AI-assisted code generation, suggesting opportunities for improvement. Utilizes GenAI tools like Cursor, Claude, and other LLMs to decompose complex requirements and auto-generate UI, API, and database scripts for rapid development. Acquires and utilizes strong technical and application knowledge to introduce and forecast the impact of new software design patterns, AI-driven development workflows, and emerging cloud technologies. Shares information and expertise to improve team productivity and empower engineers with AI-driven automation. Acts as a subject matter expert (SME) within the organization, helping resolve complex technical issues related to cloud data engineering, distributed computing, and microservices architecture. Mentors team members and fosters collaborative learning environments, particularly in areas related to GenAI, Azure, PySpark, Databricks, and CI/CD automation. Leads multiple projects within the team, ensuring seamless integration of AI-driven development into software delivery pipelines. Preferred Strengths Proficiency in GenAI-powered development, leveraging AI tools for code completion, optimization, and automated unit testing. Strong experience with SQL, relational databases, and GIT, including building and release definitions within a CI/CD environment. Expertise in Microsoft Azure cloud services, including Azure Data Factory, Azure Functions, and Azure Databricks. Familiarity with serverless architectures, containerization (Docker/Kubernetes), and big data frameworks like Apache Spark. Requirements, Skills, And Knowledge 7+ years of software engineering experience building enterprise applications using Python, .NET. Proven ability to analyze, decompose, and automate requirement-based development using GenAI. Strong experience in building and deploying cloud-based data processing applications using PySpark and Azure Databricks. Hands-on expertise in automating and optimizing cloud infrastructure using Terraform, Bicep, or ARM templates. Experience implementing business-critical database applications, REST microservices, and real-time event-driven architectures using Kafka, Orkes, and Databricks. Deep knowledge of SDLC methodologies (Agile, DevOps) and experience leading technical implementations from architecture to production deployment. Proficiency in coding standards, code reviews, source control management, build processes, testing, and operations. Experience integrating AI-based automation for improving code quality, predictive analytics, and data-driven decision-making. While Wealth Management domain experience is a plus, it is not mandatory. Candidates should be willing to learn/master the domain through on-the-job experience. It’s not just about work—it’s about building a career and enjoying the ride! Here’s what you can expect: Why You’ll Love Working With Us: We believe in recognizing and rewarding performance. Our compensation package includes competitive base salaries, annual performance-based bonuses, and the chance to share in the equity value you and your colleagues create during your time with the company. We offer comprehensive health benefits, including dental, life, and disability insurance. We also trust our employees to manage their time effectively, which is why we offer an unlimited paid time off program to help you perform at your best every day. Join us on this journey. Advisor360° is an equal opportunity employer committed to a diverse workforce. We believe diversity drives innovation and are therefore building a company where people of all backgrounds are truly welcome and included. Everyone is encouraged to bring their unique, authentic selves to work each and every day. The way we see it, we are here to learn from each other.",,,"Python, SQL",
3954674496,"Lead Software Engineer (Python, GenAI, LLM)",EPAM Systems,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job We are seeking a skilled Lead Software Engineer to join our team and lead a project focused on developing GenAI applications using Large Language Models (LLMs) and Python programming . In this role, you will be responsible for designing and optimizing Al-generated text prompts to maximize effectiveness for various applications. You will also collaborate with cross-functional teams to ensure seamless integration of optimized prompts into the overall product or system. Your expertise in prompt engineering principles and techniques will allow you to guide models to desired outcomes and evaluate prompt performance to identify areas for optimization and iteration. Responsibilities Design, develop, test and refine AI-generated text prompts to maximize effectiveness for various applications Ensure seamless integration of optimized prompts into the overall product or system Rigorously evaluate prompt performance using metrics and user feedback Collaborate with cross-functional teams to understand requirements and ensure prompts align with business goals and user needs Document prompt engineering processes and outcomes, educate teams on prompt best practices and keep updated on the latest AI advancements to bring innovative solutions to the project Requirements 7 to 12 years of relevant professional experience Expertise in Python programming including experience with Al/machine learning frameworks like TensorFlow, PyTorch, Keras, Langchain, MLflow, Promtflow 2-5 years of working knowledge of NLP and LLMs like BERT, GPT-3/4, T5, etc. Knowledge of how these models work and how to fine-tune them Expertise in prompt engineering principles and techniques like chain of thought, in-context learning, tree of thought, etc. Knowledge of retrieval augmented generation (RAG) Strong analytical and problem-solving skills with the ability to think critically and troubleshoot issues Excellent communication skills, both verbal and written in English at a B2+ level for collaborating across teams, explaining technical concepts, and documenting work outcomes",,,"Python, Machine Learning",
4229762913,AI / ML Developer (Senior),Infogain,"Mumbai, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Roles & Responsibilities Job Summary We are seeking a highly skilled and self-motivated AI Engineer to join us as we establish our AI Center of Excellence (CoE). As an early team member, you will play a critical role in shaping the foundation, strategy, and implementation of AI and ML solutions across the organization. This role offers a unique opportunity to work at the forefront of AI innovation, contribute to impactful use cases, and collaborate with cross-functional teams to build intelligent agentic systems. You will work with both Microsoft technologies (Copilot Studio, AI Foundry, Azure OpenAI) and open-source frameworks to design, deploy, and manage enterprise-ready AI solutions. Key Responsibilities Design, develop, and deploy AI agents using Microsoft Copilot Studio and AI Foundry. Build and fine-tune machine learning models for NLP, prediction, classification, and recommendation tasks. Conduct exploratory data analysis (EDA) to extract insights and support model development. Implement and manage LLM workflows, including prompt engineering, fine-tuning, evaluation, deployment, and monitoring. Utilize open-source frameworks such as LangChain, Hugging Face, MLflow, and RAG pipelines to build scalable, modular AI solutions. Integrate AI solutions with business workflows using APIs and cloud-native deployment methods. Use Azure AI services, including AI Foundry and Azure OpenAI, for secure and scalable model operations. Contribute to the creation of an AI governance framework, including Responsible AI principles, model explainability, fairness, and accountability. Support the creation of standards, reusable assets, and documentation as the CoE grows. Collaborate with engineering, data, and business teams to define problems, build solutions, and demonstrate value. Stay up to date with emerging AI capabilities such as Model Context Protocol (MCP), Agent-to-Agent (A2A) frameworks, and Agent Communication Protocols (ACP), and proactively evaluate opportunities to integrate them into enterprise solutions. Required Qualifications Bachelor's or master's degree in computer science, Data Science, Engineering, or a related field. 5+ years of experience in AI, machine learning, or data science with production-level deployments. Strong foundation in statistics, ML algorithms, and data analysis techniques. Hands-on experience building with LLMs, GenAI platforms, and AI copilots. Proficient in Python, with experience using libraries such as Pandas, Scikit-learn, PyTorch, TensorFlow, and Transformers. Experience with Microsoft Copilot Studio, AI Foundry, and Azure OpenAI. Working knowledge of open-source GenAI tools (LangChain, Haystack, MLflow). Understanding of cloud deployment, API integration, and version control (Git). Experience 6-8 Years Skills Primary Skill: AI/ML Development Sub Skill(s): AI/ML Development Additional Skill(s): TensorFlow, NLP, Pytorch, GenAI Fundamentals, Large Language Models (LLM) About The Company Infogain is a human-centered digital platform and software engineering company based out of Silicon Valley. We engineer business outcomes for Fortune 500 companies and digital natives in the technology, healthcare, insurance, travel, telecom, and retail & CPG industries using technologies such as cloud, microservices, automation, IoT, and artificial intelligence. We accelerate experience-led transformation in the delivery of digital platforms. Infogain is also a Microsoft (NASDAQ: MSFT) Gold Partner and Azure Expert Managed Services Provider (MSP). Infogain, an Apax Funds portfolio company, has offices in California, Washington, Texas, the UK, the UAE, and Singapore, with delivery centers in Seattle, Houston, Austin, Kraków, Noida, Gurgaon, Mumbai, Pune, and Bengaluru.",,,"Python, Machine Learning, Data Analysis",
4217268794,Machine Learning Engineer (Remote),Uplers,"Bhubaneswar, Odisha, India (Remote)",Save Machine Learning Engineer (Remote) at Uplers,Full-time,,"About the job Experience : 5.00 + years Salary : INR 5000000.00 / year (based on experience) Expected Notice Period : 15 Days Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full Time Permanent position(Payroll and Compliance to be managed by: Precanto) (*Note: This is a requirement for one of Uplers' client - A fast-growing, VC-backed B2B SaaS platform revolutionizing financial planning and analysis for modern finance teams.) What do you need for this opportunity? Must have skills required: async workflows, MLOps, Ray Tune, Data Engineering, MLFlow, Supervised Learning, Time-Series Forecasting, Docker, machine_learning, NLP, Python, SQL A fast-growing, VC-backed B2B SaaS platform revolutionizing financial planning and analysis for modern finance teams. is Looking for: We are a fast-moving startup building AI-driven solutions to the financial planning workflow. We’re looking for a versatile Machine Learning Engineer to join our team and take ownership of building, deploying, and scaling intelligent systems that power our core product. Job Description- Full-time Team: Data & ML Engineering We’re looking for 5+ years of experience as a Machine Learning or Data Engineer (startup experience is a plus) What You Will Do- Build and optimize machine learning models — from regression to time-series forecasting Work with data pipelines and orchestrate training/inference jobs using Ray, Airflow, and Docker Train, tune, and evaluate models using tools like Ray Tune, MLflow, and scikit-learn Design and deploy LLM-powered features and workflows Collaborate closely with product managers to turn ideas into experiments and production-ready solutions Partner with Software and DevOps engineers to build robust ML pipelines and integrate them with the broader platform Basic Skills Proven ability to work creatively and analytically in a problem-solving environment Excellent communication (written and oral) and interpersonal skills Strong understanding of supervised learning and time-series modeling Experience deploying ML models and building automated training/inference pipelines Ability to work cross-functionally in a collaborative and fast-paced environment Comfortable wearing many hats and owning projects end-to-end Write clean, tested, and scalable Python and SQL code Leverage async workflows and cloud-native infrastructure (S3, Docker, etc.) for high-throughput data processing. Advanced Skills Familiarity with MLOps best practices Prior experience with LLM-based features or production-level NLP Experience with LLMs, vector stores, or prompt engineering Contributions to open-source ML or data tools TECH STACK Languages: Python, SQL Frameworks & Tools: scikit-learn, Prophet, pyts, MLflow, Ray, Ray Tune, Jupyter Infra: Docker, Airflow, S3, asyncio, Pydantic How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience async workflows, MLOps, Ray Tune, Data Engineering, MLFlow, Supervised Learning, Time-Series Forecasting, Docker, machine_learning, NLP, Python, SQL",manager,,"Python, SQL, Machine Learning",
4250877655,Machine Learning Engineer,ACL Digital,"Ahmedabad, Gujarat, India (On-site)",On-site,Full-time,,"About the job We are looking for an experienced Machine Learning Engineer to join our team. The ideal candidate should have a strong background in developing, implementing, and deploying machine learning models on edge platforms. With at least 5 years of overall experience and at least 3 years of machine learning experience, you will significantly contribute to our projects, driving innovation and delivering high-quality solutions. Responsibilities: ● Design, develop, and deploy machine learning models and algorithms on the edge platforms. ● Perform data analysis and feature engineering to enhance model performance. ● Collaborate with cross-functional teams to integrate ML solutions into existing systems. ● Monitor and maintain deployed models, ensuring optimal performance and reliability. ● Stay current with the latest advancements in machine learning and AI. ● Document processes and best practices for machine learning workflows. ● Troubleshoot and resolve issues related to ML models and data pipelines. Experience & Background Requirement: ● Bachelor's or Master's degree in Engineering or equivalent. ● Minimum of 7+ years of overall experience. ● Minimum of 7 years of machine learning experience. ● Proficiency in programming languages such as Python, C, C++. ● Experience with any of HW platforms like NXP, NVidia, Qualcomm, Synaptcis . ● Strong understanding of machine learning algorithms and techniques (e.g., regression, classification, clustering, neural networks). ● Experience with machine learning libraries and frameworks (e.g., TensorFlow, PyTorch, Scikit-learn, Pandas, Numpy, Matplotlib, OpenCV). ● Knowledge of data preprocessing, feature engineering, and model training/evaluation. ● Experience with data storage and processing technologies (e.g., SQL, JSON, XML). ● Excellent problem-solving and analytical skills. ● Strong communication and collaboration abilities. ● Experience of streaming and GUI development is an advantage.",Executive,,"Python, SQL, Machine Learning, Data Analysis",
4236278640,AI/ML Lead Engineer,Meltwater,"Hyderabad, Telangana, India (Hybrid)",Hybrid,Full-time,,"About the job Description What We’re Looking For: As a AI/ML Lead Engineer at Meltwater, you'll play a vital role in building cutting-edge social solutions for our global client base within the Explore mission. We're seeking a proactive, quick-learning engineer who thrives in a collaborative environment. Our culture values continuous learning, team autonomy, and a DevOps mindset. Meltwater development teams take full ownership of their subsystems and infrastructure, including running on-call rotations. With a heavy reliance Software Engineer in AI/ML and Data Science. We seek individuals with experience in Cloud infrastructure and containerisation, Docker, Azure or AWS is required (Azure is preferred). Data Preparation, Model Lifecycle (training, serving and registries) & Natural language Processing (NLP) and LLMs In this role, you'll have the opportunity to push the boundaries of our technology stack, from modifying open-source libraries to innovating with existing technologies. If you're passionate about distributed systems at scale and finding new ways to extract insights from vast amounts of data, we invite you to join us in this exciting journey. What You'll Do: Leading/mentoring a small team while doing hands coding as well. Excellent communication and collaboration skills. What You'll Bring: Bachelor's or master's degree in computer science or equivalent degree or demonstrable experience. Proven experience as a Lead Software Engineer in AI/ML and Data Science. Minimum of 6+ years of working experience. Leadership experience as tech or team lead (2+ Years) Strong knowledge of Python and software engineering principles (5+ Years) Strong knowledge of cloud infrastructure and containerization (5+ Years) Docker is required Azure or AWS is required (Azure is preferred) Strong working knowledge of TensorFlow / PyTorch (5+ Years) Good working knowledge of ML-Ops Principles (3+ Years) Data Preparation Model Lifecycle (training, serving and registries) Good theoretical knowledge of AI / Data Science in one or more of the following areas: Natural language Processing (NLP) and LLMs Neural Networks Topic modelling and clustering Retrieval Augmented Generation Speech to Text Excellent communication and collaboration skills. What We Offer: Enjoy flexible paid time off options for enhanced work-life balance. Comprehensive health insurance tailored for you. Employee assistance programs cover mental health, legal, financial, wellness, and behaviour areas to ensure your overall well-being. Complimentary Calm App subscription for you and your loved ones, because mental wellness matters. Energetic work environment with a hybrid work style, providing the balance you need. Benefit from our family leave program, which grows with your tenure at Meltwater. Thrive within our inclusive community and seize ongoing professional development opportunities to elevate your career. Where You'll Work: HITEC City, Hyderabad. When You'll Join: As per the Offer Letter. Our Story At Meltwater, we believe that when you have the right people in the right environment, great things happen. Our best-in-class technology empowers our 27,000 customers around the world to make better business decisions through data. But we can’t do that without our global team of developers, innovators, problem-solvers, and high-performers who embrace challenges and find new solutions for our customers. Our award-winning global culture drives everything we do and creates an environment where our employees can make an impact, learn every day, feel a sense of belonging, and celebrate each other’s successes along the way. We are innovators at the core who see the potential in people, ideas and technologies. Together, we challenge ourselves to go big, be bold, and build best-in-class solutions for our customers. We’re proud of our diverse team of 2,200+ employees in 50 locations across 25 countries around the world. No matter where you are, you’ll work with people who care about your success and get the support you need to unlock new heights in your career. We are Meltwater. We love working here, and we think you will too. ""Inspired by innovation, powered by people."" Equal Employment Opportunity Statement Meltwater is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: At Meltwater, we are dedicated to fostering an inclusive and diverse workplace where every employee feels valued, respected, and empowered. We are committed to the principle of equal employment opportunity and strive to provide a work environment that is free from discrimination and harassment. All employment decisions at Meltwater are made based on business needs, job requirements, and individual qualifications, without regard to race, colour, religion or belief, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, marital status, veteran status, or any other status protected by the applicable laws and regulations. Meltwater does not tolerate discrimination or harassment of any kind, and we actively promote a culture of respect, fairness, and inclusivity. We encourage applicants of all backgrounds, experiences, and abilities to apply and join us in our mission to drive innovation and make a positive impact in the world.",,,Python,
4165485938,Principle Engineer - Data & AI,Anblicks,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Overview We are seeking a dynamic Consulting Lead with deep expertise in data and AI to drive critical projects and deliver strategic insights. This role requires a proactive leader who excels in problem solving, thought leadership, and cultivating strong client relationships, while identifying opportunities for growth and executing high-impact initiatives. Key Responsibilities Strategic Leadership: Drive and oversee data and AI projects with clear accountability and focus on measurable outcomes. Provide thought leadership and innovative solutions that align with business objectives. Project Execution: Manage end-to-end project lifecycles, ensuring timely and high-quality delivery. Collaborate with cross-functional teams to translate complex data insights into actionable strategies. Client & Stakeholder Engagement: Maintain and nurture healthy client relationships through effective communication and trust-building. Present compelling stories and insights through high-quality presentations to diverse stakeholders. Business Growth: Identify and create new opportunities for business expansion and revenue growth. Align data initiatives with broader business processes and strategic goals. Required Qualifications Proven expertise in data analytics, AI, or a related field with a solid track record in consulting roles. Strong problem-solving skills combined with excellent project management capabilities. Exceptional communication and presentation skills, with an ability to tell compelling stories from data. Deep understanding of business processes and the ability to translate technical insights into business value. Demonstrated ability to build and maintain robust client relationships. Education & Experience Bachelor’s or master’s degree in data science, Computer Science, Business, or a related field. Significant experience in a consulting role with a focus on data and AI initiatives.",,,,
4253252097,Data Research Engineer-AI/ML,Uplers,"Jamshedpur, Jharkhand, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - Forbes Advisor) What do you need for this opportunity? Must have skills required: TensorFlow, PyTorch, rag, LangChain Forbes Advisor is Looking for: Location - Remote (For candidate's from Chennai or Mumbai it's hybrid) Forbes Advisor is a new initiative for consumers under the Forbes Marketplace umbrella that provides journalist- and expert-written insights, news and reviews on all things personal finance, health, business, and everyday life decisions. We do this by providing consumers with the knowledge and research they need to make informed decisions they can feel confident in, so they can get back to doing the things they care about most. At Marketplace, our mission is to help readers turn their aspirations into reality. We arm people with trusted advice and guidance, so they can make informed decisions they feel confident in and get back to doing the things they care about most. We are an experienced team of industry experts dedicated to helping readers make smart decisions and choose the right products with ease. Marketplace boasts decades of experience across dozens of geographies and teams, including Content, SEO, Business Intelligence, Finance, HR, Marketing, Production, Technology and Sales. The team brings rich industry knowledge to Marketplace’s global coverage of consumer credit, debt, health, home improvement, banking, investing, credit cards, small business, education, insurance, loans, real estate and travel. The Data Extraction Team is a brand-new team who plays a crucial role in our organization by designing, implementing, and overseeing advanced web scraping frameworks. Their core function involves creating and refining tools and methodologies to efficiently gather precise and meaningful data from a diverse range of digital platforms. Additionally, this team is tasked with constructing robust data pipelines and implementing Extract, Transform, Load (ETL) processes. These processes are essential for seamlessly transferring the harvested data into our data storage systems, ensuring its ready availability for analysis and utilization. A typical day in the life of a Data Research Engineer will involve coming up with ideas regarding how the company/team can best harness the power of AI/LLM, and use it not only simplify operations within the team, but also to streamline the work of the research team in gathering/retrieving large sets of data. The role is that of a leader who sets a vision for the future of AI/LLM’s use within the team and the company. They think outside the box and are proactive in engaging with new technologies and developing new ideas for the team to move forward in the AI/LLM field. The candidate should also at least be willing to acquire some basic skills in scraping and data pipelining. Responsibilities: Develop methods to leverage the potential of LLM and AI within the team. Proactive at finding new solutions to engage the team with AI/LLM, and streamline processes in the team. Be a visionary with AI/LLM tools and predict how the use of future technologies could be harnessed early on so that when these technologies come out, the team is ahead of the game regarding how it could be used. Assist in acquiring and integrating data from various sources, including web crawling and API integration. Stay updated with emerging technologies and industry trends. Explore third-party technologies as alternatives to legacy approaches for efficient data pipelines. Contribute to cross-functional teams in understanding data requirements. Assume accountability for achieving development milestones. Prioritize tasks to ensure timely delivery, in a fast-paced environment with rapidly changing priorities. Collaborate with and assist fellow members of the Data Research Engineering Team as required. Leverage online resources effectively like StackOverflow, ChatGPT, Bard, etc., while considering their capabilities and limitations. Skills And Experience Bachelor's degree in Computer Science, Data Science, or a related field. Higher qualifications is a plus. Think proactively and creatively regarding the next AI/LLM technologies and how to use them to the team’s and company’s benefits. “Think outside the box” mentality. Experience prompting LLMs in a streamlined way, taking into account how the LLM can potentially “hallucinate” and return wrong information. Experience building agentic AI platforms with modular capabilities and autonomous task execution. (crewai, lagchain, etc.) Proficient in implementing Retrieval-Augmented Generation (RAG) pipelines for dynamic knowledge integration. (chromadb, pinecone, etc) Experience managing a team of AI/LLM experts is a plus: this includes setting up goals and objectives for the team and fine-tuning complex models. Strong proficiency in Python programming Proficiency in SQL and data querying is a plus. Familiarity with web crawling techniques and API integration is a plus but not a must. Experience in AI/ML engineering and data extraction Experience with LLMs, NLP frameworks (spaCy, NLTK, Hugging Face, etc.) Strong understanding of machine learning frameworks (TensorFlow, PyTorch) Design and build AI models using LLMs Integrate LLM solutions with existing systems via APIs Collaborate with the team to implement and optimize AI solutions Monitor and improve model performance and accuracy Familiarity with Agile development methodologies is a plus. Strong problem-solving and analytical skills with attention to detail. Creative and critical thinking. Ability to work collaboratively in a team environment. Good and effective communication skills. Experience with version control systems, such as Git, for collaborative development. Ability to thrive in a fast-paced environment with rapidly changing priorities. Comfortable with autonomy and ability to work independently. Perks: Day off on the 3rd Friday of every month (one long weekend each month) Monthly Wellness Reimbursement Program to promote health well-being Monthly Office Commutation Reimbursement Program Paid paternity and maternity leaves How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience TensorFlow, PyTorch, rag, LangChain",,,"Python, SQL, Machine Learning",
4250359750,Full stack Gen AI Engineer - Sr Associate,PwC Acceleration Centers in India,"Andhra Pradesh, India",,Full-time,,"About the job At PwC, our people in software and product innovation focus on developing cutting-edge software solutions and driving product innovation to meet the evolving needs of clients. These individuals combine technical experience with creative thinking to deliver innovative software products and solutions. In quality engineering at PwC, you will focus on implementing leading practice standards of quality in software development and testing processes. In this field, you will use your experience to identify and resolve defects, optimise performance, and enhance user experience. The Opportunity When you join PwC Acceleration Centers (ACs), you step into a pivotal role focused on actively supporting various Acceleration Center services, from Advisory to Assurance, Tax and Business Services. In our innovative hubs, you’ll engage in challenging projects and provide distinctive services to support client engagements through enhanced quality and innovation. You’ll also participate in dynamic and digitally enabled training that is designed to grow your technical and professional skills. As part of the AI Engineering team you will design, develop, and scale AI-driven web applications and platforms. As a Senior Associate you will analyze complex problems, mentor others, and maintain rigorous standards while building meaningful client connections and navigating increasingly complex situations. This role is well-suited for engineers eager to blend their entire stack development skills with the emerging world of AI and machine learning in a fast-paced, cross-functional environment. Responsibilities Design and implement AI-driven web applications and platforms Analyze complex challenges and develop impactful solutions Mentor junior team members and foster their professional growth Maintain exemplary standards of quality in every deliverable Build and nurture meaningful relationships with clients Navigate intricate situations and adapt to evolving requirements Collaborate in a fast-paced, cross-functional team environment Leverage broad stack development skills in AI and machine learning projects What You Must Have Bachelor's Degree in Computer Science, Software Engineering, or a related field 4-9 years of experience Oral and written proficiency in English required What Sets You Apart Bachelor's Degree in Computer Science, Engineering Skilled in modern frontend frameworks like React or Angular Demonstrating hands-on experience with GenAI applications Familiarity with LLM orchestration tools Understanding of Responsible AI practices Experience with DevOps tools like Terraform and Kubernetes Knowledge of MLOps capabilities Security experience with OpenID Connect and OAuth2 Experience in AI/ML R&D or cross-functional teams Preferred Knowledge/Skills Role Overview We are looking for a skilled and proactive Full Stack Engineer to join our AI Engineering team. You will play a pivotal role in designing, developing, and scaling AI-driven web applications and platforms. This role is ideal for engineers who are passionate about blending full stack development skills with the emerging world of AI and machine learning, and who thrive in cross-functional, fast-paced environments. Key Responsibilities Develop and maintain scalable web applications and APIs using Python (FastAPI, Flask, Django) and modern frontend frameworks (React.js, Angular.js). Build intuitive, responsive UIs using JavaScript/TypeScript, CSS3, Bootstrap, and Material UI for AI-powered products. Collaborate closely with product teams to deliver GenAI/RAG-based solutions. Design backend services for: Data pipelines (Azure Data Factory, Data Lake, Delta Lake) Model inference Embedding and metadata storage (SQL, NoSQL, Vector DBs) Optimize application performance for AI inference and data-intensive workloads. Integrate third-party APIs, model-hosting platforms (OpenAI, Azure ML, AWS SageMaker), and vector databases. Implement robust CI/CD pipelines using Azure DevOps, GitHub Actions, or Jenkins. Participate in architectural reviews and contribute to design best practices across the engineering organization. Required Skills & Experience 4–9 years of professional full-stack engineering experience. Bachelor's degree in Computer Science, Engineering, or related technical field (BE/BTech/MCA) Strong Python development skills, particularly with FastAPI, Flask, or Django. Experience with data processing using Pandas. Proficient in JavaScript/TypeScript with at least one modern frontend framework (React, Angular). Solid understanding of RESTful and GraphQL API design. Experience with at least one cloud platform: Azure: Functions, App Service, AI Search, Service Bus, AI Foundry AWS: Lambda, S3, SageMaker, EC2 Hands-on experience building GenAI applications using RAG and agent frameworks. Database proficiency with: Relational databases: PostgreSQL, SQL Server NoSQL databases: MongoDB, DynamoDB Vector stores for embedding retrieval Familiarity with LLM orchestration tools: LangChain, AutoGen, LangGraph, Crew AI, A2A, MCP Understanding of Responsible AI practices and working knowledge of LLM providers (OpenAI, Anthropic, Google PaLM, AWS Bedrock) Good To Have Skills DevOps & Infrastructure: Terraform, Kubernetes, Docker, Jenkins MLOps capabilities: model versioning, inference monitoring, automated retraining Security experience with OpenID Connect, OAuth2, JWT Deep experience with data platforms: Databricks, Microsoft Fabric Prior experience in AI/ML R&D or working within cross-functional product teams",Associate,,"Python, SQL, R, Machine Learning",
4255440925,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4248113377,"Staff Engineer, Gen AI",Qualcomm,"Hyderabad, Telangana, India",,Full-time,,"About the job Company: Qualcomm India Private Limited Job Area: Engineering Group, Engineering Group > Software Engineering General Summary: More details below: Join the exciting Generative AI team at Qualcomm focused on integrating cutting edge GenAI models on Qualcomm chipsets. The team uses Qualcomm chips’ extensive heterogeneous computing capabilities to allow inference of GenAI models on-device without a need for connection to the cloud. Our inference engine is designed to help developers run neural network models trained in a variety of frameworks on Snapdragon platforms at blazing speeds while still sipping the smallest amount of power. Utilize this power efficient hardware and Software stack to run Large Language Models (LLMs) and Large Vision Models (LVM) at near GPU speeds! Responsibilities: In this role, you will spearhead the development and commercialization of the Qualcomm AI Runtime (QAIRT) SDK on Qualcomm SoCs. As an AI inferencing expert, you'll push the limits of performance from large models. Your mastery in deploying large C/C++ software stacks using best practices will be essential. You'll stay on the cutting edge of GenAI advancements, understanding LLMs/Transformers and the nuances of edge-based GenAI deployment. Most importantly, your passion for the role of edge in AI's evolution will be your driving force. Minimum Qualifications: Bachelor’s degree in engineering, Computer Science, or related field and 10+ years of Systems Engineering or related work experience. OR Master’s degree in engineering, Computer Science, or related field and 9+ years of Systems Engineering or related work experience. Requirements: Strong understanding of Generative AI models – LLM, LVM, LMMs and building blocks (self-attention, cross attention, KV caching etc.) Floating-point, Fixed-point representations and Quantization concepts. Experience with optimizing algorithms for AI hardware accelerators (like CPU/GPU/NPU). Hands-on experience in C/C++ programming, Design Patterns and OS concepts. Excellent analytical and debugging skills. Exposure to shell scripts, python scripts, understanding of Linux/Windows systems and automation scripts/environment. Good communication skills, presentation skills and should manage his/her tasks independently. Ability to collaborate across a globally diverse team and multiple interests. Preferred Qualifications Strong understanding of SIMD processor architecture and system design. Proficiency in object-oriented software development and familiarity Familiarity with Linux and Windows environment Strong background in kernel development for SIMD architectures. Familiarity with frameworks like llama.cpp, MLX, and MLC is a plus. Good knowledge of PyTorch, TFLite, and ONNX Runtime is preferred. Experience with parallel computing systems and languages like OpenCL and CUDA is a plus Minimum Qualifications: Bachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Engineering or related work experience. OR Master's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience. OR PhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience. 2+ years of work experience with Programming Language such as C, C++, Java, Python, etc. Applicants : Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here . Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries). Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law. To all Staffing and Recruiting Agencies : Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications. If you would like more information about this role, please contact Qualcomm Careers . 3073180",,,Python,
4204047948,Data Engineer (PySpark),Virtusa,"Bangalore Urban, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job About The Role We are seeking a highly skilled Data Engineer with deep expertise in PySpark and the Cloudera Data Platform (CDP) to join our data engineering team. As a Data Engineer, you will be responsible for designing, developing, and maintaining scalable data pipelines that ensure high data quality and availability across the organization. This role requires a strong background in big data ecosystems, cloud-native tools, and advanced data processing techniques. The ideal candidate has hands-on experience with data ingestion, transformation, and optimization on the Cloudera Data Platform, along with a proven track record of implementing data engineering best practices. You will work closely with other data engineers to build solutions that drive impactful business insights. Responsibilities Data Pipeline Development: Design, develop, and maintain highly scalable and optimized ETL pipelines using PySpark on the Cloudera Data Platform, ensuring data integrity and accuracy. Data Ingestion: Implement and manage data ingestion processes from a variety of sources (e.g., relational databases, APIs, file systems) to the data lake or data warehouse on CDP. Data Transformation and Processing: Use PySpark to process, cleanse, and transform large datasets into meaningful formats that support analytical needs and business requirements. Performance Optimization: Conduct performance tuning of PySpark code and Cloudera components, optimizing resource utilization and reducing runtime of ETL processes. Data Quality and Validation: Implement data quality checks, monitoring, and validation routines to ensure data accuracy and reliability throughout the pipeline. Automation and Orchestration: Automate data workflows using tools like Apache Oozie, Airflow, or similar orchestration tools within the Cloudera ecosystem. Education and Experience Bachelors or Masters degree in Computer Science, Data Engineering, Information Systems, or a related field. 3+ years of experience as a Data Engineer, with a strong focus on PySpark and the Cloudera Data Platform. Technical Skills PySpark: Advanced proficiency in PySpark, including working with RDDs, DataFrames, and optimization techniques. Cloudera Data Platform: Strong experience with Cloudera Data Platform (CDP) components, including Cloudera Manager, Hive, Impala, HDFS, and HBase. Data Warehousing: Knowledge of data warehousing concepts, ETL best practices, and experience with SQL-based tools (e.g., Hive, Impala). Big Data Technologies: Familiarity with Hadoop, Kafka, and other distributed computing tools. Orchestration and Scheduling: Experience with Apache Oozie, Airflow, or similar orchestration frameworks. Scripting and Automation: Strong scripting skills in Linux. Desired Skills and Experience DevOps",Manager,,SQL,
4213684918,Python Machine learning Engineer,Infosys,"Bengaluru East, Karnataka, India (On-site)",On-site,Full-time,,"About the job Technical knowledge- has expertise in cloud technologies, specifically MS Azure, and services with hands on coding to – Python Programming - Expert and Experienced - 4 -5 years DevOps Working knowledge with implementation experience - 1 or 2 projects a minimum Hands-On MS Azure Cloud knowledge Understand and take requirements on Operationalization of ML Models from Data Scientist Help team with ML Pipelines from creation to execution List Azure services required for deployment, Azure Data bricks and Azure DevOps Setup Assist team to coding standards (flake8 etc) Guide team to debug on issues with pipeline failures Engage with Business / Stakeholders with status update on progress of development and issue fix Automation, Technology and Process Improvement for the deployed projects Setup Standards related to Coding, Pipelines and Documentation Adhere to KPI / SLA for Pipeline Run, Execution Research on new topics, services and enhancements in Cloud Technologies Responsible for successful delivery of MLOps solutions and services in client consulting environments; Define key business problems to be solved; formulate high level solution approaches and identify data to solve those problems, develop, analyze/draw conclusions and present to client. Assist clients with operationalization metrics to track performance of ML Models Agile trained to manage team effort and track through JIRA High Impact Communication- Assesses the target audience need, prepares and practices a logical flow, answers audience questions appropriately and sticks to timeline. Master’s degree in Computer Science Engineering, with Relevant experience in the field of MLOps / Cloud Domain experience in Capital Markets, Banking, Risk and Compliance etc. Exposure to US/ overseas markets is preferred Azure Certified – DP100, AZ/AI900 Domain / Technical / Tools Knowledge: Object oriented programming, coding standards, architecture & design patterns, Config management, Package Management, Logging, documentation Experience in Test Driven Development and experience in using Pytest frameworks, git version control, Rest APIs Azure ML best practices in environment management, run time configurations (Azure ML & Databricks clusters), alerts. Experience designing and implementing ML Systems & pipelines, MLOps practices Exposure to event driven orchestration, Online Model deployment Contribute towards establishing best practices in MLOps Systems development Proficiency with data analysis tools (e.g., SQL, R & Python) High level understanding of database concepts/reporting & Data Science concepts Hands on experience in working with client IT/Business teams in gathering business requirement and converting into requirement for development team Experience in managing client relationship and developing business cases for opportunities Azure AZ-900 Certification with Azure Architecture understanding is a plus",,,"Python, SQL, R, Data Analysis",
4252368194,Engineer-Data Science,Hitachi Energy,"Vadodara, Gujarat, India",,Full-time,,"About the job The opportunity Data Science/Big Data Mining work includes: Creating data mining architectures/models/protocols, statistical reporting, and data analysis methodologies to identify trends in large data sets. Analysis may be applied to various areas of the business (e.g., Market Economics, Supply Chain, Marketing/Advertising, Scientific Research, etc.). Researching and applying knowledge of existing and emerging data science principles, theories, and techniques to inform business decisions. At higher career levels, may conduct scientific research projects with the goal of breaking new ground in data analytics An Experienced Professional (P2) applies practical knowledge of job area typically obtained through advanced education and work experience. May require the following proficiency: Works independently with general supervision. Problems faced are difficult but typically not complex. May influence others within the job area through explanation of facts, policies and practices. How You’ll Make An Impact The success candidate will be the part of an International Design and Engineering Team heavily specialized in Power Transformers design covering US factory. Responsible for building visualizations in PBI based on various sources and datasets of power transformers factories Responsible for DAX queries / DAX functions / Power Query Editor Responsible for development of transformer dashboard in coordination with global Hitachi Energy factory based on requirement. Expertise in using advance level calculations on the data set. Able to develop tabular and multidimensional models that are compatible with warehouse standards. Able to properly understand the business requirements and develop data models accordingly by taking care of the resources. Familiar with Row Level Security (RLS) Basic knowledge and skills for secondary tools such as Microsoft Azure, SQL data warehouse, SSAS, Visual Studio, Power Apps etc. Living Hitachi Energy’s core values of safety and integrity, which means taking responsibility for your own actions while caring for your colleagues and the business. Responsible to ensure compliance with applicable external and internal regulations, procedures, and guidelines. Your Background Bachelor’s degree of Electrical or Mechanical or Data Science Engineering. 5 - 10 years’ experience working in Data Analytics from start to end process. Candidates with higher experience also to be considered. Experience of manufacturing industry is an additional advantage. Extended MS Office knowledge & skills, especially excel but also eg PowerPoint, etc. Experienced in building MS Teams Space & SharePoint pages. Specialist on building visualizations in PBI based on various sources and datasets. Strong capabilities of DAX queries / DAX functions / Power Query Editor. DA-100 certification preferred. Experience with SAP / S4 HANA -Data handling preferred, data sources in Power BI. Proficiency in both spoken & written English language is required. Hitachi Energy is a global technology leader that is advancing a sustainable energy future for all. We serve customers in the utility, industry and infrastructure sectors with innovative solutions and services across the value chain. Together with customers and partners, we pioneer technologies and enable the digital transformation required to accelerate the energy transition towards a carbon-neutral future. We employ around 45,000 people in 90 countries who each day work with purpose and use their different backgrounds to challenge the status quo. We welcome you to apply today and be part of a global team that appreciates a simple truth: Diversity + Collaboration = Great Innovation.",manager,,"SQL, Excel, Power BI, Data Analysis",
4210299650,AI ML - Consultant,Virtusa,"Gurgaon, Haryana, India (Hybrid)",Hybrid,Full-time,,"About the job Write in Python to deliver a wide variety of Machine Learning & Data Science solutions Implement models and algorithms on Databricks and H2O Building tools to accelerate feature experimentation and exploration with lineage, data privacy protection and easier model performance debugging. Collaborate with Product Owners to apply Workdays agile processes and be responsible for the initiation, delivery, and communication of projects for the stakeholder organizations Building ML-as-a-service, with the purpose of taking experiments to production quickly. Share learnings and project findings with the wider Workday Machine Learning Community Willing to work across multiple time zones. What You will Bring Proficient experience in Python coding, SQL, Spark and experience developing models and other data science work with Python 3 - 4+ years of experience implementing models or machine learning algorithms in production Experience on any of these cloud platforms (AWS, Azure, GCP) Desired Skills and Experience Data analytics, Python",,,"Python, SQL, Machine Learning",
4259096915,Frontend Developer Intern,Innovate Solutions,India (Remote),Remote,Full-time,,"About the job Job Title: Front-End Developer Trainee Location: Remote Job Type: Internship (Full-Time) Duration: 1–3 Months Stipend: ₹25,000/month Department: Web Development / UI Engineering Job Summary: We are looking for a creative and motivated Front-End Developer Trainee to join our remote development team. This internship is perfect for candidates who are passionate about building visually appealing and user-friendly web interfaces. You’ll gain real-world experience working on front-end features, responsive designs, and modern web development practices. Key Responsibilities: Develop responsive and interactive user interfaces using HTML, CSS, and JavaScript Assist in building and optimizing web pages for speed and scalability Work with front-end libraries and frameworks like React, Vue.js, or Angular (as applicable) Collaborate with design and backend teams to implement UI/UX designs Debug and troubleshoot UI/UX issues across browsers and devices Maintain clean, well-documented, and reusable code Qualifications: Bachelor’s degree (or final-year student) in Computer Science, IT, or related field Strong foundation in HTML5, CSS3, and JavaScript Familiarity with one or more JavaScript frameworks/libraries (React, Vue, or Angular preferred) Understanding of responsive design principles and cross-browser compatibility Good attention to detail and problem-solving ability Ability to work independently in a remote environment Preferred Skills (Nice to Have): Knowledge of version control systems like Git Experience with tools like Figma or Adobe XD for working with UI designs Familiarity with CSS preprocessors (SASS/LESS) and build tools (Webpack, Vite) Awareness of accessibility (a11y) and SEO best practices What We Offer: ₹25,000/month stipend Fully remote internship Hands-on experience with real front-end projects Mentorship and code reviews from experienced front-end developers Certificate of Completion Opportunity for full-time employment based on performance",,,,
4187613495,"Data Engineer, Translation Services Data Analytics (TSDA)",Amazon,"Hyderabad, Telangana, India",,Full-time,,"About the job Description Translation Services Data and Analytics seeks a passionate Data Engineer to drive innovations in translation analytics space to create the data pipelines handling large volume data and help our customer's to analyze and understand Amazon Translation coverage across the languages.We support Translation Services in making data-driven decisions by providing easy access to data and self-serve analytics. We work closely with internal stakeholders and cross-functional teams to solve business problems through data by building data pipelines, develop automated reporting and dive deep into data to identify actionable root cause. Key job responsibilities Work closely with data scientists and business intelligence engineers to create robust data architectures and pipelines. Develop and manage scalable, automated, and fault-tolerant data solutions. Simplify and enhance the accessibility, clarity, and usability of large or complex datasets through the development of advanced ETL, BI dashboards and applications. Take ownership of the design, creation, and upkeep of metrics, reports, analyses, and dashboards to inform key business decisions. Navigate ambiguous environments by evaluating various options using both data-driven insights and business expertise. A day in the life Data Engineers focus on managing customer requests, maintaining operational excellence, and enhancing core data analytics infrastructure. You will be collaborating closely with both technical and non-technical teams to design and execute roadmaps for essential Translation Services metrics. If you are not sure that every qualification on the list above describes you exactly, we'd still love to hear from you! At Amazon, we value people with unique backgrounds, experiences, and skillsets. If you’re passionate about this role and want to make an impact on a global scale, please apply! Basic Qualifications 3+ years of data engineering experience Experience with data modeling, warehousing and building ETL pipelines Experience with SQL Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS Preferred Qualifications Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases) Bachelor's degree Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI HYD 13 SEZ Job ID: A2929407",,,"Python, SQL",
4259209028,ERP Senior Specialist Developer - SAP PI,NTT DATA North America,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Req ID: 331091 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a ERP Senior Specialist Developer - SAP PI to join our team in HYDERABAD, Telangana (IN-TG), India (IN). ERP - Sr.Developer - SAP PI Key Responsibilities of an SAP PI/PO Developer: Designing and Developing Integration Interfaces: This involves creating objects in the Enterprise Service Repository (ESR) like data types, message types, service interfaces, and mappings. Configuring Communication Channels: Setting up and configuring communication channels in the Integration Directory (ID) to enable message exchange between different systems. Developing Message Mappings: Creating mappings to transform data formats between different systems. Monitoring and Troubleshooting: Monitoring the PI/PO system for errors and troubleshooting any issues related to message processing. Collaboration with Stakeholders: Working with business users, functional consultants, and other development teams to gather requirements and ensure successful integration. Staying Updated with Technologies: Keeping up with the latest features and functionalities of SAP PI/PO and related technologies. Skills and Qualifications: Experience with SAP PI/PO: Proven experience in designing, developing, and implementing integration solutions using SAP PI/PO. Strong Understanding of Integration Concepts: Knowledge of middleware concepts, message protocols (like SOAP, RFC, JDBC, JMS, etc.), and integration patterns. ABAP and Java Development Skills: Familiarity with ABAP and Java programming languages, especially in the context of SAP PI/PO. Experience with ESR and ID: Proficiency in using the Enterprise Service Repository (ESR) and Integration Directory (ID) for development and configuration. Problem-Solving and Analytical Skills: Ability to analyze integration issues and develop effective solutions. Communication and Collaboration Skills: Ability to communicate effectively with technical and non-technical stakeholders. Strong Expertise in SAP PI Interface Developments Translate high level functional requirements into technical requirements in a clear manner that is comprehensible for other developers and other team members Strong Knowledge and experience with Adobe Forms & Workflows. Facilitate and participate in User Demos of Development Units Provide technical assistance to the process teams in debugging functional issues as needed Work closely with SAP functional teams to analyze and test the effect of system changes as needed Facilitate and participate in User Demos of Development Units. SAP PI Must have SAP PI/PO Certification (preferred) with at least 6+ yrs. of experience in SAP as SAP Middleware Technical Consultant with expertise in XI/PI/PO technology. Multiple project experience in SAP PI/PO Development/Integration projects, Upgrades and Production support. Experience working on S4HANA Migration/ Implementation/ Upgrade. Managed Onsite and Offshore SAP PI/PO and other Middleware (such as Dell Boomi, MuleSoft, webMethods, etc.) teams SME in ABAP/EDI/ALE/PI/Net Weaver/Workflow. J2EE Administration experience Expertise in Integrations using Add-on, EDI and PI which involves order to cash and procure to pay. Prior integration experience architecting solutions for SAP with 3rd party applications such as MES, OpenText, IBP, SuccessFactors, Ariba Network Hands-on experience in SAP Application Interface Framework (AIF) Must have Developed technical, mapping specs Interfaces and EDI messages. Good understanding of various Business processes and SAP processes in OTC, P2P. Worked extensively in Cross Application using EDI/IDOC/BAPI/RFC technology. Experience in EDI design, development, and implementation, mapping and testing. Worked on projects Integrating SAP with PI/PO and other middleware’s like Gentran or SeeBurger. Worked on FILE, IDOC, RFC, XI, SOAP, JDBC, AS2, SFTP, RNIF and B2B Adapters. Having very good project experience in SAP Net Weaver Integration - (Design, Configuration and Deployment) with Java, XSLT mapping knowledge. Knowledge of Cloud app integration using SAP Cloud Platform Integration or Open Connections services would be added advantage. Worked extensively with graphical mapping, user-defined functions, Proxies, BPM, and Alerts. Experience in Runtime Workbench for Message Monitoring, Component Monitoring. Extensive experience in IDOCs, ALE, RFC, BAPI, ALV, LSMW, Data Dictionary, Reports (Classical and Interactive Report), BDC (Batch-Input and Call Transaction Methods), SAPScripts, Adobe Forms, Enhancements. Expertise in developing ABAP Proxies,and Web services integration. Involved in Data Extraction and Conversion between SAP system and legacy system. Excellent Inter-personal Skills, verbal and written communication Possesses a solid understanding of various Web/form techniques using the latest technologies available. Must have strong analytical skills and teamwork 8+ years exp in SAP PI / PO (Process Integration and Process Orchestration) About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",Director,,R,
4257551431,Java Software Engineer,Three Across,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Job Title: Ref Data Software Engineer Location: Pune Employment Type: Full-Time Experience: 5-8 Years Role Overview We are seeking a skilled and driven Ref Data Software Engineer to design, develop, and enhance enterprise-grade software solutions. This role is ideal for a proactive developer who thrives in cross-functional environments, embraces innovation, and can contribute to the evolution of data-driven platforms using modern technologies and secure engineering practices. Key Responsibilities Design and deliver high-quality software using Java, Spring Boot, and cloud-native technologies. Develop scalable, maintainable, and performance-optimized solutions aligned with business goals. Collaborate with product managers, designers, and engineers to translate requirements into technical solutions. Participate in code reviews and promote a culture of code quality, reusability, and knowledge sharing. Follow secure coding standards to safeguard data and mitigate vulnerabilities. Apply unit testing and CI/CD practices to ensure solution reliability and quality. Stay updated on emerging technologies and actively contribute to internal engineering communities. Take ownership of delivery outcomes, risk mitigation, and continuous improvement within your domain. Technical Requirements Essential Qualifications & Experience Proficient in Java 8/11 or higher Strong hands-on experience with Spring Boot, Spring MVC, and JPA Expertise in RESTful API development and Web Services Experience with message queueing systems such as Kafka or Solace PubSub+ Solid experience with AWS services (e.g., Lambda, S3, CloudWatch) Working knowledge of Unix/Linux systems and shell scripting Experience with NoSQL and relational databases like Oracle , SQL Server , or PostgreSQL Hands-on experience with Goldensource EDM platform Familiarity with multithreading, concurrency, and performance tuning Proficiency with Git, Maven/Gradle, and CI/CD tools Desirable Skills Experience with Elasticsearch Familiarity with aPaaS/OpenShift and containerized deployments Exposure to Infrastructure-as-Code (CloudFormation/Terraform) Understanding of MVC design patterns and secure software lifecycle best practices Behavioral Expectations & Leadership Deliver work with high standards of precision, responsibility, and integrity Collaborate effectively with cross-functional teams and business stakeholders Demonstrate leadership by mentoring peers or leading small teams (if applicable) Embrace and foster a culture of continuous improvement, innovation, and resilience Take ownership for embedding compliance, risk management, and quality assurance practices in development processes Why Join Us? You’ll be part of a collaborative engineering team shaping the digital transformation of our data and technology platforms. This is a unique opportunity to work on high-impact projects that directly support our customers and colleagues.",manager,,SQL,
4224377162,Principal Machine Learning Engineer,PubMatic,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,,"About the job About The Role We are hiring a results-oriented Principal Machine Learning Engineer to join our growing team in Pune on a hybrid schedule. Reporting to the Director of Machine Learning, you will partner with Product and Engineering teams to both solve problems and identify new opportunities for the business. The ideal candidate will apply quantitative analysis, modeling, and data mining to help drive informed product decisions for PubMatic + get things done. What You'll Do Perform deep dive analysis to understand and optimize the key product KPIs. Apply statistics, modeling, and machine learning to improve the efficiency of systems and relevance algorithms across our business application products. Conduct data analysis to make product recommendations and design A/B experiments. Partner with Product and Engineering teams to solve problems and identify trends and opportunities. Collaborate with cross-functional stakeholders to understand their business needs, formulate and complete end-to-end analysis that includes data gathering, analysis, ongoing scaled deliverables, and presentations. We'd Love for You to Have Seven plus years of hands-on experience designing Machine Learning models to solve business problems with statistical packages, such as R, MATLAB, Python (NumPy, Scikit-learn + Pandas) or MLlib. Proven ability to inspire, mentor, and develop team members to deliver value consistently. Experience with articulating product questions and using statistics to arrive at an answer. Experience with scripting in SQL - extracting large data sets and designing ETL flows. Work experience in an inter-disciplinary/cross-functional field. Deep interest and aptitude in data, metrics, analysis, and trends, and applied knowledge of measurement, statistics, and program evaluation. Distinctive problem-solving skills and impeccable business judgment. Capable of translating analysis results into business recommendations. Should have a bachelor’s degree in engineering (CS / IT) or equivalent degree from a well-known institute/university. Additional Information Return to Office : PubMatic employees throughout the globe have returned to our offices via a hybrid work schedule (3 days “in office” and 2 days “working remotely”) that is intended to maximize collaboration, innovation, and productivity among teams and across functions. Benefits: Our benefits package includes the best of what leading organizations provide, such as paternity/maternity leave, healthcare insurance, broadband reimbursement. As well, when we’re back in the office, we all benefit from a kitchen loaded with healthy snacks and drinks and catered lunches and much more! Diversity and Inclusion : PubMatic is proud to be an equal opportunity employer; we don’t just value diversity, we promote and celebrate it. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status About PubMatic PubMatic is one of the world’s leading scaled digital advertising platforms, offering more transparent advertising solutions to publishers, media buyers, commerce companies and data owners, allowing them to harness the power and potential of the open internet to drive better business outcomes. Founded in 2006 with the vision that data-driven decisioning would be the future of digital advertising, we enable content creators to run a more profitable advertising business, which in turn allows them to invest back into the multi-screen and multi-format content that consumers demand.",Director,,"Python, SQL, R, Machine Learning, Data Analysis",
4251687798,AI Engineer,Uplers,"Patna, Bihar, India (Remote)",Remote,Full-time,,"About the job Experience : 2.00 + years Salary : INR 2000000-2500000 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full Time Permanent position(Payroll and Compliance to be managed by: I-Stem) (*Note: This is a requirement for one of Uplers' client - I-Stem) What do you need for this opportunity? Must have skills required: Voice AI, Voice AI products, AI models, Large Language Models (LLMs), Python, Model deployment, Building AI Models, ASR models, Text-to-Speech (TTS) I-Stem is Looking for: You will: Develop, test, and refine end-to-end voice agent models (ASR, NLU, dialog management, TTS) Stress-test agents in noisy, real-world scenarios and iterate for improved robustness and low latency Research and prototype cutting-edge techniques (e.g. robust speech recognition, adaptive language understanding) Partner with backend and frontend engineers to seamlessly integrate AI components into live voice products Monitor agent performance in production, analyze failure cases, and drive continuous improvement You are: An AI/Software Engineer with hands-on experience in speech-centric ML (ASR, NLU or TTS) Skilled in building and tuning transformer-based speech models and handling real-time audio pipelines Obsessed with reliability: you design experiments to push agents to their limits and root-cause every error A clear thinker who deconstructs complex voice interactions from first principles Passionate about making voice technology inclusive and accessible for diverse users Comfortable moving fast in a small team, yet dogged about code quality, testing and reproducibility Interview Process : Intro call Technical Round (Coding + problem statement + design the live solution on call) Offer discussion How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Voice AI, Voice AI products, AI models, Large Language Models (LLMs), Python, Model deployment, Building AI Models, ASR models, Text-to-Speech (TTS)",,,Python,
4256415975,Systems Engr I,Honeywell,Pune/Pimpri-Chinchwad Area (Hybrid),Hybrid,Full-time,,"About the job JD for Systems Engineer I Reporting to Systems Engineering Supervisor Travel: 30-70% (as per project requirement) Roles and Responsibilities: Controls Systems Hardware and Application software hands-on experience - DCS. ESD, F&G systems (ICSS projects) Deliver technical solution to customers within agreed schedule and budget Work closely with Project Lead, Engineering Supervisor, other Leads and Project Manager. Understand the customer's project Specifications, RFQ, Architecture, etc., Hands-on working in detail engineering, System Architecture, BOM To collaborate with team and carry out Control System Hardware and Software Detail Engineering (including HMI), Application Development, Testing, Integration of Hardware, FAT with customer at factory as per project duration, Site Commissioning, system Cut-over's, Loop Checking. Use effectively Typical / Templates for Complex Loops and project specific standards To read, understand P&IDs, Control Narratives, Logic diagrams, etc. Complete assigned work scope against the project plan, with 100% quality delivery (Right the First time) Site visit for Control & safety Systems Installation supervision, SAT, pre-commissioning, commissioning and hand over the project to customer / LSS team. Ensure compliance with quality / safety procedures during Engineering & Site execution phase. Identify possible improvement opportunities, share and contribute for its implementation Practice common methods, techniques, tools and products and provide feedback for future improvement Usage of engineering tools for optimization of Engineering man hours Technical Skills: Should have minimum 3+ years of hands-on experience in: DCS / Safety PLC / PLC (preferably on Honeywell Systems) - Being part of Detail engineering, Testing and Commissioning. Third party systems interface - Modbus TCP, Modbus RTU, OPC (UA, DA, HDA, A&E), ProfiNet, Profibus and similar. HART, Foundation Fieldbus, Profibus Advanced L2/L3 nodes - Alarm, History, Asset, Network Management Networking Knowledge: TCP/IP protocols, Switch/Router and domain controller configurations. Virtualization of control nodes - added advantage Domain knowledge - Refinery, Petrochemicals, Pipeline, Power, Renewables Behavioral Skills: Plan, Execute & deliver as per commitments Team player with Good command on Oral + Written communication Strong ability to work as team player and acquire/share technical skills and competencies. Customer interaction capabilities during Project life cycle. As a Systems Engr I here at Honeywell, you will design, implement, and manage complex systems that drive innovation and efficiency. Work on cutting-edge projects and ensure alignment with quality standards. You will report directly to our Sr Systems Eng Supervisor and you'll work out of our Pune, Maharashtra location on a Hybrid work schedule. Education Bachelor's degree (BE/B Tech - Instrumentation, Electronics) WE VALUE Very good knowledge of Control & Safety systems Individual who quickly analyze, incorporate, and apply new information and concepts. Diverse and global teaming and collaboration Ability to communicate with individuals within the project team. Individuals who are self-motivated and able to work independently, who consistently complete the assignments within schedule & 100% Quality. Ability to adapt to change with ease About Us Honeywell helps organizations solve the world's most complex challenges in automation, the future of aviation and energy transition. As a trusted partner, we provide actionable solutions and innovation through our Aerospace Technologies, Building Automation, Energy and Sustainability Solutions, and Industrial Automation business segments - powered by our Honeywell Forge software - that help make the world smarter, safer and more sustainable.",Manager,,,
4255437924,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4217746783,Machine Learning Engineer - C12 - BANGALORE,Citi,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job The Applications Development Senior Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities. Responsibilities: Conduct tasks related to feasibility studies, time and cost estimates, IT planning, risk technology, applications development, model development, and establish and implement new or revised applications systems and programs to meet specific business needs or user areas Monitor and control all phases of development process and analysis, design, construction, testing, and implementation as well as provide user and operational support on applications to business users Utilize in-depth specialty knowledge of applications development to analyze complex problems/issues, provide evaluation of business process, system process, and industry standards, and make evaluative judgement Recommend and develop security measures in post implementation analysis of business usage to ensure successful system design and functionality Consult with users/clients and other technology groups on issues, recommend advanced programming solutions, and install and assist customer exposure systems Ensure essential procedures are followed and help define operating standards and processes Serve as advisor or coach to new or lower level analysts Has the ability to operate with a limited level of direct supervision. Can exercise independence of judgement and autonomy. Acts as SME to senior stakeholders and /or other team members. Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: 5-8 years of relevant experience Experience in systems analysis and programming of software applications Experience in managing and implementing successful projects Working knowledge of consulting/project management techniques/methods Ability to work under pressure and manage deadlines or unexpected changes in expectations or requirements Education: Bachelor’s degree/University degree or equivalent experience This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. ------------------------------------------------------ Job Family Group: Technology ------------------------------------------------------ Job Family: Applications Development ------------------------------------------------------ Time Type: Full time ------------------------------------------------------ Most Relevant Skills Please see the requirements listed above. ------------------------------------------------------ Other Relevant Skills For complementary skills, please see above and/or contact the recruiter. ------------------------------------------------------ Citi is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi . View Citi’s EEO Policy Statement and the Know Your Rights poster.",,,,
4222838518,"Engineer 4, Machine Learning",Comcast,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Comcast brings together the best in media and technology. We drive innovation to create the world's best entertainment and online experiences. As a Fortune 50 leader, we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines. We are at the forefront of change and move at an amazing pace, thanks to our remarkable people, who bring cutting-edge products and services to life for millions of customers every day. If you share in our passion for teamwork, our vision to revolutionize industries and our goal to lead the future in media and technology, we want you to fast-forward your career at Comcast. Job Summary A senior-level data science role responsible for designing, developing, and implementing advanced time series forecasting models to predict future trends based on historical data. Job Description Core Responsibilities Lead the design and development of complex time series forecasting models using various techniques like ARIMA, Exponential Smoothing, Seasonal Decomposition, Prophet, LSTM networks, and other cutting-edge algorithms based on business needs. Thoroughly analyze large volumes of time series data to understand patterns, trends, seasonality, and potential anomalies. Fine-tune LLM models and work on time series models. Prototype and develop solutions for ML/LLM operations and Applied AI. Lead a team of data scientists and engineers focused on time series forecasting projects. Provide technical guidance, mentorship, and knowledge transfer to team members on time series analysis techniques and best practices. Employees At All Levels Are Expected To Understand our Operating Principles; make them the guidelines for how you do your job. Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services. Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences. Win as a team - make big things happen by working together and being open to new ideas. Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers. Drive results and growth. Respect and promote inclusion & diversity. Do what's right for each other, our customers, investors and our communities. Disclaimer This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications. Comcast is proud to be an equal opportunity workplace. We will consider all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, genetic information, or any other basis protected by applicable law. Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits to eligible employees. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details. Education Bachelor's Degree While possessing the stated degree is preferred, Comcast also may consider applicants who hold some combination of coursework and experience, or who have extensive related professional experience. Relevant Work Experience 7-10 Years",,,,
4256414465,Machine Learning Trainee,Lead India,India (Remote),Remote,Full-time,,"About the job Job Title: Back End Developer Trainee Location: Remote Job Type: Internship (Full-Time) Duration: 1–3 Months Stipend: ₹25,000/month Department: Software Development / Engineering Job Summary: We are looking for a highly motivated and technically driven Back End Developer Trainee to join our remote team. This internship is ideal for individuals with a strong foundation in server-side development who are eager to gain hands-on experience working on real-world applications, APIs, and databases. Key Responsibilities: Assist in building and maintaining server-side logic, APIs, and databases Write clean, scalable, and efficient code using languages such as Python, Node.js, or Java Help integrate front-end elements with server-side logic Work with databases (e.g., MySQL, PostgreSQL, MongoDB) to store and manage data Participate in testing, debugging, and performance tuning of backend systems Document code and backend processes for clarity and maintainability Qualifications: Bachelor’s degree (or final year student) in Computer Science, IT, or a related field Solid understanding of one or more backend languages (Python, Node.js, Java, etc.) Basic knowledge of RESTful API design and development Familiarity with relational and/or NoSQL databases Good problem-solving and analytical skills Ability to work independently in a remote environment Preferred Skills (Nice to Have): Experience with version control systems like Git Familiarity with frameworks (e.g., Express.js, Django, Spring Boot) Understanding of authentication, authorization, and secure coding practices Exposure to Docker, cloud platforms, or CI/CD pipelines is a plus What We Offer: Monthly stipend of ₹25,000 Remote work opportunity Mentorship and training from experienced backend engineers Involvement in real-world projects and live systems Certificate of Completion Potential for a full-time opportunity based on performance",,,Python,
4213175413,Lead Machine Learning Engineer,DIAGEO India,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Job Description About Diageo: Diageo is the world’s leading premium drinks company with Outstanding collection of brands, such as Johnnie Walker, Smirnoff, Baileys, Captain Morgan, Tanqueray and Guinness. With over 200 brands in 180 countries and a global network of daring individuals, our teams blend a diverse range of experience, knowledge and skills. We connect customers and consumers to our iconic products and build innovative experiences that bring people together to celebrate life. Who we are: The Digital & Technology vision is to own the way in the transformation of Diageo business capabilities, demonstrating data & digital technology, to build a driven edge in the marketplace. About The Function Our Digital and Technology (D&T) team are innovators, delivering ground-breaking solutions that will help craft the future of our iconic brands. Technology touches every part of our business, from the sourcing of sustainable ingredients to marketing and development of our online platforms. We utilise data insights to build competitive advantage, supporting our people to deliver value faster. Our D&T team includes some of the most dedicated digital professionals in the industry. Every day, we come together to push boundaries and innovate, shaping the digital solutions of tomorrow. Whatever your passion, we’ll help you become the best you can be, creating career-defining work and delivering breakthrough thinking. 6 to 8 years of hands-on experience working on ML engineering Experience in end-to-end model development life cycle spanning (but not limited to) data sampling, model training, deployment, and performance evaluation Expertise in Python with the ability to write performant production-quality code Familiarity with SQL, knowledge of spark and cloud data environments (Azure cloud services) Experience of using Azure DevOps, ADF, MLFlow, Feature Stores etc. Knowledge of building and deploying CI/CD pipelines Validated understanding of machine learning algorithms and techniques Experience working on large scale machine learning projects, handling big data, and distributed computing frameworks like Hadoop or Spark. Proficient in data manipulation, data preprocessing, and feature engineering. - Strong problem-solving and analytical skills. Experience of working in an Agile framework Worker Type Regular Primary Location: Bangalore Karle Town SEZ Additional Locations : Job Posting Start Date 2024-10-22",,,"Python, SQL, Machine Learning",
4209657588,Staff Machine Learning Engineer,Zscaler,"Bengaluru East, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job About Zscaler Serving thousands of enterprise customers around the world including 45% of Fortune 500 companies, Zscaler (NASDAQ: ZS) was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. As the operator of the world’s largest security cloud, Zscaler accelerates digital transformation so enterprises can be more agile, efficient, resilient, and secure. The pioneering, AI-powered Zscaler Zero Trust Exchange™ platform, which is found in our SASE and SSE offerings, protects thousands of enterprise customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. Named a Best Workplace in Technology by Fortune and others, Zscaler fosters an inclusive and supportive culture that is home to some of the brightest minds in the industry. If you thrive in an environment that is fast-paced and collaborative, and you are passionate about building and innovating for the greater good, come make your next move with Zscaler. Our Engineering team built the world's largest cloud security platform from the ground up, and we keep building. With more than 100 patents and big plans for enhancing services and increasing our global footprint, the team has made us and our multitenant architecture today's cloud security leader, with more than 15 million users in 185 countries. Bring your vision and passion to our team of cloud architects, software engineers, security experts, and more who are enabling organizations worldwide to harness speed and agility with a cloud-first strategy. Responsibilities We're looking for an experienced Staff Software Engineer to join our Unified API platform team. Reporting to the Director, you'll be responsible for: Leading identification and resolution of performance issues by developing advanced AI/ML models that pinpoint root causes of poor experience and detect performance bottlenecks for users Developing, maintaining, and refining predictive models to forecast user behavior, system performance, and potential friction points in the digital experience Implementing advanced AI/ML algorithms to detect and forecast anomalies in user experience across multiple dimensions Overseeing the entire lifecycle of ML projects, including analysis, training, testing, building, and deploying ML models into production environments Designing and creating compelling visualizations to effectively communicate findings and insights to both technical and non-technical stakeholders What We're Looking For (Minimum Qualifications) A Bachelors or Master’s(preferable) degree in Computer Science, Data Science, Statistics, or a related field with 4+ years of professional experience in data science or a related role Proficiency with data science tools and platforms such as Python, R, TensorFlow, SQL, and related libraries and frameworks Strong experience with networking and end-point observability systems Expertise in multi-dimensional anomaly detection algorithms, with a specific focus on time series data sets Strong experience in building and deploying ML models in production environments, including model orchestration using tools like Kubernetes and Airflow What Will Make You Stand Out (Preferred Qualifications) Published research or contributions to digital experience/end-user observability/networking/ data science community Demonstrated experience in the monitoring space, with a deep understanding of user experience metrics, monitoring tools, and methodologies Experience with designing complex systems and scaling ML models on large scale distributed systems At Zscaler, we are committed to building a team that reflects the communities we serve and the customers we work with. We foster an inclusive environment that values all backgrounds and perspectives, emphasizing collaboration and belonging. Join us in our mission to make doing business seamless and secure. Benefits Our Benefits program is one of the most important ways we support our employees. Zscaler proudly offers comprehensive and inclusive benefits to meet the diverse needs of our employees and their families throughout their life stages, including: Various health plans Time off plans for vacation and sick time Parental leave options Retirement options Education reimbursement In-office perks, and more! By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines. Zscaler is committed to providing equal employment opportunities to all individuals. We strive to create a workplace where employees are treated with respect and have the chance to succeed. All qualified applicants will be considered for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status, or any other characteristic protected by federal, state, or local laws. See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link. Pay Transparency Zscaler complies with all applicable federal, state, and local pay transparency rules. Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",Director,,"Python, SQL, R",
4255410207,Lead Consultant - AI Engineer,AstraZeneca,"Chennai, Tamil Nadu, India",,Full-time,,"About the job Job Description Job Title: Lead Consultant - AI Engineer Career Level - E Introduction to role Are you ready to leverage technology to impact patients and ultimately save lives? We are seeking a Senior AI Engineer to develop and deploy key AI products, generating business and scientific insights through advanced data science techniques. This role involves building models using both foundational and cutting-edge methods, processing structured and unstructured data, and collaborating closely with internal stakeholders to solve complex problems in drug development, manufacturing, and supply chain. Accountabilities As a Lead Consultant - AI Engineer, you will drive the implementation of advanced modelling algorithms (e.g., classification, regression, clustering, NLP, image analysis, graph theory, generative AI) to generate actionable business insights. You will mentor AI scientists, plan and supervise technical work, collaborate with stakeholders, and work within an agile framework and in cross-functional teams to align AI solutions with business goals. You will engage internal stakeholders and external partners for the successful delivery of AI solutions. You will continuously monitor and optimize AI models to improve accuracy and efficiency (scalable, reliable, and well-maintained). You will document processes, models, and key learnings & contribute to building internal AI capabilities. Lastly, you will ensure AI models adhere to ethical standards, privacy regulations, and fairness guidelines. Essential Skills/Experience Bachelor's in operations research, mathematics, computer science, or related quantitative field. Advanced expertise in Python and familiarity with database systems (e.g. SQL, NoSQL, Graph). Proven proficiency in at least 3 of the following domains: Generative AI, Computer Vision, MLOps, Optimization, Traditional ML. Proficiency in ML libraries sklearn, pandas, TensorFlow/PyTorch. Experience productionizing ML/ Gen AI services and working with complex datasets. Strong understanding of software development, algorithms, optimization, and scaling. Excellent communication and business analysis skills. Master’s or PhD in a relevant quantitative field. Cloud engineering experience (AWS cloud services) Snowflake Software development experience (e.g. React JS, Node JS When we put unexpected teams in the same room, we unleash bold thinking with the power to inspire life-changing medicines. In-person working gives us the platform we need to connect, work at pace and challenge perceptions. That's why we work, on average, a minimum of three days per week from the office. But that doesn't mean we're not flexible. We balance the expectation of being in the office while respecting individual flexibility. Join us in our unique and ambitious world. At AstraZeneca, we are one purpose-led global organisation. The enablers and innovators, ensuring that we can fulfil our mission to push the boundaries of science and discover and develop life-changing medicines. We take pride in working close to the cause, opening the locks to save lives, ultimately making a massive difference to the outside world. Our work has a direct impact on patients. transforming our ability to develop life-changing medicines. We empower the business to perform at its peak and lead a new way of working, combining cutting-edge science with leading digital technology platforms and data. All with a passion to impact lives through data, analytics, AI, machine learning and more. Join us at a crucial stage of our journey in becoming a digital and data-led enterprise. Make the impossible possible by building partnerships and ecosystems, creating new ways of working and driving scale and speed to deliver exponential growth. Focused and committed, and backed with the investment to succeed, we're driving cross-company change to disrupt the entire industry. Ready to make a difference? Apply now and join us in our mission to save lives! Date Posted 23-Jun-2025 Closing Date 04-Jul-2025 AstraZeneca embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements.",,,"Python, SQL, Machine Learning",
4255306950,"Mid Data Science & AIML, GenAI Lead/Engineer",NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 312514 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Mid Data Science & AIML, GenAI Lead/Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Job Title: Data Science & AIML, GenAI Lead/Engineer Key Responsibilities: Develop and implement traditional machine learning algorithms. Deploy at least one model in a production environment. Write and maintain Python code for data science and machine learning projects. Minimum Skills Required: Preferred Qualifications: Knowledge of Deep Learning (DL) techniques. Experience working with Generative AI (GenAI) and Large Language Models (LLM). Exposure to Langchain. #GenAINTT About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4250583320,"Lead Engineer,Senior - Machine Learning",Qualcomm,"Hyderabad, Telangana, India",,Full-time,,"About the job Company Qualcomm India Private Limited Job Area Engineering Group, Engineering Group > Software Engineering General Summary As a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Software Engineer, you will design, develop, create, modify, and validate embedded and cloud edge software, applications, and/or specialized utility programs that launch cutting-edge, world class products that meet and exceed customer needs. Qualcomm Software Engineers collaborate with systems, hardware, architecture, test engineers, and other teams to design system-level software solutions and obtain information on performance requirements and interfaces. Minimum Qualifications Bachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience. OR Master's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience. OR PhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience. 2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc. Job Location: Hyderabad More Details Below About the team: Join the growing team at Qualcomm focused on advancing state-of-the-art in Machine Learning. The team uses Qualcomm chips’ extensive heterogeneous computing capabilities to allow inference of trained neural networks on-device without a need for connection to the cloud. Our inference engine is designed to help developers run neural network models trained in a variety of frameworks on Snapdragon platforms at blazing speeds while still sipping the smallest amount of power. See your work directly impact billions of devices around the world. Responsibilities In this position, you will be responsible for the development and commercialization of ML solutions like Snapdragon Neural Processing Engine (SNPE) SDK on Qualcomm SoCs. You will be developing various SW features in our ML stack. You would be porting AI/ML solutions to various platforms and optimize the performance on multiple hardware accelerators (like CPU/GPU/NPU). You will have expert knowledge in deployment aspects of large software C/C++ dependency stacks using best practices. You will also have to keep up with the fast-paced development happening in the industry and academia to continuously enhance our solution from software engineering as well as machine learning standpoint. Work Experience 7-9 years of relevant work experience in software development. Live and breathe quality software development with excellent analytical and debugging skills. Strong understanding about Processor architecture, system design fundamentals. Experience with embedded systems development or equivalent. Strong development skills in C and C++. Excellent communication skills (verbal, presentation, written). Ability to collaborate across a globally diverse team and multiple interests. Preferred Qualifications Experience in embedded system development. Experience in C, C++, OOPS and Design patterns. Experience in Linux kernel or driver development is a plus. Strong OS concepts. Applicants : Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here . Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries). Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law. To all Staffing and Recruiting Agencies : Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications. If you would like more information about this role, please contact Qualcomm Careers . 3072303",,,"Python, Machine Learning",
4253253075,Data Research Engineer-AI/ML,Uplers,"Cuttack, Odisha, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - Forbes Advisor) What do you need for this opportunity? Must have skills required: TensorFlow, PyTorch, rag, LangChain Forbes Advisor is Looking for: Location - Remote (For candidate's from Chennai or Mumbai it's hybrid) Forbes Advisor is a new initiative for consumers under the Forbes Marketplace umbrella that provides journalist- and expert-written insights, news and reviews on all things personal finance, health, business, and everyday life decisions. We do this by providing consumers with the knowledge and research they need to make informed decisions they can feel confident in, so they can get back to doing the things they care about most. At Marketplace, our mission is to help readers turn their aspirations into reality. We arm people with trusted advice and guidance, so they can make informed decisions they feel confident in and get back to doing the things they care about most. We are an experienced team of industry experts dedicated to helping readers make smart decisions and choose the right products with ease. Marketplace boasts decades of experience across dozens of geographies and teams, including Content, SEO, Business Intelligence, Finance, HR, Marketing, Production, Technology and Sales. The team brings rich industry knowledge to Marketplace’s global coverage of consumer credit, debt, health, home improvement, banking, investing, credit cards, small business, education, insurance, loans, real estate and travel. The Data Extraction Team is a brand-new team who plays a crucial role in our organization by designing, implementing, and overseeing advanced web scraping frameworks. Their core function involves creating and refining tools and methodologies to efficiently gather precise and meaningful data from a diverse range of digital platforms. Additionally, this team is tasked with constructing robust data pipelines and implementing Extract, Transform, Load (ETL) processes. These processes are essential for seamlessly transferring the harvested data into our data storage systems, ensuring its ready availability for analysis and utilization. A typical day in the life of a Data Research Engineer will involve coming up with ideas regarding how the company/team can best harness the power of AI/LLM, and use it not only simplify operations within the team, but also to streamline the work of the research team in gathering/retrieving large sets of data. The role is that of a leader who sets a vision for the future of AI/LLM’s use within the team and the company. They think outside the box and are proactive in engaging with new technologies and developing new ideas for the team to move forward in the AI/LLM field. The candidate should also at least be willing to acquire some basic skills in scraping and data pipelining. Responsibilities: Develop methods to leverage the potential of LLM and AI within the team. Proactive at finding new solutions to engage the team with AI/LLM, and streamline processes in the team. Be a visionary with AI/LLM tools and predict how the use of future technologies could be harnessed early on so that when these technologies come out, the team is ahead of the game regarding how it could be used. Assist in acquiring and integrating data from various sources, including web crawling and API integration. Stay updated with emerging technologies and industry trends. Explore third-party technologies as alternatives to legacy approaches for efficient data pipelines. Contribute to cross-functional teams in understanding data requirements. Assume accountability for achieving development milestones. Prioritize tasks to ensure timely delivery, in a fast-paced environment with rapidly changing priorities. Collaborate with and assist fellow members of the Data Research Engineering Team as required. Leverage online resources effectively like StackOverflow, ChatGPT, Bard, etc., while considering their capabilities and limitations. Skills And Experience Bachelor's degree in Computer Science, Data Science, or a related field. Higher qualifications is a plus. Think proactively and creatively regarding the next AI/LLM technologies and how to use them to the team’s and company’s benefits. “Think outside the box” mentality. Experience prompting LLMs in a streamlined way, taking into account how the LLM can potentially “hallucinate” and return wrong information. Experience building agentic AI platforms with modular capabilities and autonomous task execution. (crewai, lagchain, etc.) Proficient in implementing Retrieval-Augmented Generation (RAG) pipelines for dynamic knowledge integration. (chromadb, pinecone, etc) Experience managing a team of AI/LLM experts is a plus: this includes setting up goals and objectives for the team and fine-tuning complex models. Strong proficiency in Python programming Proficiency in SQL and data querying is a plus. Familiarity with web crawling techniques and API integration is a plus but not a must. Experience in AI/ML engineering and data extraction Experience with LLMs, NLP frameworks (spaCy, NLTK, Hugging Face, etc.) Strong understanding of machine learning frameworks (TensorFlow, PyTorch) Design and build AI models using LLMs Integrate LLM solutions with existing systems via APIs Collaborate with the team to implement and optimize AI solutions Monitor and improve model performance and accuracy Familiarity with Agile development methodologies is a plus. Strong problem-solving and analytical skills with attention to detail. Creative and critical thinking. Ability to work collaboratively in a team environment. Good and effective communication skills. Experience with version control systems, such as Git, for collaborative development. Ability to thrive in a fast-paced environment with rapidly changing priorities. Comfortable with autonomy and ability to work independently. Perks: Day off on the 3rd Friday of every month (one long weekend each month) Monthly Wellness Reimbursement Program to promote health well-being Monthly Office Commutation Reimbursement Program Paid paternity and maternity leaves How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience TensorFlow, PyTorch, rag, LangChain",,,"Python, SQL, Machine Learning",
4253793026,"SDE 2, Full Stack Machine Learning Engineer",Poppulo,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction: Are you looking to make a significant impact in a thriving software company? At Poppulo, we are shaping the future of communications and workplace technology. We recognize the challenges of effectively reaching every employee, managing hybrid office spaces, and enhancing customer experiences. Our mission is to simplify these processes and create harmony for our clients. We operate at enterprise scale, with our omnichannel communications and workplace experience platform trusted by over 6,000 organizations, reaching more than 35 million employees and delivering content to over 500,000 digital signs. We believe there’s no “perfect” candidate; everyone is evolving and acquiring new skills. We encourage you to apply even if you don’t meet all the requirements, as we value diverse perspectives to foster growth The Opportunity: As a SDE 2, Full Stack Machine Learning Engineer , you will lead the development of intelligent, scalable, and user-focused applications. This role combines full-stack engineering with advanced AI/ML capabilities, including Agentic AI and LLMOps , to create innovative, production-ready solutions that transform ideas into impactful products leveraging modern AI. Key Responsibilities Build End-to-End AI-Powered Products: Design and develop full-stack applications that integrate ML models into seamless user experiences across web and mobile platforms. Develop Scalable APIs and Services: Create robust backend services and APIs to serve ML models, manage data pipelines, and support real-time inference. Craft Intuitive Frontends: Build responsive, user-friendly interfaces using modern frameworks to visualize and interact with ML outputs. Operationalize ML Solutions: Implement the full ML lifecycle—from data engineering and model development to deployment, monitoring, and MLOps on cloud platforms. Prototype Rapidly: Create high-cadence proof-of-concepts to validate ideas and align with product strategy. Optimize Performance: Continuously enhance system and model performance for speed, scalability, and cost-efficiency. LLMOps Integration: Design and manage workflows for deploying, monitoring, and updating large language models (LLMs) in production environments. Collaborate Cross-Functionally: Work closely with product managers, designers, and other engineers to ensure cohesive and impactful product delivery. Stay Ahead of the Curve: Keep up with the latest in AI/ML, full-stack technologies, LLMOps, and Agentic AI to guide architectural decisions. Technical Skills / Competencies ML & GenAI Expertise: Strong background in ML (e.g., classification, computer vision) and generative AI (LLMs, RAG, prompt engineering, vector databases). Agentic AI Systems: Experience designing and deploying autonomous AI agents capable of reasoning, planning, and interacting with complex environments. LLMOps: Proficiency in managing the lifecycle of large language models, including fine-tuning, deployment, monitoring, and continuous improvement. Frontend Development: Proficiency in HTML, CSS, JavaScript, and frameworks like React, Vue, or Angular. Backend Development: Experience with backend frameworks such as Node.js, Django, Flask, or FastAPI; strong understanding of RESTful and GraphQL APIs. Database Management: Skilled in both SQL (PostgreSQL, MySQL) and NoSQL (MongoDB, DynamoDB) databases. Cloud & DevOps: Hands-on experience with AWS, GCP, or Azure; containerization (Docker, Kubernetes); CI/CD pipelines. MLOps: Experience deploying and managing ML workflows in production environments. System Design: Ability to architect scalable, secure, and maintainable systems. Problem Solving: Strong analytical skills to break down complex challenges into practical, innovative solutions. Team Leadership: Experience mentoring and guiding engineering teams. Education & Experience Master’s or PhD in Computer Science, AI, Statistics, or a related field. 3+ years of experience building and deploying full-stack applications and ML systems in production. Proven track record of delivering complex, distributed software solutions across the full development lifecycle. Who We Are We are a values-driven organization that empowers our employees to be their authentic selves at work and make a tangible impact on our products, clients, and culture. Our dynamic environment is filled with motivated, fun, and flexible individuals who thrive on challenges and responsibilities. Join us and contribute to a company that’s on the move. We embody the Poppulo values every day, which are essential to our mission: Bring Your Best Self: We show up authentically, are self-aware, and always strive to improve. See it. Own it. Solve it.: We proactively innovate and solve for our customers and each other, setting high standards for our work and fostering a culture of learning. Together We’re Better: We value and celebrate our diversity, learn from others, and focus on building trust as a team. Recognized as a Great Place to Work from 2015 to 2021, we are a fast-growing global technology company with offices in Ireland, the US, and the UK. Poppulo is an equal opportunity employer. We are committed to protecting your privacy. For details on how we collect, use, and protect your personal information, please refer to our Job Applicant Privacy Policy.",manager,,"SQL, Machine Learning",
4255439934,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4192438822,Staff Machine Learning Engineer,Automation Anywhere,"Bengaluru, Karnataka, India",,Full-time,,"About the job About Us Automation Anywhere is a leader in AI-powered process automation that puts AI to work across organizations. The company’s Automation Success Platform is powered with specialized AI, generative AI and offers process discovery, RPA, end-to-end process orchestration, document processing, and analytics, with a security and governance-first approach. Automation Anywhere empowers organizations worldwide to unleash productivity gains, drive innovation, improve customer service and accelerate business growth. The company is guided by its vision to fuel the future of work by unleashing human potential through AI-powered automation. Learn more at www.automationanywhere.com Key Responsibilities Develop and optimize machine learning models leveraging NLP, Computer Vision, and GenAI. Architect and implement scalable ML pipelines for training, validation, deployment, and monitoring of production models. Drive the development of large-scale ML infrastructure, ensuring low-latency inference and efficient resource utilization across cloud and hybrid environments. Implement MLOps best practices, automating model training, validation, deployment, and performance monitoring. Work closely with data engineers, software engineers, and product teams to ensure seamless integration of ML solutions into production systems. Optimize ML models for performance, scalability, and efficiency, leveraging techniques like quantization, pruning, and distributed training. Enhance model reliability by implementing automated monitoring, CI/CD pipelines, and versioning strategies. Lead efforts in data acquisition and preprocessing, including annotation and refinement of datasets to improve model accuracy. Stay updated with state-of-the-art ML research, identifying opportunities to integrate new techniques and technologies into production systems. Bachelor’s or Master’s Degree in Computer Science, Data Science, or related fields. Advanced degrees are a plus. 6+ years of hands-on experience in building and deploying machine learning models, with a focus on NLP, Computer Vision, or GenAI solutions. Proven experience deploying machine learning models into production environments, ensuring high availability, scalability, and reliability. Proficiency with modern ML frameworks (e.g., TensorFlow, PyTorch). Experience in building ML pipelines and implementing MLOps for automating and scaling machine learning workflows. Strong programming skills in Python, R, SQL, and experience with big data technologies (e.g., Spark, Hadoop) for data processing and analytics. Basic proficiency in at least one cloud-based ML services (e.g., AWS SageMaker, Azure ML, Google AI Platform) for training, deploying, and scaling machine learning models. Hands-on experience with containerization (Docker), orchestration (Kubernetes), and model serving platforms (e.g., Triton Inference Server, ONNX) for production-ready ML deployments. Familiarity with end-to-end ML pipelines, including data collection, feature engineering, model training, and model evaluation. Knowledge of model optimization techniques (e.g., quantization, pruning) to improve inference performance on cloud or edge devices. Excellent problem-solving skills, with the ability to break down complex challenges in document extraction and transform them into scalable ML solutions. Strong communication skills, with the ability to articulate ML problems clearly and work autonomously. Nice To Have Experience in fine-tuning large language models (LLMs) and applying GenAI techniques. Experience with distributed training techniques to optimize large-scale model training across multiple GPUs or cloud environments. Familiarity with CI/CD pipelines for ML, automated model versioning, and monitoring tools for performance and drift in production models. All unsolicited resumes submitted to any @automationanywhere.com email address, whether submitted by an individual or by an agency, will not be eligible for an agency fee.",Manager,,"Python, SQL, R, Machine Learning",
4246446474,"Founding Engineer (Machine Learning, Data Science)",e-Hireo,"Bengaluru, Karnataka, India (Remote)",Remote,Full-time,,"About the job JOB DESCRIPTION Experience : 7 - 12 Yrs Location : Bengaluru Designation : Founding Engineer (Machine Learning, Data Science) The Role: We’re looking for a talented Founding Engineer to lead the development and deployment of AI/ML models. You’ll be responsible for the full pipeline—from building and fine-tuning models to implementing scalable workflows and deploying production-grade AI solutions. As part of a small and dynamic team, your contributions will be instrumental in defining our AI/ML strategy. Additionally, you'll have the chance to mentor and shape the future of our growing data science team. Key Responsibilities: • Machine Learning Model Development: Design, build, and deploy cutting-edge ML models across supervised/unsupervised learning, deep learning, and reinforcement learning. • Agentic Workflows Implementation: Develop autonomous AI-driven workflows to enhance operational efficiency. • Data Infrastructure: Architect and manage scalable data pipelines to handle structured and unstructured data. • Model Optimization: Fine-tune pre-trained models and implement models optimized for real-world applications in pharma and materials. • Collaboration: Work closely with cross-functional teams (product, engineering) to integrate AI solutions into business workflows. • Mentorship: Help guide and mentor junior data scientists, setting technical standards for the team. Top Requirements: • Experience: 8+ years in data science, preferably within pharmaceutical or highgrowth tech sectors (e.g., fintech, healthcare, or similar). • Technical Proficiency: Expertise in Python, SQL, and machine learning frameworks (TensorFlow, PyTorch, Scikit-learn). • Data Engineering Skills: Experience with tools like Airflow, Spark, or dbt for data pipelines and workflows. • Cloud Platforms: Hands-on experience with cloud platforms (AWS, GCP, or Azure) for data storage and model deployment. • Model Fine-Tuning: Expertise in fine-tuning ML models for specific tasks and ensuring optimal performance. • Problem Solving: Strong analytical and problem-solving abilities with a focus on innovative solutions. • Big Data: Knowledge of big data technologies (Hadoop, Spark) and ETL/ELT pipelines. • Agentic Workflows: Experience designing and implementing agentic workflows that leverage AI agents for automation. • Statistical Analysis: Strong foundation in statistical methods and machine learning algorithms. Bonus Skills: • Startup Experience: Background in startup environments or high-growth companies. • MLOps: Familiarity with MLOps best practices. • Containerization & Orchestration: Experience with Docker, Kubernetes, etc. • Data Visualization: Proficiency in tools like Tableau or Power BI for presenting data insights.",Executive,,"Python, SQL, Tableau, Power BI, Machine Learning",
4257566898,JAVA DEVELOPER,Tata Consultancy Services,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Hi {fullName} There is an opportunity for JAVA MICROSERVICES IN NOIDA for which WALKIN interview is there on 12th JULY 25 between 9:30 AM TO 12:30 PM PLS SHARE below details to mamidi.p@tcs.com with subject line as JAVA MICROSERVICES12TH JULY 25 if you are interested Email id: Contact no: Total EXP: Preferred Location: CURRENT CTC: EXPECTED CTC: NOTICE PERIOD: CURRENT ORGANIZATION: HIGHEST QUALIFICATION THAT IS FULL TIME : HIGHEST QUALIFICATION UNIVERSITY: ANY GAP IN EDUCATION OR EMPLOYMENT: IF YES HOW MANY YEARS AND REASON FOR GAP: ARE U AVAILABLE FOR WALKIN INTERVIEW AT NOIDA ON 12TH JULY 25(YES/NO): We will share a mail to you by tom Night if you are shortlisted. PLS FIND JD BELOW Java Developer Java 8, Spring, Hibernate/JPA, Micro Services Java 8, Spring, Hibernate/JPA, Micro Services API Thanks & Regards Priyanka Talent Acquisition Group Tata Consultancy Services",,,,
4255306945,"Mid Data Science & AIML, GenAI Lead/Engineer",NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 312510 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Mid Data Science & AIML, GenAI Lead/Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Job Title: Data Science & AIML, GenAI Lead/Engineer Key Responsibilities: Develop and implement traditional machine learning algorithms. Deploy at least one model in a production environment. Write and maintain Python code for data science and machine learning projects. Minimum Skills Required: Preferred Qualifications: Knowledge of Deep Learning (DL) techniques. Experience working with Generative AI (GenAI) and Large Language Models (LLM). Exposure to Langchain. #GenAINTT About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4216698234,GEN AI,Virtusa,"Bangalore Urban, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Should lead key initiatives in GenAI COE on new tech trends, R and D on new product POC Work on proposals, Provide solutions architecture design solution on different business use cases Ability to work across various different GenAI Models and cloud providers Should have a strong experience in implementing projects in Digital Engineering Or Data Analytics Technically lead a team of developers and groom talent Extensive implementation experience in data analytics space or a senior developer role in one of the modern technology stack Excellent programming skills and proficiency in at least one of the major programming scripting languages used in Gen AI orchestration such as Python or PySpark or Java Ability to build API based scalable solutions and debug & troubleshoot software or design issues Hands on exposure to integrating atleast one of the popular LLMs(Open AI GPT, PaLM 2, Dolly, Claude 2, Cohere etc.) using API endpoints. Thorough understanding of prompt engineering; implementation exposure to LLM agents like LangChain & vector databases Pinecone or Chroma or FAISS Basic data engineering skills to load structured & unstructured data from source systems to target data stores. Build and maintain data pipelines and infrastructure to support Hands on exposure to using cloud(Azure/GCP/AWS) services for storage, serverless-logic, search, transcription and chat Extensive experience with data engineering and should be hands on in using Agentic AI Framework, RAG Desired Skills and Experience Python, Lang Chain",,,"Python, R",
4213472884,Revalsys Technologies - Data Engineer - Machine Learning &amp; Statistical Modeling,Revalsys Technologies,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Responsibilities Gains a thorough understanding of the requirements and ensure that work product aligns with customer requirements. Works within the established development guidelines, standards, methodologies, and naming conventions Builds processes to ingest, process and store massive amount of data. Assists with optimization the performance of bigdata ecosystems. Wrangles data in support of data science projects Performs productionization of ML and statistical models for Data Scientists & Statisticians Develops, constructs, tests, and maintains scalable data solutions for structured and unstructured data to support reporting, analytics, ML and AI Assists with research and building of proof of concepts to test out theories recommended by Senior and Lead Data Engineers Work complexity is low and help from senior team members is expected. Staff Data Engineers work requires the application of a wide variety of established processes or Bachelor of Science in a related field preferred or working towards it A total minimum of 2 years of design and development Experience, Skills, and Knowledge: Knowledge of CRISP-DM methodology relevant to Data Engineering i.e: Data preparation and Deployment. Knowledge in Big Data technologies, concepts, and their applications for data processing. Advanced knowledge of Business Intelligence, Data Warehousing. Knowledge in fundamentals of Machine Learning and Artificial Intelligence using Microsoft technologies. Performance tuning and code optimization in SQL. Data profiling and dimension modeling techniques and creation of logical and physical data models. Experience working with job scheduling tools. Experience with SQL, Python, Linux Shell Scripting or MS Power Shell, Spark, NoSQL Experience with Cloud Service Models: PaaS, IaaS, SaaS. Any Cloud Vendor out of three will be fine (Azure/GCP/AWS). Strong communication skills with the ability to explain complex topics in a simple and understandable way to non-technical audiences (ref:hirist.tech)",,,"Python, SQL, Machine Learning",
4255405315,Senior Data Analytics & AI Engineer,AstraZeneca,"Chennai, Tamil Nadu, India",,Full-time,,"About the job Job Title: Senior Data Analytics & AI Engineer GCL: D2 Accountabilities Lead the design, development, and deployment of high-performance, scalable data warehouses and data pipelines. Collaborate closely with multi-functional teams to understand business requirements and translate them into technical solutions. Oversee and optimize the use of Snowflake for data storage and analytics. Develop and maintain SQL-based ETL processes. Implement data workflows and orchestrations using Airflow. Apply DBT for data transformation and modeling tasks. Mentor and guide junior data engineers, fostering a culture of learning and innovation within the team. Conduct performance tuning and optimization for both ongoing and new data projects. Confirmed ability to handle large, complex data sets and develop data-centric solutions. Strong problem-solving skills and a keen analytical mentality. Excellent communication and leadership skills, with the ability to work effectively in a team-oriented environment. 8-12 years of experience in data engineering roles, focusing on data warehousing, data integration, and data product development. Essential Skills/Experience Snowflake SQL Airflow DBT Desirable Skills/Experience Snaplogic Python Academic Qualifications Bachelor’s or Master’s degree in Computer Science, Information Technology, or related field. When we put unexpected teams in the same room, we unleash bold thinking with the power to inspire life-changing medicines. In-person working gives us the platform we need to connect, work at pace and challenge perceptions. That's why we work, on average, a minimum of three days per week from the office. But that doesn't mean we're not flexible. We balance the expectation of being in the office while respecting individual flexibility. Join us in our unique and ambitious world. At AstraZeneca, our work directly impacts patients by transforming our ability to develop life-changing medicines. We empower our teams to perform at their peak by combining cutting-edge science with leading digital technology platforms. Here, you'll have the opportunity to innovate, take ownership, and explore new solutions in a dynamic environment. With a commitment to disrupting the industry, we provide the backing and investment needed to succeed. Join us as we drive cross-company change and shape the technologies of the future. Ready to make a difference? Apply now and be part of our journey! Date Posted 03-Jun-2025 Closing Date 02-Jul-2025 AstraZeneca embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements.",,,"Python, SQL",
4259208244,Java Backend developer || 3-6 Yrs || Chennai,Capgemini,"Chennai, Tamil Nadu, India",,Full-time,,"About the job At Capgemini Engineering, the world leader in engineering services, we bring together a global team of engineers, scientists, and architects to help the world’s most innovative companies unleash their potential. From autonomous cars to life-saving robots, our digital and software technology experts think outside the box as they provide unique R&D and engineering services across all industries. Join us for a career full of opportunities. Where you can make a difference. Where no two days are the same. Job Description Job Description: Good knowledge in Java 1.8, Reactive Technology is must: Spring 5/ Spring Boot Experience in Microservices Architecture (REST services) is mandatory Knowledge in any of the database Oracle/ No SQL/ Maria DB / My SQL Understanding of design patterns Exposure to tools - Bit bucket, GIT, Maven, Jira, Intellij, Eclise Familiarity with Agile methods and Continuous Integration including but not limited to Program and Release Backlog Management (Jira), Defect Tracking (Jira), Collaboration (Confluence, Jive, others) Code Review tools (Sonar, Findbugs) Experience in Swagger classes Experience in Authorization and Authentication modules Experience in JPA and Spring Security Experience in RabbitMQ Job Description - Grade Specific Focus on Industrial Operations Engineering. Develops competency in own area of expertise. Shares expertise and provides guidance and support to others. Interprets clients needs. Completes own role independently or with minimum supervision. Identifies problems and relevant issues in straight forward situations and generates solutions. Contributes in teamwork and interacts with customers. Capgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, generative AI, cloud and data, combined with its deep industry expertise and partner ecosystem.",,,"SQL, R",
4245526803,AI Fullstack Engineer,Uplers,"Guwahati, Assam, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - HurixDigital) What do you need for this opportunity? Must have skills required: Python, LLM, Rag (retrieval-augmented generation), AWS HurixDigital is Looking for: Job Summary We are seeking a highly skilled and innovative AI Engineer with Full Stack capabilities to join our dynamic team. The ideal candidate will bring a strong blend of expertise in artificial intelligence, modern software engineering practices, and cloud infrastructure. You will be responsible for designing, developing, and deploying intelligent applications that are scalable, resilient, and deliver real business value. Key Responsibilities Develop and deploy end-to-end AI-powered applications leveraging full-stack development best practices. Architect and integrate AI/ML models and pipelines using tools like LangChain, Hugging Face, OpenAI, and Anthropic Claude APIs. Design and implement microservices, RESTful APIs, and backend systems with scalability and maintainability in mind. Leverage cloud platforms (AWS, Azure, GCP) for hosting, automation, and scaling services. Integrate CI/CD pipelines to ensure smooth and frequent deployment cycles. Collaborate with cross-functional teams to translate business requirements into technical solutions. Apply techniques such as content chunking, vector search, embedding models, and retrievers to build advanced AI retrieval systems. Ensure robust architecture that can withstand variable load conditions, focusing on fault tolerance and high availability. Maintain documentation and adhere to best practices in software development and AI model integration. Required Qualifications Bachelor's or Master's degree in Computer Science, Engineering, or a related field. 5+ years of hands-on experience in AI engineering and full-stack development. Strong proficiency with AI/ML tools including LangChain, Hugging Face, OpenAI, and Claude APIs. Deep understanding of vector databases, retrievers, and modern NLP workflows. Proficient in one or more full-stack frameworks (e.g., Node.js, Django, React, Angular). Experience with Python Experience with cloud platforms (AWS, Azure, GCP) and infrastructure automation tools (e.g., Terraform, CloudFormation). Solid experience with CI/CD pipelines, GitOps, and container orchestration (e.g., Docker, Kubernetes). Proven ability to architect resilient systems and optimize performance under fluctuating workloads. Preferred Skills Knowledge of prompt engineering and LLM fine-tuning techniques. Familiarity with DevSecOps practices and AI compliance requirements. Exposure to multimodal models and real-time inference systems. What We Offer Opportunity to work on cutting-edge AI products and tools. Collaborative and inclusive team environment. Flexible work schedule and remote work options. Competitive salary and performance bonuses. How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Python, LLM, Rag (retrieval-augmented generation), AWS",,,Python,
4257288918,Senior Machine Learning Engineer,AB InBev APAC,Greater Nashik Area (On-site),On-site,Full-time,,"About the job Dreaming big is in our DNA. It’s who we are as a company. It’s our culture. It’s our heritage. And more than ever, it’s our future. A future where we’re always looking forward. Always serving up new ways to meet life’s moments. A future where we keep dreaming bigger. We look for people with passion, talent, and curiosity, and provide them with the teammates, resources and opportunities to unleash their full potential. The power we create together – when we combine your strengths with ours – is unstoppable. Are you ready to join a team that dreams as big as you do? AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics. Do You Dream Big? We Need You. Job Description Job Title: Senior Machine Learning Engineer Location: Bangalore Reporting to: Senior Manager Purpose of the role We are seeking a talented Machine Learning Engineer to design, develop, and deploy advanced machine learning models and MLOps pipelines on the Azure cloud platform. The ideal candidate will have expertise in Azure cloud services, Azure Data Factory (ADF), Databricks, machine learning, MLOps, and Python, along with strong stakeholder management skills to align solutions with business objectives. Key tasks & accountabilities Machine Learning Development: Design, train, and deploy machine learning models using Azure Machine Learning, Databricks, and Python-based frameworks (e.g., Scikit-learn, TensorFlow, PyTorch). MLOps Implementation: Build and maintain MLOps pipelines for model versioning, automated training, deployment, monitoring, and retraining using Azure and Databricks. Data Integration: Utilize Azure Data Factory (ADF) to orchestrate data pipelines for model training and inference, ensuring seamless data flow from Azure Data Lake or Blob Storage. Azure Cloud Expertise: Leverage Azure cloud services (e.g., Azure Machine Learning, Azure Kubernetes Service, Azure Synapse Analytics) to build scalable and secure AI solutions. Python Programming: Write robust, efficient Python code for model development, data preprocessing, and automation tasks. Stakeholder Collaboration: Partner with business stakeholders, data scientists, and product teams to gather requirements, communicate technical concepts, and deliver AI-driven solutions. Model Optimization: Optimize machine learning models for performance, scalability, and cost-efficiency in production environments. Documentation & Best Practices: Document ML workflows, ensure reproducibility, and share knowledge with team members and stakeholders. Qualifications, Experience, Skills Level Of Educational Attainment Required Master’s Degree or equivalent Technical Skills Required Azure Cloud Services: Proficiency in Azure Machine Learning, Azure Data Factory, Azure Data Lake, Blob Storage, and related services. Databricks: Hands-on experience with Databricks for machine learning workflows and data processing. Machine Learning: Strong knowledge of ML algorithms, deep learning frameworks, and model evaluation techniques. MLOps: Expertise in MLOps practices, including CI/CD for ML, model monitoring, and lifecycle management. Python: Advanced proficiency in Python for machine learning, data manipulation, and automation. And above all of this, an undying love for beer! We dream big to create future with more cheers .",Manager,,"Python, Machine Learning",
4258438515,"Sr. Data Science & AIML, GenAI Lead/Engineer",NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 312478 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Sr. Data Science & AIML, GenAI Lead/Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Job Title: Data Science & AIML, GenAI Lead/Engineer Key Responsibilities: Develop and implement traditional machine learning algorithms. Deploy at least one model in a production environment. Write and maintain Python code for data science and machine learning projects. Minimum Skills Required: Preferred Qualifications: Knowledge of Deep Learning (DL) techniques. Experience working with Generative AI (GenAI) and Large Language Models (LLM). Exposure to Langchain. #GenAINTT About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4232867170,Senior Machine Learning Engineer,Oracle,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Job Description Oracle Cloud Infrastructure (OCI) is a strategic growth area for Oracle. It is a comprehensive cloud service offering in the enterprise software industry, spanning Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). OCI is currently building a future-ready Gen2 cloud Data Science service platform. At the core of this platform, lies Cloud AI Cloud Service. What OCI AI Cloud Services are: A set of services on the public cloud, that are powered by ML and AI to meet the Enterprise modernization needs, and that work out of the box. These services and models can be easily specialized for specific customers/domains by demonstrating existing OCI services. Key Points: Enables customers to add AI capabilities to their Apps and Workflows easily via APIs or Containers, Useable without needing to build AI expertise in-house and Covers key gaps – Decision Support, NLP, for Public Clouds and Enterprise in NLU, NLP, Vision and Conversational AI. You’re Opportunity: As we innovate to provide a single collaborative ML environment for data-science professionals, we will be extremely happy to have you join us and share the very future of our Machine Learning platform - by building an AI Cloud service. We are addressing exciting challenges at the intersection of artificial intelligence and innovative cloud infrastructure. We are building cloud services in Computer vision for Image/Video and Document Analysis, Decision Support (Anomaly Detection, Time series forecasting, Fraud detection, Content moderation, Risk prevention, predictive analytics), Natural Language Processing (NLP), and, Speech that works out of the box for enterprises. Our product vision includes the ability for enterprises to be able to customize the services for their business and train them to specialize in their data by creating micro models that enhance the global AI models. What You’ll Do Develop scalable infrastructure, including microservices and a backend, that automates training, deployment, and optimization of ML model inference. Building a core of Artificial Intelligence and AI services such as Vision, Speech, Language, Decision, and others. Brainstorm and design various POCs using AI Perpetual AI Services for new or existing enterprise problems. Collaborate with fellow data scientists/SW engineers to build out other parts of the infrastructure, effectively communicating your needs, understanding theirs, and addressing external and internal shareholder product challenges. Lead research and development efforts to explore new tools, frameworks, and methodologies to improve backend development processes. Experiment with ML models in Python/C++ using machine learning libraries (Pytorch, ONNX, TensorRT, Triton, TensorFlow, Jax), etc. Leverage Cloud technology – Oracle Cloud (OCI), AWS, GCP, Azure, or similar technology. Qualifications Master’s degree or equivalent experience (preferred) in computer science, Statistics or Mathematics, artificial intelligence, machine learning, Computer vision, operations research, or related technical field. 3+ years for PhD or equivalent experience, 5+ years for Masters, or demonstrated ability designing, implementing, and deploying machine learning models in production environments. Practical experience in design, implementation, and production deployment of distributed systems using microservices architecture and APIs using common frameworks like Spring Boot (Java), etc. Practical experience working in a cloud environment: Oracle Cloud (OCI), AWS, GCP, Azure, and containerization (Docker, Kubernetes). Working knowledge of current techniques, approaches, and inference optimization strategies in machine learning models. Experience with performance tuning, scalability, and load balancing techniques. Expert in at least one high-level language such as Java/C++ (Java preferred). Expert in at least one scripting language such as Python, Javascript, and Shell . Deep understanding of data structures, and algorithms, and excellent problem-solving skills. Experience or willingness to learn and work in Agile and iterative development and DevOps processes. Strong drive to learn and master new technologies and techniques. You enjoy a fast-paced work environment. Additional Preferred Qualifications Experience with Cloud Native Frameworks tools and products is a plus Experience in Computer vision tasks like Image Classification, Object Detection, Segmentation, Text detection & recognition, Information extraction from documents, etc. Having an impressive set of GitHub projects or contributions to open-source technologies is a plus Hands-on experience with horizontally scalable data stores such as Hadoop and other NoSQL technologies like Cassandra is a plus. Our vision is to provide an immersive AI experience on Oracle Cloud. Aggressive as it might sound, our growth journey is fueled by highly energetic, technology-savvy engineers like YOU who are looking to grow with us to meet the demands of building a powerful next-generation platform. Are you ready to do something big? Career Level - IC3 About Us As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s challenges. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. We know that true innovation starts when everyone is empowered to contribute. That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States. Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.",manager,,"Python, Machine Learning",
4255439935,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4259096930,Python Developer Intern,Innovate Solutions,India (Remote),Remote,Full-time,,"About the job Job Title: Python Developer Trainee Location: Remote Job Type: Internship (Full-Time) Duration: 1–3 Months Stipend: ₹25,000/month Department: Software Development Job Summary: We are seeking a passionate and detail-oriented Python Developer Trainee to join our remote development team. This internship is ideal for individuals looking to strengthen their backend development skills by working on real-world projects involving APIs, automation, and data-driven applications using Python. Key Responsibilities: Write clean, scalable, and efficient Python code Assist in developing backend components, services, and integrations Work with databases (SQL/NoSQL) for data storage and access Debug, test, and optimize code for performance and reliability Support the development and integration of APIs and web services Collaborate with senior developers on software design and architecture Qualifications: Bachelor’s degree (or final-year student) in Computer Science, Software Engineering, or a related field Strong understanding of Python fundamentals and object-oriented programming Familiarity with Python frameworks such as Flask, Django, or FastAPI Basic understanding of RESTful APIs and database operations Good problem-solving and logical thinking skills Ability to work independently in a remote environment Preferred Skills (Nice to Have): Experience with Git and version control tools Familiarity with Docker, cloud platforms, or CI/CD pipelines Knowledge of frontend basics (HTML, CSS, JavaScript) Understanding of testing frameworks (e.g., pytest, unittest) What We Offer: ₹25,000/month stipend 100% remote work Real-world experience in Python-based development projects Mentorship from experienced developers Certificate of Completion Opportunity for full-time placement based on performance",,,"Python, SQL",
4251862900,Senior ML engineer - SAP Business AI - SAP Knowledge Graph,SAP,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job We help the world run better At SAP, we enable you to bring out your best. Our company culture is focused on collaboration and a shared passion to help the world run better. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from. What you`ll do At SAP, we amplify the strength of AI technology, fusing it with our robust industry-focused data and profound process knowledge. Our vision is to infuse every SAP application with sophisticated AI capabilities, revolutionizing the way businesses operate. Large Language Models (LLMs) are transforming Machine Learning but pose challenges in business applications due to their limited understanding of structured and unstructured business data such as business data models, business process metadata and documentation, which slows the development progress. It is SAP's mission to overcome these challenges within the realm of Business AI. Our goal is to provide Knowledge Graphs (KG) as key differentiators to address LLM challenges like hallucination and compliance and to deliver distinctive generative AI solutions to our customers. As a Senior AI Scientist, you will play a pivotal role in shaping and executing data engineering activities while driving AI-driven innovation for SAP’s Knowledge Graph initiatives. The Role Design and implement robust ETL pipelines to ingest and process data, metadata, and other artifacts into SAP’s Knowledge Graph. Contribute to the development and deployment of AI-driven solutions, focusing on LLM applications and their integration with Knowledge Graphs. Extract, preprocess, and enrich information from various Line of Business (LoB) data sources to support foundational models and AI use cases. Collaborate with domain experts across SAP’s business units to align AI and data engineering strategies with business goals. Build stable and scalable applications to operationalize AI models and ensure their seamless integration into enterprise systems. Guide junior team members and foster a collaborative team environment. Lead critical design and implementation decisions, ensuring the alignment of AI and data engineering architectures with SAP’s strategic vision. Drive thought leadership in generative AI by leveraging Knowledge Graphs and foundational models for business innovation. What You Bring 5+ years of professional experience in software engineering, with at least 2 years as a data engineer and significant exposure to AI/ML applications. Bachelor's or master's degree in computer science, Artificial Intelligence, Physics, Mathematics, or other relevant disciplines. Proficiency in Python, with experience in frameworks like Tensorflow, PyTorch and tools for building ETL pipelines (e.g., Metaflow, Airflow). Hands-on experience with cloud platforms (AWS, GCP, Azure, or BTP). Strong knowledge of relational databases, object stores, and vector databases. Experience in Knowledge Graph technologies (e.g., RDF, SPARQL) and familiarity with SAP S/4HANA backend data models (e.g., CDS Views, RAP) is a plus. Expertise in building scalable data pipelines for AI applications, particularly those involving LLMs or similar models. Strong communication, collaboration, and leadership skills, with experience working in agile and cross-cultural teams. A curiosity to experiment with and adopt emerging technologies and frameworks. Meet your team SAP Business AI organization is committed to seamlessly integrating AI into enterprise applications, empowering customers, partners, and developers to enhance business processes and deliver exceptional business value. Join our dynamic, innovative, and globally connected AI team, where opportunities for personal growth and collaboration abound. #SAPBusinessAICareers #SAPAICareers Bring out your best SAP innovations help more than four hundred thousand customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with two hundred million users and more than one hundred thousand employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, you can bring out your best. We win with inclusion SAP’s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world. SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy . Specific conditions may apply for roles in Vocational Training. EOE AA M/F/Vet/Disability Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability. Successful candidates might be required to undergo a background verification with an external vendor. Requisition ID: 411742 | Work Area: Software-Design and Development | Expected Travel: 0 - 10% | Career Status: Professional | Employment Type: Regular Full Time | Additional Locations: .",,,"Python, Machine Learning",
4246255774,Senior ML Engineer,Corpay,"Nagpur, Maharashtra, India",,Full-time,,"About the job Your role As a Senior ML Engineer, you will play a crucial role in analyzing, interpreting and building ML models to drive informed business decisions. You will be responsible for developing and implementing OCR solutions, analyzing complex datasets, and providing valuable insights to support our business objectives. Your expertise in statistical techniques, data mining, and reporting will contribute to optimizing efficiency and quality within our organization. What You'll Be Doing Roles & Responsibilities Interpret and analyse data using statistical techniques to identify trends, patterns, and insights. Develop and implement databases, data collection systems, and data analytics strategies to optimize statistical efficiency and quality. Own and lead the project and the team under you. Acquire data from primary and secondary sources to build models. Build, train and deploy models into Production systems. Clean and filter data by reviewing computer reports, printouts, and performance indicators to identify and correct code problems. Collaborate with management to prioritize business and information needs. Identify and define new process improvement opportunities based on data analysis findings. Act as primary and sole contact for the project. Develop and present ongoing reports and dashboards to stakeholders, highlighting key insights and recommendations. Ability to take ad hoc meetings to support offshore customer queries. Utilize reporting packages, databases, and programming languages (such as SQL, Python, or R) for data analysis and visualization. Stay updated with the latest trends and advancements in data analysis techniques and tools. Skills Required Bachelor's degree in computer science, Statistics, Mathematics, or a related field. A master's degree is a plus. Minimum of 5 years of proven working experience as ML Engineer or Data Science Engineer, preferably in a technology or finance-related industry. Strong technical expertise in data models, database design development, data mining, and segmentation techniques. Proficiency in reporting packages (e.g., Business Objects), databases (e.g., SQL), and programming languages (e.g., Python, R frameworks). Knowledge of statistics and experience using statistical packages for analyzing datasets (e.g., Excel, SPSS, SAS). Exceptional analytical skills with the ability to collect, organize, Analyse, and disseminate significant amounts of information with attention to detail and accuracy. Proficient in querying databases, report writing, and presenting findings effectively to both technical and non-technical stakeholders. Strong problem-solving abilities and a proactive mindset to identify opportunities for process improvements. Excellent communication and collaboration skills, with the ability to work effectively in a team-oriented environment. Experience in building OCR models is an advantage. About Corpay Corpay is a global technology organisation that is leading the future of commercial payments with a culture of innovation that drives us to constantly create new and better ways to pay. Our specialized payment solutions help businesses control, simplify, and secure payment for fuel, general payables, toll and lodging expenses. Millions of people in over 80 countries around the world use our solutions for their payments. All offers of employment made by Corpay (and its subsidiary companies) are subject to the successful completion of satisfactory pre-employment vetting by an independent supplier (Experian). This is in accordance with Corpay's Resourcing Policy and include employment referencing, identity, adverse financial, criminal and sanctions list checks. We do this to meet our legal and regulatory requirements. Corpay is dedicated to encouraging a supportive and inclusive culture among our employees. It is within our best interest to promote diversity and eliminate discrimination in the workplace. We seek to ensure that all employees and job applicants are given equal opportunities. Notice to Agency and Search Firm Representatives: Corpay will not accept unsolicited CV's from agencies and/or search firms for this job posting. Resumes submitted to any Corpay employee by a third party agency and/or search firm without a valid written & signed search agreement, will become the sole property of Corpay. No fee will be paid if a candidate is hired for this position as a result of an unsolicited agency or search firm referral. Thank you.",,,"Python, SQL, Excel, R, Data Analysis",
4109314148,Sr. ML Engineer (Python developer),Bluevine,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Internship,,"About the job About Bluevine Bluevine is transforming small business banking with innovative solutions like checking, lending, and credit—all tailored to help entrepreneurs thrive. With best-in-class technology, advanced security, and a deep understanding of the small business community, we’re empowering entrepreneurs to grow with confidence. Backed by leading investors like Lightspeed Venture Partners, Menlo Ventures, 83North, and Citi Ventures, we’ve been supporting SMBs since 2013, serving over 500,000 customers nationwide and growing a dynamic global team of 500 people. Our mission? To fuel small businesses with the financial tools they need to succeed. At Bluevine, you’ll be part of a collaborative, fast-paced team that’s reshaping the future of banking. Ready to make an impact? In this role, you will shape and own the ecosystem that productizes our core data products - you will work closely with our Data teams and influence how data is consumed and integrated throughout the organization, take an integral part on the designing of new ML solutions, find innovative solutions for real-time analytics, and build complex data pipelines. What You'll Do: Support Bluevine’s business and research Data teams by designing and developing data-centric infrastructure tools to facilitate and enhance Data Analytics and Research, both in real-time and offline. Help design and implement next-generation ML workloads, focusing on modern, efficient Big Data technologies. Use pipeline orchestration tools such as AirFlow, ML platforms such as SageMaker, and data frameworks to design and develop first-in-class solutions for the financial sector. Design and develop end-to-end data pipelines, from data collection, through data validation and transformation, to making the data available to processes and stakeholders. Work closely with Bluevine’s Data Science, Data Engineering and Data Analytics teams. Work closely with Bluevine’s other R&D teams to help incorporate industry best practices, define and enforce data governance procedures, and monitor system performance What We Look For: Bachelor or Master in Computer Science or related field 5+ years of full-time work experience (not including internships, study, personal/school projects) as a Backend engineer/ML Infra engineer in a fast-paced, data-centric environment. 5+ years of hands-on Python programming experience (not including internships, study, personal/school projects). Experience with AWS ecosystem and container technology (e.g. Docker, K8S) Exceptional communication skills, ability to collaborate smoothly with and convey complex ideas in a clear way to people of different backgrounds. Be a quick learner, adaptable and have the ability to work independently or as part of a team in a fast-paced environment Ability to quickly and independently learn new technologies, frameworks, and algorithms. Proactive, result-driven and multi-tasker; creative but committed to meeting deadlines. Very good English, written and verbal. Bonus points if you also have: Experience with AWS SageMaker Experience with databases such as PostgreSQL Redshift, Neptune Experience with monitoring tools like Grafana, Sentry, Opensearch Experience working Python ML libraries (e.g. Pandas, Numpy, Scikit Learn) Experience working with Airflow Experience in working with Jenkins based CI/CD Experience with streaming and real time analytics systems Benefits & Perks Excellent group health coverage and life insurance Stock options Hybrid work model Meal allowance Transportation assistance (terms and conditions apply) Generous paid time off plan, Holidays Company-sponsored mental health benefits Financial advisory services for both short- and long-term goals Learning and development opportunities to support career growth Community-based volunteering opportunities",,,"Python, R",
4227310965,"Engineer, Cloud ML Accelerator",Qualcomm,"Bengaluru, Karnataka, India",,Full-time,,"About the job Company Qualcomm India Private Limited Job Area Engineering Group, Engineering Group > Software Engineering General Summary Job Description As a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Software Engineer, you will design, develop, create, modify, and validate embedded and cloud edge software, applications, and/or specialized utility programs that launch cutting-edge, world class products that meet and exceed customer needs. Qualcomm Software Engineers collaborate with systems, hardware, architecture, test engineers, and other teams to design system-level software solutions and obtain information on performance requirements and interfaces. Job Summary 3+ years experience with Programming Language such as C, C++, exposure to Python, etc. 3+ years development experience with Programming Language such as C, C++, Python, etc.. 3+ years professional work experience in embedded software, driver development, OS like Linux/Android/QNX any RTOS etc. 3+ years experience with low level software/ interface and debugging. 3+ years experience with industry standard software development tools: HSW/HE debuggers, code revision systems (GIT, Gerrit, Perforce), IDEs and build tools. Strong OS fundamentals. Linux and kernel development a strong plus Experience with ARM architecture is added advantage. Experience in BSP development. Experience with low level device driver programming, boot code development Excellent communication skills (written and verbal) and team player Should be self motivated and self driven Preferred Qualifications Bachelors/Master's Degree in Engineering, Information Systems, Computer Science or related field. 3+ years of Software Engineering or related work experience. 3+ years of experience with API. 3+ year of work experience with Git, Perforce, or Source Code Management System Minimum Qualifications Bachelor's degree in Engineering, Information Systems, Computer Science, or related field. Applicants : Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here . Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries). Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law. To all Staffing and Recruiting Agencies : Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications. If you would like more information about this role, please contact Qualcomm Careers . 3075116",,3+ years experience,Python,
4211450106,Lead Machine Learning Engineer,GE Vernova,"Hyderabad, Telangana, India",,Full-time,,"About the job Job Description Summary Many employers promise the chance to make a difference – at GE Vernova, you can change the world. Bringing clean, affordable power to the developing world, decarbonizing the world’s electricity network, helping to build the grid of the future powered by renewable energy … they’re all part of our company’s strategy. If you're passionate about applying AI, and excited to tackle UN SDG-7,13 and Energy Transition challenges, as well as motivated by the prospect of shaping the future of energy industry through innovation and new business models, we encourage you to apply. Join us in our journey to redefine what's possible with AI and make a lasting impact on the world of Energy. We are seeking a dynamic, forward-thinking and results-driven Lead Machine Learning (ML) engineer, who will work on building and deployment of grid innovation application AIML models. Additionally, will develop systems to validate and verify proof-of-concepts of the AIML application in grid space. Reporting to AI leader in CTO organization, the Lead Machine Learning engineer will work in close collaboration with GA product lines, R&D teams, product management and other GA functions. This role will also be responsible to work with other functions across Grid Automation (GA) business to identify areas where the business can leverage data and artificial intelligence to drive efficiency, increase customer satisfaction, and develop POCs to solve critical problems for our customers, build state-of-the-art models and deploy them on edge or cloud based systems. Job Description ESSENTIAL RESPONSIBILITIES: The Lead ML Engineer Will Be Responsible For Demonstrate novel & transformational applications/analytics to drive innovation & differentiation. Define the framework to collect, structure and use of databases for AI, to extract value. Develop AI/ML application to build differentiated products and solutions; with ability to work on customers value-driven applications/analytics to drive innovations. Design and deploy high-quality, scalable, and secure AI/ML models and applications on edge or cloud, using native or container or microservices principles. Monitor, maintain, and optimize deployed AI/ML models, ensuring continuous improvements in model’s accuracy and performance. Develop and implement strategies for optimizing the performance of machine learning models in production. Ensure that AI/ML solutions are scalable, efficient, and integrate seamlessly with existing systems and data infrastructure. Collaborate with cross-functional teams of product management, R&D, and other functions, to understand their needs and develop innovative solutions. Qualifications/Requirements Masters/PhD Degree in computer science, Information technology (IT), or electrical engineering, specifically in the computer and electric power engineering field with hands-on experience in data science and AIML model building. 8+ years of experience of working in professional working environment and knowledge of statistical techniques, artificial intelligence (AI) and machine learning (ML), including, unsupervised learning, supervised learning, reinforcement learning, Deep learning, and large language models (LLMs). Strong expertise in algorithms, libraries (e.g., scikit-learn), machine learning frameworks (e.g. TensorFlow, PyTorch, Scikit-learn), and data processing tools. Proven experience in applying AI/ML frameworks/workflows in the production environment. Usage of MLOPs to streamline the process of taking/updating ML models to production. Able to share ideas and work well in a team environment, proactive approach to tasks displaying initiative. Flexible and adaptable; open to change and modification of tasks, working in multi-tasking environment. Desired Characteristics 6+ years of industry experience Ability to simulate using scientific programming tools or languages, such as, C++, C, or Python, R, MATLAB etc. Experience of developing and deploying ML models, such as predictive maintenance, load forecasting, etc. for the power system domain. Extensive knowledge of machine learning algorithms, deep learning, reinforcement learning, NLP, and computer vision. Understanding of data structures, data modeling and software architecture. Experience with Linux virtualized system deployment using VM, Hypervisor (EsXi, KVM, Xen etc.), Dockers and related tools. Experience with microservices architecture, containerization technologies (Docker, Kubernetes), and cloud computing platforms (AWS, Azure, Google Cloud) Understanding and usage of GraphDB, MongoDB, SQL/NoSQL, MS Access databases. Understanding/experience applying data analytics for Electrical Power System or industrial OT system. Understanding of GPU, Spark, Scala for distributed computing. Understanding related to power system protection and automation, monitoring and diagnostics. Strong communication skills and a proactive and open approach to conflict resolution. Strong organizational skills, self-motivated, and self-directed. Additional Information Relocation Assistance Provided: Yes",,,"Python, SQL, R, Machine Learning",
4207352733,AI / ML Developer (Lead),Infogain,"Gurugram, Haryana, India (On-site)",On-site,Full-time,,"About the job Roles & Responsibilities Core Skills Presales & Consulting Engage with clients to understand business needs, pain points, and analytics maturity. Develop and deliver compelling presentations, demonstrations, and proof-of-concepts tailored to client requirements. Develop solution architecture with estimation . Collaborate with sales and delivery teams to craft customized solutions leveraging data platforms and advanced analytics, AI/ML, and data platforms. Conduct pre-sales workshops and high-level discovery sessions . Provide consulting services to clients on data & analytics. Domain Expertise & Consulting: Act as a subject matter expert in Forecasting, Pricing Analytics, and Sales & Marketing Analytics. Translate business requirements into technical specifications and solution designs. Emerging Trends & Innovation: Stay up to date with the latest trends in analytics, AI/ML, Gen AI, data platforms. Identify opportunities for innovation and differentiation in analytics solutions. Functional Expertise: Deep understanding of Demand Forecasting, Pricing Analytics, and Sales & Marketing Analytics. Experience in leveraging analytics for business decisionmaking and strategy. Knowledge of industry-specific use cases, particularly in CPG, Retail, Life Sciences. Technical Expertise: Strong understanding of data platforms, data engineering, and cloud ecosystems (Azure, Databricks). Proficiency in analytics tools such as Python, R, SQL, Power BI, Tableau, or similar visualization platforms Experience with AI/ML models for forecasting, price optimization, and marketing effectiveness. Familiarity with data integration, ETL pipelines, and data governance principles. Working Knowledge in building Gen AI solutions Presales & Consulting Skills: Proven experience in a presales, solution consulting Strong presentation, storytelling, and communication skills. Ability to simplify complex analytics concepts for business stakeholders. Strong problem-solving and strategic thinking abilities. Qualifications Bachelor’s or Master’s degree in Data Science, Analytics, Computer Science, or a related field. 10-12 years of experience in analytics, with at least 3+ years in a presales or consulting role Experience 11-12 Years Skills Primary Skill: AI/ML Development Sub Skill(s): AI/ML Development Additional Skill(s): Python, ETL, AI/ML Development, Analytics Architecture, Marketing Research, PreSales Activities, databricks, SQL, TensorFlow, Pytorch, GenAI Fundamentals About The Company Infogain is a human-centered digital platform and software engineering company based out of Silicon Valley. We engineer business outcomes for Fortune 500 companies and digital natives in the technology, healthcare, insurance, travel, telecom, and retail & CPG industries using technologies such as cloud, microservices, automation, IoT, and artificial intelligence. We accelerate experience-led transformation in the delivery of digital platforms. Infogain is also a Microsoft (NASDAQ: MSFT) Gold Partner and Azure Expert Managed Services Provider (MSP). Infogain, an Apax Funds portfolio company, has offices in California, Washington, Texas, the UK, the UAE, and Singapore, with delivery centers in Seattle, Houston, Austin, Kraków, Noida, Gurgaon, Mumbai, Pune, and Bengaluru.",,,"Python, SQL, Tableau, Power BI, R",
4232871007,Senior Machine Learning Engineer,Oracle,"Trivandrum, Kerala, India (On-site)",On-site,Full-time,,"About the job Job Description Oracle Cloud Infrastructure (OCI) is a strategic growth area for Oracle. It is a comprehensive cloud service offering in the enterprise software industry, spanning Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). OCI is currently building a future-ready Gen2 cloud Data Science service platform. At the core of this platform, lies Cloud AI Cloud Service. What OCI AI Cloud Services are: A set of services on the public cloud, that are powered by ML and AI to meet the Enterprise modernization needs, and that work out of the box. These services and models can be easily specialized for specific customers/domains by demonstrating existing OCI services. Key Points: Enables customers to add AI capabilities to their Apps and Workflows easily via APIs or Containers, Useable without needing to build AI expertise in-house and Covers key gaps – Decision Support, NLP, for Public Clouds and Enterprise in NLU, NLP, Vision and Conversational AI. You’re Opportunity: As we innovate to provide a single collaborative ML environment for data-science professionals, we will be extremely happy to have you join us and share the very future of our Machine Learning platform - by building an AI Cloud service. We are addressing exciting challenges at the intersection of artificial intelligence and innovative cloud infrastructure. We are building cloud services in Computer vision for Image/Video and Document Analysis, Decision Support (Anomaly Detection, Time series forecasting, Fraud detection, Content moderation, Risk prevention, predictive analytics), Natural Language Processing (NLP), and, Speech that works out of the box for enterprises. Our product vision includes the ability for enterprises to be able to customize the services for their business and train them to specialize in their data by creating micro models that enhance the global AI models. What You’ll Do Develop scalable infrastructure, including microservices and a backend, that automates training, deployment, and optimization of ML model inference. Building a core of Artificial Intelligence and AI services such as Vision, Speech, Language, Decision, and others. Brainstorm and design various POCs using AI Perpetual AI Services for new or existing enterprise problems. Collaborate with fellow data scientists/SW engineers to build out other parts of the infrastructure, effectively communicating your needs, understanding theirs, and addressing external and internal shareholder product challenges. Lead research and development efforts to explore new tools, frameworks, and methodologies to improve backend development processes. Experiment with ML models in Python/C++ using machine learning libraries (Pytorch, ONNX, TensorRT, Triton, TensorFlow, Jax), etc. Leverage Cloud technology – Oracle Cloud (OCI), AWS, GCP, Azure, or similar technology. Qualifications Master’s degree or equivalent experience (preferred) in computer science, Statistics or Mathematics, artificial intelligence, machine learning, Computer vision, operations research, or related technical field. 3+ years for PhD or equivalent experience, 5+ years for Masters, or demonstrated ability designing, implementing, and deploying machine learning models in production environments. Practical experience in design, implementation, and production deployment of distributed systems using microservices architecture and APIs using common frameworks like Spring Boot (Java), etc. Practical experience working in a cloud environment: Oracle Cloud (OCI), AWS, GCP, Azure, and containerization (Docker, Kubernetes). Working knowledge of current techniques, approaches, and inference optimization strategies in machine learning models. Experience with performance tuning, scalability, and load balancing techniques. Expert in at least one high-level language such as Java/C++ (Java preferred). Expert in at least one scripting language such as Python, Javascript, and Shell . Deep understanding of data structures, and algorithms, and excellent problem-solving skills. Experience or willingness to learn and work in Agile and iterative development and DevOps processes. Strong drive to learn and master new technologies and techniques. You enjoy a fast-paced work environment. Additional Preferred Qualifications Experience with Cloud Native Frameworks tools and products is a plus Experience in Computer vision tasks like Image Classification, Object Detection, Segmentation, Text detection & recognition, Information extraction from documents, etc. Having an impressive set of GitHub projects or contributions to open-source technologies is a plus Hands-on experience with horizontally scalable data stores such as Hadoop and other NoSQL technologies like Cassandra is a plus. Our vision is to provide an immersive AI experience on Oracle Cloud. Aggressive as it might sound, our growth journey is fueled by highly energetic, technology-savvy engineers like YOU who are looking to grow with us to meet the demands of building a powerful next-generation platform. Are you ready to do something big? Career Level - IC3 About Us As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s challenges. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. We know that true innovation starts when everyone is empowered to contribute. That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States. Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.",manager,,"Python, Machine Learning",
4245526799,AI Fullstack Engineer,Uplers,"Noida, Uttar Pradesh, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - HurixDigital) What do you need for this opportunity? Must have skills required: Python, LLM, Rag (retrieval-augmented generation), AWS HurixDigital is Looking for: Job Summary We are seeking a highly skilled and innovative AI Engineer with Full Stack capabilities to join our dynamic team. The ideal candidate will bring a strong blend of expertise in artificial intelligence, modern software engineering practices, and cloud infrastructure. You will be responsible for designing, developing, and deploying intelligent applications that are scalable, resilient, and deliver real business value. Key Responsibilities Develop and deploy end-to-end AI-powered applications leveraging full-stack development best practices. Architect and integrate AI/ML models and pipelines using tools like LangChain, Hugging Face, OpenAI, and Anthropic Claude APIs. Design and implement microservices, RESTful APIs, and backend systems with scalability and maintainability in mind. Leverage cloud platforms (AWS, Azure, GCP) for hosting, automation, and scaling services. Integrate CI/CD pipelines to ensure smooth and frequent deployment cycles. Collaborate with cross-functional teams to translate business requirements into technical solutions. Apply techniques such as content chunking, vector search, embedding models, and retrievers to build advanced AI retrieval systems. Ensure robust architecture that can withstand variable load conditions, focusing on fault tolerance and high availability. Maintain documentation and adhere to best practices in software development and AI model integration. Required Qualifications Bachelor's or Master's degree in Computer Science, Engineering, or a related field. 5+ years of hands-on experience in AI engineering and full-stack development. Strong proficiency with AI/ML tools including LangChain, Hugging Face, OpenAI, and Claude APIs. Deep understanding of vector databases, retrievers, and modern NLP workflows. Proficient in one or more full-stack frameworks (e.g., Node.js, Django, React, Angular). Experience with Python Experience with cloud platforms (AWS, Azure, GCP) and infrastructure automation tools (e.g., Terraform, CloudFormation). Solid experience with CI/CD pipelines, GitOps, and container orchestration (e.g., Docker, Kubernetes). Proven ability to architect resilient systems and optimize performance under fluctuating workloads. Preferred Skills Knowledge of prompt engineering and LLM fine-tuning techniques. Familiarity with DevSecOps practices and AI compliance requirements. Exposure to multimodal models and real-time inference systems. What We Offer Opportunity to work on cutting-edge AI products and tools. Collaborative and inclusive team environment. Flexible work schedule and remote work options. Competitive salary and performance bonuses. How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Python, LLM, Rag (retrieval-augmented generation), AWS",,,Python,
4235521706,Machine Learning Operations Engineer III,"Lytx, Inc.","Bengaluru East, Karnataka, India (On-site)",On-site,Full-time,,"About the job Why Lytx?: As our MLOps Engineer you will join our Applied Machine Learning Team who develops machine learning and computer vision algorithms to monitor and assess the state of drivers and their environments to identify risk and improve safety for our clients. You will contribute to all aspects of the development cycle to optimize workflows, dataset generation, model performance and code efficiency to help enhance and differentiate us as the leader in the Video Safety and Telematics industry. If this sounds like you, we encourage you to apply! What You'll Do Build and maintain cloud deployment of ML models and surrounding infrastructure Contribute to infrastructure and process improvements for data collection, labeling, model development and deployment Design and implement R&D data engineering solutions for delivery of ML model value from device to cloud, including message payload design, data ingest and database architecture Help prepare and automate builds for device model deployment Assist on projects led by other team members via data processing, programming, monitoring of production applications, etc. Other duties as assigned. What You'll Need Bachelor’s degree in Computer Science or equivalent experience 4 to 6 years of experience with a Strong background in MLOps, Python, GNU/Linux CLI Versatile and adaptable engineer who can address evolving needs of team. Strong understanding of data engineering principles and architecture Knowledge of relational database modeling and integration. Experience with NoSQL is helpful. Ability to manage cloud resources and technologies within AWS, including Sagemaker, EC2 and S3 Experience with software automation tools, e.g., Airflow, Ansible, Terraform, Jenkins Experience with automated unit testing and regression testing methodologies Familiar with Linux software build toolchains and patterns. (e.g., Make, gcc) Experience with source control and tracking (git) Strong teammate who enjoys working in a collaborative, fast-paced team-focused environment Innovation Lives Here You go all in no matter what you do, and so do we. At Lytx, we’re powered by cutting-edge technology and Happy People. You want your work to make a positive impact in the world, and that’s what we do. Join our diverse team of hungry, humble and capable people united to make a difference. Together, we help save lives on our roadways. Find out how good it feels to be a part of an inclusive, collaborative team. We’re committed to delivering an environment where everyone feels valued, included and supported to do their best work and share their voices. Lytx, Inc. is proud to be an equal opportunity/affirmative action employer and maintains a drug-free workplace. We’re committed to attracting, retaining and maximizing the performance of a diverse and inclusive workforce. EOE/M/F/Disabled/Vet.",manager,,"Python, R, Machine Learning",
4236308977,AI Data Engineer- Tietoevry Tech Services,Tietoevry Tech Services,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job You may apply to Tietoevry by selecting Apply and fill your application details to the form. You may also Apply by using LinkedIn and populate details to your application from your LinkedIn profile. Job Description – Experience: 6+ years. We are looking for senior AI application development and AI engineer for our Gen AI applications to join our growing team of AI & cloud data experts. You will collaborate with our global team of data architects, data engineers on building, optimizing, and maintaining the data platform for a major client in Nordics. Primarily focus - Supporting Azure AI application development Defining a template how AI development would be done. Azure app development tooling and services (frontend and backend) Experience working on Local LLM Hosting Platforms - Ollama, RAG and Agentic frameworks such as Langchain, Lama Working experience on Vector Stores - Azure AI Search, Pgvector Containerization using Docker and Kubernetes GraphQL API and REST API GraphRAG, Knowledge Graphs Working with Cursor and Github Copilots for code generation App development architecture including the runtime and environment setup CI/CD - development and deployment to higher environments Maintainability aspects (monitoring, logging, alerting) Knowledge of the Azure AI services Secondary focus - Work on generic data platform topics which would require knowledge on one or more of the following technologies Azure devops CICD Common Azure services (storage, vm, networking, key vault, app services, log analytics, etc.) Skill Set - Experience working on Local LLM Hosting Platforms - Ollama, RAG and Agentic frameworks such as Langchain, Lama , Containerization using Docker and Kubernetes , GraphQL API and REST API, Working experience on Vector Stores - Azure AI Search, Pgvector Azure AI Fundamentals , Azure AI services , Azure DevOps , Cloud Infra , Terraform , Python , Azure Cosmos DB , Azure SQL Database , Azure API Management, Azure Data Services, GitHub, Gen AI etc At Tietoevry, we believe in the power of diversity, equity, and inclusion. We encourage applicants of all backgrounds, genders (m/f/d), and walks of life to join our team, as we believe that this fosters an inspiring workplace and fuels innovation. Our commitment to openness, trust, and diversity is at the heart of our mission to create digital futures that benefit businesses, societies, and humanity. Diversity, equity and inclusion (tietoevry.com)",,,"Python, SQL",
4256416515,Application Developer-SAP ABAP HANA,IBM,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology. As an Application Developer, you will lead IBM into the future by translating system requirements into the design and development of customized systems in an agile environment. The success of IBM is in your hands as you transform vital business needs into code and drive innovation. Your work will power IBM and its clients globally, collaborating and integrating code into enterprise systems. You will have access to the latest education, tools and technology, and a limitless career path with the world’s technology leader. Come to IBM and make a global impact! Your Role And Responsibilities Responsible to design, develop and/or re-engineer highly complex application components and integrate software packages, programs and reusable objects residing on multiple platforms. Responsible to Designs, development of applications in one or more of the areas like SAP Portal, SAP Fiori, SAP UI5, SAP Mobile Platform (SMP), SAP Cloud Platform Mobile Services (SCPMs). Customization to standard application in case required. Experience in working in Implementation, Upgrade, Maintenance and Postproduction support projects would be an advantage. Practitioner must willing to travel to client location for the Project duration Ability to create Screens, Controllers, OData DPC and MPC. Hands-on HTML5, JS, CSS3 coding experience. SAP Web IDE, SAP Frontend Server Experience. Preferred Education Master's Degree Required Technical And Professional Expertise BE / B Tech in any stream, M.Sc. (Computer Science/IT) / M.C.A, Min. 2-4 years of work experience in SAP Portal, SAP Fiori, SAP UI5, SAP Mobile Platform (SMP), SAP Cloud Platform Mobile Services (SCPMs Experience in Business Application Programming Interface and XI (Exchange Infrastructure) and Extensive experience in SAPUI5 application development Experience in MVC framework for UI, SAPUI5, HTML5, and JavaScript and Expertise in SAPUI5 controls and Fiori Design patterns Understanding of SAP functional requirement, conversion into technical design and development using ABAP Language for Report, Interface, Conversion, Enhancement and Forms in implementation or support project: Minimum 3-4 implementation experience Expertise in Fiori application and system architecture and Exposure in SAP Fiori Launchpad configuration and app integration Preferred Technical And Professional Experience Cement industry business knowledge is preferable. Knowledge and experience on SAP Workflow and Good experience in OData. Understanding of SAP functional requirement, conversion into technical design and development using ABAP Language for Report, Interface, Conversion, Enhancement and Forms in implementation or support project: Minimum 3-4 implementation experience",,,,
4248677301,AI Integration Engineer on AWS IRC266925,GlobalLogic,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Description Responsibilities Build and integrate AI-powered features using third-party models (e.g., OpenAI, Cohere, Hugging Face, Google Cloud AI). Design robust API integrations, pipelines, and workflows using LLMs or other foundation models. Collaborate with product managers, designers, and backend/frontend teams to ship features like chatbots, summarizers, smart search, etc. Handle AI prompt tuning, caching, rate limiting, and fallback mechanisms. Monitor and optimize AI feature performance (latency, cost, token usage). Ensure AI usage is safe, ethical, and aligns with business goals. Keep up with the fast-moving AI landscape and make recommendations for tools and services. Must-Have Skills 3+ years of software development experience (preferably in full-stack or backend roles). Solid Experience With Python, Node.js, Or Another Backend Language. Familiarity with RESTful APIs, cloud platforms (AWS, GCP, Azure), and AI-as-a-service offerings. Experience integrating with LLMs (e.g., OpenAI GPT APIs) or AI APIs (e.g., image, vision, speech). Ability to write clean, maintainable, and scalable code. Comfortable working in cross-functional teams in agile environments. Nice-to-Have Skills Experience with LangChain, RAG systems, or vector databases (e.g., Pinecone, Weaviate). Familiarity with prompt engineering and chaining logic. Exposure to frontend frameworks (React, Next.js) is a plus. Understanding of LLM performance tuning and observability tools. Prior work on AI agents, copilots, or workflow automation with AI tools. Nice-to-Haves Experience with LangChain, Semantic Kernel, or LLM orchestration frameworks. Familiarity with vector databases (Pinecone, Weaviate, Amazon Kendra). Exposure to frontend dev (React, Next.js) for building AI-first UIs. Background in conversational UX or prompt design. Understanding of AI safety, prompt injection, and red-teaming strategies. What You’ll Get Work with a team of AI-native builders — devs who ship fast with LLMs, not just talk about them. Access to cutting-edge tooling: Cursor AI, Bedrock, Claude, GPT-4, and more. Autonomy and support to explore, test, and launch new AI features. An environment that values speed, creativity, and pragmatism. Learning budget for conferences, courses, and AI tinkering. Requirements About the Role We’re building the next generation of AI-native products — fast, smart, and deeply user-centric. As an AI Application Engineer, your mission is to bring intelligence into real-world apps. You won’t be building models from scratch — instead, you’ll work with cutting-edge tools like Cursor AI for AI-native dev workflows and AWS Bedrock for scalable, secure access to foundation models. If you get excited about hacking together LLM workflows, building smart assistants, and crafting AI features users love (and trust), we want you on the team. What You’ll Do Design and build AI-powered product features using foundation models via AWS Bedrock (Anthropic, Cohere, Mistral, Amazon Titan, etc.). Rapidly prototype and ship features using AI-native dev environments like Cursor AI. Integrate LLMs and other AI APIs into real products — chat, summarization, intelligent search, document processing, and more. Own the full lifecycle of AI features: from idea to prompt design to API integration to production rollout. Build scalable, efficient, and observable AI workflows using best practices (prompt caching, rate limiting, retry logic). Collaborate closely with designers, PMs, and full-stack engineers to co-design intuitive, AI-first experiences. Track performance, reduce latency and costs, and improve user trust in AI responses. Stay up to date on rapidly evolving AI APIs and dev tools — and bring your learnings back to the team. Job responsibilities Responsibilities Build and integrate AI-powered features using third-party models (e.g., OpenAI, Cohere, Hugging Face, Google Cloud AI). Design robust API integrations, pipelines, and workflows using LLMs or other foundation models. Collaborate with product managers, designers, and backend/frontend teams to ship features like chatbots, summarizers, smart search, etc. Handle AI prompt tuning, caching, rate limiting, and fallback mechanisms. Monitor and optimize AI feature performance (latency, cost, token usage). Ensure AI usage is safe, ethical, and aligns with business goals. Keep up with the fast-moving AI landscape and make recommendations for tools and services. Must-Have Skills 3+ years of software development experience (preferably in full-stack or backend roles). Solid Experience With Python, Node.js, Or Another Backend Language. Familiarity with RESTful APIs, cloud platforms (AWS, GCP, Azure), and AI-as-a-service offerings. Experience integrating with LLMs (e.g., OpenAI GPT APIs) or AI APIs (e.g., image, vision, speech). Ability to write clean, maintainable, and scalable code. Comfortable working in cross-functional teams in agile environments. Nice-to-Have Skills Experience with LangChain, RAG systems, or vector databases (e.g., Pinecone, Weaviate). Familiarity with prompt engineering and chaining logic. Exposure to frontend frameworks (React, Next.js) is a plus. Understanding of LLM performance tuning and observability tools. Prior work on AI agents, copilots, or workflow automation with AI tools. Nice-to-Haves Experience with LangChain, Semantic Kernel, or LLM orchestration frameworks. Familiarity with vector databases (Pinecone, Weaviate, Amazon Kendra). Exposure to frontend dev (React, Next.js) for building AI-first UIs. Background in conversational UX or prompt design. Understanding of AI safety, prompt injection, and red-teaming strategies. What You’ll Get Work with a team of AI-native builders — devs who ship fast with LLMs, not just talk about them. Access to cutting-edge tooling: Cursor AI, Bedrock, Claude, GPT-4, and more. Autonomy and support to explore, test, and launch new AI features. An environment that values speed, creativity, and pragmatism. Learning budget for conferences, courses, and AI tinkering. What we offer Culture of caring. At GlobalLogic, we prioritize a culture of caring. Across every region and department, at every level, we consistently put people first. From day one, you’ll experience an inclusive culture of acceptance and belonging, where you’ll have the chance to build meaningful connections with collaborative teammates, supportive managers, and compassionate leaders. Learning and development. We are committed to your continuous learning and development. You’ll learn and grow daily in an environment with many opportunities to try new things, sharpen your skills, and advance your career at GlobalLogic. With our Career Navigator tool as just one example, GlobalLogic offers a rich array of programs, training curricula, and hands-on opportunities to grow personally and professionally. Interesting & meaningful work. GlobalLogic is known for engineering impact for and with clients around the world. As part of our team, you’ll have the chance to work on projects that matter. Each is a unique opportunity to engage your curiosity and creative problem-solving skills as you help clients reimagine what’s possible and bring new solutions to market. In the process, you’ll have the privilege of working on some of the most cutting-edge and impactful solutions shaping the world today. Balance and flexibility. We believe in the importance of balance and flexibility. With many functional career areas, roles, and work arrangements, you can explore ways of achieving the perfect balance between your work and life. Your life extends beyond the office, and we always do our best to help you integrate and balance the best of work and life, having fun along the way! High-trust organization. We are a high-trust organization where integrity is key. By joining GlobalLogic, you’re placing your trust in a safe, reliable, and ethical global company. Integrity and trust are a cornerstone of our value proposition to our employees and clients. You will find truthfulness, candor, and integrity in everything we do. About GlobalLogic GlobalLogic, a Hitachi Group Company, is a trusted digital engineering partner to the world’s largest and most forward-thinking companies. Since 2000, we’ve been at the forefront of the digital revolution – helping create some of the most innovative and widely used digital products and experiences. Today we continue to collaborate with clients in transforming businesses and redefining industries through intelligent products, platforms, and services.",manager,,Python,
4145358436,Staff Engineer MLOps & ML Engineering,Pattern®,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Job Description: As a machine learning operations leader, together with Pattern's Data Science and Engineering teams, you will lead a team that creates and maintains impactful solutions for our brands across the world. From traditional machine learning to large language models, you will work and lead throughout the model lifecycle. Responsibilities: Leadership: MLOps is a team sport, and we require a leader who can elevate everyone in the MLOps organization. While technical skills and vision are required, your leadership skills will take AI and machine learning from theoretical to operational, delivering tangible value to both customers and internal teams. Pipeline Management: Architect, implement, and maintain scalable ML pipelines, with seamless integration from data ingestion to production deployment. Model Monitoring: Lead the operationalization of machine learning models, ensuring hundreds of models are continuously monitored, retrained, and optimized in real-time environments Deployment: Deploy machine learning solutions in the cloud, securely and cost effectively. Reporting: Effectively communicate actionable insights across teams using both automatic (e.g., alerts) and non-automatic methods. The type of game changing candidate we are looking for: Seasoned: Demonstrated experience successfully leading teams both formally and informally. Transparent: Willingness to identify and admit errors and seek out opportunities to continually improve both in their own work and across the team. Communication: MLOps is a central node in a complex system. Clear, actionable, and concise communication, both written and verbal is a must. Coaching and Team Advancement: An MLOps leader is continually developing team members and fostering a constant flow of communication and improvement across team members. Master's/PhD degree or a strong demonstration of technical expertise in Computer Science, Machine Learning, Data Science, or a related field Multiple years of direct extensive experience with AWS Multiple years of experience with MLOps monitoring and testing tools Ability to prioritize projects effectively once clear vision and goals are identified Excited to empower DS with tools, practices, and training that simplify MLOps enough for Data Science to increasingly practice MLOps on their own and own products in production. Pattern is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",,,Machine Learning,
4227313612,Cloud Machine Learning LLM Serving Staff engineer,Qualcomm,"Bengaluru, Karnataka, India",,Full-time,,"About the job Company Qualcomm India Private Limited Job Area Engineering Group, Engineering Group > Software Engineering General Summary JD for Cloud Machine Learning LLM Serving Staff engineer Job Overview The Qualcomm Cloud Computing team is developing hardware and software for Machine Learning solutions spanning the data center, edge, infrastructure, automotive market. We are seeking ambitious, bright, and innovative engineers with experience in machine learning framework development. Job activities span the whole product life cycle from early design to commercial deployment. The environment is fast-paced and requires cross-functional interaction daily so good communication, planning and execution skills are a must. Key Responsibilities Analyze software requirements, determine the feasibility of design within the given constraints, consult with architecture and HW engineers, and implement software solutions best suited for Qualcomm's SOCs. Analyze and identify system level issues, interface with the software development, integration, and test teams Lead high performing teams towards system design and deliverables. Proven track record of leading teams in Machine learning software engineering. Strong foundation of Mathematical modeling of problems and linear algebra, coupled with state of the art algorithms in ML/AI space. Improve and optimize key Deep Learning models on Qualcomm AI 100. Build deep learning framework extensions for Qualcomm AI 100 in upstream open-source repositories. Collaborate and interact with internal teams to analyze and optimize training and inference for deep learning. Build software tools and ecosystem around AI SW Stack. Work on vLLM, Triton, ExecuTorch, Inductor, TorchDynamo to build abstraction layers for inference accelerator. Optimize workloads for both scale-up (multi-SoC) and scale-out (multi-card) systems. Optimize the entire deep learning pipeline including graph compiler integration. Apply knowledge of software engineering best practices. Desirable Skills And Aptitudes Deep Learning experience or knowledge – LLMs, Natural Language Processing, Vision, Audio, Recommendation systems. Knowledge of the structure and function of different components of Pytorch, TensorFlow software stacks. Excellent C/C++/Python programming and software design skills, including debugging, performance analysis, and test design. Ability to work independently, define requirements and scope, and lead your own development effort. Well versed with open-source development practices. Strong developer with a research mindset – strives to innovate. Avid problem solver – should be able to find solutions to key engineering and domain problems. Knowledge of tiling and scheduling a Machine learning operator is a plus. Experience in using C++ 14 (advanced features) Experience of profiling software and optimization techniques Hands on experience writing SIMD and/or multi-threaded high-performance code is a plus. Experience of ML compiler, Auto-code generation (using MLIR) is a plus. Experiences to run workloads on large scale heterogeneous clusters is a plus. Hands-on experience with CUDA, CUDNN is a plus. Qualifications Bachelor's / Masters/ PHD degree in Engineering, Machine learning/ AI, Information Systems, Computer Science, or related field. 8+ years Software Engineering or related work experience. 8+ years’ experience with Programming Language such as C++, Python. Minimum Qualifications Bachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Engineering or related work experience. OR Master's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience. OR PhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience. 2+ years of work experience with Programming Language such as C, C++, Java, Python, etc. Applicants : Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here . Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries). Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law. To all Staffing and Recruiting Agencies : Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications. If you would like more information about this role, please contact Qualcomm Careers . 3075067",,,"Python, Machine Learning",
4222043356,EY - GDS Consulting - AI Enabled Automation - AI Engineer - Staff,EY,"Kanayannur, Kerala, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. AI Engineer Role Overview: We are seeking a highly skilled and experienced AI Engineers with a minimum of 2 years of experience in Data Science and Machine Learning, preferably with experience in NLP, Generative AI, LLMs, MLOps, Optimization techniques, and AI solution Architecture. In this role, you will play a key role in the development and implementation of AI solutions, leveraging your technical expertise. The ideal candidate should have a deep understanding of AI technologies and experience in designing and implementing cutting-edge AI models and systems. Additionally, expertise in data engineering, DevOps, and MLOps practices will be valuable in this role. Your technical responsibilities: Assist in the development and implementation of AI models and systems, leveraging techniques such as Large Language Models (LLMs) and generative AI. Design, develop, and maintain efficient, reusable, and reliable Python code Stay updated with the latest advancements in generative AI techniques, such as LLMs, and evaluate their potential applications in solving enterprise challenges. Utilize generative AI techniques, such as LLMs, Agentic Framework to develop innovative solutions for enterprise industry use cases. Integrate with relevant APIs and libraries, such as Azure Open AI GPT models and Hugging Face Transformers, to leverage pre-trained models and enhance generative AI capabilities. Utilize vector databases, such as Redis, and NoSQL databases to efficiently handle large-scale generative AI datasets and outputs. Implement similarity search algorithms and techniques to enable efficient and accurate retrieval of relevant information from generative AI outputs. Ensure compliance with data privacy, security, and ethical considerations in AI applications. Leverage data engineering skills to curate, clean, and preprocess large-scale datasets for generative AI applications. Write unit tests and conduct code reviews to ensure high-quality, bug-free software. Troubleshoot and debug applications to optimize performance and fix issues. Work with databases (SQL, NoSQL) and integrate third-party APIs. Requirements: Bachelor's or Master's degree in Computer Science, Engineering, or a related field. Minimum 2 years of experience in Python, Data Science, Machine Learning, OCR and document intelligence In-depth knowledge of machine learning, deep learning, and generative AI techniques. Proficiency in programming languages such as Python, R, and frameworks like TensorFlow or PyTorch. Strong understanding of NLP techniques and frameworks such as BERT, GPT, or Transformer models. Familiarity with computer vision techniques for image recognition, object detection, or image generation. Strong knowledge of Python frameworks such as Django, Flask, or FastAPI. Experience with RESTful API design and development. Experience with cloud platforms such as Azure, AWS, or GCP and deploying AI solutions in a cloud environment. Expertise in data engineering, including data curation, cleaning, and preprocessing. Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions. Strong communication and interpersonal skills, with the ability to collaborate effectively with stakeholders at various levels. Understanding of data privacy, security, and ethical considerations in AI applications. Good to Have Skills: Understanding of agentic AI concepts and frameworks Proficiency in designing or interacting with agent-based AI architectures Apply trusted AI practices to ensure fairness, transparency, and accountability in AI models and systems. Utilize optimization tools and techniques, including MIP (Mixed Integer Programming). Implement CI/CD pipelines for streamlined model deployment and scaling processes. Utilize tools such as Docker, Kubernetes, and Git to build and manage AI pipelines. Apply infrastructure as code (IaC) principles, employing tools like Terraform or CloudFormation. Implement monitoring and logging tools to ensure AI model performance and reliability. EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",,,"Python, SQL, R, Machine Learning",
4246212740,Data Scientist - R Package Developer,Acuity Knowledge Partners,"Bangalore Urban, Karnataka, India (On-site)",On-site,Full-time,,"About the job Candidates should have a B.E./B.Tech/MCA/MBA in Finance, Information Systems, Computer Science or a related field 5-9 years of Strong experience in R programming and package development Proficiency with GitHub and unit testing frameworks. Strong documentation and communication skills. A background or work experience in biostatistics or a similar discipline (Preferred). Expert knowledge in Survival Analysis (Preferred) Statistical model deployment, and end-to-end MLOps is nice to have. Having worked extensively on cloud infrastructure, preferably Databricks and Azure. Shiny development is nice to have. Can work with customer stakeholders to understand business processes and workflows and can design solutions to optimize processes via streamlining and automation. DevOps experience and familiarity with software release process. Familiar with agile delivery methods. Excellent communication skills, both written and verbal Extremely strong organizational and analytical skills with strong attention to detail Strong track record of excellent results delivered to internal and external clients Able to work independently without the needs for close supervision and also collaboratively as part of cross-team efforts Experience with delivering projects within an agile environment",manager,,R,
4225989120,Principal AI/Machine Learning Engineer,Skillsoft,"Hyderabad, Telangana, India",,Full-time,,"About the job At Skillsoft, we propel organizations and people to grow together through transformative learning experiences. We believe every team member has the potential to be AMAZING. Join us in our quest to transform learning and help individuals unleash their edge. Skillsoft is the global leader in eLearning. Trusted by the world's leading organizations, including 65% of the Fortune 500. Our 100,000+ courses, videos and books are accessed over 100 million times every month, across more than 100 countries. At Skillsoft, we believe knowledge is the fuel for innovation and innovation is the fuel for business growth. Join us in our quest to democratize learning and help individuals unleash their edge. Are you ready to shape the future of learning through cutting-edge AI? As a Principal AI/Machine Learning Engineer at Skillsoft, you’ll dive into the heart of innovation, crafting intelligent systems that empower millions worldwide. From designing generative AI solutions to pioneering agentic workflows, you’ll collaborate with multiple teams to transform knowledge into a catalyst for growth—unleashing your edge while helping others do the same. Join us in redefining eLearning for the world’s leading organizations! Responsibilities Hands-on AI/ML software engineer Prompt engineering, agentic workflow development and testing Work with product owners to understand requirements and guide new features Collaborate to identify new feature impacts Evaluate new AI/ML technology advancements and socialize finding Research, prototype, and select appropriate COTS and develop in-house AI/ML technology Consult with external partners to review and guide development and integration of AI technology Collaborate with teams to design, and guide AI development, and enhancements Document designs and implementation to ensure consistency and alignment with standards Create documentation including system and sequence diagrams Create appropriate data pipelines for AI/ML training and inference Analyze, curate, cleanse, and preprocess data Utilize and apply generative AI to increase productivity for yourself and the organization Periodically explore new technologies and design patterns with proof-of-concept Participate in developing best practices and improving operational processes Present research and work to socialize and share knowledge across the organization Contribute to patentable AI innovations Environment, Tools & Technologies Agile/Scrum Operating Systems – Mac, Linux JavaScript, Node.js, Python PyTorch, Tensorflow, Keras, OpenAI, Anthropic, and friends Langchain, Langgraph, etc. APIs GraphQL, REST Docker, Kubernetes Amazon Web Services (AWS), MS Azure SQL: Postgres RDS NoSQL: Cassandra, Elasticsearch (VectorDb) Messaging – Kafka, RabbitMQ, SQS Monitoring – Prometheus, ELK GitHub, IDE (your choice) Skills & Qualifications: (8+ years experience) Experience with LLMs and fine-tuning models Development experience including unit testing Design and documentation experience of new APIs, data models, service interactions Familiarity with and ability to explain: system and API security techniques data privacy concerns microservices architecture vertical vs horizontal scaling Generative AI, NLP, DNN, auto-encoders, etc. Attributes For Success Proactive, Independent, Adaptable Collaborative team player Customer service minded with an ownership mindset Excellent analytic and communication skills Ability and desire to coach and mentor other developers Passionate, curious, open to new ideas, and ability to research and learn new technologies More About Skillsoft Skillsoft delivers online learning, training, and talent solutions to help organizations unleash their edge . Leveraging immersive, engaging content, Skillsoft enables organizations to unlock the potential in their best assets – their people – and build teams with the skills they need for success. Empowering 36 million learners and counting, Skillsoft democratizes learning through an intelligent learning experience and a customized, learner-centric approach to skills development with resources for Leadership Development, Business Skills, Technology & Development, Digital Transformation, and Compliance. Skillsoft is partner to thousands of leading global organizations, including many Fortune 500 companies. The company features three award-winning systems that support learning, performance and success: Skillsoft learning content, the Percipio intelligent learning experience platform, which offers measurable impact across the entire employee lifecycle. Learn more at www.skillsoft.com . Thank you for taking the time to learn more about us. If this opportunity intrigues you, we would love for you to apply! NOTE TO EMPLOYMENT AGENCIES: We value the partnerships we have built with our preferred vendors. Skillsoft does not accept unsolicited resumes from employment agencies. All resumes submitted by employment agencies directly to any Skillsoft employee or hiring manager in any form without a signed Skillsoft Employment Agency Agreement on file and search engagement for that position will be deemed unsolicited in nature. No fee will be paid in the event the candidate is subsequently hired as a result of the referral or through other means. Skillsoft is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, age, national origin, disability, veteran status, genetic information, and other legally protected categories.",manager,8+ years experience,"Python, SQL, Machine Learning",
4243012383,Senior AI Engineer,AlphaSense,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job About AlphaSense The world’s most sophisticated companies rely on AlphaSense to remove uncertainty from decision-making. With market intelligence and search built on proven AI, AlphaSense delivers insights that matter from content you can trust. Our universe of public and private content includes equity research, company filings, event transcripts, expert calls, news, trade journals, and clients’ own research content. The acquisition of Tegus by AlphaSense in 2024 advances our shared mission to empower professionals to make smarter decisions through AI-driven market intelligence. Together, AlphaSense and Tegus will accelerate growth, innovation, and content expansion, with complementary product and content capabilities that enable users to unearth even more comprehensive insights from thousands of content sets. Our platform is trusted by over 4,000 enterprise customers, including a majority of the S&P 500. Founded in 2011, AlphaSense is headquartered in New York City with more than 2,000 employees across the globe and offices in the U.S., U.K., Finland, India, Singapore, Canada, and Ireland. Come join us! About The Role AlphaSense is seeking a passionate Senior AI engineer to join our AI & Search mission. This cluster of teams is responsible for developing cutting edge deep learning, NLP, search, and next-generation Generative AI platform powering AlphaSense’s AI & Search product features. As part of this team, you will collaborate with talented engineers to deliver scalable solutions for our world-class AI-powered search platform. What You’ll Do Architect, design, and implement highly scalable services for AlphaSense AI and Search products Improve the reliability, latency, and cost-efficiency of AI and search services in cloud environments. Deploy AI and Search services to both SaaS and single-tenant cloud environments. Translate product requirements into software architectures in collaboration with Product Management. Solve challenges that come along with working with large language models (high latency, variance, etc.), leading to a defensive, fault-first mindset. Provide technical leadership and implement best practices for software development. Who You Are Strong software engineering skills in back-end engineering on complex, data-intensive applications with professional, real-world experience with applications at scale Extremely proficient in Applied LLM/NLP, developing and deploying solutions using NLP frameworks like LangChain, HuggingFace, back-end web frameworks like FastAPI Hands on experience building and deploying Open Source and Commercial LLMs like Llama, Claude etc., deep understanding of Prompt Engineering Deep, hands-on experience across a few back-end web frameworks like FastAPI, Django, Sanic etc Experience in leading teams and/or projects in a full-stack environment Excellent communication, organizational, problem-solving, debugging, and analytical skills. Experience designing large-scale software systems and writing high-quality code and tests. Which includes handling error cases, asynchronous code, streaming data, caching, logging and analytics for understanding behavior in production. Familiarity with Kubernetes, Docker, and cloud platforms such as AWS, GCP, or Azure. Experience in deploying AI and search services (e.g. vector search) to single-tenant cloud environments. Knowledge of modern development practices, including CI/CD pipelines and automated testing frameworks. Experience in optimizing the performance and cost of cloud services. AlphaSense is an equal-opportunity employer. We are committed to a work environment that supports, inspires, and respects all individuals. All employees share in the responsibility for fulfilling AlphaSense’s commitment to equal employment opportunity. AlphaSense does not discriminate against any employee or applicant on the basis of race, color, sex (including pregnancy), national origin, age, religion, marital status, sexual orientation, gender identity, gender expression, military or veteran status, disability, or any other non-merit factor. This policy applies to every aspect of employment at AlphaSense, including recruitment, hiring, training, advancement, and termination. In addition, it is the policy of AlphaSense to provide reasonable accommodation to qualified employees who have protected disabilities to the extent required by applicable laws, regulations, and ordinances where a particular employee works. Recruiting Scams and Fraud We At AlphaSense Have Been Made Aware Of Fraudulent Job Postings And Individuals Impersonating AlphaSense Recruiters. These Scams May Involve Fake Job Offers, Requests For Sensitive Personal Information, Or Demands For Payment. Please Note AlphaSense never asks candidates to pay for job applications, equipment, or training. All official communications will come from an @ alpha-sense.com email address. If you’re unsure about a job posting or recruiter, verify it on our Careers page . If you believe you’ve been targeted by a scam or have any doubts regarding the authenticity of any job listing purportedly from or on behalf of AlphaSense please contact us. Your security and trust matter to us.",,,,
4245523891,AI Fullstack Engineer,Uplers,Greater Lucknow Area (Remote),Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - HurixDigital) What do you need for this opportunity? Must have skills required: Python, LLM, Rag (retrieval-augmented generation), AWS HurixDigital is Looking for: Job Summary We are seeking a highly skilled and innovative AI Engineer with Full Stack capabilities to join our dynamic team. The ideal candidate will bring a strong blend of expertise in artificial intelligence, modern software engineering practices, and cloud infrastructure. You will be responsible for designing, developing, and deploying intelligent applications that are scalable, resilient, and deliver real business value. Key Responsibilities Develop and deploy end-to-end AI-powered applications leveraging full-stack development best practices. Architect and integrate AI/ML models and pipelines using tools like LangChain, Hugging Face, OpenAI, and Anthropic Claude APIs. Design and implement microservices, RESTful APIs, and backend systems with scalability and maintainability in mind. Leverage cloud platforms (AWS, Azure, GCP) for hosting, automation, and scaling services. Integrate CI/CD pipelines to ensure smooth and frequent deployment cycles. Collaborate with cross-functional teams to translate business requirements into technical solutions. Apply techniques such as content chunking, vector search, embedding models, and retrievers to build advanced AI retrieval systems. Ensure robust architecture that can withstand variable load conditions, focusing on fault tolerance and high availability. Maintain documentation and adhere to best practices in software development and AI model integration. Required Qualifications Bachelor's or Master's degree in Computer Science, Engineering, or a related field. 5+ years of hands-on experience in AI engineering and full-stack development. Strong proficiency with AI/ML tools including LangChain, Hugging Face, OpenAI, and Claude APIs. Deep understanding of vector databases, retrievers, and modern NLP workflows. Proficient in one or more full-stack frameworks (e.g., Node.js, Django, React, Angular). Experience with Python Experience with cloud platforms (AWS, Azure, GCP) and infrastructure automation tools (e.g., Terraform, CloudFormation). Solid experience with CI/CD pipelines, GitOps, and container orchestration (e.g., Docker, Kubernetes). Proven ability to architect resilient systems and optimize performance under fluctuating workloads. Preferred Skills Knowledge of prompt engineering and LLM fine-tuning techniques. Familiarity with DevSecOps practices and AI compliance requirements. Exposure to multimodal models and real-time inference systems. What We Offer Opportunity to work on cutting-edge AI products and tools. Collaborative and inclusive team environment. Flexible work schedule and remote work options. Competitive salary and performance bonuses. How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Python, LLM, Rag (retrieval-augmented generation), AWS",,,Python,
4211354178,Senior AI Engineer,Anblicks,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job 5+ years of experience in data science, with proficiency in Agentic frameworks, Python, and SQL. Excellent communication and stakeholder management skills. Strong Analytical Abilities And Problem-solving Skills. Proven track record in delivering AI solutions and collaborating with cross-functional teams. Experience deploying ML solutions in production that generate significant value.",,,"Python, SQL",
4244463093,"Staff Software Developer, Machine Learning",Kinaxis,"Bengaluru, Karnataka, India (Remote)",Remote,Full-time,,"About the job About Kinaxis Elevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis. In 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers. Our journey in India began in 2020 and we have been growing steadily since then! Building a high-trust and high-performance culture is important to us and we are proud to be Great Place to Work® Certified TM . Our state-of-the-art office, located in the World Trade Centre in Chennai, offers our growing team space for expansion and collaboration. Location Bangalore, India (Hybrid) About The Team The AI team is responsible for delivering machine learning solutions in the supply and demand space for verticals such as Retail, Consumer Packaged Goods, Life Sciences etc. This includes problems in the space of forecasting, optimization, replenishment, recommendation, explainability, and more. The uniqueness of the team is that it performs at the intersection of technology and real business problems. You will contribute to the product that delights customers world-wide! Kinaxis is seeking a talented and passionate Machine Learning Staff Developer to join our cutting-edge Generative AI development team. As a Staff Developer in the Product R&D team, you will work at the forefront of shaping the future of artificial intelligence leveraging the Generative AI. Your work will directly impact our enterprise-grade AI software platform and solutions, which are used by hundreds of customers worldwide to manage their supply chains. What you will do All aspects of the machine learning development life cycle are familiar to you. You are passionate about shipping large-scale software systems in a fast-paced environment, but you can balance longer term issues such as maintainability, scalability and quality. You’re fluent in Python object-oriented development and in the cloud. In addition to working with modern data storage, familiarity with Kubernetes, docker and have hands-on experience with big data technologies. You have the ability and enthusiasm to learn new technologies whether they are infrastructure or language or platform and easily adapt to change. You will define, drive, design, and build end-to-end AI solutions that not only solve real customer problems but also create automated ML-based solutions specifically tailored for building a cutting-edge application leveraging LLM to orchestrate our customers’ supply chains, including architectural design, relevant design documentation, test planning and execution. You will contribute to the end-to-end AI software development lifecycle, ensuring reproducible research and state of the art results for our customers. You will operate as a technical leader in the Product R&D team. Oversee the work of junior developers and actively engage team members to develop their skills and build shared ownership across the code base. Proactively engages outside of team to unblock other team members while progressing their own technical assignments. You are a team player, a quick starter and a problem solver, as well as comfortable talking requirements with product managers. You work well in a cross-functional team and can listen and contribute to discussions. Ideally provide readily available solutions while considering technical aspects, effort, and risk. Technologies we use Bachelor’s degree or equivalent in Computer Science or a related field, with focus in machine learning. Strong software engineering skills with a minimum of 10+ years’ experience in enterprise software development. Proficient in Python, with expertise in building REST APIs using frameworks like FASTAPI. Strong understanding of machine learning algorithms, with experience developing, debugging and optimizing ML data pipelines and transformations using Python/Pandas/SQL Solid background in Machine Learning fundamentals, statistical methods for ML, time series forecasting, Bayesian methods, parametric and non-parametric methods, generative models, stochastic processes, model explainability, etc. Demonstrated experience in designing comprehensive test plans, including functional, integration, system, and acceptance testing, with strong hands-on expertise in automation frameworks such as PyTest and continuous testing using GitHub Actions Experienced in managing end-to-end release processes, including product versioning, CI/CD pipeline integration, coordinating with cross-functional stakeholders —to ensure smooth and reliable software delivery. Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams and business audiences. What we are looking for Retail business background with supply chain knowledge Strong knowledge of NLP, Large Language Models (LLM), RAG, fine-tuning and LLM model development and evaluation. Familiarity with the latest open-source libraries, tools, and frameworks in AI and GenAI, such as LangChain, agents, vector databases, etc. SaaS, and multi-tenant platforms development experience (microservice frameworks, queuing systems, event-based processing and web services). Comfortable working in Linux environments and cloud-native ecosystems, with expertise in containerization technologies such as Docker, Kubernetes, Argo, and Helm. Experience working with major cloud technologies (AWS, Azure, and GCP) #Intermediate Work With Impact: Our platform directly helps companies power the world’s supply chains. We see the results of what we do out in the world every day—when we see store shelves stocked, when medications are available for our loved ones, and so much more. Work with Fortune 500 Brands: Companies across industries trust us to help them take control of their integrated business planning and digital supply chain. Some of our customers include Ford, Unilever, Yamaha, P&G, Lockheed-Martin, and more. Social Responsibility at Kinaxis: Our Diversity, Equity, and Inclusion Committee weighs in on hiring practices, talent assessment training materials, and mandatory training on unconscious bias and inclusion fundamentals. Sustainability is key to what we do and we’re committed to net-zero operations strategy for the long term. We are involved in our communities and support causes where we can make the most impact. People matter at Kinaxis and these are some of the perks and benefits we created for our team: Flexible vacation and Kinaxis Days (company-wide day off on the last Friday of every month) Flexible work options Physical and mental well-being programs Regularly scheduled virtual fitness classes Mentorship programs and training and career development Recognition programs and referral rewards Hackathons For more information, visit the Kinaxis web site at www.kinaxis.com or the company’s blog at http://blog.kinaxis.com . Kinaxis welcomes candidates to apply to our inclusive community. We provide accommodations upon request to ensure fairness and accessibility throughout our recruitment process for all candidates, including those with specific needs or disabilities. If you require an accommodation, please reach out to us at recruitmentprograms@kinaxis.com. Please note that this contact information is strictly for accessibility requests and cannot be used to inquire about application statuses. Kinaxis is committed to ensuring a fair and transparent recruitment process. We use artificial intelligence (AI) tools in the initial step of the recruitment process to compare submitted resumes against the job description, to identify candidates whose education, experience and skills most closely match the requirements of the role. After the initial screening, all subsequent decisions regarding your application, including final selection, are made by our human recruitment team. AI does not make any final hiring decisions.",manager,,"Python, SQL, R, Machine Learning",
4259070338,SQL Developer Intern,Workassist,"Chennai, Tamil Nadu, India (Remote)",Remote,Full-time,"Type : Information Technology Function : Database Administrator Key Skills : mSQL,SQL Writing,PLSQL Education : Graduate Note: This is a requirement for one of the Workassist Hiring Partner Responsibilities Write, optimize, and maintain SQL queries, stored procedures, and functions. This is a Remote Position. Assist in designing and managing relational databases. Perform data extraction, transformation, and loading (ETL) tasks. Ensure database integrity, security, and performance. Work with developers to integrate databases into applications. Support data analysis and reporting by writing complex queries. Document database structures, processes, and best practices. Company Description Workassist is an online recruitment and employment solution platform based in Lucknow, India. We provide relevant profiles to employers and connect job seekers with the best opportunities across various industries. With a network of over 10,000+ recruiters, we help employers recruit talented individuals from sectors such as Banking & Finance, Consulting, Sales & Marketing, HR, IT, Operations, and Legal. We have adapted to the new normal and strive to provide a seamless job search experience for job seekers worldwide. Our goal is to enhance the job seeking experience by leveraging technology and matching job seekers with the right employers. For a seamless job search experience, visit our website: https://bit.ly/3QBfBU2 (Note: There are many more opportunities apart from this on the portal. Depending on the skills, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Put your best foot forward with your application Put your best foot forward with your application Hire a resume writer Hire a resume writer Get a resume review About the company Workassist 77,978 followers Follow Staffing and Recruiting 51-200 employees 59 on LinkedIn Workassist is an online recruitment and employment solution providing a platform in India. Workassist provides relevant profiles to employers and relevant jobs to job seekers across different industries and with varying levels of experience leveraging the technology through e-recruitment. Workassist has quickly adapted to the new normal and assists job seekers with the best opportunities and employers with the best talent from all over the world. Get in touch to enhance the job seeking experience as we work with Recruiters from sectors such as Banking & Finance, Consulting, Sales & Marketing, Healthcare, IT and Operations and legal to help them recruit great emerging talents. >>>>For a seamless job search experience, >>>>Visit: https://bit.ly/3ztaKSi … show more Show more","About the job Work Level : Individual Core : Responsible Leadership : Team Alignment Industry Type : Information Technology Function : Database Administrator Key Skills : mSQL,SQL Writing,PLSQL Education : Graduate Note: This is a requirement for one of the Workassist Hiring Partner Responsibilities Write, optimize, and maintain SQL queries, stored procedures, and functions. This is a Remote Position. Assist in designing and managing relational databases. Perform data extraction, transformation, and loading (ETL) tasks. Ensure database integrity, security, and performance. Work with developers to integrate databases into applications. Support data analysis and reporting by writing complex queries. Document database structures, processes, and best practices. Company Description Workassist is an online recruitment and employment solution platform based in Lucknow, India. We provide relevant profiles to employers and connect job seekers with the best opportunities across various industries. With a network of over 10,000+ recruiters, we help employers recruit talented individuals from sectors such as Banking & Finance, Consulting, Sales & Marketing, HR, IT, Operations, and Legal. We have adapted to the new normal and strive to provide a seamless job search experience for job seekers worldwide. Our goal is to enhance the job seeking experience by leveraging technology and matching job seekers with the right employers. For a seamless job search experience, visit our website: https://bit.ly/3QBfBU2 (Note: There are many more opportunities apart from this on the portal. Depending on the skills, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",,,"SQL, Data Analysis",
4250838078,Senior AI Engineer,Xactly Corp,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Job Description WHO WE ARE Xactly is a leader in Sales Performance Management Solutions and a part of Vista Equity Partners portfolio companies since 2017. The Xactly Intelligent Revenue Platform helps businesses improve go-to-market outcomes through increased collaboration, greater efficiencies, and connecting data from all critical functions of the revenue lifecycle on a single platform. Born in the cloud almost 20 years ago, Xactly provides customers with extensive experience in solving the most challenging problems customers of all sizes face, backed by almost 20 years of proprietary data and award-winning AI. Named among the best workplaces in the U.S. by Great Place to Work six times, honored on FORTUNE Magazine’s inaugural list of the 100 Best Workplaces for Millennials, and chosen as the “Market Leader in Incentive Compensation” by CRM magazine. We’re building a culture of success and are looking for motivated professionals to join us! THE OPPORTUNITY Join us as we build out our AI Labs team as a Senior AI Engineer where you’ll be working alongside a visionary Head of AI Labs based in the U.S. This is your change to shape the future of enterprise AI from our Bengaluru hub where you’ll be designing, prototyping and testing cutting edge Generative AI solutions that redefine how businesses operate. You’ll collaborate closely with global stakeholders to bring bold ideas to life - building rapid experiments, iterating with real customer feedback and turning proof-of-concepts into platform-ready innovations. If you’re passionate about pushing the boundaries of applied AI and your work to have real, tangible impact, this is the opportunity for you. Responsibilities Conduct rapid prototyping and experimentation to explore new AI opportunities and validate hypotheses. Design, build, and deploy AI/GenAI-powered features that enhance core SPM capabilities such as incentive planning, quota optimization, territory alignment, and sales forecasting. Integrate LLMs (e.g., GPT, Claude, Llama) into our SaaS platform to power intelligent assistants, report generation, and conversational interfaces. Develop and fine-tune GenAI & ML models for predictive analytics (e.g., attrition risk, attainment forecasting, gamification insights). Work with product managers and UX designers to conceptualize AI-first features that deliver measurable business impact. Collaborate with data engineering teams to ensure high-quality data pipelines and model serving infrastructure. Research and experiment with cutting-edge GenAI approaches (e.g., RAG, fine-tuning, prompt engineering) to solve enterprise-specific problems. Monitor model performance in production and continuously improve for accuracy, scalability, and fairness. Collaborate with data engineers to ensure the availability of high-quality, relevant data for AI model training and inference. Seamlessly integrate AI/ML models and functionalities into our existing SaaS enterprise platform, ensuring high performance, reliability, and scalability. Qualifications Bachelor’s or Master’s degree in Computer Science, AI/ML, Data Science, or related field. 6+ years of experience in AI/ML, with at least 1 year working with GenAI or LLMs. Strong programming skills in Python/Java, with experience using libraries like Transformers, LangChain, PyTorch, TensorFlow and Scikit-learn. Experience integrating AI/ML models intoSaaS platforms at scale. Familiarity with cloud platforms (AWS, Azure, GCP) and AIOps/MLOps practices for model deployment, monitoring and lifecycle management.. Experience with RAG pipelines, vector databases (e.g., FAISS, Pinecone), and embedding models Strong understanding in natural language processing (NLP) and deep learning techniques. Proficient in SQL and experience working with large datasets in relational and/or NoSQL databases. Excellent communication and collaboration skills, with the ability to explain complex technical concepts to cross-functional stakeholders. Preferred Qualifications Knowledge of sales performance processes (e.g., compensation modeling, quota setting, sales analytics). Experience working in a fast-paced innovation lab or startup environment. Hands-on experience with prompt engineering and LLM APIs (OpenAI, Anthropic, etc.). Strong intuition for experimentation, prototyping and rapid iteration. Comfort with ambiguity and ability to thrive in an exploratory R&D setting. Ability to collaborate effectively with global teams and communicate technical concepts clearly. Familiarity with data governance, responsible AI practices, and enterprise security protocols. Experience with real-time AI inference and streaming data. Contributions to open-source AI/ML projects. Benefits & Perks Paid Time Off (PTO) Comprehensive Health and Accidental Insurance Coverage Tuition Reimbursement XactlyFit Gym/Fitness Program Reimbursement Free snacks onsite(if you work in office) Generous Employee Referral Program Free Parking and Subsidized Bus Pass (a go-green initiative!) Wellness program OUR VISION : Unleashing human potential to maximize company performance. We address a critical business need: to incentivize employees and align their behaviors with company goals. OUR CORE VALUES : Customer Focus | Accountability | Respect | Excellence (CARE) are the keys to our success, and each day we’re committed to upholding them by delivering the best we can to our customers. Xactly is proud to be an Equal Opportunity Employer. Xactly provides equal employment opportunities to all employees and applicants without regard to race, color, religion, sex, age, national origin, disability, veteran status, pregnancy, sexual orientation, or any other characteristic protected by law. This means we believe in celebrating diversity and creating an inclusive workplace environment, where everyone feels valued, heard, and has a sense of belonging. By doing this, everyone in the Xactly family has the power to make a difference and unleash their full potential. We do not accept resumes from agencies, headhunters, or other suppliers who have not signed a formal agreement with us.",manager,,"Python, SQL, R",
4237344989,Staff Engineer Data Science,Infineon Technologies,"Bengaluru East, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Are you passionate about transforming data into actionable insights? Join our team at Infineon Technologies as a Staff Engineer in Data Engineering & Analytics! In this role, you'll be at the forefront of harnessing the power of data to drive innovation and efficiency. Collaborate with experts, design robust data ecosystems, and support digitalization projects. If you have a strong background in data engineering, database concepts, and a flair for turning complex business needs into solutions, we want to hear from you. Elevate your career with us and be part of shaping the future! Job Description In your new role you will: Identify and understand the different needs and requirements of consumers and data providers (e.g. transaction processing, data ware housing, big data, AI/ML) and translate business digitalization needs to technical system requirements. Team up with our domain-, IT- and process experts to assess the status quo, to capture the full value of our data and to derive target data-ecosystems based on business needs Design, build, deploy and maintain scalable and reliable data assets, pipelines and architectures. Team-up with domain IT- and process experts and especially with you key users to validate the effectiveness and efficiency of the designed data solutions and contribute to their continuous improvement and to their future-proofing. Support data governance (Data Catalogue, Data Lineage, Meta Data, Data Quality, Roles and Responsibilities) and enable analytics use cases with a focus on data harmonization, connection and visualization. Drive and/or contribute to digitalization projects in cross-functional coordination with IT and business counterparts (e.g. data scientists, domain experts, process owners). Act as first point of contact for data solutions in the ATV QM organization to consult and guide stakeholders to leverage the full value from data and to cascade knowledge of industry trends and technology roadmaps for the major market players (guidelines,principles, frameworks, industry standards and best practice, upcoming innovation, new features and technologies) Your Profile You are best equipped for this task if you have: A degree in Information Technology, Business Informatics, Computer Science or related field of studies. At least 5 years of relevant work experience related to Data Engineering and/or Analytics with strong data engineering focus Ability to translate complex business needs into concrete actions Excellent expertise of database concepts (e.g. DWH, Hadoop/Big Data, OLAP), related query languages (e.g. SQL, Scala, Java, MDX) Expertise in data virtualization (e.g. Denodo) Working knowledge on the latest toolsets for data analytics, reporting and data visualization (e.g. Tableau, SAP BO) as well as in Python, R and Spark is a plus Ability to work both independently and within a team #WeAreIn for driving decarbonization and digitalization. As a global leader in semiconductor solutions in power systems and IoT, Infineon enables game-changing solutions for green and efficient energy, clean and safe mobility, as well as smart and secure IoT. Together, we drive innovation and customer success, while caring for our people and empowering them to reach ambitious goals. Be a part of making life easier, safer and greener. Are you in? We are on a journey to create the best Infineon for everyone. This means we embrace diversity and inclusion and welcome everyone for who they are. At Infineon, we offer a working environment characterized by trust, openness, respect and tolerance and are committed to give all applicants and employees equal opportunities. We base our recruiting decisions on the applicant´s experience and skills. Please let your recruiter know if they need to pay special attention to something in order to enable your participation in the interview process. Click here for more information about Diversity & Inclusion at Infineon.",,,"Python, SQL, Tableau, R",
4235819112,Lead Machine Learning Developer,Arctic Wolf,"Bengaluru, Karnataka, India",,Full-time,,"About the job At Arctic Wolf, we're not just navigating the cybersecurity landscape - we're redefining it. Our global team of dedicated Pack members is driving innovation and setting new industry standards every day. Our impact speaks for itself: we've earned recognition on the Forbes Cloud 100, CNBC Disruptor 50, Fortune Future 50, and Fortune Cyber 60 lists, and we recently took home the 2024 CRN Products of the Year award. We’re proud to be named a Leader in the IDC MarketScape for Worldwide Managed Detection and Response Services and earning a Customers' Choice distinction from Gartner Peer Insights . Our Aurora Platform also received CRN’s Products of the Year award in the inaugural Security Operations Platform category. Join a company that’s not only leading, but also shaping, the future of security operations. Lead ML Developer The Lead ML Developer will be responsible for the design and development of complex and exciting platforms in our Arctic Wolf Labs department. They will drive the technical roadmap of the AI/ML platforms at Arctic Wolf and enable the AI/ML teams to contribute to our Security Research and Threat Intelligence products and initiatives, and will develop cutting-edge systems, services, and frameworks for Arctic Wolf Labs. We are looking for a developer with a strong foundation of AI/ML concepts and workflows to join our pack, support a practice that will continuously evolve and expand the capabilities of our data science team, and contribute to our security products and services. Arctic Wolf Labs is the research-focused division at Arctic Wolf focused on advancing innovation in the field of security operations. The mission of Arctic Wolf Labs is to develop cutting-edge technology and tools that are designed to enhance the company’s core mission to end cyber risk, while also bringing comprehensive security intelligence to Arctic Wolf’s customer base and the security community-at-large. Leveraging the more than six trillion security events the Arctic Wolf Security Operations Cloud ingests, parses, enriches, and analyzes each week, Arctic Wolf Labs is responsible for performing threat research on new and emerging adversaries, developing advanced threat detection models, and driving improvement in the speed, scale, and detection abilities of Arctic Wolf’s solution offerings. The Arctic Wolf Labs team comprises security and threat intelligence researchers, data scientists, security development engineers with deep domain knowledge in artificial intelligence (AI), security R&D, as well as advanced threat offensive and defensive methods and technologies. Security Research Services Development partners with these groups to understand requirements, design & implement scalable, fault-tolerant solutions, and build the next generation of security capabilities for Arctic Wolf. As A Lead ML Developer At Arctic Wolf, You Will: Support R&D of distributed, highly scalable, and fault-tolerant microservices Use test-driven development techniques to develop beautiful, efficient, and secure code Create and scale high-performance services that bring new capabilities to Arctic Wolf’s data science organizations Execute on deliverables on the roadmap of ML engineering, modeling, and operations at Arctic Wolf Influence the work of team members, and mentor emerging technical leaders. Develop trusted cross-team relationships to deliver solutions that span multiple areas of expertise Identify problems proactively and propose novel solutions to solve them Continuously learn and expand your technical horizons Our mission is simple: End Cyber Risk. We’re looking for a Senior Principal Developer to be part of making that happen. We’re Looking For Someone Who Will collaborate closely with our data science and ML teams across different cybersecurity domains to define ML infrastructure requirements and build critical data services Can leverage MLOps best practices to design and develop scalable model training, evaluation, experimentation and deployment workflows Has extensive experience in ML training (local and distributed), feature extraction, dataset creation Is comfortable deploying software with CI / CD tools including Jenkins, Harness, Terraform etc. Is an expert at developing and deploying assets in the cloud - preferably AWS and Kubernetes using IAC (infrastructure as code) Can build a workflow orchestration platform to be used by other developers Has hands-on experience of 2+ years implementing data pipeline infrastructure for data ingestion and transformation near real-time availability of data for applications and ML pipelines Has experience designing optimized solutions for ingestion, curation of large datasets Has working knowledge of Data Lake technologies, data storage formats (Parquet, ORC, Avro), and query engines (Athena, Presto, Dremio) and associated concepts for building optimized solutions at scale Maintains a proficient level in one of the following programming languages or similar- Python, Java, Go Has experience with data pipelines tools (Flink, Spark or Ray) and orchestration tools such as Airflow, Dagster or Step Functions Is an expert in implementing data streaming and event-based data solutions (Kafka, Kinesis, SQS/SNS or the like) About The Company At Arctic Wolf, we foster a collaborative and inclusive work environment that thrives on diversity of thought, background, and culture. This is reflected in our multiple awards, including Top Workplace USA (2021-2024), Best Places to Work – USA (2021-2024), Great Place to Work – Canada (2021-2024), Great Place to Work – UK (2024), and Kununu Top Company – Germany (2024). Our commitment to bold growth and shaping the future of security operations is matched by our dedication to customer satisfaction, with over 7,000 customers worldwide and more than 2,000 channel partners globally. As we continue to expand globally and enhance our technology, Arctic Wolf remains the most trusted name in the industry. Our Values Arctic Wolf recognizes that success comes from delighting our customers, so we work together to ensure that happens every day. We believe in diversity and inclusion, and truly value the unique qualities and unique perspectives all employees bring to the organization. And we appreciate that—by protecting people’s and organizations’ sensitive data and seeking to end cyber risk— we get to work in an industry that is fundamental to the greater good. We celebrate unique perspectives by creating a platform for all voices to be heard through our Pack Unity program. We encourage all employees to join or create a new alliance. See more about our Pack Unity here. We also believe and practice corporate responsibility, and have recently joined the Pledge 1% Movement, ensuring that we continue to give back to our community. We know that through our mission to End Cyber Risk we will continue to engage and give back to our communities. All wolves receive compelling compensation and benefits packages, including: Equity for all employees Flexible annual leave, paid holidays and volunteer days Training and career development programs Comprehensive private benefits plan including medical insurance for you and your family, life insurance (3x compensation), and personal accident insurance. Fertility support and paid parental leave Arctic Wolf is an Equal Opportunity Employer and considers applicants for employment without regard to race, color, religion, sex, orientation, national origin, age, disability, genetics, or any other basis forbidden under federal, provincial, or local law. Arctic Wolf is committed to fostering a welcoming, accessible, respectful, and inclusive environment ensuring equal access and participation for people with disabilities. As such, we strive to make our entire employee experience as accessible as possible and provide accommodations as required for candidates and employees with disabilities and/or other specific needs where possible. Please let us know if you require any accommodations by emailing recruiting@arcticwolf.com. Security Requirements Conducts duties and responsibilities in accordance with AWN’s Information Security policies, standards, processes and controls to protect the confidentiality, integrity and availability of AWN business information (in accordance with our employee handbook and corporate policies). Background checks are required for this position.",associate,,"Python, R",
4253277445,"Lead Machine Learning Engineer, Digital & Technology",General Mills India,"Mumbai, Maharashtra, India",,Full-time,"experience. Experience in supervised ML algorithms, optimization, and performance tuning. Track record of producing machine learning models and production infrastructure at scale. Strong verbal and written communication skills including the ability to interact effectively with colleagues of varying technical and non-technical abilities. Passionate about agile software processes, data-driven development, reliability, and systematic experimentation. Passion for learning new technologies and solving challenging problems. Good understanding of CI, CD, TDD, and tools such as Jenkins. Strong understanding of orchestration frameworks such Airflow/Kubeflow/MLFlow. Agile software development experience such as Kanban and Scrum. Experience in software version control team practices and tools such as GIT and TFS. Expertise in Data Transformation and Manipulation through Big-Query/SQL Professional experience with Vertex AI and GCP Services. Strong proficiency in Python. Preferred Qualifications GCP Machine Learning certification Understanding of CPG industry Exposure to Deep Learning/RL/LLMs Prior experience with CPG industry. Publications or contributions to the data science and AI community. Certifications in AI, machine learning, or related fields. Company Overview We exist to make food the world loves. But we do more than that. Our company is a place that prioritizes being a force for good, a place to expand learning, explore new perspectives and reimagine new possibilities, every day. We look for people who want to bring their best — bold thinkers with big hearts who challenge one other and grow together. Because becoming the undisputed leader in food means surrounding ourselves with people who are hungry for what’s next. Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company General Mills India 57,915 followers Follow Manufacturing 1,001-5,000 employees 813 on LinkedIn We exist to make food the world loves. But we do more than that. General Mills is a place that prioritizes being a force for good, a place to expand learning, explore new perspectives and reimagine new possibilities, every day. We look for people who want to bring their best—bold thinkers with big hearts who challenge one other and grow together. Because becoming the undisputed leader in food means surrounding ourselves with people who are hungry for what’s next. … show more Show more","About the job About General Mills We make food the world loves: 100 brands. In 100 countries. Across six continents . With iconic brands like Cheerios, Pillsbury, Betty Crocker, Nature Valley, and Häagen-Dazs, we’ve been serving up food the world loves for 155 years (and counting). Each of our brands has a unique story to tell. How we make our food is as important as the food we make. Our values are baked into our legacy and continue to accelerate us into the future as an innovative force for good. General Mills was founded in 1866 when Cadwallader Washburn boldly bought the largest flour mill west of the Mississippi. That pioneering spirit lives on today through our leadership team who upholds a vision of relentless innovation while being a force for good. For more details, check out http://www.generalmills.com General Mills India Center (GIC) is our global capability center in Mumbai that works as an extension of our global organization, delivering business value, service excellence and growth, while standing for good for our planet and people. With our team of 1800+ professionals, we deliver superior value across the areas of Supply chain (SC), Digital & Technology (D&T) Innovation, Technology & Quality (ITQ), Consumer and Market Intelligence (CMI), Sales Strategy & Intelligence (SSI), Global Shared Services (GSS), Finance Shared Services (FSS) and Human Resources Shared Services (HRSS). For more details, check out https://www.generalmills.co.in We advocate for advancing equity and inclusion to create more equitable workplaces and a better tomorrow. Job Overview Function Overview The Digital and Technology team at General Mills stands as the largest and foremost unit, dedicated to exploring the latest trends and innovations in technology while leading the adoption of cutting-edge technologies across the organization. Collaborating closely with global business teams, the focus is on understanding business models and identifying opportunities to leverage technology for increased efficiency and disruption. The team's expertise spans a wide range of areas, including AI/ML, Data Science, IoT, NLP, Cloud, Infrastructure, RPA and Automation, Digital Transformation, Cyber Security, Blockchain, SAP S4 HANA and Enterprise Architecture. The MillsWorks initiative embodies an agile@scale delivery model, where business and technology teams operate cohesively in pods with a unified mission to deliver value for the company. Employees working on significant technology projects are recognized as Digital Transformation change agents. The team places a strong emphasis on service partnerships and employee engagement with a commitment to advancing equity and supporting communities. In fostering an inclusive culture, the team values individuals passionate about learning and growing with technology, exemplified by the ""Work with Heart"" philosophy, emphasizing results over facetime. Those intrigued by the prospect of contributing to the digital transformation journey of a Fortune 500 company are encouraged to explore more details about the function through the provided Link Purpose of the role General Mills, Digital and Technology India, is seeking a Lead ML Engineer to join our dynamic and innovative Global Data Science team. In this role, you are a critical member of the data science group focused on leading efforts in migrating ML-based solutions from concept to production-level operational excellence. You will lead initiatives building scalable, resilient, and automated solutions in GCP (Google Cloud Platform) to ensure that models deliver on organizational objectives. You will professionally engineer solutions considering notions of risk and FMEA (failure modes and effects analysis). The ideal candidate will have expertise in AI platforms, ML model development life cycle, model management including orchestration, deployment, and monitoring, GCP Vertex AI, and a proven track record of successful AI solution delivery. The ML Engineering capability is leveraged to fuel advanced AI/ML solutions driving decision-making for critical enterprise needs. It is also responsible for implementing and enhancing the community of practice to determine the best practices, standards, and MLOps frameworks to efficiently deliver enterprise data solutions at General Mills. This role works in close collaboration with Data Scientists, Data Engineers, Architects and other teams to support the analytic consumption needs. Enhances the performance of the models and automates the production pipelines to gain efficiency. Key Accountabilities Establish and Implement MLOps practices: Development of end-to-end MLOps framework and Machine Learning Pipeline using GCP, Vertex AI, and Software tools Serving Pipeline with multiple creation Vertex AI and GCP services. Improve ML pipeline documentation and understandability. Automate logging of model usage and predictions provided. Improve logging and diagnostic processes. Automate monitoring of models both for failures and degradation. Automate monitoring of data sources to identify issues and/or data changes. Design and implement dynamic re-training of ML pipelines using event-based or custom logic. Resource and Infra Monitoring configuration and pipeline development using GCP service. Branching strategies and Version Control using GitHub ML Pipeline orchestration and configuration using Airflow/Kubeflow. Code refactorization & coding best practices implementation as per industry standard Implementing MLOps practices on a project and establishing MLOps best practices: Lead the investigation and resolution of production issues, perform root cause analysis, and recommend changes to reduce/eliminate re-occurrence of issues. Optimize deployment and change control processes for models. Create and operationalize quality assurance processes for ML models. Lead the execution of ML Solutions @Scale: Partners with business stakeholders to design the right deliver value-added insights and intelligent solutions through ML and AI. Collaborates with Data Science Leads, ML System Engineering and Platform teams to ensure the models are deployed in a scaled and optimized way. Additionally, ensure support the post-production to ensure model performance degrades are proactively managed. Play a lead role in spearheading the development effort of new standards (design patterns, coding practices, orchestration patterns) and drive value and adoption across the Data Science team. Is considered an expert in the ML Ops and Model management space; brings together business knowledge, architecture, resources, people, and technology to create more effective solutions. Research, Evolve And Publish Best Practices Research and operationalize technology and processes necessary to scale ML Ops Recommend model changes to optimize cloud spend. Ability to research and recommend MLOps best practices on new technologies, platforms, and services. Drive ideation, design, and creation of new ML Architecture patterns in discussion with the Enterprise Architecture team. MLOps pipeline improvement plan and suggestion Communication And Collaboration Knowledge sharing with the broader analytics team and stakeholders. Communicate on the on-goings to embrace the remote and geographical culture. Ability to communicate the accomplishments, failures, and risks in timely manner. Knowledge sharing session with team for specific ML Ops topics. Coach and Mentor junior ML members in the team. Foster a collaborative and innovative team environment. Contribute to the overall effort to educate stakeholders on AI practices. Closely collaborates with the stakeholders on projects and data science leaders to ensure practices are developed and enhanced to support accelerated analytic development and maintainability Embrace a Learning Mindset Continually invest in one’s knowledge and skillset through formal training, reading, and attending conferences and meetups Minimum Qualifications Full-time graduate from an accredited University. Advanced degree in a quantitative field (CS, engineering, statistics, math, data science). Proven technical leadership in a large, complex matrixed organization. Relevant Machine Learning experience of 6+ years and overall 12+ years of Industry experience. Experience in supervised ML algorithms, optimization, and performance tuning. Track record of producing machine learning models and production infrastructure at scale. Strong verbal and written communication skills including the ability to interact effectively with colleagues of varying technical and non-technical abilities. Passionate about agile software processes, data-driven development, reliability, and systematic experimentation. Passion for learning new technologies and solving challenging problems. Good understanding of CI, CD, TDD, and tools such as Jenkins. Strong understanding of orchestration frameworks such Airflow/Kubeflow/MLFlow. Agile software development experience such as Kanban and Scrum. Experience in software version control team practices and tools such as GIT and TFS. Expertise in Data Transformation and Manipulation through Big-Query/SQL Professional experience with Vertex AI and GCP Services. Strong proficiency in Python. Preferred Qualifications GCP Machine Learning certification Understanding of CPG industry Exposure to Deep Learning/RL/LLMs Prior experience with CPG industry. Publications or contributions to the data science and AI community. Certifications in AI, machine learning, or related fields. Company Overview We exist to make food the world loves. But we do more than that. Our company is a place that prioritizes being a force for good, a place to expand learning, explore new perspectives and reimagine new possibilities, every day. We look for people who want to bring their best — bold thinkers with big hearts who challenge one other and grow together. Because becoming the undisputed leader in food means surrounding ourselves with people who are hungry for what’s next.",,,"Python, SQL, Machine Learning",
4218975475,Elastic Search Developer,Infosys,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Technology->DevOps->Continuous delivery - Continuous deployment and release->Elastic Logstash and Kibana (ELK) A day in the life of an Infoscion As part of the Infosys delivery team, your primary role would be to interface with the client for quality assurance, issue resolution and ensuring high customer satisfaction. You will understand requirements, create and review designs, validate the architecture and ensure high levels of service offerings to clients in the technology domain. You will participate in project estimation, provide inputs for solution delivery, conduct technical risk planning, perform code reviews and unit test plan reviews. You will lead and guide your teams towards developing optimized high quality code deliverables, continual knowledge management and adherence to the organizational guidelines and processes. You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! Knowledge of more than one technology Basics of Architecture and Design fundamentals Knowledge of Testing tools Knowledge of agile methodologies Understanding of Project life cycle activities on development and maintenance projects Understanding of one or more Estimation methodologies, Knowledge of Quality processes Basics of business domain to understand the business requirements Analytical abilities, Strong Technical Skills, Good communication skills Good understanding of the technology and domain Ability to demonstrate a sound understanding of software quality assurance principles, SOLID design principles and modelling methods Awareness of latest technologies and trends Excellent problem solving, analytical and debugging skills",,,,
4232867169,Senior Machine Learning Engineer,Oracle,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Job Description Oracle Cloud Infrastructure (OCI) is a strategic growth area for Oracle. It is a comprehensive cloud service offering in the enterprise software industry, spanning Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). OCI is currently building a future-ready Gen2 cloud Data Science service platform. At the core of this platform, lies Cloud AI Cloud Service. What OCI AI Cloud Services are: A set of services on the public cloud, that are powered by ML and AI to meet the Enterprise modernization needs, and that work out of the box. These services and models can be easily specialized for specific customers/domains by demonstrating existing OCI services. Key Points: Enables customers to add AI capabilities to their Apps and Workflows easily via APIs or Containers, Useable without needing to build AI expertise in-house and Covers key gaps – Decision Support, NLP, for Public Clouds and Enterprise in NLU, NLP, Vision and Conversational AI. You’re Opportunity: As we innovate to provide a single collaborative ML environment for data-science professionals, we will be extremely happy to have you join us and share the very future of our Machine Learning platform - by building an AI Cloud service. We are addressing exciting challenges at the intersection of artificial intelligence and innovative cloud infrastructure. We are building cloud services in Computer vision for Image/Video and Document Analysis, Decision Support (Anomaly Detection, Time series forecasting, Fraud detection, Content moderation, Risk prevention, predictive analytics), Natural Language Processing (NLP), and, Speech that works out of the box for enterprises. Our product vision includes the ability for enterprises to be able to customize the services for their business and train them to specialize in their data by creating micro models that enhance the global AI models. What You’ll Do Develop scalable infrastructure, including microservices and a backend, that automates training, deployment, and optimization of ML model inference. Building a core of Artificial Intelligence and AI services such as Vision, Speech, Language, Decision, and others. Brainstorm and design various POCs using AI Perpetual AI Services for new or existing enterprise problems. Collaborate with fellow data scientists/SW engineers to build out other parts of the infrastructure, effectively communicating your needs, understanding theirs, and addressing external and internal shareholder product challenges. Lead research and development efforts to explore new tools, frameworks, and methodologies to improve backend development processes. Experiment with ML models in Python/C++ using machine learning libraries (Pytorch, ONNX, TensorRT, Triton, TensorFlow, Jax), etc. Leverage Cloud technology – Oracle Cloud (OCI), AWS, GCP, Azure, or similar technology. Qualifications Master’s degree or equivalent experience (preferred) in computer science, Statistics or Mathematics, artificial intelligence, machine learning, Computer vision, operations research, or related technical field. 3+ years for PhD or equivalent experience, 5+ years for Masters, or demonstrated ability designing, implementing, and deploying machine learning models in production environments. Practical experience in design, implementation, and production deployment of distributed systems using microservices architecture and APIs using common frameworks like Spring Boot (Java), etc. Practical experience working in a cloud environment: Oracle Cloud (OCI), AWS, GCP, Azure, and containerization (Docker, Kubernetes). Working knowledge of current techniques, approaches, and inference optimization strategies in machine learning models. Experience with performance tuning, scalability, and load balancing techniques. Expert in at least one high-level language such as Java/C++ (Java preferred). Expert in at least one scripting language such as Python, Javascript, and Shell . Deep understanding of data structures, and algorithms, and excellent problem-solving skills. Experience or willingness to learn and work in Agile and iterative development and DevOps processes. Strong drive to learn and master new technologies and techniques. You enjoy a fast-paced work environment. Additional Preferred Qualifications Experience with Cloud Native Frameworks tools and products is a plus Experience in Computer vision tasks like Image Classification, Object Detection, Segmentation, Text detection & recognition, Information extraction from documents, etc. Having an impressive set of GitHub projects or contributions to open-source technologies is a plus Hands-on experience with horizontally scalable data stores such as Hadoop and other NoSQL technologies like Cassandra is a plus. Our vision is to provide an immersive AI experience on Oracle Cloud. Aggressive as it might sound, our growth journey is fueled by highly energetic, technology-savvy engineers like YOU who are looking to grow with us to meet the demands of building a powerful next-generation platform. Are you ready to do something big? Career Level - IC3 About Us As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s challenges. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. We know that true innovation starts when everyone is empowered to contribute. That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States. Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.",manager,,"Python, Machine Learning",
4214708283,"Digital & AI/ML Senior Engineer (Python, R/Java)",Franklin Templeton India,"Hyderabad, Telangana, India",,Full-time,,"About the job At Franklin Templeton, we’re driving our industry forward by developing new and innovative ways to help our clients achieve their investment goals. Our dynamic and diversified firm spans asset management, wealth management, and fintech, offering many ways to help investors make progress toward their goals. Our talented teams working around the globe bring expertise that’s both broad and unique. From our welcoming, inclusive, and flexible culture to our global and diverse business, we offer opportunities not only to help you reach your potential but also to contribute to our clients’ achievements. Come join us in delivering better outcomes for our clients around the world! What is the “AI/ML Senior Engineer” in FTT AI & Digital Transformation group responsible for? The AI/ML Engineer in the FTT AI & Digital Transformation group is responsible for researching and developing state-of-the-art generative AI tools and products. These tools aim to enhance the productivity and efficiency of our internal teams, specifically the sales, distribution, and operations teams. The role involves conducting extensive research and performing proof-of-concept work to validate the feasibility and effectiveness of AI models. The engineer will collaborate with cross-functional teams to integrate AI solutions seamlessly into existing workflows. Additionally, the AI/ML Engineer is expected to stay abreast of the latest advancements in AI and machine learning to ensure our solutions are cutting-edge and competitive. Research And Proof-of-Concept Work The role includes a significant focus on research work to explore the potential of new AI technologies and methodologies. This involves experimenting with different algorithms and models to identify the most effective solutions for our needs. Proof-of-concept work is crucial to demonstrate the practicality and benefits of these AI solutions before full-scale implementation. What are the ongoing responsibilities of AI/ML Senior Engineer? Developing AI-powered tools: Design, implement, and maintain generative AI systems to support the needs of internal teams. Ensure these tools are scalable, reliable, and efficient for daily use. Conducting research: Regularly explore and analyze new AI trends and technologies to incorporate the latest advancements into our products. This includes reading research papers, attending conferences, and participating in industry forums. Proof-of-concept (PoC) work: Create PoCs to evaluate the feasibility and performance of different AI models. Use these PoCs to demonstrate the potential benefits to stakeholders and guide decision-making. Collaborating with teams: Work closely with sales, distribution, and operations teams to understand their needs and challenges. Tailor AI solutions to address specific pain points and improve overall efficiency. Data preprocessing and analysis: Clean, preprocess, and analyze large datasets to extract meaningful insights. Use these insights to train and optimize AI models. Integration and deployment: Integrate AI models into existing systems and workflows. Ensure smooth deployment and monitor the performance of these models in a production environment. Documentation and reporting: Maintain comprehensive documentation of AI models, algorithms, and systems. Regularly report progress and results to stakeholders. Mentorship and knowledge sharing: Provide guidance and mentorship to junior team members. Share knowledge and best practices to foster a collaborative and innovative work environment. What ideal qualifications, skills & experience would help someone to be successful? Bachelor’s degree in Computer Science, Data Science, Machine Learning, or a related field. A master’s or Ph.D. is preferred. Strong understanding of machine learning algorithms, deep learning frameworks, and statistical analysis. Proficiency in programming languages such as Python, R, or Java. Work Experience 2-8 years of experience in AI/ML engineering or a related field. Proven track record of developing and deploying AI solutions in a production environment. Experience with data preprocessing, model training, and optimization techniques. Familiarity with cloud platforms and tools for AI/ML development and deployment. Strong problem-solving skills and the ability to work in a fast-paced, collaborative environment. Job Level - Individual Contributor Work Shift Timings - 2:00 PM - 11:00 PM IST Experience our welcoming culture and reach your professional and personal potential! Our culture is shaped by our diverse global workforce and strongly held core values. Regardless of your interests, lifestyle, or background, there’s a place for you at Franklin Templeton. We provide employees with the tools, resources, and learning opportunities to help them excel in their career and personal life. Hear more from our employees By joining us, you will become part of a culture that focuses on employee well-being and provides multidimensional support for a positive and healthy lifestyle. We understand that benefits are at the core of employee well-being and may vary depending on individual needs. Whether you need support for maintaining your physical and mental health, saving for life’s adventures, taking care of your family members, or making a positive impact in your community, we aim to have them covered. Highlights Of Our Benefits Include Professional development growth opportunities through in-house classes and over 150 Web-based training courses An educational assistance program to financially help employees seeking continuing education Medical, Life and Personal Accident Insurance benefit for employees. Medical insurance also cover employee’s dependents (spouses, children and dependent parents) Life insurance for protection of employees’ families Personal accident insurance for protection of employees and their families Personal loan assistance Employee Stock Investment Plan (ESIP) 12 weeks Paternity leave Onsite fitness center, recreation center, and cafeteria Transport facility Child day care facility for women employees Cricket grounds and gymnasium Library Health Center with doctor availability HDFC ATM on the campus Learn more about the wide range of benefits we offer at Franklin Templeton Franklin Templeton is an Equal Opportunity Employer. We are committed to providing equal employment opportunities to all applicants and existing employees, and we evaluate qualified applicants without regard to ancestry, age, color, disability, genetic information, gender, gender identity, or gender expression, marital status, medical condition, military or veteran status, national origin, race, religion, sex, sexual orientation, and any other basis protected by federal, state, or local law, ordinance, or regulation. Franklin Templeton is committed to fostering a diverse and inclusive environment. If you believe that you need an accommodation or adjustment to search for or apply for one of our positions, please send an email to accommodations@franklintempleton.com. In your email, please include the accommodation or adjustment you are requesting, the job title, and the job number you are applying for. It may take up to three business days to receive a response to your request. Please note that only accommodation requests will receive a response.",manager,,"Python, Excel, R, Machine Learning",
4248677302,AI Integration Engineer on AWS IRC265094,GlobalLogic,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Description Responsibilities Build and integrate AI-powered features using third-party models (e.g., OpenAI, Cohere, Hugging Face, Google Cloud AI). Design robust API integrations, pipelines, and workflows using LLMs or other foundation models. Collaborate with product managers, designers, and backend/frontend teams to ship features like chatbots, summarizers, smart search, etc. Handle AI prompt tuning, caching, rate limiting, and fallback mechanisms. Monitor and optimize AI feature performance (latency, cost, token usage). Ensure AI usage is safe, ethical, and aligns with business goals. Keep up with the fast-moving AI landscape and make recommendations for tools and services. Must-Have Skills 3+ years of software development experience (preferably in full-stack or backend roles). Solid Experience With Python, Node.js, Or Another Backend Language. Familiarity with RESTful APIs, cloud platforms (AWS, GCP, Azure), and AI-as-a-service offerings. Experience integrating with LLMs (e.g., OpenAI GPT APIs) or AI APIs (e.g., image, vision, speech). Ability to write clean, maintainable, and scalable code. Comfortable working in cross-functional teams in agile environments. Nice-to-Have Skills Experience with LangChain, RAG systems, or vector databases (e.g., Pinecone, Weaviate). Familiarity with prompt engineering and chaining logic. Exposure to frontend frameworks (React, Next.js) is a plus. Understanding of LLM performance tuning and observability tools. Prior work on AI agents, copilots, or workflow automation with AI tools. Nice-to-Haves Experience with LangChain, Semantic Kernel, or LLM orchestration frameworks. Familiarity with vector databases (Pinecone, Weaviate, Amazon Kendra). Exposure to frontend dev (React, Next.js) for building AI-first UIs. Background in conversational UX or prompt design. Understanding of AI safety, prompt injection, and red-teaming strategies. What You’ll Get Work with a team of AI-native builders — devs who ship fast with LLMs, not just talk about them. Access to cutting-edge tooling: Cursor AI, Bedrock, Claude, GPT-4, and more. Autonomy and support to explore, test, and launch new AI features. An environment that values speed, creativity, and pragmatism. Learning budget for conferences, courses, and AI tinkering. Requirements About the Role We’re building the next generation of AI-native products — fast, smart, and deeply user-centric. As an AI Application Engineer, your mission is to bring intelligence into real-world apps. You won’t be building models from scratch — instead, you’ll work with cutting-edge tools like Cursor AI for AI-native dev workflows and AWS Bedrock for scalable, secure access to foundation models. If you get excited about hacking together LLM workflows, building smart assistants, and crafting AI features users love (and trust), we want you on the team. What You’ll Do Design and build AI-powered product features using foundation models via AWS Bedrock (Anthropic, Cohere, Mistral, Amazon Titan, etc.). Rapidly prototype and ship features using AI-native dev environments like Cursor AI. Integrate LLMs and other AI APIs into real products — chat, summarization, intelligent search, document processing, and more. Own the full lifecycle of AI features: from idea to prompt design to API integration to production rollout. Build scalable, efficient, and observable AI workflows using best practices (prompt caching, rate limiting, retry logic). Collaborate closely with designers, PMs, and full-stack engineers to co-design intuitive, AI-first experiences. Track performance, reduce latency and costs, and improve user trust in AI responses. Stay up to date on rapidly evolving AI APIs and dev tools — and bring your learnings back to the team. Job responsibilities Responsibilities Build and integrate AI-powered features using third-party models (e.g., OpenAI, Cohere, Hugging Face, Google Cloud AI). Design robust API integrations, pipelines, and workflows using LLMs or other foundation models. Collaborate with product managers, designers, and backend/frontend teams to ship features like chatbots, summarizers, smart search, etc. Handle AI prompt tuning, caching, rate limiting, and fallback mechanisms. Monitor and optimize AI feature performance (latency, cost, token usage). Ensure AI usage is safe, ethical, and aligns with business goals. Keep up with the fast-moving AI landscape and make recommendations for tools and services. Must-Have Skills 3+ years of software development experience (preferably in full-stack or backend roles). Solid Experience With Python, Node.js, Or Another Backend Language. Familiarity with RESTful APIs, cloud platforms (AWS, GCP, Azure), and AI-as-a-service offerings. Experience integrating with LLMs (e.g., OpenAI GPT APIs) or AI APIs (e.g., image, vision, speech). Ability to write clean, maintainable, and scalable code. Comfortable working in cross-functional teams in agile environments. Nice-to-Have Skills Experience with LangChain, RAG systems, or vector databases (e.g., Pinecone, Weaviate). Familiarity with prompt engineering and chaining logic. Exposure to frontend frameworks (React, Next.js) is a plus. Understanding of LLM performance tuning and observability tools. Prior work on AI agents, copilots, or workflow automation with AI tools. Nice-to-Haves Experience with LangChain, Semantic Kernel, or LLM orchestration frameworks. Familiarity with vector databases (Pinecone, Weaviate, Amazon Kendra). Exposure to frontend dev (React, Next.js) for building AI-first UIs. Background in conversational UX or prompt design. Understanding of AI safety, prompt injection, and red-teaming strategies. What You’ll Get Work with a team of AI-native builders — devs who ship fast with LLMs, not just talk about them. Access to cutting-edge tooling: Cursor AI, Bedrock, Claude, GPT-4, and more. Autonomy and support to explore, test, and launch new AI features. An environment that values speed, creativity, and pragmatism. Learning budget for conferences, courses, and AI tinkering. What we offer Culture of caring. At GlobalLogic, we prioritize a culture of caring. Across every region and department, at every level, we consistently put people first. From day one, you’ll experience an inclusive culture of acceptance and belonging, where you’ll have the chance to build meaningful connections with collaborative teammates, supportive managers, and compassionate leaders. Learning and development. We are committed to your continuous learning and development. You’ll learn and grow daily in an environment with many opportunities to try new things, sharpen your skills, and advance your career at GlobalLogic. With our Career Navigator tool as just one example, GlobalLogic offers a rich array of programs, training curricula, and hands-on opportunities to grow personally and professionally. Interesting & meaningful work. GlobalLogic is known for engineering impact for and with clients around the world. As part of our team, you’ll have the chance to work on projects that matter. Each is a unique opportunity to engage your curiosity and creative problem-solving skills as you help clients reimagine what’s possible and bring new solutions to market. In the process, you’ll have the privilege of working on some of the most cutting-edge and impactful solutions shaping the world today. Balance and flexibility. We believe in the importance of balance and flexibility. With many functional career areas, roles, and work arrangements, you can explore ways of achieving the perfect balance between your work and life. Your life extends beyond the office, and we always do our best to help you integrate and balance the best of work and life, having fun along the way! High-trust organization. We are a high-trust organization where integrity is key. By joining GlobalLogic, you’re placing your trust in a safe, reliable, and ethical global company. Integrity and trust are a cornerstone of our value proposition to our employees and clients. You will find truthfulness, candor, and integrity in everything we do. About GlobalLogic GlobalLogic, a Hitachi Group Company, is a trusted digital engineering partner to the world’s largest and most forward-thinking companies. Since 2000, we’ve been at the forefront of the digital revolution – helping create some of the most innovative and widely used digital products and experiences. Today we continue to collaborate with clients in transforming businesses and redefining industries through intelligent products, platforms, and services.",manager,,Python,
4245529182,AI Fullstack Engineer,Uplers,"Amritsar, Punjab, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - HurixDigital) What do you need for this opportunity? Must have skills required: Python, LLM, Rag (retrieval-augmented generation), AWS HurixDigital is Looking for: Job Summary We are seeking a highly skilled and innovative AI Engineer with Full Stack capabilities to join our dynamic team. The ideal candidate will bring a strong blend of expertise in artificial intelligence, modern software engineering practices, and cloud infrastructure. You will be responsible for designing, developing, and deploying intelligent applications that are scalable, resilient, and deliver real business value. Key Responsibilities Develop and deploy end-to-end AI-powered applications leveraging full-stack development best practices. Architect and integrate AI/ML models and pipelines using tools like LangChain, Hugging Face, OpenAI, and Anthropic Claude APIs. Design and implement microservices, RESTful APIs, and backend systems with scalability and maintainability in mind. Leverage cloud platforms (AWS, Azure, GCP) for hosting, automation, and scaling services. Integrate CI/CD pipelines to ensure smooth and frequent deployment cycles. Collaborate with cross-functional teams to translate business requirements into technical solutions. Apply techniques such as content chunking, vector search, embedding models, and retrievers to build advanced AI retrieval systems. Ensure robust architecture that can withstand variable load conditions, focusing on fault tolerance and high availability. Maintain documentation and adhere to best practices in software development and AI model integration. Required Qualifications Bachelor's or Master's degree in Computer Science, Engineering, or a related field. 5+ years of hands-on experience in AI engineering and full-stack development. Strong proficiency with AI/ML tools including LangChain, Hugging Face, OpenAI, and Claude APIs. Deep understanding of vector databases, retrievers, and modern NLP workflows. Proficient in one or more full-stack frameworks (e.g., Node.js, Django, React, Angular). Experience with Python Experience with cloud platforms (AWS, Azure, GCP) and infrastructure automation tools (e.g., Terraform, CloudFormation). Solid experience with CI/CD pipelines, GitOps, and container orchestration (e.g., Docker, Kubernetes). Proven ability to architect resilient systems and optimize performance under fluctuating workloads. Preferred Skills Knowledge of prompt engineering and LLM fine-tuning techniques. Familiarity with DevSecOps practices and AI compliance requirements. Exposure to multimodal models and real-time inference systems. What We Offer Opportunity to work on cutting-edge AI products and tools. Collaborative and inclusive team environment. Flexible work schedule and remote work options. Competitive salary and performance bonuses. How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Python, LLM, Rag (retrieval-augmented generation), AWS",,,Python,
4239591506,Senior Machine Learning Engineer,AB InBev APAC,Greater Nashik Area (On-site),On-site,Full-time,,"About the job Dreaming big is in our DNA. It’s who we are as a company. It’s our culture. It’s our heritage. And more than ever, it’s our future. A future where we’re always looking forward. Always serving up new ways to meet life’s moments. A future where we keep dreaming bigger. We look for people with passion, talent, and curiosity, and provide them with the teammates, resources and opportunities to unleash their full potential. The power we create together – when we combine your strengths with ours – is unstoppable. Are you ready to join a team that dreams as big as you do? AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics. Do You Dream Big? We Need You. Job Description Job Title: Senior Machine Learning Engineer Location: Bangalore Reporting to: Senior Manager Purpose of the role Anheuser-Busch InBev (AB InBev)ʼs Forecasting team is seeking a Senior Machine Learning Engineer. This role is ideal for someone passionate about designing and maintaining robust forecasting systems, building scalable ML pipelines, and enabling productization of time series models in a cloud-native environment. work at the intersection of MLOps, statistical modeling, and backend systems—empowering users to build and test their own forecasting models through a frontend application (maintained by a separate UI team). Key tasks & accountabilities Lead forecasting package development and ensure code modularity, extensibility, and reliability for production use. Design and maintain ML pipelines for model training, evaluation, and deployment using Docker, Airflow, and Kubernetes (AKS). Collaborate with product and frontend teams to enable seamless user interaction with model-building workflows via internal platforms. Establish and enforce best practices around testing, CI/CD, containerization, and monitoring for ML applications. Contribute to and scale existing solutions for time series forecasting across multiple markets and product lines. Evaluate new algorithms, tools, and frameworks to enhance our forecasting capabilities and infrastructure. Mentor junior engineers and promote knowledge sharing within the team. Qualifications, Experience, Skills Level Of Educational Attainment Required Bachelor's or Master's degree in Computer Science, Data Science, Engineering, or a related field Previous Work Experience 6+ years of industry experience in machine learning engineering with a strong focus on time series forecasting and MLOps. Proficiency in Python with hands-on experience in scientific computing and ML libraries (e.g., `scikit-learn`, `pmdarima`, `Prophet`, `XGBoost`, etc.). Strong experience with containerized environments using Docker and orchestrating workloads on Kubernetes (AKS preferred). Proficient with workflow orchestration tools like Airflow for managing ETL and model pipelines. Hands-on experience deploying and maintaining ML systems in production, including monitoring and logging. Familiarity with API development (e.g., FastAPI, Flask) and backend integration for ML apps. Solid understanding of CI/CD tools and practices (e.g., GitHub Actions, Azure DevOps). Preferred Skills Experience in developing or maintaining internal Python packages for data science workflows. Working knowledge of Azure ecosystem (e.g., Azure ML, Blob Storage, AKS). Exposure to frontend-backend communication patterns and RESTful service integration. Understanding of software engineering best practices: code versioning, testing, modular design. Exposure to time series modeling and evaluation techniques in a business context. Why join us Work with a collaborative and impact-driven team that’s transforming forecasting at scale. Contribute to internal tools used by analysts and data scientists globally. Opportunity to mentor, influence architecture, and shape MLOps best practices. And above all of this, an undying love for beer! We dream big to create future with more cheers",Manager,,"Python, Machine Learning",
4258593260,Machine Learning Engineer - Data Modeling,QAAgility Technologies,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job This job is sourced from a job board. Learn More Role : Machine Learning and AI Engineer Exp : 4+ Years Type : Hybrid Location : Bangalore We are looking for a skilled Mid-Level AI Engineer with extensive experience in building full-stack AI solutions. The ideal candidate will have a strong foundation in Machine Learning and Deep Learning algorithms, proficient in frameworks like TensorFlow and PyTorch. Expertise in Large Language Models (LLMs) such as OpenAI, Gemini, DeepSeek and other reasoning models. Familiarity with Knowledge Graphs is a plus. Additional qualifications include proficiency in Python frameworks like FastAPI and Django, along with extensive experience on Azure platforms - including App Service, Blob, Cosmos DB, Databricks, and Azure Machine Learning. Familiarity with containerization technologies such as Docker and orchestration tools like Kubernetes is highly desirable. Design and implement full-stack AI solutions using a variety of Machine Learning and Deep Learning algorithms. Develop and optimize algorithms for NLP and Computer Vision applications utilizing frameworks such as TensorFlow and PyTorch. Work with Large Language Models (LLMs) such as OpenAI, Gemini, or LLama to create intelligent applications. Leverage Azure platforms (App Service, Blob, Cosmos DB, Databricks, and Azure Machine Learning) to enhance application deployment and scalability. Apply algorithms rigorously to solve complex problems in AI, ensuring performance and accuracy in models. Build Python-based applications with frameworks like FastAPI and Django that integrate seamlessly with AI solutions. Collaborate with interdisciplinary teams to gather requirements and translate them into technical specifications. Utilize containerization (Docker) and orchestration (Kubernetes) technologies to optimize deployment workflows and enhance operational efficiency. Stay updated on the latest advancements in algorithms and methodologies in Machine Learning and Deep Learning. Bachelors or Masters degree in Computer Science, Engineering, or a related field. Proven experience in developing AI solutions with a solid understanding of Machine Learning and Deep Learning algorithms. Strong expertise in frameworks such as TensorFlow and PyTorch for model development. Demonstrated experience with NLP and Computer Vision applications. Proficient in working with Large Language Models (OpenAI, Gemini, LLama). Extensive experience with Azure platforms, specifically App Service, Blob, Cosmos DB, Databricks, and Azure Machine Learning. Strong knowledge of Python frameworks such as FastAPI and Django. Familiarity with containerization technologies (Docker) and orchestration tools (Kubernetes) is highly desirable. Excellent problem-solving abilities and capacity to work in a dynamic environment. (ref:hirist.tech)",,,"Python, Machine Learning",
4232865357,Senior Machine Learning Engineer,Oracle,"Ahmedabad, Gujarat, India (On-site)",On-site,Full-time,,"About the job Job Description Oracle Cloud Infrastructure (OCI) is a strategic growth area for Oracle. It is a comprehensive cloud service offering in the enterprise software industry, spanning Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). OCI is currently building a future-ready Gen2 cloud Data Science service platform. At the core of this platform, lies Cloud AI Cloud Service. What OCI AI Cloud Services are: A set of services on the public cloud, that are powered by ML and AI to meet the Enterprise modernization needs, and that work out of the box. These services and models can be easily specialized for specific customers/domains by demonstrating existing OCI services. Key Points: Enables customers to add AI capabilities to their Apps and Workflows easily via APIs or Containers, Useable without needing to build AI expertise in-house and Covers key gaps – Decision Support, NLP, for Public Clouds and Enterprise in NLU, NLP, Vision and Conversational AI. You’re Opportunity: As we innovate to provide a single collaborative ML environment for data-science professionals, we will be extremely happy to have you join us and share the very future of our Machine Learning platform - by building an AI Cloud service. We are addressing exciting challenges at the intersection of artificial intelligence and innovative cloud infrastructure. We are building cloud services in Computer vision for Image/Video and Document Analysis, Decision Support (Anomaly Detection, Time series forecasting, Fraud detection, Content moderation, Risk prevention, predictive analytics), Natural Language Processing (NLP), and, Speech that works out of the box for enterprises. Our product vision includes the ability for enterprises to be able to customize the services for their business and train them to specialize in their data by creating micro models that enhance the global AI models. What You’ll Do Develop scalable infrastructure, including microservices and a backend, that automates training, deployment, and optimization of ML model inference. Building a core of Artificial Intelligence and AI services such as Vision, Speech, Language, Decision, and others. Brainstorm and design various POCs using AI Perpetual AI Services for new or existing enterprise problems. Collaborate with fellow data scientists/SW engineers to build out other parts of the infrastructure, effectively communicating your needs, understanding theirs, and addressing external and internal shareholder product challenges. Lead research and development efforts to explore new tools, frameworks, and methodologies to improve backend development processes. Experiment with ML models in Python/C++ using machine learning libraries (Pytorch, ONNX, TensorRT, Triton, TensorFlow, Jax), etc. Leverage Cloud technology – Oracle Cloud (OCI), AWS, GCP, Azure, or similar technology. Qualifications Master’s degree or equivalent experience (preferred) in computer science, Statistics or Mathematics, artificial intelligence, machine learning, Computer vision, operations research, or related technical field. 3+ years for PhD or equivalent experience, 5+ years for Masters, or demonstrated ability designing, implementing, and deploying machine learning models in production environments. Practical experience in design, implementation, and production deployment of distributed systems using microservices architecture and APIs using common frameworks like Spring Boot (Java), etc. Practical experience working in a cloud environment: Oracle Cloud (OCI), AWS, GCP, Azure, and containerization (Docker, Kubernetes). Working knowledge of current techniques, approaches, and inference optimization strategies in machine learning models. Experience with performance tuning, scalability, and load balancing techniques. Expert in at least one high-level language such as Java/C++ (Java preferred). Expert in at least one scripting language such as Python, Javascript, and Shell . Deep understanding of data structures, and algorithms, and excellent problem-solving skills. Experience or willingness to learn and work in Agile and iterative development and DevOps processes. Strong drive to learn and master new technologies and techniques. You enjoy a fast-paced work environment. Additional Preferred Qualifications Experience with Cloud Native Frameworks tools and products is a plus Experience in Computer vision tasks like Image Classification, Object Detection, Segmentation, Text detection & recognition, Information extraction from documents, etc. Having an impressive set of GitHub projects or contributions to open-source technologies is a plus Hands-on experience with horizontally scalable data stores such as Hadoop and other NoSQL technologies like Cassandra is a plus. Our vision is to provide an immersive AI experience on Oracle Cloud. Aggressive as it might sound, our growth journey is fueled by highly energetic, technology-savvy engineers like YOU who are looking to grow with us to meet the demands of building a powerful next-generation platform. Are you ready to do something big? Career Level - IC3 About Us As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s challenges. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. We know that true innovation starts when everyone is empowered to contribute. That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States. Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.",manager,,"Python, Machine Learning",
4222042567,EY - GDS Consulting - AI Enabled Automation - AI Engineer - Staff,EY,"Trivandrum, Kerala, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. AI Engineer Role Overview: We are seeking a highly skilled and experienced AI Engineers with a minimum of 2 years of experience in Data Science and Machine Learning, preferably with experience in NLP, Generative AI, LLMs, MLOps, Optimization techniques, and AI solution Architecture. In this role, you will play a key role in the development and implementation of AI solutions, leveraging your technical expertise. The ideal candidate should have a deep understanding of AI technologies and experience in designing and implementing cutting-edge AI models and systems. Additionally, expertise in data engineering, DevOps, and MLOps practices will be valuable in this role. Your technical responsibilities: Assist in the development and implementation of AI models and systems, leveraging techniques such as Large Language Models (LLMs) and generative AI. Design, develop, and maintain efficient, reusable, and reliable Python code Stay updated with the latest advancements in generative AI techniques, such as LLMs, and evaluate their potential applications in solving enterprise challenges. Utilize generative AI techniques, such as LLMs, Agentic Framework to develop innovative solutions for enterprise industry use cases. Integrate with relevant APIs and libraries, such as Azure Open AI GPT models and Hugging Face Transformers, to leverage pre-trained models and enhance generative AI capabilities. Utilize vector databases, such as Redis, and NoSQL databases to efficiently handle large-scale generative AI datasets and outputs. Implement similarity search algorithms and techniques to enable efficient and accurate retrieval of relevant information from generative AI outputs. Ensure compliance with data privacy, security, and ethical considerations in AI applications. Leverage data engineering skills to curate, clean, and preprocess large-scale datasets for generative AI applications. Write unit tests and conduct code reviews to ensure high-quality, bug-free software. Troubleshoot and debug applications to optimize performance and fix issues. Work with databases (SQL, NoSQL) and integrate third-party APIs. Requirements: Bachelor's or Master's degree in Computer Science, Engineering, or a related field. Minimum 2 years of experience in Python, Data Science, Machine Learning, OCR and document intelligence In-depth knowledge of machine learning, deep learning, and generative AI techniques. Proficiency in programming languages such as Python, R, and frameworks like TensorFlow or PyTorch. Strong understanding of NLP techniques and frameworks such as BERT, GPT, or Transformer models. Familiarity with computer vision techniques for image recognition, object detection, or image generation. Strong knowledge of Python frameworks such as Django, Flask, or FastAPI. Experience with RESTful API design and development. Experience with cloud platforms such as Azure, AWS, or GCP and deploying AI solutions in a cloud environment. Expertise in data engineering, including data curation, cleaning, and preprocessing. Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions. Strong communication and interpersonal skills, with the ability to collaborate effectively with stakeholders at various levels. Understanding of data privacy, security, and ethical considerations in AI applications. Good to Have Skills: Understanding of agentic AI concepts and frameworks Proficiency in designing or interacting with agent-based AI architectures Apply trusted AI practices to ensure fairness, transparency, and accountability in AI models and systems. Utilize optimization tools and techniques, including MIP (Mixed Integer Programming). Implement CI/CD pipelines for streamlined model deployment and scaling processes. Utilize tools such as Docker, Kubernetes, and Git to build and manage AI pipelines. Apply infrastructure as code (IaC) principles, employing tools like Terraform or CloudFormation. Implement monitoring and logging tools to ensure AI model performance and reliability. EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",,,"Python, SQL, R, Machine Learning",
4225321853,Senior Software Engineer (Machine Learning),Clarivate,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Clarivate is on the lookout for a Sr. Software Engineer ML (machine learning) to join our Patent Service team in Noida . The successful candidate will be responsible focus on supporting machine learning (ML) projects, for deploying, scaling, and maintaining ML models in production environments, working closely with data scientists, ML engineers, and software developers to architect robust infrastructure, implement automation pipelines, and ensure the reliability and scalability of our ML systems. The ideal candidate should be eager to learn, equipped with strong hands-on technical and analytical thinking skills, have a passion for teamwork, and staying updated with the latest technological trends. About You – Experience, Education, Skills, And Accomplishments Holding a Bachelor's in Engineering or a Master's degree (BE, ME, B.Tech, M.Tech, MCA, MS) with strong communication and reasoning abilities is required. Proven experience as a Machine Learning Engineer or similar position Deep knowledge of math, probability, statistics and algorithms Outstanding analytical and problem-solving skills Understanding of data structures, data modeling and software architecture Good understanding of ML concepts and frameworks (e.g., TensorFlow, Keras, PyTorch) Proficiency with Python and basic libraries for machine learning such as scikit-learn and pandas Expertise in Prompt engineering . Expertise in visualizing and manipulating big datasets Working experience for managing ML workload in production Implement and/ or practicing MLOps or LLMOps concepts Additionally, It Would Be Advantageous If You Have Experience in Terraform or similar, and IAC in general. Familiarity with AWS Bedrock. Experience with OCR engines and solutions, e.g. AWS Textract, Google Cloud Vision. Interest in exploring and adopting Data Science methodologies, and AI/ML technologies to optimize project outcomes. Experience working in a CI/CD setup with multiple environments, and with an ability to manage code and deployments towards incrementally faster releases. Experience with RDBMS and NoSQL databases, particularly MySQL or PostgreSQL. What will you be doing in this role? Overall, you will play a pivotal role in driving the success of the development projects and achieving business objectives through innovative and efficient agile software development practices. Designing and developing machine learning systems Implementing appropriate ML algorithms, analyzing ML algorithms that could be used to solve a given problem and ranking them by their success probability Running machine learning tests and experiments, perform statistical analysis and fine-tuning using test results, training and retraining systems when necessary Implement monitoring and alerting systems to track the performance and health of ML models in production. Ensure security best practices are followed in the deployment and management of ML systems. Optimize infrastructure for performance, scalability, and cost efficiency. Develop and maintain CI/CD pipelines for automated model training, testing, and deployment. Troubleshoot issues related to infrastructure, deployments, and performance of ML models. Stay up to date with the latest advancements in ML technologies, and evaluate their potential impact on our workflows. About The Team Our team comprises driven professionals who are deeply committed to leveraging technology to make a tangible impact in our field of the patent services area. Joining us, you'll thrive in a multi-region, cross-cultural environment, collaborating on cutting-edge technologies with a strong emphasis on a user-centric approach. At Clarivate, we are committed to providing equal employment opportunities for all qualified persons with respect to hiring, compensation, promotion, training, and other terms, conditions, and privileges of employment. We comply with applicable laws and regulations governing non-discrimination in all locations.",,,"Python, Machine Learning",
4223719594,Machine Learning/Node Js Engineer,Motorola Solutions,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Company Overview At Motorola Solutions, we believe that everything starts with our people. We’re a global close-knit community, united by the relentless pursuit to help keep people safer everywhere. Our critical communications, video security and command center technologies support public safety agencies and enterprises alike, enabling the coordination that’s critical for safer communities, safer schools, safer hospitals and safer businesses. Connect with a career that matters, and help us build a safer future. Department Overview Noggin, a Motorola Solutions company, is a leader in integrated resilience management technology, offering a next-generation, cloud-based platform that combines 10 essential solutions into one unified system. Our award-winning platform seamlessly integrates operational and third-party risk management, operational resilience, business continuity, incident and crisis management, emergency management, and security and safety operations. The Product Engineering area is responsible for designing, writing, testing and deploying the code for our software products at Noggin. Job Description Motorola Solutions is seeking a skilled and experienced Machine Learning Engineer be the ML specialist in one of our product engineering teams, designing and building an exciting new project. Responsibilities: Design and implement backend services using NodeJS in TypeScript. Develop secure and scalable cloud-based solutions on AWS to meet evolving customer needs. Apply Machine Learning skills and experience, and coach other team members in this field. Apply comprehensive testing strategies to ensure our products meet customer expectations, and continuously improve software engineering processes, including quality assurance, design, and innovation techniques. Provide technical advice to management, team leads, and customers, assist other teams as needed, and actively engage in technology chapter meetings. Basic Requirements Bachelors degree with 3+ years of software development experience AND 2+ years of Machine Learning experience(Preferably AWS bedrock) AND 1+ years of NodeJS experience AND 1+ years of AWS experience Travel Requirements None Relocation Provided None Position Type Experienced Referral Payment Plan No EEO Statement Motorola Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion or belief, sex, sexual orientation, gender identity, national origin, disability, veteran status or any other legally-protected characteristic. We are proud of our people-first and community-focused culture, empowering every Motorolan to be their most authentic self and to do their best work to deliver on the promise of a safer world. If you’d like to join our team but feel that you don’t quite meet all of the preferred skills, we’d still love to hear why you think you’d be a great addition to our team. We’re committed to providing an inclusive and accessible recruiting experience for candidates with disabilities, or other physical or mental health conditions. To request an accommodation, please complete this Reasonable Accommodations Form so we can assist you.",,,Machine Learning,
4255312360,"Sr. Data Science & AIML, GenAI Lead/Engineer",NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 312482 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Sr. Data Science & AIML, GenAI Lead/Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Job Title: Data Science & AIML, GenAI Lead/Engineer Key Responsibilities: Develop and implement traditional machine learning algorithms. Deploy at least one model in a production environment. Write and maintain Python code for data science and machine learning projects. Minimum Skills Required: Preferred Qualifications: Knowledge of Deep Learning (DL) techniques. Experience working with Generative AI (GenAI) and Large Language Models (LLM). Exposure to Langchain. #GenAINTT About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4250362430,AI Engineer - Sr Associate,PwC Acceleration Centers in India,"Bengaluru, Karnataka, India",,Full-time,,"About the job At PwC, our people in data and analytics engineering focus on leveraging advanced technologies and techniques to design and develop robust data solutions for clients. They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth. Those in data science and machine learning engineering at PwC will focus on leveraging advanced analytics and machine learning techniques to extract insights from large datasets and drive data-driven decision making. You will work on developing predictive models, conducting statistical analysis, and creating data visualisations to solve complex business problems. Focused on relationships, you are building meaningful client connections, and learning how to manage and inspire others. Navigating increasingly complex situations, you are growing your personal brand, deepening technical expertise and awareness of your strengths. You are expected to anticipate the needs of your teams and clients, and to deliver quality. Embracing increased ambiguity, you are comfortable when the path forward isn’t clear, you ask questions, and you use these moments as opportunities to grow. Skills Examples of the skills, knowledge, and experiences you need to lead and deliver value at this level include but are not limited to: Respond effectively to the diverse perspectives, needs, and feelings of others. Use a broad range of tools, methodologies and techniques to generate new ideas and solve problems. Use critical thinking to break down complex concepts. Understand the broader objectives of your project or role and how your work fits into the overall strategy. Develop a deeper understanding of the business context and how it is changing. Use reflection to develop self awareness, enhance strengths and address development areas. Interpret data to inform insights and recommendations. Uphold and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm's code of conduct, and independence requirements. Role Overview We are seeking a Senior Associate – AI Engineer / MLOps / LLMOps with a passion for building resilient, cloud-native AI systems. In this role, you’ll collaborate with data scientists, researchers, and product teams to build infrastructure, automate pipelines, and deploy models that power intelligent applications at scale. If you enjoy solving real-world engineering challenges at the convergence of AI and software systems, this role is for you. Key Responsibilities Architect and implement AI/ML/GenAI pipelines, automating end-to-end workflows from data ingestion to model deployment and monitoring. Develop scalable, production-grade APIs and services using FastAPI, Flask, or similar frameworks for AI/LLM model inference. Design and maintain containerized AI applications using Docker and Kubernetes. Operationalize Large Language Models (LLMs) and other GenAI models via cloud-native deployment (e.g., Azure ML, AWS Sagemaker, GCP Vertex AI). Manage and monitor model performance post-deployment, applying concepts of MLOps and LLMOps including model versioning, A/B testing, and drift detection. Build and maintain CI/CD pipelines for rapid and secure deployment of AI solutions using tools such as GitHub Actions, Azure DevOps, GitLab CI. Implement security, governance, and compliance standards in AI pipelines. Optimize model serving infrastructure for speed, scalability, and cost-efficiency. Collaborate with AI researchers to translate prototypes into robust production-ready solutions. Required Skills & Experience 4 to 9 years of hands-on experience in AI/ML engineering, MLOps, or DevOps for data science products. Bachelor's degree in Computer Science, Engineering, or related technical field (BE/BTech/MCA). Strong software engineering foundation with hands-on experience in Python, Shell scripting, and familiarity with ML libraries (scikit-learn, transformers, etc.). Experience deploying and maintaining LLM-based applications, including prompt orchestration, fine-tuned models, and agentic workflows. Deep understanding of containerization and orchestration (Docker, Kubernetes, Helm). Experience with CI/CD pipelines, infrastructure-as-code tools (Terraform, CloudFormation), and automated deployment practices. Proficiency in cloud platforms: Azure (preferred), AWS, or GCP – including AI/ML services (e.g., Azure ML, AWS Sagemaker, GCP Vertex AI). Experience managing and monitoring ML lifecycle (training, validation, deployment, feedback loops). Solid understanding of APIs, microservices, and event-driven architecture. Experience with model monitoring/orchestration tools (e.g, Kubeflow, MLflow). Exposure to LLMOps-specific orchestration tools such as LangChain, LangGraph, Haystack, or PromptLayer. Experience with serverless deployments (AWS Lambda, Azure Functions) and GPU-enabled compute instances. Knowledge of data pipelines using tools like Apache Airflow, Prefect, or Azure Data Factory. Exposure to logging and observability tools like ELK stack, Azure Monitor, or Datadog. Good to Have Experience implementing multi-model architecture, serving GenAI models alongside traditional ML models. Knowledge of data versioning tools like DVC, Delta Lake, or LakeFS. Familiarity with distributed systems and optimizing inference pipelines for throughput and latency. Experience with infrastructure cost monitoring and optimization strategies for large-scale AI workloads. It would be great if the candidate has exposure to full-stack ML/DL. Soft Skills & Team Expectations Strong communication and documentation skills; ability to clearly articulate technical concepts to both technical and non-technical audiences. Demonstrated ability to work independently as well as collaboratively in a fast-paced environment. A builder's mindset with a strong desire to innovate, automate, and scale. Comfortable in an agile, iterative development environment. Willingness to mentor junior engineers and contribute to team knowledge growth. Proactive in identifying tech stack improvements, security enhancements, and performance bottlenecks.",Associate,,"Python, Machine Learning",
4141953821,Senior Machine Learning Engineer,Haleon,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Hello. We’re Haleon. A new world-leading consumer health company. Shaped by all who join us. Together, we’re improving everyday health for billions of people. By growing and innovating our global portfolio of category-leading brands – including Sensodyne, Panadol, Advil, Voltaren, Theraflu, Otrivin, and Centrum – through a unique combination of deep human understanding and trusted science. What’s more, we’re achieving it in a company that we’re in control of. In an environment that we’re co-creating. And a culture that’s uniquely ours. Care to join us. It isn’t a question. With category leading brands such as Sensodyne, Voltaren and Centrum, built on trusted science and human understanding, and combined with our passion, knowledge and expertise, we’re uniquely placed to do this and to grow a strong, successful business. This is an exciting time to join us and help shape the future. It’s an opportunity to be part of something special. About The Role This is an excellent opportunity for a Senior Machine Learning Engineer to provide key contribution to a strategic digital programme expected to transform the integrated business planning process in Haleon. The successful candidate will lead the deployment of machine learning solutions that will transform our integrated business planning process. In this role, you will be responsible for designing and implementing end-to-end machine learning pipelines for various applications. Key Responsibilities Of The Role Lead the deployment of ML solutions on the enterprise infrastructure, in line with ML engineering standards and best practices (version control, testing, deployment, maintenance). Manage the entire lifecycle of data science/machine learning models, including monitoring, data gathering for retraining, and updates. Implement ML engineering best practices, such as coding standards, code reviews, and automated testing. Define and implement metrics to evaluate the functional performance and computational resource efficiency of ML and AI components. Can coordinate and manage competing priorities across a portfolio of projects. Ability to influence across organisations, proven collaboration skills, comfortable working with ambiguity, collaborate with cross-functional teams, including data scientists, data engineers, and business stakeholders. People and Team management Contribute to a highly collaborative team with a culture of ownership, initiative and responsibility. Contribute to the development of our Team’s ML engineering standards of reusable DS, ML, and AI assets. Motivate, coach, mentor colleagues within the ML Engineering Team to develop technical excellence. Manage a team of up to 3 Machine Learning Engineers Necessary Qualifications & Skills BSc, MSc or PhD degree in mathematics, computer science, or another scientific discipline that provides solid foundations on relevant aspects of Data Science. 5-10 years of industry experience with proven experience implementing machine learning engineering pipelines on large datasets. Strong understanding of ML engineering best practices. Strong collaboration skills and comfortable working with ambiguity, making quick, informed decisions considering trade-offs. Experience with deploying machine learning solutions on enterprise infrastructure. Strong programming skills in Python or similar programming languages.. Ability to manage competing priorities across a portfolio of projects. Highly Desirable Qualifications & Skills Strong experience with cloud-based infrastructure and distributed computing systems, such as Azure, AWS, or GCP. Experience with containerization and orchestration tools, such as Docker and Kubernetes. Understanding of software engineering principles, such as modular design, clean code, and testing. Familiarity with DevOps practices and tools, such as continuous integration and deployment (CI/CD) pipelines and configuration management tools like Ansible or Terraform. Excellent problem-solving skills and the ability to debug complex issues in production environments. Strong communication skills and the ability to collaborate with cross-functional teams. Familiarity with monitoring and logging tools, such as Grafana, Prometheus, and ELK Stack. Knowledge of security best practices in machine learning engineering. Care to join us. Find out what life at Haleon is really like www.haleon.com/careers/ At Haleon we embrace our diverse workforce by creating an inclusive environment that celebrates our unique perspectives, generates curiosity to create unmatched understanding of each other, and promotes fair and equitable outcomes for everyone. We're striving to create a climate where we celebrate our diversity in all forms by treating each other with respect, listening to different viewpoints, supporting our communities, and creating a workplace where your authentic self belongs and thrives. We believe in an agile working culture for all our roles. If flexibility is important to you, we encourage you to explore with our hiring team what the opportunities are. As you apply, we will ask you to share some personal information, which is entirely voluntary. We want to have an opportunity to consider a diverse pool of qualified candidates and this information will assist us in meeting that objective and in understanding how well we are doing against our inclusion and diversity ambitions. We would really appreciate it if you could take a few moments to complete it. Rest assured, Hiring Managers do not have access to this information and we will treat your information confidentially. Haleon is an Equal Opportunity Employer. All qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class. Accommodation Requests If you require a reasonable accommodation or other assistance to apply for a job at Haleon at any stage of the application process, please let your recruiter know by providing them with a description of specific accommodations you are requesting. We’ll provide all reasonable accommodations to support you throughout the recruitment process and treat all information you provide us in confidence.",Manager,,"Python, Machine Learning",
4242248452,"Senior Machine Learning Engineer – MLOps, VertexAI, LLMs, GenAI, ML Model Management",UPS,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Before you apply to a job, select your language preference from the options available at the top right of this page. Explore your next opportunity at a Fortune Global 500 organization. Envision innovative possibilities, experience our rewarding culture, and work with talented teams that help you become better every day. We know what it takes to lead UPS into tomorrow—people with a unique combination of skill + passion. If you have the qualities and drive to lead yourself or teams, there are roles ready to cultivate your skills and take you to the next level. Job Description Job Summary: We are seeking a highly skilled MLOps Engineer to design, deploy, and manage machine learning pipelines in Google Cloud Platform (GCP). In this role, you will be responsible for automating ML workflows, optimizing model deployment, ensuring model reliability, and implementing CI/CD pipelines for ML systems. You will work with Vertex AI, Kubernetes (GKE), BigQuery, and Terraform to build scalable and cost-efficient ML infrastructure. The ideal candidate must have a good understanding of ML algorithms, experience in model monitoring, performance optimization, Looker dashboards and infrastructure as code (IaC), ensuring ML models are production-ready, reliable, and continuously improving. You will be interacting with multiple technical teams, including architects and business stakeholders to develop state of the art machine learning systems that create value for the business. Responsibilities Managing the deployment and maintenance of machine learning models in production environments and ensuring seamless integration with existing systems. Monitoring model performance using metrics such as accuracy, precision, recall, and F1 score, and addressing issues like performance degradation, drift, or bias. Troubleshoot and resolve problems, maintain documentation, and manage model versions for audit and rollback. Analyzing monitoring data to preemptively identify potential issues and providing regular performance reports to stakeholders. Optimization of the queries and pipelines. Modernization of the applications whenever required Qualifications Expertise in programming languages like Python, SQL Solid understanding of best MLOps practices and concepts for deploying enterprise level ML systems. Understanding of Machine Learning concepts, models and algorithms including traditional regression, clustering models and neural networks (including deep learning, transformers, etc.) Understanding of model evaluation metrics, model monitoring tools and practices. Experienced with GCP tools like BigQueryML, MLOPS, Vertex AI Pipelines (Kubeflow Pipelines on GCP), Model Versioning & Registry, Cloud Monitoring, Kubernetes, etc. Solid oral and written communication skills and ability to prepare detailed technical documentation of new and existing applications. Strong ownership and collaborative qualities in their domain. Takes initiative to identify and drive opportunities for improvement and process streamlining. Bachelor’s Degree in a quantitative field of mathematics, computer science, physics, economics, engineering, statistics (operations research, quantitative social science, etc.), international equivalent, or equivalent job experience. Bonus Qualifications Experience in Azure MLOPS, Familiarity with Cloud Billing. Experience in setting up or supporting NLP, Gen AI, LLM applications with MLOps features. Experience working in an Agile environment, understanding of Lean Agile principles. Employee Type Permanent UPS is committed to providing a workplace free of discrimination, harassment, and retaliation.",,,"Python, SQL, Machine Learning",
4223614905,Senior Machine Learning Engineer - 2 (Architect) - Express AI Assistant,Adobe,"Noida, Uttar Pradesh, India",,Full-time,,"About the job Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! About The Team The Adobe Express team is building a path-breaking, all-in-one creative application for all platforms - web, desktop, and mobile. This platform combines the power of Adobe’s creative technologies with intuitive, AI-enhanced workflows that empower anyone to create standout content quickly and effortlessly. The Opportunity We’re looking for a Senior Machine Learning Engineer (Architect) to play a key role in shaping the next generation of AI-powered creative experiences in Adobe Express. This role will build high-impact AI Workflows for Adobe Express in Image editing space. Concentrating on brand new generative AI workflows, including personalized assistants and intelligent creative tools. Speed up AI culture by sharing knowledge, encouraging experimentation, and improving developer efficiency. Experience Requirements: 15+ years of proven experience in hands-on Machine Learning work. As a Machine Learning Engineer, you will: Build and scale advanced ML models to make Image editing easy and seamless for users Develop AI Agents for Adobe Express in Imaging space Partner closely with product, design and engineering teams across Adobe to integrate Adobe’s latest generative AI capabilities user-facing features. Help drive a culture of AI innovation and learning through internal knowledge-sharing, best-practice documentation, and experimentation frameworks that boost team productivity. Detailed Responsibilities: Research, design, and implement advanced ML models and scalable pipelines across training, inference, and deployment stages, using techniques in computer vision, NLP, deep learning, and generative AI. Integrate Large Language Models (LLMs) and agent-based frameworks to support multimodal creative workflows—enabling rich, context-aware, dynamic user experiences. Design, implement, and optimize subagent architectures for supporting modular and intelligent assistance across various creative tasks in Adobe Express. Collaborate with multi-functional teams to translate product requirements into ML solutions—especially those related to Harmony GenAI, smart recommendations, and generative tooling. Contribute to the development of internal platforms for model experimentation, A/B testing, performance monitoring, and continuous improvement. Stay up-to-date with evolving ML/GenAI research, tools, and frameworks—including federated learning, retrieval-augmented generation, and optimization for real-time inference. Champion an AI-first culture by mentoring peers, promoting learning opportunities, and encouraging innovation at both technical and organizational levels. Special Skills Requirements: Proficiency in Python for model development and C++ for systems integration. Strong hands-on experience with TensorFlow, PyTorch, and emerging GenAI toolkits. Experience working with LLMs, agent architectures, and user interfaces powered by AI technology. Deep understanding of computer vision and NLP techniques, especially for multimodal AI applications. Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more about our vision here. Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.",,,"Python, Machine Learning",
4245321140,MLOps Engineer / AI Infrastructure Specialist,Tata Consultancy Services,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Join the virtual drive at TCS Chennai, Bangalore, Hyderabad & Kolkata location on 13 jun-2025 for skill MLOps Engineer / AI Infrastructure Specialist exp req:5 to 8 yrs jd Primary skills:MLOps & Pipeline Engineering, Model Deployment & Scalability, Model Monitoring & Performance Analysis, AI Infrastructure Management Creates scalable and automated pipelines for deploying and managing machine learning models in production environments. Monitors model performance, maintains enterprise AI platforms, and ensures reliable AI infrastructure. Focuses on the operationalization of AI through robust and scalable systems.",Associate,,Machine Learning,
4257566459,Full Stack Engineer,BrightEdge,India (Remote),Remote,Full-time,,"About the job Job Description: Full Stack Engineer Location: INDIA, Remote Experience: 5 – 7 years Employment Type: Full time About the Role: We are looking for a highly skilled Full Stack Engineer with 4 – 6 years of experience who is proficient in JavaScript, ReactJS, Python, databases, and cloud platforms (AWS/GCP) . The ideal candidate should have experience working in fast-paced environments, preferably in startups , and be comfortable handling both front-end and back-end development. Key Responsibilities: Design, develop, and maintain scalable web applications using ReactJS and Python . Build and optimize APIs and backend services for high performance and scalability. Work with databases (SQL/NoSQL) for data modeling and efficient storage solutions. Deploy, manage, and optimize applications in AWS/GCP cloud environments. Collaborate with cross-functional teams to define, design, and ship new features. Ensure application security, performance, and maintainability. Troubleshoot, debug, and upgrade existing applications. Follow best practices in coding, testing, and DevOps for continuous improvement. Required Skills & Qualifications: 5 – 7 years of experience in full stack development. Expertise in JavaScript (ReactJS), Python, and backend development . Strong knowledge of databases (SQL & NoSQL) and data management. Experience with AWS or GCP cloud services for deployment and infrastructure management. Familiarity with microservices architecture, RESTful APIs, and serverless computing . Understanding of CI/CD pipelines, Docker, and Kubernetes is a plus. Experience working in fast-moving, startup environments . Strong problem-solving skills, ability to work independently and in a team. Why Join Us? Opportunity to work on cutting-edge technology in a dynamic environment. A fast-paced startup culture with rapid learning and growth opportunities. Competitive salary, flexible work environment, and exciting challenges.",,,"Python, SQL",
4257342349,Machine Learning Engineer,Rail Labs,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Job Description - We are seeking a Machine Learning Engineer to assist in developing and implementing object detection and AI-based predictions. You will have the opportunity to work on real-world applications and contribute to the development of novel algorithms. As a ML engineer, you’ll collaborate with our team and works various applied AI/ML tasks. Key Responsibilities - Assist in training and fine-tuning ML models for real-time AI-based tasks. Work with large datasets to prepare, annotate, preprocess, and augment data for training purposes. Implement and test model architectures to improve accuracy, speed, and performance. Help analyze and optimize model performance based on results and metrics. Document research and findings, contributing to team knowledge and project reports. Participate in code reviews and contribute to software development best practices. Stay updated with the latest trends and research in computer vision and applied ML. Qualifications - Bachelor's or master's degree program in Computer Science, Electrical Engineering, Data Science, or a related field. Solid understanding of AI/ML concepts, data cleaning, synthetic data generation and other relevant concepts. Hands-on experience with MLOps. Hands-on experience with YOLO or similar deep learning object detection frameworks (e.g., Faster R-CNN, SSD). Proficiency in programming languages such as Python Experience with OpenCV and Pytorch is a must. Experience with Statistical Analysis and modeling is a plus. Experience with CUDA and GPU acceleration is a plus. Experience with ROS and C++ is also a huge plus. Strong problem-solving skills, attention to detail, and a collaborative mindset. Preferred Skills - Knowledge of data cleaning techniques and data preprocessing methods. Familiarity with version control systems like Git . Experience in deploying models into production environments (optional). Exposure to ROS and OpenCV in C++.",,,"Python, R, Machine Learning",
4248918427,Senior AI Developer,Hitachi Vantara,"Itanagar, Arunachal Pradesh, India",,Full-time,,"About the job Our Company: We’re Hitachi Digital, a company at the forefront of digital transformation and the fastest growing division of Hitachi Group. We’re crucial to the company’s strategy and ambition to become a premier global player in the massive and fast-moving digital transformation market. Our group companies, including GlobalLogic, Hitachi Digital Services, Hitachi Vantara and more, offer comprehensive services that span the entire digital lifecycle, from initial idea to full-scale operation and the infrastructure to run it on. Hitachi Digital represents One Hitachi, integrating domain knowledge and digital capabilities, and harnessing the power of the entire portfolio of services, technologies, and partnerships, to accelerate synergy creation and make real-world impact for our customers and society as a whole. Imagine the sheer breadth of talent it takes to unleash a digital future. We don’t expect you to ‘fit’ every requirement – your life experience, character, perspective, and passion for achieving great things in the world are equally as important to us. The team: Hitachi Digital is a leader in digital transformation, leveraging advanced AI technologies to drive innovation and efficiency across various operational companies (OpCos) and departments. We are seeking an experienced Senior AI Developer to support our new AI initiatives and enhance our existing Agentic AI capabilities. This role will involve building new AI products and refining current models to meet the evolving needs of our business. The Role Lead the design, development, and implementation of AI models and algorithms using Agentic AI and Agent Workspace for Google Gemini and EMa.AI. Drive new AI initiatives across different OpCos and departments, ensuring seamless integration and functionality. Enhance and refine existing Agentic AI capabilities to improve performance and scalability. Collaborate with cross-functional teams to integrate AI solutions into existing systems and workflows. Conduct research and stay updated on the latest advancements in AI technologies and methodologies. Optimize AI models for performance, scalability, and accuracy. Troubleshoot and resolve complex issues related to AI systems and applications. Document AI development processes, methodologies, and best practices. Mentor junior developers and participate in code reviews, providing constructive feedback to team members. What You’ll Bring Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. 4+ experience in AI model development, with a focus on Agentic AI and Agent Workspace for Google Gemini and EMa.AI. Strong programming skills in languages such as Python, Java, or C++. Primary experience with Google Cloud Platform (GCP); experience with AWS and Azure is a plus. Experience with GPU-based AI model development is a plus. Prior experience with Generative AI (GenAI) and Large Language Models (LLMs) is required. Experience with AI frameworks and libraries such as TensorFlow, PyTorch, or similar. Knowledge of machine learning algorithms, neural networks, and natural language processing. Excellent problem-solving skills and the ability to work independently and as part of a team. Strong communication skills and the ability to convey complex technical concepts to non-technical stakeholders. Preferred Qualifications Familiarity with data science tools and techniques. Previous experience in a similar role within a tech-driven company. About us: We’re a global, 1000-strong, diverse team of professional experts, promoting and delivering Social Innovation through our One Hitachi initiative (OT x IT x Product) and working on projects that have a real-world impact. We’re curious, passionate and empowered, blending our legacy of 110 years of innovation with our shaping our future. Here you’re not just another employee; you’re part of a tradition of excellence and a community working towards creating a digital future. Championing diversity, equity, and inclusion Diversity, equity, and inclusion (DEI) are integral to our culture and identity. Diverse thinking, a commitment to allyship, and a culture of empowerment help us achieve powerful results. We want you to be you, with all the ideas, lived experience, and fresh perspective that brings. We support your uniqueness and encourage people from all backgrounds to apply and realize their full potential as part of our team. How We Look After You We help take care of your today and tomorrow with industry-leading benefits, support, and services that look after your holistic health and wellbeing. We’re also champions of life balance and offer flexible arrangements that work for you (role and location dependent). We’re always looking for new ways of working that bring out our best, which leads to unexpected ideas. So here, you’ll experience a sense of belonging, and discover autonomy, freedom, and ownership as you work alongside talented people you enjoy sharing knowledge with. We’re proud to say we’re an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran, age, disability status or any other protected characteristic. Should you need reasonable accommodations during the recruitment process, please let us know so that we can do our best to set you up for success.",,,"Python, Machine Learning",
4215330521,Sr. Data Science Engineer,Uplers,Greater Bengaluru Area (On-site),On-site,Full-time,,"About the job Experience : 4.00 + years Salary : INR 1500000-3000000 / year (based on experience) Expected Notice Period : 15 Days Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Office (Bengaluru) Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Radius AI) What do you need for this opportunity? Must have skills required: Ci/Cd Pipelines, Edge Computing, CNNs, Computer Vision, Vision Transformers, AWS, Azure, GCP, machine_learning, Python Radius AI is Looking for: We are looking for a Sr. Data Science Engineer with deep expertise in computer vision and applied machine learning. This role is central to designing, building, and deploying intelligent vision systems using the latest methodologies and incremental learning strategies. As a data scientist at RadiusAI, you will collaborate closely with engineers and product stakeholders to transform large volumes of image and video data into real-world, high-impact AI applications. Key Responsibilities Design and develop machine learning models for computer vision tasks including object detection, classification, tracking, and scene understanding. Lead end-to-end model lifecycle: data preprocessing, feature engineering, model selection, training, evaluation, and deployment. Implement and experiment with state-of-the-art techniques including Vision Transformers (ViT) and class-incremental learning for continuous adaptation in production environments. Analyze data from edge devices and physical environments to generate actionable insights. Develop and maintain reproducible research pipelines using versioned data and experiment tracking tools. Collaborate with the ML Ops and engineering teams to ensure seamless integration of models into production environments. Optimize models for real-time inference performance, accuracy, and scalability on edge devices or cloud-based infrastructure. Document findings, present insights to cross-functional teams, and contribute to technical decision-making. Mentor junior data scientists and contribute to team knowledge sharing. Required Qualifications 4+ years of experience in data science or machine learning roles, with hands-on production experience. Expertise in computer vision algorithms and deep learning models.\ Strong grasp of cutting-edge architectures such as CNNs, Vision Transformers (ViT), and knowledge distillation techniques. Practical experience with class-incremental learning, transfer learning, and domain adaptation. Proficiency in Python and ML libraries such as PyTorch, TensorFlow, scikit-learn, and OpenCV. Hands-on experience with data versioning and experiment tracking tools such as DVC, MLflowetc. Solid understanding of ML model deployment and lifecycle management. Strong experience in working with structured and unstructured data, especially large-scale image/video datasets. Excellent analytical skills and the ability to interpret complex data and communicate results clearly. Preferred Qualifications Prior experience in startup or high-growth environments where adaptability is key. Experience working with cloud platforms such as AWS, GCP, or Azure for scalable ML workflows. Familiarity with edge computing, real-time inference, and model optimization frameworks like TensorRT, ONNX, or OpenVINO. Experience with CI/CD pipelines for ML projects and collaboration with ML Ops teams. Domain knowledge in retail, healthcare, logistics, or behavioral analytics is a strong plus. Contributions to open-source ML projects or published research papers. Comfort with visualization tools and reporting frameworks for data storytelling. How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Ci/Cd Pipelines, Edge Computing, CNNs, Computer Vision, Vision Transformers, AWS, Azure, GCP, machine_learning, Python",,,"Python, Machine Learning",
4224456270,Lead Analyst - AI Engineer (Full Stack),Eaton,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,"4.0 Experience with AI platforms like Palantir, Snowflake, and DataIku is advantageous ]]> Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company Eaton 1,822,816 followers Follow Appliances, Electrical, and Electronics Manufacturing 10,001+ employees 53,349 on LinkedIn Eaton is an intelligent power management company dedicated to improving the quality of life and protecting the environment for people everywhere. We are guided by our commitment to do business right, to operate sustainably and to help our customers manage power ─ today and well into the future. By capitalizing on the global growth trends of electrification and digitalization, we’re accelerating the planet’s transition to renewable energy and helping to solve the world’s most urgent power management challenges. Eaton is an Equal Opportunity Employer. Eaton is committed to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of an applicant's race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, marital status, genetic information, protected veteran status, or any other status protected by law. … show more Interested in working with us in the future? Members who share that they’re interested in a company may be 2x as likely to get a message from a recruiter than those who don’t. Learn more Learn more about Interested in working for our company I’m interested Company photos Page 1 of 3 Previous Next April 24, 2023 April 24, 2023 May 24, 2024 Show more","About the job What You’ll Do Must have proven experience in Building front-end and back-end components for AI applications, building/consuming APIs, building customer centric user interfaces and designing integrations with other systems using .Net, JavaScript, Angular or React, SQL Must have proven experience in solution deployment by packaging trained AI models as services using Azure deployment services, Kubernetes, and GitHub for version control. Should have in depth understanding of Azure AI services such as Azure Machine Learning and Cognitive Services along with other AI technologies, natural language processing (NLP), computer vision and GPT models Should have strong expertise in articulating and documenting solution architecture for AI projects by collaborating with solution architect and enterprise architects. Must have abilities to collaborate with business leaders to understand their pain points and identify key areas where AI solutions can drive significant business benefit. Must have strong analytical and problem-solving skills, with the ability to translate business requirements into effective AI solutions. Must have excellent communication skills, with the ability to convey complex AI technical concepts to non-technical stakeholders Qualifications Bachelors in engineering/ B.E/B. Tech and/or required equivalent MCA. Overall 10+ years’ experience with proven track record of 5+ years in Solutioning and deploying end to end AI Technical skills : Net, JavaScript, Angular or React, SQL Server, Azure deployment services, Kubernetes, GitHub , Azure Cognitive Services , GPT models, added advantage with GitHub Copilot Skills Proficiency in front-end technologies (React or Angular) and back-end technologies (e.g., Node.js, Python, .NET). Strong understanding of AI and machine learning frameworks (e.g., TensorFlow, PyTorch). Experience with cloud and hybrid infrastructures. Proficiency in scripting and automation tools (e.g., PowerShell, Azure CLI) Expertise in cloud native development specialized in Microsoft Azure tech stack Experience of working on AI use cases involving in Salesforce AI (Einstein and Agentforce), ServiceNow AI (NowAssist and AI Agents), SAP AI (Joule) , Oracle Cloud AI, AI applications in Industry 4.0 Experience with AI platforms like Palantir, Snowflake, and DataIku is advantageous ]]>",,,"Python, SQL, Machine Learning",
4247770333,Senior Software Engineer - AI/ML,Magnit,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Who We Are Magnit is the future of work. Serving hundreds of the world’s most recognizable brands for the past 30+ years, Magnit offers the industry’s first holistic platform for the modern workforce. Magnit's integrated workforce management (IWM) platform supported by data, software, intelligence, and best-in-class services team is key to our clients’ success. It can adapt quickly to regional or industry economic shifts, and provides the speed, scale, flexibility, transparency, and expertise required to meet an organization’s contingent workforce management, talent strategy and broader organization goals. At Magnit, you’ll work with passionate colleagues who collaborate and deliver meaningful results that positively transform the largest companies around the globe. Senior AI & ML Platform Engineer Location: Bengaluru Experience Level: 3–10 Years About The Role We are building next-generation AI-powered platforms that leverage Large Language Models (LLMs), advanced Machine Learning (ML), NLP, and agentic workflows to automate critical business processes across multiple domains. We are looking for experienced AI/ML Engineers who are passionate about building real-world AI products—not just experimenting. You will help design, prototype, and deploy intelligent systems integrating LLMs, agents, APIs, and robust ML models for classification, prediction, and optimization. Responsibilities Build and integrate agentic AI workflows using LangChain or similar frameworks. Develop APIs and backend services to support LLM and ML-driven platforms. Implement, train, and optimize lightweight and scalable ML models for classification, prediction, and anomaly detection. Work with LLMs (OpenAI, Claude, Gemini) to fine-tune prompts, create retrieval-augmented generation (RAG) systems, and chain multi-step tasks. Design and optimize vector search implementations for LLM-driven applications. Integrate AI models with external systems (VMS platforms, ERP systems) using APIs. Implement document processing pipelines combining OCR with LLM/ML validation. Apply ML techniques for supply-demand forecasting, fraud detection, and optimization. Participate in design discussions, brainstorming sessions, and agile sprints. Collaborate with senior AI architects and SMEs to refine platform capabilities. Required Skills Strong experience in Python for ML and AI development. Expertise in ML frameworks such as TensorFlow, PyTorch, scikit-learn. Knowledge of NLP tasks (text extraction, classification, summarization). Experience building and optimizing RAG workflows with vector databases. Solid understanding of API development (FastAPI, Flask, or similar frameworks). Familiarity with prompt engineering and agent orchestration concepts. Ability to build scalable ML models for classification, forecasting, and anomaly detection. Experience integrating ML solutions with cloud services (AWS, Azure, GCP). Knowledge of OCR tools and techniques for document processing. Exposure to multi-agent architectures and reinforcement learning is a plus. Understanding of feature engineering, model evaluation, and optimization techniques. Mindset We Are Looking For Builder’s mindset: You love turning ideas into working solutions fast. Curiosity: Passionate about keeping up with the latest in GenAI and ML. Problem-solver: Comfortable working in ambiguous environments where solutions need discovery, not just execution. Collaboration: Open to learning from senior architects and iterating based on feedback. What Magnit Will Offer You At Magnit, you’ll be joining an innovative, high-growth environment and can quickly make an impact to help transform the largest companies in the world. You will work with passionate colleagues who collaborate and deliver. Magnit offers all employees the opportunity for growth and development, and we want individuals to fulfill their potential and blaze their own trails! Magnit will offer you a competitive PTO and benefits package, including medical, dental, and vision coverage, retirement planning, as well as discounts and perks for tickets, travel, merchandise and more! Magnit encourages employees to participate in giving back, and we will match employee contributions to favorite charities and support corporate volunteering hours to make a difference in your community! If this role isn’t for you Stay in touch, we will let you know when we have new positions on the team. To see a complete list of our open career opportunities please visit. https://magnitglobal.com/us/en/company/careers.html To do our best work we need different viewpoints. Therefore, we celebrate diversity and embrace inclusion. As an equal opportunity employer, we are dedicated to building a team that represents a variety of backgrounds, perspectives, and skills. We strive to ensure that we maintain a positive and enriching work environment for all. By applying to this role, you consent to Magnit safely storing and managing your personal data. Please read this link to learn more. https://magnitglobal.com/us/en/privacy-notice.html",,,"Python, Machine Learning",
4218282651,EY - GDS Consulting - AI Enabled Automation - AI Engineer - Senior,EY,"Kanayannur, Kerala, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. Job Description: Senior AI Engineer (Tech Lead) Role Overview: We are seeking a highly skilled and experienced Senior AI Engineers with a minimum of 4 years of experience in Data Science and Machine Learning, preferably with experience in NLP, Generative AI, LLMs, MLOps, Optimization techniques, and AI solution Architecture. In this role, you will play a key role in the development and implementation of AI solutions, leveraging your technical expertise. The ideal candidate should have a deep understanding of AI technologies and experience in designing and implementing cutting-edge AI models and systems. Additionally, expertise in data engineering, DevOps, and MLOps practices will be valuable in this role. Responsibilities: Your technical responsibilities: Contribute to the design and implementation of state-of-the-art AI solutions. Leading a team of 4-6 developers Assist in the development and implementation of AI models and systems, leveraging techniques such as Large Language Models (LLMs) and generative AI. Collaborate with stakeholders to identify business opportunities and define AI project goals. Stay updated with the latest advancements in generative AI techniques, such as LLMs, and evaluate their potential applications in solving enterprise challenges. Utilize generative AI techniques, such as LLMs, Agentic Framework to develop innovative solutions for enterprise industry use cases. Integrate with relevant APIs and libraries, such as Azure Open AI GPT models and Hugging Face Transformers, to leverage pre-trained models and enhance generative AI capabilities. Implement and optimize end-to-end pipelines for generative AI projects, ensuring seamless data processing and model deployment. Utilize vector databases, such as Redis, and NoSQL databases to efficiently handle large-scale generative AI datasets and outputs. Implement similarity search algorithms and techniques to enable efficient and accurate retrieval of relevant information from generative AI outputs. Collaborate with domain experts, stakeholders, and clients to understand specific business requirements and tailor generative AI solutions accordingly. Conduct research and evaluation of advanced AI techniques, including transfer learning, domain adaptation, and model compression, to enhance performance and efficiency. Establish evaluation metrics and methodologies to assess the quality, coherence, and relevance of generative AI outputs for enterprise industry use cases. Ensure compliance with data privacy, security, and ethical considerations in AI applications. Leverage data engineering skills to curate, clean, and preprocess large-scale datasets for generative AI applications. Requirements: Bachelor's or Master's degree in Computer Science, Engineering, or a related field. Minimum 4 years of experience in Python, Data Science, Machine Learning, OCR and document intelligence Experience in leading a team of 4-6 developers Demonstrated ability to conceptualize technical solutions, apply accurate estimation techniques, and effectively engage with customer stakeholders In-depth knowledge of machine learning, deep learning, and generative AI techniques. Proficiency in programming languages such as Python, R, and frameworks like TensorFlow or PyTorch. Strong understanding of NLP techniques and frameworks such as BERT, GPT, or Transformer models. Familiarity with computer vision techniques for image recognition, object detection, or image generation. Strong knowledge of Python frameworks such as Django, Flask, or FastAPI. Experience with RESTful API design and development. Experience with cloud platforms such as Azure, AWS, or GCP and deploying AI solutions in a cloud environment. Expertise in data engineering, including data curation, cleaning, and preprocessing. Knowledge of trusted AI practices, ensuring fairness, transparency, and accountability in AI models and systems. Strong collaboration with software engineering and operations teams to ensure seamless integration and deployment of AI models. Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions. Strong communication and interpersonal skills, with the ability to collaborate effectively with stakeholders at various levels. Understanding of data privacy, security, and ethical considerations in AI applications. Track record of driving innovation and staying updated with the latest AI research and advancements. Good to Have Skills: Understanding of agentic AI concepts and frameworks Proficiency in designing or interacting with agent-based AI architectures Apply trusted AI practices to ensure fairness, transparency, and accountability in AI models and systems. Utilize optimization tools and techniques, including MIP (Mixed Integer Programming). Drive DevOps and MLOps practices, covering continuous integration, deployment, and monitoring of AI models. Implement CI/CD pipelines for streamlined model deployment and scaling processes. Utilize tools such as Docker, Kubernetes, and Git to build and manage AI pipelines. Apply infrastructure as code (IaC) principles, employing tools like Terraform or CloudFormation. Implement monitoring and logging tools to ensure AI model performance and reliability. Collaborate seamlessly with software engineering and operations teams for efficient AI model integration and deployment. Familiarity with DevOps and MLOps practices, including continuous integration, deployment, and monitoring of AI models. EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",,,"Python, R, Machine Learning",
4246511218,Staff Engineer (Data Science),Omnissa,Greater Bengaluru Area (Hybrid),Hybrid,Full-time,,"About the job Job Description What is the opportunity? Responsibilities As a Staff Engineer – I you will be responsible for statistical machine learning, deep learning, data mining, data analysis, information retrieval, optimization algorithms.. Here is a breakdown: Masters or Doctorate Degree in Statistics, Computer Science, Electrical or Computer Engineering, or related field. 12+ years of hands-on experience in using statistical machine learning, deep learning, data mining, data analysis, information retrieval, optimization algorithms. 2+ years of hands-on experience working with large language models (LLMs). Proficient in Python and working knowledge of at least one other programming languages such as Java, Scala, or C++. Extensive experience with frameworks and libraries such as PyTorch, Numpy, Pandas, SciPy, Scikit-Learn, LangChain and Hugging Face Transformers. Proficiency in SQL and experience with big data technologies such as Hadoop, Spark, or equivalent. Demonstrated expertise in training, fine-tuning, and deploying machine learning models, particularly LLMs. Proficiency in prompt engineering and retrieval-augmented generation (RAG) techniques. Familiarity with cloud platforms and Tools such as AWS, Azure, or Google Cloud for development, deploying and scaling ML models. Excellent problem-solving skills, with a track record of successfully addressing complex technical challenges. Strong communication and collaboration skills, with the ability to work effectively in cross-functional teams. Demonstrated commitment to ethical AI practices and data privacy/security regulations. What will you bring to Omnissa? Lead the design and development of advanced data science and machine learning analytics models using structured, unstructured and semi-structured data. Work with engineers to design and implement machine learning pipelines, covering all stages from data ingestion and feature extraction to training, testing, validation, inference, and continuous learning in production systems. Leverage key technologies and state-of-the-art tools necessary for exploring/querying data, visualization, and advanced analytics - distribution of key attributes, relationships between attributes, feature engineering, and statistical analyses. Be an expert in and lead the development of Large Language Models (LLMs) and Retrieval-augmented generation (RAG) based Solutions. Develop and optimize algorithms for training and fine-tuning LLMs, improving their performance, accuracy, efficiency, and scalability. Design and implement prompt engineering strategies to optimize the performance of LLM based applications. Participate in design/code reviews, and knowledge-sharing sessions to maintain high standards of product development excellence. Mentors and guide junior data scientists and engineers, fostering a culture of continuous learning and professional growth. Collaborate with cross-functional teams to integrate AI/ML enabled features into existing products. Track advances in industry and academia to stay up to date with the latest research and algorithms in the field of machine learning and AI, and drive innovation by incorporating relevant advancements into ongoing projects. Actively contribute to the body of thought leadership and intellectual property (IP) best practices by actively participating in external conferences. Location: Bengaluru, India Location Type: Hybrid This role offers a balanced arrangement, with the expectation of working 3 days a week in our local office and the flexibility to work from home for the remaining days. It is essential that you reside within a reasonable commuting distance of the office location for the in-office workdays.",,,"Python, SQL, Machine Learning, Data Analysis",
4255311589,"Sr. Data Science & AIML, GenAI Lead/Engineer",NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 312483 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Sr. Data Science & AIML, GenAI Lead/Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Job Title: Data Science & AIML, GenAI Lead/Engineer Key Responsibilities: Develop and implement traditional machine learning algorithms. Deploy at least one model in a production environment. Write and maintain Python code for data science and machine learning projects. Minimum Skills Required: Preferred Qualifications: Knowledge of Deep Learning (DL) techniques. Experience working with Generative AI (GenAI) and Large Language Models (LLM). Exposure to Langchain. #GenAINTT About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4248191566,"Senior Machine Learning engineer (Python, Azure databricks, Devops, Pyspark/ SPARK, Github, MLE models, Tensorflow)",NielsenIQ,Pune/Pimpri-Chinchwad Area (On-site),On-site,Full-time,,"About the job Company Description FK - Growth from Knowledge. For over 89 years, we have earned the trust of our clients around the world by solving critical questions in their decision-making process. We fuel their growth by providing a complete understanding of their consumers’ buying behavior, and the dynamics impacting their markets, brands and media trends. In 2023, GfK combined with NIQ, bringing together two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights - delivered with advanced analytics through state-of-the-art platforms - GfK drives “Growth from Knowledge”. Gfk is seeking a Machine Learning Engineer with hands-on Python experience and proven analytical and problem solving skills. You will be involved with various data engineering aspects - data collection, cleaning, and preprocessing, to training models and deploying them to production. The ideal candidate will possess strong technical and interpersonal skills, along with certain ML skills. In addition, the candidate will collaborate across multi-functional teams to achieve product milestones as agreed with stakeholders. Job Description Position Description Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress Analyzing the ML algorithms that could be used to solve a given problem and ranking them by their success probability Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world Verifying data quality and ensuring it via data cleaning Defining validation strategies Defining the preprocessing or feature engineering to be done on a given dataset Defining data augmentation pipelines Finding available datasets that could be used for training Training models and tuning their hyperparameters Analyzing the errors of the model and designing strategies to overcome them Deploying models to production Work independently and collaboratively on a multi-disciplined project team in an Agile development environment Be actively involved in the design, development and testing activities for Big data product Provide feedback to development teams on code/architecture optimization Qualifications Required Skills and Experience 5+ years of experience in Machine learning with Devops 5+ years of hands-on experience developing Python ,PySpark Experience with Spark is preferred Possess a strong foundation in statistics and utilize statistical methods to analyze data and derive meaningful insights Familiarity with Azure Databricks or similar Proficiency with a deep learning frameworks such as TensorFlow or PyTorch or Keras Proficiency with Python and basic libraries for machine learning such as scikit-learn and pandas Expertise in visualizing and manipulating big datasets 5+ years of experience - Ability to select hardware to run an ML model with the required latency Familiarity with Azure services Proven experience with CI/CD Proven experience with version control ( Github, Bitbucket) Familiarity with Linux OS/concepts Strong written and verbal communication skills Self-motivated and ability to work well in a team Education Bachelor of Science degree from an accredited university Additional Information Enjoy a flexible and rewarding work environment with peer-to-peer recognition platforms Recharge and revitalize with help of wellness plans made for you and your family Plan your future with financial wellness tools Stay relevant and upskill yourself with career development opportunities Our Benefits Flexible working environment Volunteer time off LinkedIn Learning Employee-Assistance-Program (EAP) About NIQ NIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population. For more information, visit NIQ.com Want to keep up with our latest updates? Follow us on: LinkedIn | Instagram | Twitter | Facebook Our commitment to Diversity, Equity, and Inclusion NIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Manager,,"Python, Machine Learning",
4229158597,Machine Learning Engineer Lead - C13 - CHENNAI,Citi,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job The Data Science Lead Analyst is a strategic professional who stays abreast of developments within own field and contributes to directional strategy by considering their application in own job and the business. Recognized technical authority for an area within the business. Requires basic commercial awareness. There are typically multiple people within the business that provide the same level of subject matter expertise. Developed communication and diplomacy skills are required in order to guide, influence and convince others, in particular colleagues in other areas and occasional external customers. Significant impact on the area through complex deliverables. Provides advice and counsel related to the technology or operations of the business. Work impacts an entire area, which eventually affects the overall performance and effectiveness of the sub-function/job family. Responsibilities: Conducts strategic data analysis, identifies insights and implications and make strategic recommendations, develops data displays that clearly communicate complex analysis. Mines and analyzes data from various banking platforms to drive optimization and improve data quality. Deliver analytics initiatives to address business problems with the ability to determine data required, assess time & effort required and establish a project plan. Consults with business clients to identify system functional specifications. Applies comprehensive understanding of how multiple areas collectively integrate to contribute towards achieving business goals. Consults with users and clients to solve complex system issues/problems through in-depth evaluation of business processes, systems and industry standards; recommends solutions. Leads system change process from requirements through implementation; provides user and operational support of application to business users. Formulates and defines systems scope and goals for complex projects through research and fact-finding combined with an understanding of applicable business systems and industry standards. Impacts the business directly by ensuring the quality of work provided by self and others; impacts own team and closely related work teams. Considers the business implications of the application of technology to the current business environment; identifies and communicates risks and impacts. Drives communication between business leaders and IT; exhibits sound and comprehensive communication and diplomacy skills to exchange complex information. Conduct workflow analysis, business process modeling; develop use cases, test plans, and business rules; assist in user acceptance testing. Collaborate on design and implementation of workflow solutions that provide long term scalability, reliability, and performance, and integration with reporting. Develop in-depth knowledge and proficiency of supported business areas and engage business partners in evaluating opportunities for process integration and refinement. Gather requirements and provide solutions across Business Sectors Partner with cross functional teams to analyze, deconstruct, and map current state process and identify improvement opportunities including creation of target operation models. Assist in negotiating for resources owned by other areas in order ensure required work is completed on schedule Develop and maintain documentation on an ongoing basis, and train new and existing users Direct the communication of status, issue, and risk disposition to all stakeholders, including Senior Management Direct the identification of risks which impact project delivery and ensure mitigation strategies are developed and executed when necessary Ensure that work flow business case / cost benefit analyses are in line with business objectives Deliver coherent and concise communications detailing the scope, progress and results of initiatives underway Develop strategies to reduce costs, manage risk, and enhance services Deploy influencing and matrix management skills in order to ensure technology solutions meet business requirements Performs other duties and functions as assigned. Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: MBA or Advanced Degree Information Systems, Business Analysis / Computer Science 6-10 years experience using tools for statistical modeling of large data sets Process Improvement or Project Management experience Education: Bachelor’s/University degree or equivalent experience, potentially Masters degree This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. ------------------------------------------------------ Job Family Group: Technology ------------------------------------------------------ Job Family: Data Science ------------------------------------------------------ Time Type: Full time ------------------------------------------------------ Most Relevant Skills Please see the requirements listed above. ------------------------------------------------------ Other Relevant Skills For complementary skills, please see above and/or contact the recruiter. ------------------------------------------------------ Citi is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi . View Citi’s EEO Policy Statement and the Know Your Rights poster.",,10 years experience,Data Analysis,
4209777915,Principal AI Engineer - MLOps,Rapid7,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,,"About the job Principal AI Engineer - ML Ops About The Team The AI Center of Excellence team includes Data Scientists and AI Engineers that work together to conduct research, build prototypes, design features and build production AI components and systems. Our mission is to leverage the best available technology to protect our customers' attack surfaces. We partner closely with Detection and Response teams, including our MDR service, to leverage AI/ML for enhanced customer security and threat detection. We operate with a creative, iterative approach, building on 20+ years of threat analysis and a growing patent portfolio. We foster a collaborative environment, sharing knowledge, developing internal learning, and encouraging research publication. If you’re passionate about AI and want to make a major impact in a fast-paced, innovative environment, this is your opportunity. The Technologies We Use Include AWS for hosting our research environments, data, and features EKS to deploy applications Terraform to manage infrastructure Python for analysis and modeling, taking advantage of numpy and pandas for data wrangling. Jupyter notebooks (locally and remotely hosted) as a computational environment Sci-kit learn for building machine learning models Anomaly detection methods to make sense of unlabeled data About The Role Rapid7 is seeking a Principal AI Engineer to join our team as we expand and evolve our growing AI and MLOps efforts. You should have a strong foundation in applied AI R&D, software engineering, and MLOps and DevOps systems and tools. Further, you’ll have a demonstrated track record of taking models created in the AI R&D process to production with repeatable deployment, monitoring and observability patterns. In this intersectional role, you will combine your expertise in AI/ML deployments, cloud systems and software engineering to enhance our product offerings and streamline our platform's functionalities. In This Role, You Will Architect and manage the end-to-end design of ML production systems, including project scoping, data requirements, modeling strategies, and deployment Develop and maintain data pipelines, manage the data lifecycle, and ensure data quality and consistency throughout Assure robust implementation of ML guardrails and manage all aspects of service monitoring Develop and deploy accessible endpoints, including web applications and REST APIs, while maintaining steadfast data privacy and adherence to security best practices and regulations Share expertise and knowledge consistently with internal and external stakeholders, nurturing a collaborative environment and fostering the development of junior engineers Embrace agile development practices, valuing constant iteration, improvement, and effective problem-solving in complex and ambiguous scenarios The Skills You’ll Bring Include 15 years experience as a Software Engineer with 3-5 years focused on gaining expertise in ML deployment (especially in AWS) Solid technical experience in the following is required: Software engineering: developing APIs with Flask or FastAPI, paired with strong Python knowledge DevOps and MLOps: Designing and integrating scalable AI/ML systems into production environments, CI/CD tooling, Docker, Kubernetes, cloud AI resource utilization and management Pipelines, monitoring, and observability: Data pre-processing and feature engineering, model monitoring and evaluation A growth mindset - welcoming the challenge of tackling complex problems with a bias for action Strong written and verbal communication skills - able to effectively communicate technical concepts to diverse audiences and creating clear documentation of system architectures and implementation details Proven ability to collaborate effectively across engineering, data science, product, and other teams to drive successful MLOps initiatives and ensure alignment on goals and deliverables. Established track record of mentoring and guiding junior engineers, fostering their technical growth and promoting engineering excellence within the organization Experience With The Following Would Be Advantageous AI and ML models, understanding their operational frameworks and limitations Deploying resources that enable data scientists to fine tune and experiment with LLMs Implementing model risk management strategies, including model registries, concept/covariate drift monitoring, and hyperparameter tuning We know that the best ideas and solutions come from multi-dimensional teams. That’s because these teams reflect a variety of backgrounds and professional experiences. If you are excited about this role and feel your experience can make an impact, please don’t be shy - apply today. About Rapid7 At Rapid7, we are on a mission to create a secure digital world for our customers, our industry, and our communities. We do this by embracing tenacity, passion, and collaboration to challenge what’s possible and drive extraordinary impact. Here, we’re building a dynamic workplace where everyone can have the career experience of a lifetime. We challenge ourselves to grow to our full potential. We learn from our missteps and celebrate our victories. We come to work every day to push boundaries in cybersecurity and keep our 10,000 global customers ahead of whatever’s next. Join us and bring your unique experiences and perspectives to tackle some of the world’s biggest security challenges.",,15 years experience,"Python, R, Machine Learning",
4259094722,Software Development Engineer 1,Auto Data Catalog,"Gurgaon, Haryana, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Responsibilities Design, develop, test, and deploy scalable and maintainable code. Perform Data Analysis while collaborating with other engineers to refine API contracts and integrate services. Identify and resolve bugs. Follow best practices in code quality and security. Requirements React-NextJS/Python/Go/Java. Object-oriented programming and software design principles. Strong problem-solving skills and the ability to write clean, maintainable, and testable code. 2023/24 Engineering Grad. This job was posted by Manas Pant from Auto Data Catalog. Desired Skills and Experience Golang,Java,JavaScript,Python,React.js",,,"Python, Data Analysis",
4228843476,Senior AI Engineer - REMOTE,Uplers,"Ranchi, Jharkhand, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4247408206,Statistical Analytics Engineer (F/M/D),Klüber Lubrication,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Working at Freudenberg: ""We will wow your world!"" This is our promise. As a global technology group, we not only make the world cleaner, healthier and more comfortable, but also offer our 52,000 employees a networked and diverse environment where everyone can thrive individually. Be surprised and experience your own wow moments. Klüber Lubrication, a company of the Freudenberg Group, is the global leader in speciality lubrication with manufacturing operations in North and South America, Europe and Asia, subsidiaries in more than 30 different countries and distribution partners in all regions of the world, supported by our HQs in Germany. We are passionate about innovative tribological solutions that help our customers to be successful. We supply products and services, many of them customized, in almost all industries from automotive to the wind energy markets. Some of your Benefits Diversity & Inclusion: We focus on providing an inclusive environment and recognize our diversity contributes to our success. Health Insurance: Rely on comprehensive services whenever you need it. Personal Development: We offer a variety of trainings to ensure you can develop in your career. Safe Environment: We strive to ensure safety remains a top priority, and provide a stable environment for our employees. Sustainability & Social Commitment: We support social and sustainable projects and encourage employee involvement. Bangalore On-Site Klüber Lubrication India Pvt. Ltd. You support our team as Statistical Analytics Engineer (F/M/D) Responsibilities Performs projects in statistics, data science and artificial intelligence in the technical field of KL under the guidance of experts, evaluates and comments on results Implements data processes and data products into operations and works on their operation and optimization Coordinates regularly with experts in statistics, data science and artificial intelligence at KL Maintains a balance between effort (time, cost) and expected benefit of incoming requests Contributes ideas for KL-relevant developments and methods, especially in the field of data analysis and artificial intelligence, and implements them as needed Supports the improvement and automation of processes/workflows in own & adjacent work areas through statistical methods and evaluations Works on cross-functional project teams and projects with external partners Keeps own expertise up to date (self-study, external training, meetings, specialist groups) Supports technical colleagues in the introduction, use and quality assurance of data analysis tools Presents contributions to statistics and data science in the context of Klüber internal and customer training Qualifications Engineering Graduate /Masters in Chemistry, Physics or equivalent degree Overall 7 -10 years of experience in data modelling, analysis and visualization in manufacturing or industrial environment. Completed higher education in science, focus on chemistry, physics, mathematics or related discipline Strong experience in methods for processing, evaluating and modeling data In depth programming knowledge with a focus on data science and data engineering, preferably in Python Experience using cheminformatics, materials informatics, generative AI and machine learning Experience in developing interactive data applications with frameworks like Shiny, Dash or streamlit good knowledge of relational data (SQL), experience in tools like JupyterLab, Gitlab, Airflow, MLFlow, knowledge of chemical analysis and organic chemistry The Freudenberg Group is an equal opportunity employer that is committed to diversity and inclusion. Employment opportunities are available to all applicants and associates without regard to race, color, religion, creed, gender (including pregnancy, childbirth, breastfeeding, or related medical conditions), gender identity or expression, national origin, ancestry, age, mental or physical disability, genetic information, marital status, familial status, sexual orientation, protected military or veteran status, or any other characteristic protected by applicable law.",associate,,"Python, SQL, Machine Learning, Data Analysis",
4249766681,AI / ML Developer (Senior),Infogain,"Mumbai, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Roles & Responsibilities Have hands on experience on real time ML Models / Projects Coding in Python Language, Machine Learning, Basic SQL, Git, MS Excel Experience in using IDE like Jupyter Notebook, Spyder, PyCharm Hands on with AWS Services like S3 bucket, EC2, Sagemaker, Step Functions. Engage with clients/consultants to understand requirements Taking ownership of delivering ML models with high precision outcomes. Accountable for high quality and timely completion of specified work deliverables Write codes that are well detailed structured and compute efficient Experience 8-11 Years Skills Primary Skill: AI/ML Development Sub Skill(s): AI/ML Development Additional Skill(s): AI/ML Development, TensorFlow, NLP, Pytorch About The Company Infogain is a human-centered digital platform and software engineering company based out of Silicon Valley. We engineer business outcomes for Fortune 500 companies and digital natives in the technology, healthcare, insurance, travel, telecom, and retail & CPG industries using technologies such as cloud, microservices, automation, IoT, and artificial intelligence. We accelerate experience-led transformation in the delivery of digital platforms. Infogain is also a Microsoft (NASDAQ: MSFT) Gold Partner and Azure Expert Managed Services Provider (MSP). Infogain, an Apax Funds portfolio company, has offices in California, Washington, Texas, the UK, the UAE, and Singapore, with delivery centers in Seattle, Houston, Austin, Kraków, Noida, Gurgaon, Mumbai, Pune, and Bengaluru.",,,"Python, SQL, Excel, Machine Learning",
4233766709,EY - GDS Consulting - AI Enabled Automation - AI Engineer - Senior,EY,"Kanayannur, Kerala, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. EY-Consulting – AI Enabled Automation – Senior - Full Stack Developer At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture, and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. Key Responsibilities: Requires 3-5 years minimum prior experience. Develop and maintain applications using Python. Collaborate with cross-functional teams to define, design, and ship new features. Optimize applications for maximum speed and scalability. Troubleshoot and debug applications. Work on both the front-end and back-end of the application stack. Relevant Experience of more than 2 years Required Skills: Strong proficiency in Python with at least 2 years of relevant experience. Experience with web frameworks such as Django or Flask. Familiarity with front-end technologies like HTML, CSS, and JavaScript. Preferred Skills: Knowledge of React JS, Node JS, or Angular. Understanding of RESTful APIs and web services. Experience with version control systems like Git. Knowledge of database technologies such as SQL and NoSQL. Additional Requirements: Excellent problem-solving skills. Strong communication and teamwork abilities. Ability to work in an agile development environment. What Working At EY Offers At EY, we’re dedicated to helping our clients, from start–ups to Fortune 500 companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",,,"Python, SQL",
4221289596,Lead Product Software - Data Science Engineer,Wolters Kluwer,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Job Description Summary Designs, develops, tests, debugs and implements more complex operating systems components, software tools, and utilities with full competency. Coordinates with users to determine requirements. Reviews systems under development and related documentation. Makes more complex modifications to existing software to fit specialized needs and configurations, and maintains program libraries and technical documentation. May coordinate activities of the project team and assist in monitoring project schedules and costs. Essential Duties And Responsibilities Lead and Manage configuration, maintenance, and support of portfolio of AI models and related products. Manage model delivery to Production deployment team and coordinate model production deployments. Ability to analyze complex data requirements, understand exploratory data analysis, and design solutions that meet business needs. Work on analyzing data profiles, transformation, quality and security with the dev team to build and enhance data pipelines while maintaining proper quality and control around the data sets. Work closely with cross-functional teams, including business analysts, data engineers, and domain experts. Understand business requirements and translate them into technical solutions. Understand and review the business use cases for data pipelines for the Data Lake including ingestion, transformation and storing in the Lakehouse. Present architecture and solutions to executive-level. Minimum Qualifications Bachelor's or master's degree in computer science, Engineering, or related technical field Minimum of 5 years' experience in building data pipelines for both structured and unstructured data. At least 2 years' experience in Azure data pipeline development. Preferably 3 or more years' experience with Hadoop, Azure Databricks, Stream Analytics, Eventhub, Kafka, and Flink. Strong proficiency in Python and SQL Experience with big data technologies (Spark, Hadoop, Kafka) Familiarity with ML frameworks (TensorFlow, PyTorch, scikit-learn) Knowledge of model serving technologies (TensorFlow Serving, MLflow, KubeFlow) will be a plus Experience with one pof the cloud platforms (Azure preferred) and their Data Services. Understanding ML services will get preference. Understanding of containerization and orchestration (Docker, Kubernetes) Experience with data versioning and ML experiment tracking will be great addition Knowledge of distributed computing principles Familiarity with DevOps practices and CI/CD pipelines Preferred Qualifications Bachelor's degree in Computer Science or equivalent work experience. Experience with Agile/Scrum methodology. Experience with tax and accounting domain a plus. Azure Data Scientist certification a plus. Applicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",executive,,"Python, SQL, Data Analysis",
4224918036,Lead Analyst - AI Engineer (Full Stack),Eaton,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,"4.0 Experience with AI platforms like Palantir, Snowflake, and DataIku is advantageous ]]> About the company Eaton 1,822,816 followers Follow Appliances, Electrical, and Electronics Manufacturing 10,001+ employees 53,349 on LinkedIn Eaton is an intelligent power management company dedicated to improving the quality of life and protecting the environment for people everywhere. We are guided by our commitment to do business right, to operate sustainably and to help our customers manage power ─ today and well into the future. By capitalizing on the global growth trends of electrification and digitalization, we’re accelerating the planet’s transition to renewable energy and helping to solve the world’s most urgent power management challenges. Eaton is an Equal Opportunity Employer. Eaton is committed to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of an applicant's race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, marital status, genetic information, protected veteran status, or any other status protected by law. … show more Interested in working with us in the future? Members who share that they’re interested in a company may be 2x as likely to get a message from a recruiter than those who don’t. Learn more Learn more about Interested in working for our company I’m interested Company photos Page 1 of 3 Previous Next April 24, 2023 April 24, 2023 May 24, 2024 Show more","About the job What You’ll Do Must have proven experience in Building front-end and back-end components for AI applications, building/consuming APIs, building customer centric user interfaces and designing integrations with other systems using .Net, JavaScript, Angular or React, SQL Must have proven experience in solution deployment by packaging trained AI models as services using Azure deployment services, Kubernetes, and GitHub for version control. Should have in depth understanding of Azure AI services such as Azure Machine Learning and Cognitive Services along with other AI technologies, natural language processing (NLP), computer vision and GPT models Should have strong expertise in articulating and documenting solution architecture for AI projects by collaborating with solution architect and enterprise architects. Must have abilities to collaborate with business leaders to understand their pain points and identify key areas where AI solutions can drive significant business benefit. Must have strong analytical and problem-solving skills, with the ability to translate business requirements into effective AI solutions. Must have excellent communication skills, with the ability to convey complex AI technical concepts to non-technical stakeholders Qualifications Bachelors in engineering/ B.E/B. Tech and/or required equivalent MCA. Overall 10+ years’ experience with proven track record of 5+ years in Solutioning and deploying end to end AI Technical skills : Net, JavaScript, Angular or React, SQL Server, Azure deployment services, Kubernetes, GitHub , Azure Cognitive Services , GPT models, added advantage with GitHub Copilot Skills Proficiency in front-end technologies (React or Angular) and back-end technologies (e.g., Node.js, Python, .NET). Strong understanding of AI and machine learning frameworks (e.g., TensorFlow, PyTorch). Experience with cloud and hybrid infrastructures. Proficiency in scripting and automation tools (e.g., PowerShell, Azure CLI) Expertise in cloud native development specialized in Microsoft Azure tech stack Experience of working on AI use cases involving in Salesforce AI (Einstein and Agentforce), ServiceNow AI (NowAssist and AI Agents), SAP AI (Joule) , Oracle Cloud AI, AI applications in Industry 4.0 Experience with AI platforms like Palantir, Snowflake, and DataIku is advantageous ]]>",,,"Python, SQL, Machine Learning",
4201289135,Senior AI Engineer,Emmes,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Overview Emmes Group: Building a better future for us all. Emmes Group is transforming the future of clinical research, bringing the promise of new medical discovery closer within reach for patients. Emmes Group was founded as Emmes more than 47 years ago, becoming one of the primary clinical research providers to the US government before expanding into public-private partnerships and commercial biopharma. Emmes has built industry leading capabilities in cell and gene therapy, vaccines and infectious diseases, ophthalmology, rare diseases, and neuroscience. We believe the work we do will have a direct impact on patients’ lives and act accordingly. We strive to build a collaborative culture at the intersection of being a performance and people driven company. We’re looking for talented professionals eager to help advance clinical research as we work to embed innovation into the fabric of our company. If you share our motivations and passion in research, come join us! Primary Purpose We are looking for a Senior AI Engineer with expertise in AWS-based AI/ML solutions to join our team. In this role, you will be responsible for automating the AI lifecycle, from data preparation, model training, and deployment to monitoring and integration within a fully AWS-driven environment. You will work closely with data engineers, data scientists, software engineers, and product managers to develop and deploy scalable Generative AI and NLP solutions using AWS services. Responsibilities Develop and deploy machine learning models using Generative AI, NLP, and Large Language Models (LLMs) in an AWS ecosystem. Utilize AI framework (Lang Chain, Llama Index etc), Bedrock, and SageMaker to develop and integrate AI-driven agents and language models. Automate and optimize end-to-end AI workflows, including data processing, model training, deployment, inference and monitoring using AWS Lambda, EC2, S3, SageMaker, and Bedrock. Architect and implement scalable and cost-effective AI solutions using AWS infrastructure best practices. Optimize AI workloads for high performance and cost-efficiency in AWS environments. Monitor model performance, retrain, and optimize ML pipelines for scalability and efficiency. Work closely with data engineers and software developers to integrate AI models into AWS-native applications. Document technical implementations and communicate best practices across teams. Stay up to date with AWS AI/ML advancements and emerging AI trends to enhance system performance and capabilities. Qualifications Engineering/master’s degree in computer science, Data Science, AI, or a related field. 4+ years of experience in Machine Learning, AI engineering, and model deployment in AWS environments. Strong expertise in AWS AI/ML services, including SageMaker, Bedrock, Lambda, S3, and EC2. Experience in Generative AI, NLP, Computer Vision, LangChain, and LLM-based solutions using Python and associated libraries. Hands-on experience with MLOps, CI/CD pipelines, and model monitoring in AWS. Proficiency in ML frameworks like TensorFlow, PyTorch, Keras, and scikit-learn. Solid understanding of cloud-native AI architectures, infrastructure optimization, and security best practices. Strong problem-solving and analytical skills with the ability to work in a cross-functional team. Excellent communication skills for technical and non-technical stakeholders. Preferred Qualifications: AWS certifications such as AWS Certified Machine Learning - Specialty. Experience with fine-tuning and deploying custom LLMs in AWS. Hands-on knowledge of distributed AI training and inference optimization in AWS. If you are passionate about cutting-edge AI and AWS-driven solutions, we invite you to join our team and contribute to groundbreaking AI innovations! CONNECT WITH US! Follow us on Twitter - @EmmesCRO Find us on LinkedIn - Emmes",manager,,"Python, Machine Learning",
4239582688,"Data Engineer II, Global GBS - Analytics COE-2",Kraft Heinz,"Ahmedabad, Gujarat, India",,Full-time,,"About the job Job Description GBS Analytics COE –Data Engineer About The Position We have an excellent opportunity available for a Data Engineer to make a difference at Kraft Heinz. The Data Engineer role lies within the newly created Analytics Centre of Excellence within the Global Business Services organization. The Analytics COE has been set up to build, maintain and enhance analytical products for our business to generate actionable insights from data and make better informed decisions. The individual for this position will be a technical expert providing leadership and expertise in the areas of data management, data quality, data governance, and data engineering. They will provide hands-on design, preparation, and development of data solutions for analytical products. They will work with internal stakeholders to translate business problems into data requirements and then create the data solutions to enable the development of analytical tools. Key Responsibilities Design, deliver and maintain the appropriate data solution to provide the correct data for analytical development to address key issues within the organization. Gather detailed data requirements and collaborate with a cross-functional team to deliver high quality results (such as Tableau developers, analysts, business users). Develop and operate modern data architecture approaches to meet key business objectives and provide end-to-end data solutions. Contribute to generic frameworks for data ingestion, data processing, and data integrations per business requirements. Extend DevOps capabilities for deploying data solutions. Supports creation and adoption of data assets for the organization, putting data quality as the focus of all data solutions. Act as a data owner and functional data SME for the assigned area. Lead the coaching of all junior data engineering resources. Ensure effective and timely delivery of project work, raising issues and risks in a timely manner to project manager to ensure appropriate actions can be taken to mitigate. Ensure effective and timely delivery of project work. Enforce best practices for data design, architecture, and implementation. Qualifications & Experience Bachelor’s Degree or higher in Computer Science, Statistics, Business, Information Technology, or related field (Master’s degree preferred) 5+ years of experience in delivering and supporting data engineering capabilities and building enterprise data solutions and data assets Strong experience with cloud services within Azure, AWS, or GCP platforms (preferably Azure) Strong experience with analytical tools (preferably SQL, dbt, Snowflake, BigQuery, Tableau) Experience with design and software programming development (preferably Python, Javascript and/or R) Experience building APIs (experience with GraphQL is a plus) Hands-on experience with DevOps and CI/CD processes Experience in Agile methodologies (certifications preferred) Project management experience and strong communication skills Self-Starter, driven with high business process acumen Team Player with a positive attitude and ability to work across different business stakeholder and technical teams to accomplish complex tasks Professional Attributes Communication Skills At Kraft Heinz you’ll easily be exposed to senior management, no matter your level. Therefore, it’s important you have excellent communication skills, to deal with all kinds of different stakeholders. Analytical o We’re a very data driven company. You know how to translate complex data into a simple solution with your analytical mindset. Curiosity, positivity & enthusiasm You’re curious, positive and enthusiastic. People know you as the driver of the team. Project management skills Time management has no secrets for you. You’re organized, structured and always have an overview of all the deliverables. You know how to bring multiple projects to a successful ending within the given timeframe. Team player Achieving results is nice, but achieving results with the team is simply the best. You’re a team player, which means you’re sometimes a leader, sometimes a follower but always working towards the same common goal together with your teammates. What we offer you An ambitious employer; we only want to the best for you; A fast career track like only few other companies can match; A competitive salary Always room for new ideas; if you have an excellent idea, please let us know and we can set it in action! Location(s) Ahmedabad – Mondeal Heights – GBS Center Kraft Heinz is an Equal Opportunity Employer – Underrepresented Ethnic Minority Groups/Women/Veterans/Individuals with Disabilities/Sexual Orientation/Gender Identity and other protected classes .",manager,,"Python, SQL, Tableau, R",
4218211012,Senior Gen AI Engineer - RAG Systems & AI Transformation,Gainwell Technologies,"Bengaluru, Karnataka, India (Remote)",Remote,Full-time,,"About the job Summary We are seeking a highly skilled and forward-thinking GenAI Engineer to join our AI innovation team. This role is ideal for someone with deep technical expertise in Generative AI , a strong foundation in Python programming , and a passion for driving enterprise AI transformation . You will be instrumental in designing, developing, and deploying advanced Retrieval-Augmented Generation (RAG) systems . You’ll also play a pivotal role in enabling our internal workforce to embrace and adopt AI technologies. Your role in our mission Architect and implement scalable RAG systems using Python and modern GenAI tools. Build custom pipelines for document ingestion, chunking strategies, and embedding generation. Working knowledge in LlamaIndex is preferable. Have a deep knowledge in using AI augmented tools like GitHub Copilot. Experience in developing custom extensions Evaluate and implement different embedding models (OpenAI, Azure OpenAI, Cohere, etc.) and chunking strategies (fixed-size, semantic-aware, overlap-based). Create and optimize indexing strategies (vector, hybrid, keyword-based, hierarchical) for performance and accuracy. Work with Azure AI Services, particularly Azure Cognitive Search and OpenAI integration, to deploy end-to-end AI applications. Collaborate closely with cross-functional teams including data engineers, product managers, and domain experts. Conduct AI enablement sessions, workshops, and hands-on labs to upskill internal teams on GenAI usage and best practices. Participate in code reviews, contribute to best practices, and ensure the reliability, scalability, and maintainability of AI systems. What we're looking for 8+ years of experience in software engineering, with strong expertise in Python. Proven track record of building and deploying RAG-based GenAI solutions. Hands-on experience with LlamaIndex, LangChain, or equivalent frameworks. Familiarity with prompt engineering, prompt tuning, and managing custom Copilot extensions. Strong understanding of LLMs, vector databases (like FAISS, Pinecone, Azure Cognitive Search), and embedding techniques. Solid knowledge of Azure AI, cloud deployment, and enterprise integration strategies. Proficiency with version control and collaborative development using GitHub. What you should expect in this role Architect and implement scalable RAG systems using Python and modern GenAI tools. Build custom pipelines for document ingestion, chunking strategies, and embedding generation. Working knowledge in LlamaIndex is preferable. Have a deep knowledge in using AI augmented tools like GitHub Copilot. Experience in developing custom extensions Evaluate and implement different embedding models (OpenAI, Azure OpenAI, Cohere, etc.) and chunking strategies (fixed-size, semantic-aware, overlap-based). Create and optimize indexing strategies (vector, hybrid, keyword-based, hierarchical) for performance and accuracy. Work with Azure AI Services, particularly Azure Cognitive Search and OpenAI integration, to deploy end-to-end AI applications. Collaborate closely with cross-functional teams including data engineers, product managers, and domain experts. Conduct AI enablement sessions, workshops, and hands-on labs to upskill internal teams on GenAI usage and best practices. Participate in code reviews, contribute to best practices, and ensure the reliability, scalability, and maintainability of AI systems.",manager,,Python,
4221170280,Principal ML Engineer,Oracle,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Job Description Invent, implement and deploy state-of-the-art machine learning and/or specific domain industry algorithms and systems. Build prototypes and explore conceptually new solutions. Work collaboratively with science, engineering, and product teams to identify customer needs in order to create and implement solutions, promote innovation and drive model implementations. Applies data science capabilities and research findings to create and implement solutions to scale. Responsible for developing new intelligence around core products and services through applied research on behalf of our customers. Develops models, prototypes, and experiments that pave the way for innovative products and services. Build cloud services that work out of the box for enterprises, e.g. decision support, anomaly detection, forecasting and recommendations), natural language processing (NLP), Natural Language Understanding (NLU),Time Series, Automatic Speech Recognition (ASR), Machine Learning (ML), and Computer Vision (CV). Design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience. Conversant on ethical problems in consideration of sciences. Responsibilities Drives and plans implementation of company policy for achieving business goals. Defines the bar for science practices, and helps teams achieve those goals. Identifies and mitigates risks across full set of systems, particularly at the intersection of business and engineering. Innovate AI and ML powered solutions (rich APIs, ML models and end to end services) with strategic ISVs and customers. Develop deep product intuition to influence future product roadmaps and drive decision making. Clearly articulate technical work to audiences of all levels and across multiple functional areas in both internal and external settings. Engage in forward looking research both internal and with academic institutions globally. Hires and mentors across the org. Perform an active role in team planning, review and retrospective events. Ensures experiments are ready for hand-off to Software Developers ship into production. May perform other duties as assigned. Qualifications Career Level - IC5 About Us As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s challenges. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. We know that true innovation starts when everyone is empowered to contribute. That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States. Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.",manager,,Machine Learning,
4233878447,Crest Infosystems - Machine Learning Engineer,Crest Infosystems Pvt. Ltd.,"Surat, Gujarat, India",,Full-time,,"About the job This job is sourced from a job board. Learn More Job Description We are looking for a skilled Machine Learning Engineer or AI Model Developer with at least 5 years of hands-on experience in building, training, and deploying custom AI models. The ideal candidate will have practical experience in developing and fine-tuning machine learning models rather than integrating pre-built models via APIs. Natural Abilities Smart, self-motivated, responsible, and out of the box thinker. Detailed oriented and powerful analyzer. Great writing communication skills. Requirements 5+ years of hands-on experience in building custom machine learning models (not just using APIs or pre-built models). Proficiency in machine learning frameworks such as TensorFlow, PyTorch, Keras, or similar. Strong programming skills in Python, with experience in libraries such as NumPy, pandas, scikit-learn, and others. Experience in training and fine-tuning machine learning models using real datasets. Knowledge of machine learning algorithms, model evaluation, and feature engineering. Hands-on experience with data preprocessing, model optimization, and hyperparameter tuning. Experience with cloud-based machine learning tools (AWS, GCP, or Azure) is a plus. Responsibilities Design, develop, and implement custom machine learning models tailored to specific business problems. Train, optimize, and validate machine learning models using real-world datasets and advanced techniques. Collaborate with cross-functional teams to understand requirements and deliver AI-driven solutions. Build and maintain end-to-end machine learning pipelines from data preprocessing to model deployment. Continuously improve the performance, scalability, and reliability of AI models in production environments. Perform model evaluations and select the best-performing models for real-world applications. Ensure proper documentation of model development processes and results. Stay current with industry trends, algorithms, and new technologies related to machine learning and AI. (ref:hirist.tech)",,,"Python, Machine Learning",
4203557302,Senior AI Engineer,Armada,"Thiruvananthapuram, Kerala, India (On-site)",On-site,Full-time,,"About the job About The Company Armada is an edge computing startup that provides computing infrastructure to remote areas where connectivity and cloud infrastructure is limited, as well as areas where data needs to be processed locally for real-time analytics and AI at the edge. We’re looking to bring on the most brilliant minds to help further our mission of bridging the digital divide with advanced technology infrastructure that can be rapidly deployed anywhere . About The Role At Armada, we are unlocking the limitless potential of AI to transform operations and improve lives in some of the most remote locations on Earth. From the expansive mines of Australia to the oil fields of Northern Canada, and the coffee plantations of Colombia, Armada offers a unique opportunity to tackle exciting AI and ML challenges on a global scale. We are actively seeking passionate AI Engineers with hands-on expertise across a range of domains, including real-time computer vision, statistical machine learning, natural language processing, transformers, control and navigation, reinforcement learning, and large-scale distributed AI systems. Ideal candidates will possess strong skills in machine learning (ML), deep learning (DL), and real-time computer vision techniques. You will be responsible for building ML/DL models tailored to specific challenges, preparing datasets for testing, evaluating model performance, and deploying solutions in production environments. Familiarity with containerization, microservices architecture, and the ability to independently deploy ML models into production is essential. If you are a self-driven individual with a passion for cutting-edge AI, we want to hear from you. Armada offers an unparalleled opportunity to confront some of the most thrilling AI and ML challenges in the world. Join our dynamic AI Engineering team as we deliver disruptive edge-compute systems capable of autonomous learning, prediction, and adaptation using vast, real-time datasets. We are pioneers in developing high-performance computing solutions for self-driving cars, camera networks, robotics, drones, conversational agents, and real-time monitoring and diagnostic systems. Our vision is to empower AI systems to seamlessly and securely interact with the complexities and uncertainties of the real world, and our mission is to bridge the digital divide in the process. Location. This role is office-based at our Trivandrum, Kerala office. What You'll Do (Key Responsibilities) Translating business requirements into requirements for AI/ML models. Preparing data to train and evaluate AI/ML/DL models. Building AI/ML/DL models by applying state-of-the-art algorithms, especially transformers. In some cases, leverage existing algorithms from academic or industrial research. Testing, evaluating the AI/ML/DL models, benchmarking their quality, and publishing the models, data sets, and evaluations. Deploying the models in production by containerizing the models. Working with customers and internal employees to refine the quality of the models. Establishing continuous learning pipelines for models with online learning or transfer learning. Building and deploying containerized applications on the cloud or on-premise environments Required Qualifications BS or MS degree in computer science, computational. science/engineering, or related technical field (or equivalent experience). 5+ years of work-related experience in software development with good Python, Java, and/or C/C++ programming skills. Familiarity with containers, numeric libraries, modular software design. Hands-on expertise with traditional statistical machine learning techniques as well as deep-learning and natural language processing modeling. Expertise in supervised, unsupervised, and transfer learning techniques. Hands-on expertise in machine learning techniques and algorithms with a strong background in state-of-the-art DNN architectures (Transformers, CNN, R-CNN, RNN, BERT, GAN, autoencoders, etc.) and experience in developing or using major deep learning frameworks (e.g., PyTorch, Tensorflow, etc). Experience with solving and using machine learning for real-world problems. Preferred Experience And Skills Demonstrable experience in building, programming, and integrating software and hardware for autonomous or robotic systems. Proven experience producing computationally efficient software to meet real-time requirements. Background with container platforms such as Kubernetes. Strong analytical skills with a bias for action. Strong time-management and organization skills to thrive in a fast-paced, dynamic environment. Solid written and oral communications skills. Good teamwork and interpersonal skills. Compensation & Benefits For India-based candidates: We offer a competitive base salary along with equity options, providing an opportunity to share in the success and growth of Armada. You're a Great Fit if You're A go-getter with a growth mindset. You're intellectually curious, have strong business acumen, and actively seek opportunities to build relevant skills and knowledge A detail-oriented problem-solver. You can independently gather information, solve problems efficiently, and deliver results with a ""get-it-done"" attitude Thrive in a fast-paced environment. You're energized by an entrepreneurial spirit, capable of working quickly, and excited to contribute to a growing company A collaborative team player. You focus on business success and are motivated by team accomplishment vs personal agenda Highly organized and results-driven. Strong prioritization skills and a dedicated work ethic are essential for you Equal Opportunity Statement At Armada, we are committed to fostering a work environment where everyone is given equal opportunities to thrive. As an equal opportunity employer, we strictly prohibit discrimination or harassment based on race, color, gender, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other characteristic protected by law. This policy applies to all employment decisions, including hiring, promotions, and compensation. Our hiring is guided by qualifications, merit, and the business needs at the time.",,,"Python, R, Machine Learning",
4228839739,Senior AI Engineer - REMOTE,Uplers,"Raipur, Chhattisgarh, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4241887583,Lead Analyst - AI Engineer (Full Stack),Eaton,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,"4.0 Experience with AI platforms like Palantir, Snowflake, and DataIku is advantageous ]]> Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company Eaton 1,822,816 followers Follow Appliances, Electrical, and Electronics Manufacturing 10,001+ employees 53,349 on LinkedIn Eaton is an intelligent power management company dedicated to improving the quality of life and protecting the environment for people everywhere. We are guided by our commitment to do business right, to operate sustainably and to help our customers manage power ─ today and well into the future. By capitalizing on the global growth trends of electrification and digitalization, we’re accelerating the planet’s transition to renewable energy and helping to solve the world’s most urgent power management challenges. Eaton is an Equal Opportunity Employer. Eaton is committed to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of an applicant's race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, marital status, genetic information, protected veteran status, or any other status protected by law. … show more Interested in working with us in the future? Members who share that they’re interested in a company may be 2x as likely to get a message from a recruiter than those who don’t. Learn more Learn more about Interested in working for our company I’m interested Company photos Page 1 of 3 Previous Next April 24, 2023 April 24, 2023 May 24, 2024 Show more","About the job What You’ll Do Must have proven experience in Building front-end and back-end components for AI applications, building/consuming APIs, building customer centric user interfaces and designing integrations with other systems using .Net, JavaScript, Angular or React, SQL Must have proven experience in solution deployment by packaging trained AI models as services using Azure deployment services, Kubernetes, and GitHub for version control. Should have in depth understanding of Azure AI services such as Azure Machine Learning and Cognitive Services along with other AI technologies, natural language processing (NLP), computer vision and GPT models Should have strong expertise in articulating and documenting solution architecture for AI projects by collaborating with solution architect and enterprise architects. Must have abilities to collaborate with business leaders to understand their pain points and identify key areas where AI solutions can drive significant business benefit. Must have strong analytical and problem-solving skills, with the ability to translate business requirements into effective AI solutions. Must have excellent communication skills, with the ability to convey complex AI technical concepts to non-technical stakeholders Qualifications Bachelors in engineering/ B.E/B. Tech and/or required equivalent MCA. Overall 10+ years’ experience with proven track record of 5+ years in Solutioning and deploying end to end AI Technical skills : Net, JavaScript, Angular or React, SQL Server, Azure deployment services, Kubernetes, GitHub , Azure Cognitive Services , GPT models, added advantage with GitHub Copilot Skills Proficiency in front-end technologies (React or Angular) and back-end technologies (e.g., Node.js, Python, .NET). Strong understanding of AI and machine learning frameworks (e.g., TensorFlow, PyTorch). Experience with cloud and hybrid infrastructures. Proficiency in scripting and automation tools (e.g., PowerShell, Azure CLI) Expertise in cloud native development specialized in Microsoft Azure tech stack Experience of working on AI use cases involving in Salesforce AI (Einstein and Agentforce), ServiceNow AI (NowAssist and AI Agents), SAP AI (Joule) , Oracle Cloud AI, AI applications in Industry 4.0 Experience with AI platforms like Palantir, Snowflake, and DataIku is advantageous ]]>",,,"Python, SQL, Machine Learning",
4252297424,Gen AI Lead Engineer,NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 323699 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Gen AI Lead Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Exercise expertise in ideating and developing AI/ML applications on prediction, recommendation, text analytics, computer vision, bots, and content intelligence. Apply statistical skills and advanced statistical techniques and concepts. Demonstrate deep knowledge of ML frameworks such as TensorFlow, PyTorch, Keras, Spacy, and scikit-learn. Leverage advanced knowledge of Python open-source software stack such as Django or Flask, Django Rest or FastAPI, etc. Deep knowledge in statistics and Machine Learning models, deep learning models, NLP, Generative Adversarial Networks (GAN), and other generative models. Experience working with RAG technologies and LLM frameworks, LLM model registries (Hugging Face), LLM APIs, embedding models, and vector databases Employ technical knowledge and hands-on experience with Azure OpenAI, Google Vertex Gen AI, and AWS LLM foundational models, BERT, Transformers, PaLM, Bard, etc. Display proficiency in programming languages such as Python and understanding of various Python packages. Experience with TensorFlow, PyTorch, or Keras. Develop and implement GenAI solutions, collaborating with cross-functional teams, and supporting the successful execution of AI projects for a diverse range of clients. Assist in the design and implementation of GenAI use cases, projects, and POCs across multiple industries. Work on RAG models and Agents Frameworks to enhance GenAI solutions by incorporating relevant information retrieval mechanisms and frameworks Create and maintain data infrastructure to ingest, normalize, and combine datasets for actionable insights. Work closely with customers to understand their requirements and deliver customized AI solutions. Interact at appropriate levels to ensure client satisfaction and project success. Communicate complex technical concepts clearly to non-technical audiences. Conduct training sessions to enhance overall data science skills within the organization Build solutions for Private AI and Smart Agentic Solutions Minimum Skills Required: 2+ years of experience architecting high-impact GenAI solutions for diverse clients, preferably in Private AI and Smart Agentic Solutions 8+ year(s) of experience participating in projects that focused on one or more of the following areas: Predictive Analytics Data Design Generative AI AI/ML ML Ops 3+ years of experience using Python. Ability to travel at least 25%. Bachelor’s Degree required. About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4252678068,FS-RC- EY Comply and RVS-AI Engineer-Senior,EY,"Kolkata, West Bengal, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. Position: Senior - AI Engineer Job Summary: As an AI Engineer, you will be responsible for designing, developing, and implementing AI models and algorithms that solve complex problems and enhance our products and services. You will work closely with software engineers, business users and product managers to create intelligent systems that leverage machine learning and artificial intelligence. Responsibilities: Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. Proficiency in Generative AI: Strong understanding of GPT architecture, prompt engineering, embeddings , efficient token usage and agentic AI solutions (example async, batching, caching, piping solutions etc ). Hands-on Experience with Model Training: Demonstrated ability to train and fine-tune AI/ML models, particularly in natural language processing (NLP). Expertise in Deep Learning Frameworks: Familiarity with popular deep learning libraries such as TensorFlow, PyTorch, or similar tools. NLP Techniques: Experience with various NLP techniques, namely using AI to extract the contents from unstructured complex PDF documents. Knowledge of deep learning techniques and neural networks. Strong communication skills to convey complex technical concepts to non-technical stakeholders. Skills requirement: 4 – 6 years of hands on experience developing AI solutions. Strong programming skills in languages such as Python. Strong experience with SQL, RESTful API, JSON Experience with Azure Cloud resources is preferable. Familiarity with DevOps practices and tools. Exposure to any noSQL Databases (MongoDB, Cosmos DB and etc) is a plus EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",manager,,"Python, SQL, Machine Learning",
4255440921,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4224210467,Power Programmer - Python - Q1-26,Infosys,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Python, Elasticsearch, PostgreSQL infrastructure as a code, one-click deployment, C4 diagrams Javascript, React Git, Scrum, Pair Programming, Peer Reviewing CI/CD with Jenkins pipeline Grafana, ELK stack, Docker, Kubernetes AWS and Terraform , Amazon Web Services and cloud deployments (S3, SNS, SQS, RDS, DynamoDB, etc.), using tools such as Terraform or AWS CLI Power Programmer is an important initiative within Global Delivery to develop a team of Full Stack Developers who will be working on complex engineering projects, platforms and marketplaces for our clients using emerging technologies., They will be ahead of the technology curve and will be constantly enabled and trained to be Polyglots., They are Go-Getters with a drive to solve end customer challenges and will spend most of their time in designing and coding, End to End contribution to technology oriented development projects., Providing solutions with minimum system requirements and in Agile Mode., Collaborate with Power Programmers., Open Source community and Tech User group., Custom Development of new Platforms & Solutions ,Opportunities., Work on Large Scale Digital Platforms and marketplaces., Work on Complex Engineering Projects using cloud native architecture ., Work with innovative Fortune 500 companies in cutting edge technologies., Co creates and develop New Products and Platforms for our clients., Contribute to Open Source and continuously upskill in latest technology areas., Incubating tech user group",,,Python,
4221169282,Principal ML Engineer,Oracle,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Job Description Invent, implement and deploy state-of-the-art machine learning and/or specific domain industry algorithms and systems. Build prototypes and explore conceptually new solutions. Work collaboratively with science, engineering, and product teams to identify customer needs in order to create and implement solutions, promote innovation and drive model implementations. Applies data science capabilities and research findings to create and implement solutions to scale. Responsible for developing new intelligence around core products and services through applied research on behalf of our customers. Develops models, prototypes, and experiments that pave the way for innovative products and services. Build cloud services that work out of the box for enterprises, e.g. decision support, anomaly detection, forecasting and recommendations), natural language processing (NLP), Natural Language Understanding (NLU),Time Series, Automatic Speech Recognition (ASR), Machine Learning (ML), and Computer Vision (CV). Design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience. Conversant on ethical problems in consideration of sciences. Responsibilities Drives and plans implementation of company policy for achieving business goals. Defines the bar for science practices, and helps teams achieve those goals. Identifies and mitigates risks across full set of systems, particularly at the intersection of business and engineering. Innovate AI and ML powered solutions (rich APIs, ML models and end to end services) with strategic ISVs and customers. Develop deep product intuition to influence future product roadmaps and drive decision making. Clearly articulate technical work to audiences of all levels and across multiple functional areas in both internal and external settings. Engage in forward looking research both internal and with academic institutions globally. Hires and mentors across the org. Perform an active role in team planning, review and retrospective events. Ensures experiments are ready for hand-off to Software Developers ship into production. May perform other duties as assigned. Qualifications Career Level - IC5 About Us As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s challenges. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. We know that true innovation starts when everyone is empowered to contribute. That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States. Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.",manager,,Machine Learning,
4127238644,GEN AI,Virtusa,"Andhra Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job Gen AI Integration Developer Extensive implementation experience in data analytics space or a senior developer role in one of the modern technology stack Excellent programming skills and proficiency in at least one of the major programming scripting languages used in Gen AI orchestration such as Python or PySpark or Java Ability to build API based scalable solutions and debug & troubleshoot software or design issues Hands on exposure to integrating atleast one of the popular LLMs(Open AI GPT, PaLM 2, Dolly, Claude 2, Cohere etc.) using API endpoints. Thorough understanding of prompt engineering; implementation exposure to LLM agents like LangChain & vector databases Pinecone or Chroma or FAISS Ability to quickly conduct experiments and analyze the features and capabilities of newer versions of the LLM models as they come into market Basic data engineering skills to load structured & unstructured data from source systems to target data stores Work closely with Gen AI leads and other team members to address requirements from the product backlog Build and maintain data pipelines and infrastructure to support AI Solutions Desirable:Hands on exposure to using cloud(Azure/GCP/AWS) services for storage, serverless-logic, search, transcription and chat Extensive experience with data engineering and ETL tools is a big plus Masters/Bachelors degree in Computer Science or Statistics or Mathematics Desired Skills and Experience AWS LLM, Python",,,Python,
4253258368,AI/ML Engineer,Team Geek Solutions,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job About The Opportunity A leading player in the Artificial Intelligence and Machine Learning sector, we specialize in developing cutting-edge solutions that transform data into actionable intelligence. Our team delivers innovative algorithms and models that drive performance and user engagement across various industries. We are on the lookout for a seasoned AI/ML Developer with significant experience to join our dynamic team in India and contribute to exciting projects that impact the future. Role & Responsibilities Design, develop, and deploy state-of-the-art AI/ML models that solve complex business problems. Collaborate effectively with cross-functional teams to translate business requirements into technical specifications for data-driven applications. Implement machine learning algorithms and optimize the performance of existing models through rigorous testing and data analysis. Integrate AI/ML solutions into production environments, ensuring robustness and scalability. Mentor junior developers, providing guidance on best practices and latest industry trends. Stay updated with emerging AI technologies and frameworks while innovating new solutions that enhance our product offerings. Skills & QualificationsMust-Have 7+ years of experience in AI/ML development with a solid understanding of algorithms. Proficiency in Python and libraries such as TensorFlow, PyTorch, and Scikit-learn. Experience with natural language processing (NLP) and image processing techniques. Strong background in data analysis and statistical modeling. Familiarity with deployment tools and practices in cloud environments. Hands-on experience with big data tools like Apache Spark or Hadoop. Preferred Experience with cloud platforms such as AWS or Azure for ML deployments. Knowledge of model versioning and monitoring strategies. Familiarity with RESTful APIs and microservices architecture. Benefits & Culture Highlights Collaborative work environment focused on innovation and continuous learning. Opportunities for professional development and career advancement. Competitive compensation package and employee benefits. Skills: apache spark,hadoop,model deployment,python,model versioning,monitoring strategies,scikit-learn,aws,microservices architecture,deep learning,gcp,image processing,pytorch,statistical modeling,machine learning,cloud environments,tensorflow,ai/ml development,natural language processing (nlp),restful apis,azure,ai/ml,data analysis,deployment tools,machine learning models",,,"Python, Machine Learning, Data Analysis",
4239058474,Artificial Intelligence Engineer,Curately.ai,India (Remote),Remote,Full-time,,"About the job Design, develop, and deploy NLP systems using advanced LLM architectures (e.g., GPT, BERT, LLaMA, Mistral) tailored for real-world applications such as chatbots, document summarization, Q&A systems, and more. Implement and optimize RAG pipelines, combining LLMs with vector search engines (e.g., FAISS, Weaviate, Pinecone) to create context-aware, knowledge-grounded responses. Integrate external knowledge sources, including databases, APIs, and document repositories, to enrich language models with real-time or domain-specific information. Fine-tune and evaluate pre-trained LLMs, leveraging techniques like prompt engineering, LoRA, PEFT, and transfer learning to customize model behavior. Collaborate with data engineers and MLOps teams to ensure scalable deployment and monitoring of AI services in cloud environments (e.g., AWS, GCP, Azure). Build robust APIs and backend services to serve NLP/RAG models efficiently and securely. Conduct rigorous performance evaluation and model validation, including accuracy, latency, bias/fairness, and explainability (XAI). Stay current with advancements in AI research, particularly in generative AI, retrieval systems, prompt tuning, and hybrid modeling strategies. Participate in code reviews, documentation, and cross-functional team planning to ensure clean and maintainable code.",Manager,,,
4228276005,Principal Audio ML engineer,Logitech,"Bengaluru, Karnataka, India",,Full-time,,"About the job Logitech is the Sweet Spot for people who want their actions to have a positive global impact while having the flexibility to do it in their own way. The Role : In this role you will be part of the Logitech Hardware Audio DSP and ML team developing and will be implementing real-time audio ML solutions to deliver innovative audio experiences to the customer. If you have a strong understanding of Audio DSP and TinyML apply for this role and have a huge contribution on the audio products that we develop! Your Contribution: Be Yourself. Be Open. Stay Hungry and Humble. Collaborate. Challenge. Decide and just Do. Share our passion for Equality and the Environment. These are the behaviors and values you’ll need for success at Logitech. In this role you will: Responsible for developing model and inference on resource constrained platforms like Tensilica DSP, ARM and RISCV cores. Responsible for optimizing and improving algorithm performance in real-world conditions – demonstrating innovative solutions to tough challenges. Work with cross-functional product team to deliver seamless customer audio experience. Key Qualifications: For consideration, you must bring the following minimum skills and experiences to our team: Experience leading a ML team with 10+ years of experience working in audio signal processing/ML. Tiny ML / Embedded ML - Hands-on experience porting neural network algorithms from intermediate representations such as Tensor Flow (TFLM), ONNX, etc. onto embedded targets using device-specific compilation tools and/or inference API’s. Deep understanding of on-device quantization techniques including post-training quantization, training-aware quantization, mixed precision inference. Strong programming skills in c, python. Conceptual understanding of how neural network operators map to embedded hardware accelerators such as DSP’s and NPU’s. Familiarity with Deep Learning Audio Signal Processing approaches for tasks including Speech enhancement / noise suppression / voice pickup Additional Skills: Experienced with Linux, Docker. Familiarity with CMSIS NN, HIFI NNLib is a plus Familiarity with audio measurements and standard subjective/objective audio evaluation metrics. Experience working in hardware product teams from product concept to mass production Good Audio listening skills and experience detecting audio artifacts. Experience communicating effectively in a cross functional environment. Strong problem-solving, critical-thinking skills Familiarity with code version control practices Across Logitech we empower collaboration and foster play. We help teams collaborate/learn from anywhere, without compromising on productivity or continuity so it should be no surprise that most of our jobs are open to work from home from most locations. Our hybrid work model allows some employees to work remotely while others work on-premises. Within this structure, you may have teams or departments split between working remotely and working in-house. Logitech is an amazing place to work because it is full of authentic people who are inclusive by nature as well as by design. Being a global company, we value our diversity and celebrate all our differences. Don’t meet every single requirement? Not a problem. If you feel you are the right candidate for the opportunity, we strongly recommend that you apply. We want to meet you! We offer comprehensive and competitive benefits packages and working environments that are designed to be flexible and help you to care for yourself and your loved ones, now and in the future. We believe that good health means more than getting medical care when you need it. Logitech supports a culture that encourages individuals to achieve good physical, financial, emotional, intellectual and social wellbeing so we all can create, achieve and enjoy more and support our families. We can’t wait to tell you more about them being that there are too many to list here and they vary based on location. All qualified applicants will receive consideration for employment without regard to race, sex, age, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability. If you require an accommodation to complete any part of the application process, are limited in the ability, are unable to access or use this online application process and need an alternative method for applying, you may contact us toll free at +1-510-713-4866 for assistance and we will get back to you as soon as possible.",,,Python,
4236575808,Machine Vision Engineer-Senior Consultant-Hyderabad/Bengaluru/Gurugram,Deloitte,"Hyderabad, Telangana, India",,Full-time,,"About the job Summary Position Summary The AI&E portfolio is an integrated set of offerings that addresses our clients’ heart-of-the-business issues. This portfolio combines our functional and technical capabilities to help clients transform, modernize, and run their existing technology platforms across industries. As our clients navigate dynamic and disruptive markets, these solutions are designed to help them drive product and service innovation, improve financial performance, accelerate speed to market, and operate their platforms to innovate continuously. ROLE – Machine Vision Developer Level: Senior Consultant As Senior Consultant at Deloitte Consulting, you will be responsible for individually delivering high quality work products within due timelines in an agile framework. Need-basis consultants will be mentoring and/or directing junior team members/liaising with onsite/offshore teams to understand the functional requirements. Responsibilities: The work you will do includes: Develop, test & deploy advanced Computer Vision algorithms for industrial apps, ensuring real-time processing & high accuracy Work with data scientists to preprocess and annotate datasets, and with software engineers to integrate vision solutions into OT systems Continuously monitor, troubleshoot, and optimize vision systems for performance and efficiency. Update and retrain models to adapt to new data and changing conditions Good interpersonal and communication skills Qualifications Skills / Project Experience: Hands exp. In programming languages such as Python, C++ with GPU programming and parallel processing using CUDA or OpenCL Must Have: Good interpersonal and communication skills Flexibility to adapt and apply innovation to varied business domain and apply technical solutioning and learnings to use cases across business domains and industries. Knowledge and experience working with Microsoft Office tools Good to Have: Problem-Solving : Strong analytical and troubleshooting skills to address client-specific challenges. Adaptability : Ability to quickly adapt to changing client requirements and emerging technologies. Project Leadership : Demonstrated leadership in managing client projects, ensuring timely delivery and client satisfaction. Business Acumen : Understanding of business processes and the ability to align technical solutions with client business goals. Education: B.E./B. Tech/M.C.A./M.Sc (CS) degree or equivalent from accredited university Prior Experience: 6 - 10 years of experience working with Proven experience in developing and deploying computer vision solutions in industrial or manufacturing settings. Hands-on leadership or significant contributions in end-to-end project execution – from data acquisition and preprocessing to model deployment and integration with OT systems. Track record of working with cross-functional teams including data scientists, control engineers, and software developers. Experience fine-tuning state-of-the-art Vision Transformer models and demonstrating measurable impact over traditional CNN-based methods. Exposure to real-time systems, model optimization techniques, and deploying vision solutions on edge devices or embedded systems. Location: Bengaluru/ Hyderabad/ Gurugram The team Deloitte Consulting LLP’s Technology Consulting practice is dedicated to helping our clients build tomorrow by solving today’s complex business problems involving strategy, procurement, design, delivery, and assurance of technology solutions. Our service areas include analytics and information management, delivery, cyber risk services, and technical strategy and architecture, as well as the spectrum of digital strategy, design, and development services. Core Business Operations Practice optimizes clients’ business operations and helps them take advantage of new technologies. Drives product and service innovation, improves financial performance, accelerates speed to market, and operates client platforms to innovate continuously. Learn more about our Technology Consulting practice on www.deloitte.com. #HC&IE Our purpose Deloitte’s purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities. Our people and culture Our inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work. Professional development At Deloitte, professionals have the opportunity to work with some of the best and discover what works best for them. Here, we prioritize professional growth, offering diverse learning and networking opportunities to help accelerate careers and enhance leadership skills. Our state-of-the-art DU: The Leadership Center in India, located in Hyderabad, represents a tangible symbol of our commitment to the holistic growth and development of our people. Explore DU: The Leadership Center in India . Benefits To Help You Thrive At Deloitte, we know that great people make a great organization. Our comprehensive rewards program helps us deliver a distinctly Deloitte experience that helps that empowers our professionals to thrive mentally, physically, and financially—and live their purpose. To support our professionals and their loved ones, we offer a broad range of benefits. Eligibility requirements may be based on role, tenure, type of employment and/ or other criteria. Learn more about what working at Deloitte can mean for you. Recruiting tips From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters. Requisition code: 302207",,,Python,
4228839738,Senior AI Engineer - REMOTE,Uplers,"Jamshedpur, Jharkhand, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4255310692,"Sr. Data Science & AIML, GenAI Lead/Engineer",NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 312481 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Sr. Data Science & AIML, GenAI Lead/Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Job Title: Data Science & AIML, GenAI Lead/Engineer Key Responsibilities: Develop and implement traditional machine learning algorithms. Deploy at least one model in a production environment. Write and maintain Python code for data science and machine learning projects. Minimum Skills Required: Preferred Qualifications: Knowledge of Deep Learning (DL) techniques. Experience working with Generative AI (GenAI) and Large Language Models (LLM). Exposure to Langchain. #GenAINTT About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4255446047,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4252669947,FS-RC- EY Comply and RVS-AI Engineer-Senior,EY,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. Position: Senior - AI Engineer Job Summary: As an AI Engineer, you will be responsible for designing, developing, and implementing AI models and algorithms that solve complex problems and enhance our products and services. You will work closely with software engineers, business users and product managers to create intelligent systems that leverage machine learning and artificial intelligence. Responsibilities: Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. Proficiency in Generative AI: Strong understanding of GPT architecture, prompt engineering, embeddings , efficient token usage and agentic AI solutions (example async, batching, caching, piping solutions etc ). Hands-on Experience with Model Training: Demonstrated ability to train and fine-tune AI/ML models, particularly in natural language processing (NLP). Expertise in Deep Learning Frameworks: Familiarity with popular deep learning libraries such as TensorFlow, PyTorch, or similar tools. NLP Techniques: Experience with various NLP techniques, namely using AI to extract the contents from unstructured complex PDF documents. Knowledge of deep learning techniques and neural networks. Strong communication skills to convey complex technical concepts to non-technical stakeholders. Skills requirement: 4 – 6 years of hands on experience developing AI solutions. Strong programming skills in languages such as Python. Strong experience with SQL, RESTful API, JSON Experience with Azure Cloud resources is preferable. Familiarity with DevOps practices and tools. Exposure to any noSQL Databases (MongoDB, Cosmos DB and etc) is a plus EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",manager,,"Python, SQL, Machine Learning",
4236574901,Machine Vision Engineer-Senior Consultant-Hyderabad/Bengaluru/Gurugram,Deloitte,"Bengaluru, Karnataka, India",,Full-time,,"About the job Summary Position Summary The AI&E portfolio is an integrated set of offerings that addresses our clients’ heart-of-the-business issues. This portfolio combines our functional and technical capabilities to help clients transform, modernize, and run their existing technology platforms across industries. As our clients navigate dynamic and disruptive markets, these solutions are designed to help them drive product and service innovation, improve financial performance, accelerate speed to market, and operate their platforms to innovate continuously. ROLE – Machine Vision Developer Level: Senior Consultant As Senior Consultant at Deloitte Consulting, you will be responsible for individually delivering high quality work products within due timelines in an agile framework. Need-basis consultants will be mentoring and/or directing junior team members/liaising with onsite/offshore teams to understand the functional requirements. Responsibilities: The work you will do includes: Develop, test & deploy advanced Computer Vision algorithms for industrial apps, ensuring real-time processing & high accuracy Work with data scientists to preprocess and annotate datasets, and with software engineers to integrate vision solutions into OT systems Continuously monitor, troubleshoot, and optimize vision systems for performance and efficiency. Update and retrain models to adapt to new data and changing conditions Good interpersonal and communication skills Qualifications Skills / Project Experience: Hands exp. In programming languages such as Python, C++ with GPU programming and parallel processing using CUDA or OpenCL Must Have: Good interpersonal and communication skills Flexibility to adapt and apply innovation to varied business domain and apply technical solutioning and learnings to use cases across business domains and industries. Knowledge and experience working with Microsoft Office tools Good to Have: Problem-Solving : Strong analytical and troubleshooting skills to address client-specific challenges. Adaptability : Ability to quickly adapt to changing client requirements and emerging technologies. Project Leadership : Demonstrated leadership in managing client projects, ensuring timely delivery and client satisfaction. Business Acumen : Understanding of business processes and the ability to align technical solutions with client business goals. Education: B.E./B. Tech/M.C.A./M.Sc (CS) degree or equivalent from accredited university Prior Experience: 6 - 10 years of experience working with Proven experience in developing and deploying computer vision solutions in industrial or manufacturing settings. Hands-on leadership or significant contributions in end-to-end project execution – from data acquisition and preprocessing to model deployment and integration with OT systems. Track record of working with cross-functional teams including data scientists, control engineers, and software developers. Experience fine-tuning state-of-the-art Vision Transformer models and demonstrating measurable impact over traditional CNN-based methods. Exposure to real-time systems, model optimization techniques, and deploying vision solutions on edge devices or embedded systems. Location: Bengaluru/ Hyderabad/ Gurugram The team Deloitte Consulting LLP’s Technology Consulting practice is dedicated to helping our clients build tomorrow by solving today’s complex business problems involving strategy, procurement, design, delivery, and assurance of technology solutions. Our service areas include analytics and information management, delivery, cyber risk services, and technical strategy and architecture, as well as the spectrum of digital strategy, design, and development services. Core Business Operations Practice optimizes clients’ business operations and helps them take advantage of new technologies. Drives product and service innovation, improves financial performance, accelerates speed to market, and operates client platforms to innovate continuously. Learn more about our Technology Consulting practice on www.deloitte.com. #HC&IE Our purpose Deloitte’s purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities. Our people and culture Our inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work. Professional development At Deloitte, professionals have the opportunity to work with some of the best and discover what works best for them. Here, we prioritize professional growth, offering diverse learning and networking opportunities to help accelerate careers and enhance leadership skills. Our state-of-the-art DU: The Leadership Center in India, located in Hyderabad, represents a tangible symbol of our commitment to the holistic growth and development of our people. Explore DU: The Leadership Center in India . Benefits To Help You Thrive At Deloitte, we know that great people make a great organization. Our comprehensive rewards program helps us deliver a distinctly Deloitte experience that helps that empowers our professionals to thrive mentally, physically, and financially—and live their purpose. To support our professionals and their loved ones, we offer a broad range of benefits. Eligibility requirements may be based on role, tenure, type of employment and/ or other criteria. Learn more about what working at Deloitte can mean for you. Recruiting tips From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters. Requisition code: 302207",,,Python,
4257566828,Senior Software Engineer,Dreamcast,"Jaipur, Rajasthan, India (On-site)",On-site,Full-time,,"About the job Company Description Dreamcast is a leading event-tech suite designed to empower event leaders to host scalable events, achieve high ROI, and deliver exceptional event experiences. Our advanced solutions offer complete control for event organizers, while ensuring a secure and seamless experience for attendees. Trusted by prominent organizations like Dell, PwC, and Johnson & Johnson, we integrate functionalities such as cashless payment systems, AI matchmaking, and 3D virtual environments to optimize event management. Join us to revolutionize the event industry with innovative technology. Role Description This is a full-time, on-site role for a Senior Software Engineer located in Jaipur. The Senior Software Engineer will be responsible for designing, developing, and maintaining back-end web applications. Day-to-day tasks include coding, debugging, optimizing software performance, and collaborating with cross-functional teams to deliver high-quality software solutions. The role also involves ensuring best practices in software development and staying updated on the latest technologies and trends. Qualifications Proficiency in Software Development, and Back-End Web Development Strong foundation in Computer Science and Programming Experience with Object-Oriented Programming (OOP) Excellent problem-solving and analytical skills Ability to work collaboratively in a team environment Bachelor's degree in Computer Science, Software Engineering, or a related field Experience with cloud technologies and microservices architecture is a plus Strong communication and interpersonal skills",,,,
4256415945,Developer,Qr.nikhil,"Mumbai, Maharashtra, India (Remote)",Remote,,,"About the job The ideal candidate will be responsible for conceptualizing and executing clear, quality code to develop the best software. You will test your code, identify errors, and iterate to ensure quality code. You will also support our customers and partners by troubleshooting any of their software issues. Responsibilities Detect and troubleshoot software issues Write clear quality code for software and applications and perform test reviews Develop, implement, and test APIs Provide input on software development projects Qualifications Comfort using programming languages and relational databases Strong debugging and troubleshooting skills 3+ years' of development experience",,,,
4198517995,GEN AI,Virtusa,"Andhra Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job Gen AI Specialist 4 Machine Learning, Deep Learning, and AI Research Generative AI (GANs, VAEs, Diffusion Models) Document Detail Extraction, Feature Engineering Prompt Engineering & Chain-of-Thought Reasoning Python Programming, AI Agent Design Developed and deployed an AI-powered generative tool for extracting structured details from unstructured documents. Implemented chain of thought reasoning techniques to craft optimized prompts for generative AI models. Designed and deployed AI agents to automate complex workflows and improve efficiency. Experience with neural networks, generative models, and advanced AI techniques, Python, GANs, VAEs, diffusion models, Streamlit Desired Skills and Experience Gen AI, ET-GENAI-Azure., Azure Machine learning services",,,"Python, Machine Learning",
4257552462,Java Software Engineer,Health Catalyst,"Hyderabad, Telangana, India (Hybrid)",Hybrid,Full-time,,"About the job About us : The healthcare industry is the next great frontier of opportunity for software development, and Health Catalyst is one of the most dynamic and influential companies in this space. We are working on solving national-level healthcare problems, and this is your chance to improve the lives of millions of people, including your family and friends. Health Catalyst is a fast-growing company that values smart, hardworking, and humble individuals. Each product team is a small, mission-critical team focused on developing innovative tools to support Catalyst’s mission to improve healthcare performance, cost, and quality. Health Catalyst is expanding and maintains a large suite of Improvement Apps that contribute to healthcare analytics and process improvement solutions. This includes products that manage the care of health system populations, better serve patients at the point of care, reduce health system costs, and reduce clinician workload. Job Description: What you'll do and own in this role: High level of responsibility and Ownership from ideation through to execution. Ability to lead a team and implement best practices in every aspect of project deliverables. Stay up to date with new frameworks and tools and enable the team to use them. Ability to thrive under pressure & work in a fast-paced, timeline-oriented environment Give topmost priority to the quality of deliverables of the team Co-ordinate with various teams such as monitoring, backup, and Network to ensure the proper functioning of all servers and their services A genuine intention to work cooperatively with others, to be part of a team, to work together as opposed to working separately or competitively. Encourages and facilitates cooperation, pride, trust, and group identity; fosters commitment and team spirit; works with others to achieve goals. Develop and own solutions, ensuring the viability of proposed solutions and providing support on the appropriate approach throughout the project. Drive end-to-end solution development. Subject matter expert in assigned technology domain (i.e. infrastructure, data, application, etc.) Remain current on industry-specific technologies and emerging trends. Other duties as assigned. What you bring to this role: Strong hands-on development skills in J2EE Technologies, Spring framework, Spring Boot, JavaScript, and Git. 6+ years of experience designing, deploying, and maintaining software solutions. Experience with the installation of COTS products and the ability to evaluate different tools. Strong concepts in Microservice Architecture (MSA) and SOAP & REST web services. Require experience in the following areas: Eclipse, Apache Tomcat, hibernate ORM, JDBC, PostgreSQL, SQL, Bitbucket, Linux, HTML5, CSS3, Spring framework 4.x (including Spring MVC), Spring ecosystem components like Netflix Eureka, Swagger Codegen, etc., POI Framework, XMLBeans, regular expressions, XML, Java 1.8, Java IO processing. Working knowledge on Continuous Integration (CI) and Continuous Delivery (CD) setup, leveraging tools like SonarQube, Maven, Jenkins, Nexus, EKS, etc. Java test automation experience with testing toolkits. The candidate will ensure the conversion of mission-critical requirements into enterprise systems solutions that account for the design and technology maturity constraints of the system. The scope of these assignments will include software development tool and server system administration, process improvement, design review, and code review. Experience in AWS could platform. Knowledge and experience in Security controls and the architecture of secure applications.",,,SQL,
4247420307,AI/ML Developer,Adroit Innovative Solutions Inc,"Hyderabad, Telangana, India (On-site)",On-site,Contract,,"About the job About The Job Job Title: AI/ML Developer About The Role Duration: 12 Months Location: PAN INDIA Timings: Full Time (As per company timings) Notice Period: within 15 days or immediate joiner Experience: 1- 3 years Key Responsibilities Design and deploy ML models focused on NLP and Computer Vision. Handle data labelling, preprocessing, and model validation. Assist in API development to integrate ML models into apps. Fine-tune and train models to improve performance. Collaborate with teams to deliver practical AI-driven solutions. Maintain documentation of model processes and outcomes. Required Skills & Qualification 1- 3 years in AI/ML development with hands-on work in NLP or CV. Strong Python skills with libraries like TensorFlow, PyTorch, scikit-learn. Experience in data preprocessing and model deployment. Exposure to cloud platforms (AWS/GCP/Azure) is a plus. Familiarity with MLOps and API integration is desirable. Degree in Computer Science, Data Science, or related field. Knowledge of big data tools (Spark/Hadoop) or other languages (R/Java/C++) is an advantage.",,,"Python, R",
4111775529,AI / ML Developer,Soft Suave Technologies,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More We are seeking a Senior Developer to join our dynamic team and lead AI-driven projects. This role requires a blend of advanced technical expertise in AI and machine learning, exceptional problem-solving abilities, and experience in building and deploying scalable AI solutions. Requirements Machine Learning & AI: Expertise in ML algorithms, especially for classification, anomaly detection, and predictive analytics. Cloud Platforms: Proficiency in Google Cloud Platform (GCP) services, including Cloud Run, BigQuery, and Vertex AI. Programming Languages: Advanced knowledge of Python; experience with libraries like TensorFlow, PyTorch, Scikit-learn, and Pandas. Data Processing: Skilled in SQL, data transformations, and ETL processes, especially with BigQuery. Anomaly Detection: Proven experience in building and deploying anomaly detection models, particularly for network data. Network Data Analysis: Familiarity with analyzing network logs, IP traffic, and related data structures. DevOps & CI/CD: Experience with CI/CD pipelines for ML model deployment, particularly with tools like Cloud Build. This job was posted by Ashwini Ayyanarswamy from Soft Suave. Desired Skills and Experience Machine Learning,Python,PyTorch,Scikit-learn,TensorFlow",,,"Python, SQL, Machine Learning, Data Analysis",
4253591175,AI/ML Ops Engineer IRC268288,GlobalLogic,"Nagpur, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Description Apply machine learning algorithms to existing operational data (logs, metrics, events) to predict system failures and proactively address potential incidents. Implement automation for routine DevOps practices including automated scaling, resource optimization, and controlled restarts. Develop and maintain self-healing systems to reduce manual intervention and enhance system reliability. Build anomaly detection models to quickly identify and address unusual operational patterns. Collaborate closely with SREs, developers, and infrastructure teams to continuously enhance the operational stability and performance of the system. Provide insights and improvements through visualizations and reports leveraging AI-driven analytics. Create a phased roadmap to incrementally enhance operational capabilities and align with strategic business goals. Required Skills and Qualifications: Strong experience with AI/ML frameworks and tools (e.g., TensorFlow, PyTorch, scikit-learn). Proficiency in data processing and analytics tools (e.g., Splunk, Prometheus, Grafana, ELK stack). Solid background in scripting and automation (Python, Bash, Ansible, etc.). Experience with cloud environments and infrastructure automation. Proven track record in implementing proactive monitoring, anomaly detection, and self-healing techniques. Excellent analytical, problem-solving, and strategic planning skills. Strong communication skills and the ability to effectively collaborate across teams. Preferred Experience: Background in DevOps/Site Reliability Engineering. Familiarity with containerization and orchestration platforms (Kubernetes, Docker). Experience in building scalable, distributed systems. Requirements Apply machine learning algorithms to existing operational data (logs, metrics, events) to predict system failures and proactively address potential incidents. Implement automation for routine DevOps practices including automated scaling, resource optimization, and controlled restarts. Develop and maintain self-healing systems to reduce manual intervention and enhance system reliability. Build anomaly detection models to quickly identify and address unusual operational patterns. Collaborate closely with SREs, developers, and infrastructure teams to continuously enhance the operational stability and performance of the system. Provide insights and improvements through visualizations and reports leveraging AI-driven analytics. Create a phased roadmap to incrementally enhance operational capabilities and align with strategic business goals. Required Skills and Qualifications: Strong experience with AI/ML frameworks and tools (e.g., TensorFlow, PyTorch, scikit-learn). Proficiency in data processing and analytics tools (e.g., Splunk, Prometheus, Grafana, ELK stack). Solid background in scripting and automation (Python, Bash, Ansible, etc.). Experience with cloud environments and infrastructure automation. Proven track record in implementing proactive monitoring, anomaly detection, and self-healing techniques. Excellent analytical, problem-solving, and strategic planning skills. Strong communication skills and the ability to effectively collaborate across teams. Preferred Experience: Background in DevOps/Site Reliability Engineering. Familiarity with containerization and orchestration platforms (Kubernetes, Docker). Experience in building scalable, distributed systems. Job responsibilities Apply machine learning algorithms to existing operational data (logs, metrics, events) to predict system failures and proactively address potential incidents. Implement automation for routine DevOps practices including automated scaling, resource optimization, and controlled restarts. Develop and maintain self-healing systems to reduce manual intervention and enhance system reliability. Build anomaly detection models to quickly identify and address unusual operational patterns. Collaborate closely with SREs, developers, and infrastructure teams to continuously enhance the operational stability and performance of the system. Provide insights and improvements through visualizations and reports leveraging AI-driven analytics. Create a phased roadmap to incrementally enhance operational capabilities and align with strategic business goals. Required Skills and Qualifications: Strong experience with AI/ML frameworks and tools (e.g., TensorFlow, PyTorch, scikit-learn). Proficiency in data processing and analytics tools (e.g., Splunk, Prometheus, Grafana, ELK stack). Solid background in scripting and automation (Python, Bash, Ansible, etc.). Experience with cloud environments and infrastructure automation. Proven track record in implementing proactive monitoring, anomaly detection, and self-healing techniques. Excellent analytical, problem-solving, and strategic planning skills. Strong communication skills and the ability to effectively collaborate across teams. Preferred Experience: Background in DevOps/Site Reliability Engineering. Familiarity with containerization and orchestration platforms (Kubernetes, Docker). Experience in building scalable, distributed systems. What we offer Culture of caring. At GlobalLogic, we prioritize a culture of caring. Across every region and department, at every level, we consistently put people first. From day one, you’ll experience an inclusive culture of acceptance and belonging, where you’ll have the chance to build meaningful connections with collaborative teammates, supportive managers, and compassionate leaders. Learning and development. We are committed to your continuous learning and development. You’ll learn and grow daily in an environment with many opportunities to try new things, sharpen your skills, and advance your career at GlobalLogic. With our Career Navigator tool as just one example, GlobalLogic offers a rich array of programs, training curricula, and hands-on opportunities to grow personally and professionally. Interesting & meaningful work. GlobalLogic is known for engineering impact for and with clients around the world. As part of our team, you’ll have the chance to work on projects that matter. Each is a unique opportunity to engage your curiosity and creative problem-solving skills as you help clients reimagine what’s possible and bring new solutions to market. In the process, you’ll have the privilege of working on some of the most cutting-edge and impactful solutions shaping the world today. Balance and flexibility. We believe in the importance of balance and flexibility. With many functional career areas, roles, and work arrangements, you can explore ways of achieving the perfect balance between your work and life. Your life extends beyond the office, and we always do our best to help you integrate and balance the best of work and life, having fun along the way! High-trust organization. We are a high-trust organization where integrity is key. By joining GlobalLogic, you’re placing your trust in a safe, reliable, and ethical global company. Integrity and trust are a cornerstone of our value proposition to our employees and clients. You will find truthfulness, candor, and integrity in everything we do. About GlobalLogic GlobalLogic, a Hitachi Group Company, is a trusted digital engineering partner to the world’s largest and most forward-thinking companies. Since 2000, we’ve been at the forefront of the digital revolution – helping create some of the most innovative and widely used digital products and experiences. Today we continue to collaborate with clients in transforming businesses and redefining industries through intelligent products, platforms, and services.",manager,,"Python, Machine Learning",
4228840637,Senior AI Engineer - REMOTE,Uplers,Greater Bhopal Area (Remote),Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4249782800,Gen AI Lead Engineer,NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 323700 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Gen AI Lead Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Exercise expertise in ideating and developing AI/ML applications on prediction, recommendation, text analytics, computer vision, bots, and content intelligence. Apply statistical skills and advanced statistical techniques and concepts. Demonstrate deep knowledge of ML frameworks such as TensorFlow, PyTorch, Keras, Spacy, and scikit-learn. Leverage advanced knowledge of Python open-source software stack such as Django or Flask, Django Rest or FastAPI, etc. Deep knowledge in statistics and Machine Learning models, deep learning models, NLP, Generative Adversarial Networks (GAN), and other generative models. Experience working with RAG technologies and LLM frameworks, LLM model registries (Hugging Face), LLM APIs, embedding models, and vector databases Employ technical knowledge and hands-on experience with Azure OpenAI, Google Vertex Gen AI, and AWS LLM foundational models, BERT, Transformers, PaLM, Bard, etc. Display proficiency in programming languages such as Python and understanding of various Python packages. Experience with TensorFlow, PyTorch, or Keras. Develop and implement GenAI solutions, collaborating with cross-functional teams, and supporting the successful execution of AI projects for a diverse range of clients. Assist in the design and implementation of GenAI use cases, projects, and POCs across multiple industries. Work on RAG models and Agents Frameworks to enhance GenAI solutions by incorporating relevant information retrieval mechanisms and frameworks Create and maintain data infrastructure to ingest, normalize, and combine datasets for actionable insights. Work closely with customers to understand their requirements and deliver customized AI solutions. Interact at appropriate levels to ensure client satisfaction and project success. Communicate complex technical concepts clearly to non-technical audiences. Conduct training sessions to enhance overall data science skills within the organization Build solutions for Private AI and Smart Agentic Solutions Minimum Skills Required: 2+ years of experience architecting high-impact GenAI solutions for diverse clients, preferably in Private AI and Smart Agentic Solutions 8+ year(s) of experience participating in projects that focused on one or more of the following areas: Predictive Analytics Data Design Generative AI AI/ML ML Ops 3+ years of experience using Python. Ability to travel at least 25%. Bachelor’s Degree required. About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4255443770,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4255418580,GEN AI,Virtusa,"Chennai, Tamil Nadu, India (Hybrid)",Hybrid,Full-time,,"About the job Gen AI Integration Developer Extensive implementation experience in data analytics space or a senior developer role in one of the modern technology stack Excellent programming skills and proficiency in at least one of the major programming scripting languages used in Gen AI orchestration such as Python or PySpark or Java Ability to build API based scalable solutions and debug & troubleshoot software or design issues Hands on exposure to integrating atleast one of the popular LLMs(Open AI GPT, PaLM 2, Dolly, Claude 2, Cohere etc.) using API endpoints. Thorough understanding of prompt engineering; implementation exposure to LLM agents like LangChain & vector databases Pinecone or Chroma or FAISS Ability to quickly conduct experiments and analyze the features and capabilities of newer versions of the LLM models as they come into market Basic data engineering skills to load structured & unstructured data from source systems to target data stores Work closely with Gen AI leads and other team members to address requirements from the product backlog Build and maintain data pipelines and infrastructure to support AI Solutions Desirable:Hands on exposure to using cloud(Azure/GCP/AWS) services for storage, serverless-logic, search, transcription and chat Extensive experience with data engineering and ETL tools is a big plus Masters/Bachelors degree in Computer Science or Statistics or Mathematics Desired Skills and Experience AWS LLM, Azure LLM - Chat GPT, GCP LLM - Pal M, Python",,,Python,
4259093761,Principal Engineer,Freecharge,"Gurgaon, Haryana, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Responsibilities Ensure the quality of architecture and design of systems by serving as a technical lead on our most demanding, cross-functional teams. Functionally decompose complex problems into simple, straightforward solutions. Leverage knowledge of internal and industry in design decisions and have zeal and drive to take end-to-end ownership. Exert technical influence over multiple teams, increasing their productivity and effectiveness by sharing your deep knowledge and experience. Build performant, scalable, yet secure, enterprise-ready, cost-effective back-end architectures that can support millions of users in parallel while re-architecting the existing problems. Lead design and development of product, working closely with the business team. Independently own software components and co-own entire applications with a small group of fellow developers, and review code. Should have experience working with Product Management to create product roadmaps, functional specifications, and design specifications of features based on customer/product requirements. Research, experiment, and recommend new technologies that can help increase productivity/reduce technical risk or debt. Requirements 8+ years of software development experience with Enterprise Java (JDK 8 and above), Spring (Boot, MVC, AOP, DI), ORM Frameworks. 4+ years of experience contributing to the architecture and design (LLD, HLD, OO design patterns, reliability, and scaling) of new and current systems. Strong experience in data structures and algorithms, and their space and time complexities. Strong working experience in an agile environment, and technically leading the team of developers and reviewing code. Experience in high-traffic, highly scalable microservices, distributed system designs. Experience working with microservices-based architecture. Hands-on experience working with Databases like SQL and NoSQL Hands-on experience working with caches like Ehcache, Redis, etc. Solid understanding of multithreading, MVC, and strong OO skills with demonstrated experience in developing complex and reusable APIs and understanding of the full software development life cycle. This job was posted by Anushree Rathore from FreeCharge. Desired Skills and Experience Java,Hibernate,Spring",,,SQL,
4247919869,Senior AI/ML Engineer - R01551252,Brillio,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Senior AI/ML Engineer Primary Skills Hypothesis Testing, T-Test, Z-Test, Regression (Linear, Logistic), Python/PySpark, SAS/SPSS, Statistical analysis and computing, Probabilistic Graph Models, Great Expectation, Evidently AI, Forecasting (Exponential Smoothing, ARIMA, ARIMAX), Tools(KubeFlow, BentoML), Classification (Decision Trees, SVM), ML Frameworks (TensorFlow, PyTorch, Sci-Kit Learn, CNTK, Keras, MXNet), Distance (Hamming Distance, Euclidean Distance, Manhattan Distance), R/ R Studio Job requirements Key Responsibilities - Develop and optimize machine learning models for various applications. - Implement AI algorithms, including deep learning, neural networks, and natural language processing (NLP). - Design and maintain data pipelines for model training and deployment. - Collaborate with cross-functional teams to integrate AI solutions into products. - Conduct research on emerging AI technologies and best practices. - Ensure scalability, reliability, and efficiency of AI models in production environments. - Troubleshoot and improve existing AI/ML systems. Required Skills & Qualifications - Experience: 3-8 years in AI/ML development. - Technical Skills: Proficiency in Python, TensorFlow, PyTorch, and other ML frameworks. - Data Handling: Strong knowledge of data preprocessing, feature engineering, and model evaluation. - Cloud & Deployment: Experience with cloud platforms (AWS, Azure, GCP) and containerization (Docker, Kubernetes). - Problem-Solving: Ability to analyze complex problems and develop AI-driven solutions.",,,"Python, R, Machine Learning",
4255998545,Senior Machine Learning Engineer,AB InBev GCC India,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics. Do You Dream Big? We Need You. Job Description Job Title: Senior Machine Learning Engineer Location: Bangalore Reporting to: Senior Manager - Analytics 1. Purpose of the role We are seeking a talented Machine Learning Engineer to design, develop, and deploy advanced machine learning models and MLOps pipelines on the Azure cloud platform. The ideal candidate will have expertise in Azure cloud services, Azure Data Factory (ADF), Databricks, machine learning, MLOps, and Python, along with strong stakeholder management skills to align solutions with business objectives. 2. Key tasks & accountabilities Machine Learning Development : Design, train, and deploy machine learning models using Azure Machine Learning, Databricks, and Python-based frameworks (e.g., Scikit-learn, TensorFlow, PyTorch). MLOps Implementation : Build and maintain MLOps pipelines for model versioning, automated training, deployment, monitoring, and retraining using Azure and Databricks. Data Integration : Utilize Azure Data Factory (ADF) to orchestrate data pipelines for model training and inference, ensuring seamless data flow from Azure Data Lake or Blob Storage. Azure Cloud Expertise : Leverage Azure cloud services (e.g., Azure Machine Learning, Azure Kubernetes Service, Azure Synapse Analytics) to build scalable and secure AI solutions. Python Programming : Write robust, efficient Python code for model development, data preprocessing, and automation tasks. Stakeholder Collaboration : Partner with business stakeholders, data scientists, and product teams to gather requirements, communicate technical concepts, and deliver AI-driven solutions. Model Optimization : Optimize machine learning models for performance, scalability, and cost-efficiency in production environments. Documentation & Best Practices : Document ML workflows, ensure reproducibility, and share knowledge with team members and stakeholders. 3. Qualifications, Experience, Skills Level of educational attainment required Master’s Degree or equivalent Technical skills required Azure Cloud Services : Proficiency in Azure Machine Learning, Azure Data Factory, Azure Data Lake, Blob Storage, and related services. Databricks : Hands-on experience with Databricks for machine learning workflows and data processing. Machine Learning : Strong knowledge of ML algorithms, deep learning frameworks, and model evaluation techniques. MLOps : Expertise in MLOps practices, including CI/CD for ML, model monitoring, and lifecycle management. Python : Advanced proficiency in Python for machine learning, data manipulation, and automation. And above all of this, an undying love for beer! We dream big to create future with more cheers .",Manager,,"Python, Machine Learning",
4251691177,"Business Intel Engineer II, Global Operations - Artificial Intelligence",Amazon,"Hyderabad, Telangana, India",,Full-time,,"About the job Description Want to join the Earth’s most customer centric company? Do you like to dive deep to understand problems? Are you someone who likes to challenge Status Quo? Do you strive to excel at goals assigned to you? If yes, we have opportunities for you. Global Operations – Artificial Intelligence (GO-AI) at Amazon is looking to hire candidates who can excel in a fast-paced dynamic environment. Are you somebody that likes to use and analyze big data to drive business decisions? Do you enjoy converting data into insights that will be used to enhance customer decisions worldwide for business leaders? Do you want to be part of the data team which measures the pulse of innovative machine vision-based projects? If your answer is yes, join our team. GO-AI is looking for a motivated individual with strong skills and experience in resource utilization planning, process optimization and execution of scalable and robust operational mechanisms, to join the GO-AI Ops DnA team. In this position you will be responsible for supporting our sites to build solutions for the rapidly expanding GO-AI team. The role requires the ability to work with a variety of key stakeholders across job functions with multiple sites. We are looking for an entrepreneurial and analytical program manager, who is passionate about their work, understands how to manage service levels across multiple skills/programs, and who is willing to move fast and experiment often. Key job responsibilities Ability to maintain and refine straightforward ETL and write secure, stable, testable, maintainable code with minimal defects and automate manual processes. Proficiency in one or more industry analytics visualization tools (e.g. Excel, Tableau/Quicksight/PowerBI) and, as needed, statistical methods (e.g. t-test, Chi-squared) to deliver actionable insights to stakeholders. Building and owning small to mid-size BI solutions with high accuracy and on time delivery using data sets, queries, reports, dashboards, analyses or components of larger solutions to answer straightforward business questions with data incorporating business intelligence best practices, data management fundamentals, and analysis principles. Good understanding of the relevant data lineage: including sources of data; how metrics are aggregated; and how the resulting business intelligence is consumed, interpreted and acted upon by the business where the end product enables effective, data-driven business decisions. Having high responsibility for the code, queries, reports and analyses that are inherited or produced and having analyses and code reviewed periodically. Effective partnering with peer BIEs and others in your team to troubleshoot, research root causes, propose solutions, by either take ownership for their resolution or ensure a clear hand-off to the right owner. About The Team The Global Operations – Artificial Intelligence (GO-AI) team is an initiative, which remotely handles exceptions in the Amazon Robotic Fulfillment Centers Globally. GO-AI seeks to complement automated vision based decision-making technologies by providing remote human support for the subset of tasks which require higher cognitive ability and cannot be processed through automated decision making with high confidence. This team provides end-to-end solutions through inbuilt competencies of Operations and strong central specialized teams to deliver programs at Amazon scale. It is operating multiple programs and other new initiatives in partnership with global technology and operations teams. Basic Qualifications 5+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience Experience with data visualization using Tableau, Quicksight, or similar tools Experience with data modeling, warehousing and building ETL pipelines Experience in Statistical Analysis packages such as R, SAS and Matlab Experience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling Preferred Qualifications Experience with AWS solutions such as EC2, DynamoDB, S3, and Redshift Experience in data mining, ETL, etc. and using databases in a business environment with large-scale, complex datasets Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI HYD 16 SEZ Job ID: A3009412",manager,,"Python, SQL, Excel, Tableau, R",
4259081343,Power Apps Developer,Gigmo Solutions,"Gurugram, Haryana, India (On-site)",On-site,Full-time,,"About the job Job Description: Power Apps Developer (2-3 years experience) Position: Power Apps Developer Location: Gurugram Experience: 2-3 Years Company Overview: At Gigmos, we are at the forefront of digital transformation, helping our clients leverage the full potential of Microsoft Power Platform to optimize their business processes and workflows. We are seeking a talented and driven Power Apps Developer to join our dynamic team. If you are passionate about building intuitive, scalable, and impactful solutions, we'd love to hear from you. Job Responsibilities : Design, develop, and deploy Canvas Apps using Microsoft Power Apps to meet business requirements Utilize Power Automate to automate workflows, ensuring smooth data flow between systems and processes Leverage Microsoft Dataverse to design data models, connect applications, and optimize business data Collaborate closely with business stakeholders to gather and define requirements, ensuring technical solutions align with organizational needs Customize and configure Power Apps components, including forms, views, and business rules, to enhance user experience and functionality Create automated workflows using Power Automate for process automation across various platforms (SharePoint, Teams, Dynamics 365, etc.) Integrate Power Apps and Power Automate solutions with other enterprise systems (e.g., Dynamics 365, Office 365, third-party APIs) Troubleshoot and resolve issues related to Power Apps and Power Automate, providing timely support and solutions Ensure adherence to best practices in app development, security, and data management Continuously learn and apply new Power Platform features and enhancements to optimize application performance Technical Expertise: Proficiency in Power Apps Canvas App development, Strong knowledge of Power Automate for creating flows and automating business processes and Experience working with Microsoft Dataverse for building data models and managing application data.",,3 years experience,,
4202881589,Data Engineer,Haleon,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Hello. We’re Haleon. A new world-leading consumer health company. Shaped by all who join us. Together, we’re improving everyday health for billions of people. By growing and innovating our global portfolio of category-leading brands – including Sensodyne, Panadol, Advil, Voltaren, Theraflu, Otrivin, and Centrum – through a unique combination of deep human understanding and trusted science. What’s more, we’re achieving it in a company that we’re in control of. In an environment that we’re co-creating. And a culture that’s uniquely ours. Care to join us. It isn’t a question. With category leading brands such as Sensodyne, Voltaren and Centrum, built on trusted science and human understanding, and combined with our passion, knowledge and expertise, we’re uniquely placed to do this and to grow a strong, successful business. This is an exciting time to join us and help shape the future. It’s an opportunity to be part of something special. About The Role You will be working on the latest data platform technologies, and a part of a high-performing team fully committed to employee growth and development. If you’re a skilled engineer who wants to build using the latest technology and acquire new skills in data and analytics, then come join our team. You will be integrating components, designing frameworks, and building reusable data solutions for Haleon’s Enterprise Data & Analytics Platform. You will enable faster acquisition, ingestion, and curation of analytical-ready datasets. This is very hands-on development role which includes developing & delivering code through from origin to production, plus working in partnership with 3rd party development service providers to help ensure that code comes in on time, to quality and in line with the overall ecosystem being established. The Data Engineer will directly contribute to the extensive and varied build and deployment activities involved in establishing the new platform then continue to work on the already significant and growing pipeline of future buildouts of platform services on the Enterprise Data & Analytics Platform. Key Responsibilities Development Hands on, sleeves up development and delivery code through from origin to production, plus working in partnership with 3rd party development service providers to help ensure that performant/quality code comes is written and in line with the overall ecosystem being established The Data Engineer will directly contribute to the extensive and varied build and deployment activities involved in establishing the new products/platform then continue to work on the already significant and growing pipeline of future buildouts of platform services on the Enterprise Data & Analytics Platform. Qualifications And Essential Skills MS/BS degree in Computer Science, Engineering, Data Science or equivalent experience, with preference on experience and proven track record. Ideal candidate would have an impressive hands-on work history in an advanced, recognized, and innovative environment. 4+ years of Data engineering experience and seasoned coder in the relevant languages: Pyspark, SQL, etc 4+ years of experience with the Azure data and analytics stack: Azure Databricks, Azure Data Factory (SHIR, etc), Keyvault, LogicApp, Unity Catalog (UC), ADLS Gen2, Synapse, etc. Experience with Agile (in a highly structured and robust reporting delivery management methodology format) delivery frameworks and tools: SAFe, Jira, Confluence, Github Action and Azure DevOps (Pipelines, self-hosted agent, etc), Github, delivery break down estimation, etc. Fully conversant with big-data processing approaches and “schema-on-read” methodologies. Preference for deep understanding of Spark, Databricks and Delta Lake, and applying them to solve data science and machine learning business problems. Fluency with Data/Platform/Reliability Engineering patterns for operational resilience & co-contribution development patterns. Ability to develop and optimise the Spark code for large volumes of Data. Familiar deploying enterprise analytics solutions at scale with applicable services: administration, qualification, and user access provisioning. Experience articulating business value of analytics projects and progressing solutions from MVP to scaled-up production solutions. Production experience delivering CI/CD pipelines across Azure and vendor products. Knowledge of Data modelling, Purview and their application. Ability to work in close partnership with groups across the IT organization (security, compliance, infrastructure, etc.) and business stakeholders in the commercial organizations. Ability to develop and maintain productive working relationships with suppliers and specialist technology providers to assemble and maintain a distinctive and flexible mix of capabilities against future requirements. Ideal candidate possesses great communication skills and the ability to communicate inherently complicated technical concepts to non-technical stakeholders of all levels. Good To Have Skills Knowledge of Microsoft Fabric, PowerBI, PowerApp, Azure Synapse, Purview and Scala. Experience with visualization tools and their application: developing reports, dashboards and KPI scorecards. Knowledge of Informatica IDMC (Data Quality, Data Marketplace and Data Catalogue) is preferred Delivery Ensure project goals are achieved on time in alignment with the stakeholders’ expectation. Ability to work on complex projects and in a distributed environment. Escalate when necessary and in a timely manner. Work in close collaboration with other team members in the Enterprise Data & Analytics Platform team, to ensure Development/Delivery aspects are well represented in the project’s requirements and deliverables. Methodology Incorporate agile ways of working into the delivery process utilising DABL (Discovery, Alpha, Beta, Launch) Individuals will work as part of product-centric delivery team(s) that will focus on delivering value independently while fully embracing integrated DevOps approaches. Ownership Take ownership for the delivery/development projects and help steer until completion Governance Maintain governance that allows projects and stakeholders to manage overall project performance and manage programme risks within the global nature of some of the programmes. Forward looking Remain flexible towards technology approaches to ensure we are taking advantage of new technologies. Keep abreast of industry developments in analytics and be able to interpret how these would impact services and present new opportunities. Quality, Risk & Compliance Ensure all risk and issues associated with owned projects are recorded and managed in the appropriate Risk & Issue logs in a timely manner. Ensure all Risks and Issues have clear action/mitigation/contingency plans defined, with named action owners and timelines for completion. Technical Architecture Be conversant with technical architecture to contribute to design discussions in partnership with the Delivery/Development Lead and dedicated Analytics & Data Architect. Care to join us. Find out what life at Haleon is really like www.haleon.com/careers/ At Haleon we embrace our diverse workforce by creating an inclusive environment that celebrates our unique perspectives, generates curiosity to create unmatched understanding of each other, and promotes fair and equitable outcomes for everyone. We're striving to create a climate where we celebrate our diversity in all forms by treating each other with respect, listening to different viewpoints, supporting our communities, and creating a workplace where your authentic self belongs and thrives. We believe in an agile working culture for all our roles. If flexibility is important to you, we encourage you to explore with our hiring team what the opportunities are. As you apply, we will ask you to share some personal information, which is entirely voluntary. We want to have an opportunity to consider a diverse pool of qualified candidates and this information will assist us in meeting that objective and in understanding how well we are doing against our inclusion and diversity ambitions. We would really appreciate it if you could take a few moments to complete it. Rest assured, Hiring Managers do not have access to this information and we will treat your information confidentially. Haleon is an Equal Opportunity Employer. All qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class. Accommodation Requests If you require a reasonable accommodation or other assistance to apply for a job at Haleon at any stage of the application process, please let your recruiter know by providing them with a description of specific accommodations you are requesting. We’ll provide all reasonable accommodations to support you throughout the recruitment process and treat all information you provide us in confidence.",Manager,,"SQL, Machine Learning",
4259091955,Software Implementation Engineer,NStarX,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More We are seeking an experienced, dedicated, and technically proficient individual to join our team as a Senior System/Implementation Engineer. This role involves providing essential technical assistance, managing system configurations, and troubleshooting issues, with a strong emphasis on Linux/Unix environments and healthcare IT interfaces. The ideal candidate should possess excellent communication skills and a customer-focused approach, capable of interacting directly with clients. Responsibilities Provide technical support and perform troubleshooting for system requirements and operational issues, particularly in Linux/Unix environments. Utilize command-line tools and utilities for system management, including Docker containers. Work with MySQL and MongoDB, including writing and executing SQL queries for data management. Develop, test, and troubleshoot automation scripts using XSL/XSLT. Manage code versions and repositories using SVN. Configure and troubleshoot secure communication protocols such as SSL, SSH, and SCP. Interact directly with the client's IT staff to address system-related inquiries, coordinate system requirements, and facilitate necessary firewall configurations. Oversee the implementation and maintenance of our solution deployed on-premises, including the primary deployment and ongoing management responsibilities. Perform analysis and troubleshooting to resolve technical problems independently. Gain familiarity with hardware components like VMs, touchscreens, and thin clients. Requirements Skillset: Linux, Docker, MySQL. Experience: 5+ yrs of relevant experience. Operating Systems: Strong proficiency in Linux/Unix command-line operations, utilities, and various Linux distributions (especially RedHat, CentOS, Rocky Linux). Containerization: Experience with Docker containers. Databases: Proficient in MySQL and MongoDB, including writing and executing SQL queries. Automation/Transformation: Experience with XSL/XSLT for automation coding, testing, and troubleshooting. Healthcare Interfaces: Familiarity with HL7 interface/message standards. Version Control: Experience with SVN for code management. Networking/Security Protocols: Understanding and practical use of SSL, SSH, and SCP. Security: Familiarity with firewall concepts and configurations. Hardware Knowledge: Familiarity with virtual machines (VMs), touchscreens, and thin clients. Communication: Good verbal and written communication skills, ability to work effectively in a customer-facing role. Problem-Solving: Ability to perform independent analysis and troubleshooting when technical problems arise. This job was posted by K Anjali from NStarX. Desired Skills and Experience Linux,Unix,CentOS,Red Hat",,,SQL,
4257561902,Sr. AI/ML Engineer,PVAR SERVICES,"Gurugram, Haryana, India (On-site)",On-site,Full-time,"AI Product Role and Responsibilities: Model Development: Design, train, test, and deploy machine learning models using frameworks like Pytorch and TensorFlow, specifically for virtual try-on applications with a focus on draping and fabric simulation. Task-Specific Modeling: Build models for tasks such as Natural Language Processing (NLP), Speech-to-Text (STT), and Text-to-Speech (TTS) that integrate seamlessly with computer vision applications in the virtual try-on domain. Image Processing: Implement advanced image processing techniques including enhancement, compression, restoration, filtering, and manipulation to improve the accuracy and realism of draping in virtual try-on systems. Feature Extraction & Segmentation: Apply feature extraction methods, image segmentation techniques, and draping algorithms to create accurate and realistic representations of garments on virtual models. Machine Learning Pipelines: Develop and maintain ML pipelines for data ingestion, processing, and transformation to support large-scale deployments of virtual try-on solutions. Deep Learning & Draping: Build and train convolutional neural networks (CNNs) for image recognition, fabric draping, and texture mapping tasks crucial to the virtual try-on experience. AI Fundamentals: Leverage a deep understanding of AI fundamentals, including machine learning, computer vision, draping algorithms, and generative AI (Gen AI) techniques to drive innovation in virtual try-on technology. Programming: Proficiently code in Python and work with other programming languages like Java, C++, or R as required. Cloud Integration: Utilize cloud-based AI platforms such as AWS, Azure, or Google Cloud to deploy and scale virtual try-on solutions, with a focus on real-time processing and rendering. Data Analysis: Perform data analysis and engineering to optimize the performance and accuracy of AI models, particularly in the context of fabric draping and garment fitting. Continuous Learning: Stay informed about the latest trends and developments in machine learning, deep learning, computer vision, draping technologies, and generative AI (Gen AI), applying them to virtual try-on projects. Skills Required: Experience: Minimum of 5 years in Computer Vision Engineering or a similar role, with a focus on virtual try-on, draping, or related applications. Programming: Strong programming skills in Python, with extensive experience in Pytorch and TensorFlow. Draping & Fabric Simulation: Hands-on experience with draping algorithms, fabric simulation, and texture mapping techniques. Data Handling: Expertise in data pre-processing, feature engineering, and data analysis to support high-quality model development, especially for draping and virtual garment fitting. Deep Neural Networks & Gen AI: Extensive experience in working with Deep Neural Networks, Generative Adversarial Networks (GANs), Conditional GANs, Transformers, and other generative AI techniques relevant to virtual try-on and draping. Advanced Techniques: Proficiency with cutting-edge techniques like Stable Diffusion, Latent Diffusion, InPainting, Text-to-Image, Image-to-Image models, and their application in computer vision and virtual try-on technology. Algorithm Knowledge: Strong understanding of machine learning algorithms and techniques, including deep learning, supervised and unsupervised learning, reinforcement learning, natural language processing, and generative AI. Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company PVAR SERVICES 68,707 followers Follow Staffing and Recruiting 11-50 employees 12 on LinkedIn PVAR Services specializes in Tech and AI end-to-end recruitment services for Mid to C-suite roles. We are India's leading HR Tech Company, trusted by over 200+ companies. To revolutionize hiring through mediator-led solutions, facilitating seamless communication between employers and candidates, resulting in a streamlined recruitment process. Tech and AI Positions: Head of AI/ML, Chief Data Scientist, Senior AI Research Scientist, AI/ML Product Manager, Director of Engineering - AI/ML, VP of Artificial Intelligence, AI Delivery Engineer, ML Engineer, Data Scientist, NLP Engineer, Computer Vision Engineer, Deep Learning Engineer, AI Delivery Manager, and more. Leadership and Engineering Roles: Principal Engineer/CTO, Cloud Architect, Director of Engineering, Data Engineering Lead, Cybersecurity Head/CISO, VP of Product Engineering, MLOps Architect, Product Head, Technical Product Manager, Product Analyst, Engineering Head, Android/iOS Developer, Full Stack Developer, Tech Architect, UX/UI Designer, and more. Non- tech Position: Chief Financial Officer (CFO), Chief Marketing Officer (CMO), Head of Human Resources (HR), Chief People Officer, Director of Business Development, Head of Sales, Chief Strategy Officer (CSO), Head of Operations,  Managing Director (MD),  Head of PR, . Legal Head, VP of Customer Experience. Get In Touch: Contact our Co-founder, Vartika Singh, at vartika.singh@pvarservices.com to learn more about our services. … show more Commitments Work-life balance -Flexible working hours: We offer flexible working hours, which means our employees can work when it suits them best. This flexibility can allow employees to manage their work responsibilities while also attending to their personal needs.","About the job Designation: Sr. AI/ML Engineer Location: Gurugram Experience: 5+ years Budget: Upto 35 LPA Industry: AI Product Role and Responsibilities: Model Development: Design, train, test, and deploy machine learning models using frameworks like Pytorch and TensorFlow, specifically for virtual try-on applications with a focus on draping and fabric simulation. Task-Specific Modeling: Build models for tasks such as Natural Language Processing (NLP), Speech-to-Text (STT), and Text-to-Speech (TTS) that integrate seamlessly with computer vision applications in the virtual try-on domain. Image Processing: Implement advanced image processing techniques including enhancement, compression, restoration, filtering, and manipulation to improve the accuracy and realism of draping in virtual try-on systems. Feature Extraction & Segmentation: Apply feature extraction methods, image segmentation techniques, and draping algorithms to create accurate and realistic representations of garments on virtual models. Machine Learning Pipelines: Develop and maintain ML pipelines for data ingestion, processing, and transformation to support large-scale deployments of virtual try-on solutions. Deep Learning & Draping: Build and train convolutional neural networks (CNNs) for image recognition, fabric draping, and texture mapping tasks crucial to the virtual try-on experience. AI Fundamentals: Leverage a deep understanding of AI fundamentals, including machine learning, computer vision, draping algorithms, and generative AI (Gen AI) techniques to drive innovation in virtual try-on technology. Programming: Proficiently code in Python and work with other programming languages like Java, C++, or R as required. Cloud Integration: Utilize cloud-based AI platforms such as AWS, Azure, or Google Cloud to deploy and scale virtual try-on solutions, with a focus on real-time processing and rendering. Data Analysis: Perform data analysis and engineering to optimize the performance and accuracy of AI models, particularly in the context of fabric draping and garment fitting. Continuous Learning: Stay informed about the latest trends and developments in machine learning, deep learning, computer vision, draping technologies, and generative AI (Gen AI), applying them to virtual try-on projects. Skills Required: Experience: Minimum of 5 years in Computer Vision Engineering or a similar role, with a focus on virtual try-on, draping, or related applications. Programming: Strong programming skills in Python, with extensive experience in Pytorch and TensorFlow. Draping & Fabric Simulation: Hands-on experience with draping algorithms, fabric simulation, and texture mapping techniques. Data Handling: Expertise in data pre-processing, feature engineering, and data analysis to support high-quality model development, especially for draping and virtual garment fitting. Deep Neural Networks & Gen AI: Extensive experience in working with Deep Neural Networks, Generative Adversarial Networks (GANs), Conditional GANs, Transformers, and other generative AI techniques relevant to virtual try-on and draping. Advanced Techniques: Proficiency with cutting-edge techniques like Stable Diffusion, Latent Diffusion, InPainting, Text-to-Image, Image-to-Image models, and their application in computer vision and virtual try-on technology. Algorithm Knowledge: Strong understanding of machine learning algorithms and techniques, including deep learning, supervised and unsupervised learning, reinforcement learning, natural language processing, and generative AI.",Executive,,"Python, R, Machine Learning, Data Analysis",
4228838859,Senior AI Engineer - REMOTE,Uplers,"Patna, Bihar, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4249787288,Gen AI Lead Engineer,NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 323701 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Gen AI Lead Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Exercise expertise in ideating and developing AI/ML applications on prediction, recommendation, text analytics, computer vision, bots, and content intelligence. Apply statistical skills and advanced statistical techniques and concepts. Demonstrate deep knowledge of ML frameworks such as TensorFlow, PyTorch, Keras, Spacy, and scikit-learn. Leverage advanced knowledge of Python open-source software stack such as Django or Flask, Django Rest or FastAPI, etc. Deep knowledge in statistics and Machine Learning models, deep learning models, NLP, Generative Adversarial Networks (GAN), and other generative models. Experience working with RAG technologies and LLM frameworks, LLM model registries (Hugging Face), LLM APIs, embedding models, and vector databases Employ technical knowledge and hands-on experience with Azure OpenAI, Google Vertex Gen AI, and AWS LLM foundational models, BERT, Transformers, PaLM, Bard, etc. Display proficiency in programming languages such as Python and understanding of various Python packages. Experience with TensorFlow, PyTorch, or Keras. Develop and implement GenAI solutions, collaborating with cross-functional teams, and supporting the successful execution of AI projects for a diverse range of clients. Assist in the design and implementation of GenAI use cases, projects, and POCs across multiple industries. Work on RAG models and Agents Frameworks to enhance GenAI solutions by incorporating relevant information retrieval mechanisms and frameworks Create and maintain data infrastructure to ingest, normalize, and combine datasets for actionable insights. Work closely with customers to understand their requirements and deliver customized AI solutions. Interact at appropriate levels to ensure client satisfaction and project success. Communicate complex technical concepts clearly to non-technical audiences. Conduct training sessions to enhance overall data science skills within the organization Build solutions for Private AI and Smart Agentic Solutions Minimum Skills Required: 2+ years of experience architecting high-impact GenAI solutions for diverse clients, preferably in Private AI and Smart Agentic Solutions 8+ year(s) of experience participating in projects that focused on one or more of the following areas: Predictive Analytics Data Design Generative AI AI/ML ML Ops 3+ years of experience using Python. Ability to travel at least 25%. Bachelor’s Degree required. About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4255464396,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Operations Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: As an AI / ML Engineer, you will develop applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve designing and implementing production-ready application pipelines, ensuring high-quality standards. You will also explore the integration of generative AI models into solutions, while working on various aspects of deep learning, neural networks, chatbots, and image processing to enhance functionality and performance. Roles & Responsibilities: - Expected to be an SME. - Collaborate and manage the team to perform. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Provide solutions to problems for their immediate team and across multiple teams. - Facilitate workshops and meetings to gather requirements and feedback from stakeholders. - Develop and maintain documentation related to integration processes and solutions. - Automate complex tasks and workflows across infrastructure management, data processing, application deployments, and IT operations. - Identify process improvement opportunities and implement optimizations. - Utilize RPA solutions where applicable. - Design and implement efficient data pipelines for machine learning models. - Leverage AI/ML techniques (NLP, ML algorithms, data analysis) to create intelligent automation solutions - Perform regular maintenance (patching, upgrades, configuration changes) of security solutions. - Build and implement on-premises and cloud-based security solutions using SaaS, IaaS, and orchestration tools. - Implement robust monitoring and logging solutions. - Report on security status, incidents, and improvements to management. - Develop and maintain APIs and microservices for automation workflows. - Stay abreast of cybersecurity trends, vulnerabilities, and attack vectors. - Proactively propose enhancements to security controls. - Provide exceptional support to internal and external users. - Conduct regular security assessments and vulnerability scans. Professional & Technical Skills: - Must Have Skills: Proficiency in Artificial Intelligence & Machine Learning Operations, Python and PowerShell, including experience with automation scripts and frameworks. - Solid understanding of AI/ML concepts and experience with relevant libraries (e.g., TensorFlow, PyTorch, scikit-learn). - Proficiency in data manipulation and analysis using Pandas and NumPy. - Knowledge of version control systems (e.g., Git) and CI/CD pipelines. - Hands-on experience with orchestration tools (e.g., Ansible, Puppet). - Strong understanding of integration frameworks and methodologies. - Experience with cloud-based solutions and deployment strategies. - Familiarity with data management and data governance practices. Additional Information: - The candidate should have minimum 5 years of experience in Machine Learning Operations. - This position is based at our Hyderabad office. - A 15 years full time education is required. 15 years full time education",,,"Python, Machine Learning, Data Analysis",
4257566797,Sr. Mobile Game Developer (Unity),Zigsaw,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Unity Developer Experience: 4+ years Work location: Noida Sector 62 Work Days: 5 days (Mon-Fri) Interview Rounds: 4 Budget : Open for right Candidate it is team handling role interview mode: online Join our Engineering Team We are looking for a talented individual who possess knowledge of vectors, matrices, and linear algebra. Someone who can work with Fast growth in a company with new opportunities and a rapid career. We follow flatter structure with a way of working more independently, self-driven, and responsibly. What we want to see in your past experience: 4+ years of experience in Unity games development with experience in C#. Strong software architecture skills and understanding of game systems Drive performance improvements, Game optimisation across IOS and android Deep expertise in Unity Addressable experience in Multiplayer Game development, AI. Ability to create custom native IOS/ Android plugins and can implement in Unity. What we are looking for in you as a colleague Ability to collaborate and meet deadlines Self-driven, responsible, and curious to learn Attention to details Excellent in English, written and spoken",,,,
4244340399,"Lead Machine Learning Engineer – MLOps, VertexAI, LLMs, GenAI, ML Model Management",UPS,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Avant de postuler à un emploi, sélectionnez votre langue de préférence parmi les options disponibles en haut à droite de cette page. Découvrez votre prochaine opportunité au sein d'une organisation qui compte parmi les 500 plus importantes entreprises mondiales. Envisagez des opportunités innovantes, découvrez notre culture enrichissante et travaillez avec des équipes talentueuses qui vous poussent à vous développer chaque jour. Nous savons ce qu’il faut faire pour diriger UPS vers l'avenir : des personnes passionnées dotées d’une combinaison unique de compétences. Si vous avez les qualités, de la motivation, de l'autonomie ou le leadership pour diriger des équipes, il existe des postes adaptés à vos aspirations et à vos compétences d'aujourd'hui et de demain. Role Overview Fiche de poste : UPS Data Science and Machine Learning team is seeking a highly skilled and experienced Lead Machine Learning Engineer to manage our AI, ML, GenAI application focused on Cross Border logistics. This position leverages continuous integration and deployment of the best practices, including test automation and monitoring, to ensure successful deployment of optimal ML models and analytical systems. You will be responsible for the end-to-end lifecycle of AI models, from experimentation and fine-tuning to deployment and management in production. A strong background in prompt engineering and practical experience with either Google Cloud's Vertex AI platform is essential for this role. You will also provide technical leadership and mentorship to other members of the AI/ML team. Key Responsibilities Lead the development and deployment of generative AI solutions utilizing LLMs, SLMs, and FMs for various applications (e.g., content generation, chatbots, summarization, code generation, etc.). Architect and implement robust and scalable infrastructure for training, fine-tuning, and serving large-scale AI models, leveraging either Vertex AI. Drive the fine-tuning and adaptation of pre-trained models using proprietary data to achieve state-of-the-art performance on specific tasks. Develop and implement effective prompt engineering strategies to elicit desired outputs and control the behavior of generative models. Manage the lifecycle of deployed models, production support, including monitoring performance, identifying areas for improvement, and implementing necessary updates or retraining. Collaborate closely with cross-functional teams (e.g., product, engineering, research) to understand business requirements and translate them into technical solutions. Provide technical leadership and mentorship to junior machine learning engineers, fostering a culture of learning and innovation. Ensure the responsible and ethical development and deployment of AI models, considering factors such as bias, fairness, and privacy. Stay up to date with latest advancements in generative AI, LLMs, and related technologies, and evaluate their potential application within the company. Document technical designs, implementation details, and deployment processes. Troubleshoot and resolve issues related to model performance and deployment. Required Skills And Experience Bachelor's or Master's degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field. Minimum of 5-8 years of hands-on experience in building, deploying, and managing machine learning models in a production environment. Demonstrable experience in managing, deploying, and fine-tuning large language models (LLMs), small language models (SLMs), and foundation models (FMs). Significant hands-on experience with prompt engineering techniques for various generative AI tasks. Proven experience working with either Google Cloud's Vertex AI platform platform. including experience with their respective model registries, deployment tools, and MLOps features. Strong programming skills in Python and experience with relevant machine learning libraries (e.g., TensorFlow, PyTorch, Transformers). Experience with cloud computing platforms (beyond Vertex AI is a plus, e.g. Azure). Solid understanding of machine learning principles, deep learning architectures, and evaluation metrics. Excellent problem-solving, analytical, and communication skills. Ability to work independently and as part of a collaborative team. Experience with MLOps practices and tools for continuous integration and continuous delivery (CI/CD) of ML models is highly desirable. Experience with version control systems (e.g., Git). Bonus Points Experience with model governance frameworks and implementing ethical AI practices. Experience with specific generative AI use cases relevant to Logistics industry. Publications or contributions to open-source projects, technical blogs, or industry conferences are considered a plus Familiarity with data engineering pipelines and tools. Familiarity with emerging trends in generative AI, reinforcement learning from human feedback (RLHF), and federated learning approaches. Type De Contrat en CDI Chez UPS, égalité des chances, traitement équitable et environnement de travail inclusif sont des valeurs clefs auxquelles nous sommes attachés.",,,"Python, Machine Learning",
4196537228,GEN AI,Virtusa,"Bangalore Urban, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Extensive implementation experience in data analytics space or a senior developer role in one of the modern technology stack Excellent programming skills and proficiency in at least one of the major programming scripting languages used in Gen AI orchestration such as Python or PySpark or Java Ability to build API based scalable solutions and debug & troubleshoot software or design issues Hands on exposure to integrating atleast one of the popular LLMs(Open AI GPT, PaLM 2, Dolly, Claude 2, Cohere etc.) using API endpoints. Thorough understanding of prompt engineering; implementation exposure to LLM agents like LangChain & vector databases Pinecone or Chroma or FAISS Ability to quickly conduct experiments and analyze the features and capabilities of newer versions of the LLM models as they come into market Basic data engineering skills to load structured & unstructured data from source systems to target data stores Work closely with Gen AI leads and other team members to address requirements from the product backlog Build and maintain data pipelines and infrastructure to support AI Solutions Desirable:Hands on exposure to using cloud(Azure/GCP/AWS) services for storage, serverless-logic, search, transcription and chat Extensive experience with data engineering and ETL tools is a big plus Masters/Bachelors degree in Computer Science or Statistics or Mathematics Desired Skills and Experience Lang Chain",,,Python,
4239056787,Data Engineer-Enterprise Content Management,IBM,"Hyderabad, Telangana, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology Your Role And Responsibilities Design and Development of ECM Solutions FileNet API Integration Configure and manage Events, Subscriptions, and Triggers in the Content Engine to support business process automation. Define and enforce security policies, including Access Control Lists (ACLs), role-based access control (RBAC), and document-level security configurations Preferred Education Master's Degree Required Technical And Professional Expertise FileNet Developer with IBM FileNet P8 platform. The ideal candidate will be responsible for designing, developing, implementing, and supporting enterprise content management solutions using FileNet, including customization of IBM Content Navigator (ICN), working with FileNet APIs, managing Records Manager configurations, and executing large-scale content migrations. Required Skills and Experience: Experience in IBM FileNet P8 platform (5.2/5.5 or higher). Strong hands-on experience with FileNet Java APIs (CE/PE APIs) Understanding, configuration and management of Event, Triggers in Content Engine to automate business logic. Implement and maintain FileNet security, including ACLs, role-based access control (RBAC), and document-level security Good communication skills and ability to work independently or as part of a team Preferred Technical And Professional Experience IBM FileNet certification (e.g., IBM Certified Specialist - FileNet Content Manager). Experience with workflow design using FileNet BPM/Case Manager. Experience integrating FileNet with other enterprise systems via REST/SOAP APIs",Manager,,,
4259094707,Backend Engineer - L2,Botsync,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More We are seeking a young and analytical thinking Full Stack Software Developer Engineer to join our Bangalore team. In this role, you will design, develop, and maintain Botsync's syncOS fleet manager software and focus mostly on the backend side of the web app. The ideal candidate should have an excellent command of Python, JavaScript programming languages and frameworks (Django-React Framework), a problem-solving attitude, and prior experience with full-stack development. Responsibilities Design, develop, and maintain Botsync's syncOS Fleet Manager software. Develop and maintain the back end of the web app. Develop and maintain, and share standard deployment configurations in Docker, podman, and Kubernetes for the web app. Configure and design the application for load balancing and redundancy. Design and develop REST APIs and Websocket endpoints to allow for third-party integrations. Make updates to the user interface in React.js . Ensure cross-platform optimization. Requirements Bachelor's degree or higher qualification in Computer Science Engineering, Information Technology, or related fields. Understanding of key design principles. Excellent knowledge of the Python Programming language. Good knowledge of the JavaScript programming language and React.js framework. Working knowledge of the Django framework and Redis. Excellent understanding of SQL and NoSQL databases. Keen understanding of backend system design, data flow, architecture diagrams, and likewise. Excellent understanding of REST APIs and Websockets. Good understanding of real-time communication applications. Excellent problem-solving skills. Excellent verbal and written communication skills. Ability to think and work independently. Skills: Python | Javascript | Linux OS | Django-React Framework | REST API and websockets | SQL and NoSQL DB| DSA | OOPS | Standard MS Office offerings - Excel, Powerpoint, Word | Excellent Communication abilities. This job was posted by Sonali Adity from Botsync. Desired Skills and Experience Java,Python,Django",manager,,"Python, SQL, Excel",
4226976202,Job For Trainer(Online N.Shift) (Data Science / Data Engineer) Opening,Onjob Group,"Pune, Maharashtra, India",,Full-time,,"About the job This job is sourced from a job board. Learn More Hi, Job Description Role Responsibilities: Provide expert job support or on-the-job training in Data Science, Data Engineering, AWS, ML, AI more. Assist professionals in solving real-time project challenges. Work hourly at your convenience without affecting your full-time job. Preferred Candidate Profile 10+ years of experience in relevant technology, Data Science, Data Engineering, AWS, ML, AI more.. Strong Troubleshooting Mentoring Skills. Comfortable with flexible, hourly-based job support (WFH), Its remote job. Perks Benefits Earn 1L - 3L per month for extra 2 hours to 4 hours. Work on your scheduling commitment, no impact on your current job. Get paid hourly for your expertise. Interested? Apply Now Start Earning Extra! Contact: Bala (+91 82960 46895) and Email to bala@onjob.in This job is provided by Shine.com",,,,
4257577391,MERN Stack Developer,Cozzera,India (Remote),Remote,Full-time,,"About the job Job Title: MERN Stack Developer Experience: 6+ Years Location: Remote Employment Type: Full-Time Job Summary: We are looking for a highly experienced MERN Stack Developer with 6+ years of hands-on expertise in developing scalable web applications. The ideal candidate should be proficient in building full-stack applications using MongoDB, Express.js, React.js, and Node.js, with a strong focus on clean architecture and performance. Key Responsibilities: Design, develop, and maintain full-stack web applications using the MERN stack Build reusable components and front-end libraries for future use Develop and manage well-functioning databases and servers Ensure responsiveness and performance across platforms and devices Write clean, scalable, and efficient code with proper documentation Collaborate with UI/UX designers, backend developers, and QA for seamless development Integrate RESTful APIs and third-party services Optimize application for maximum speed and scalability Participate in code reviews and technical discussions Required Skills: Strong proficiency in MongoDB, Express.js, React.js, and Node.js Experience with modern JavaScript (ES6+) and TypeScript In-depth understanding of React workflows (Redux, Context API) Experience in RESTful API development and integration Familiarity with authentication mechanisms like JWT, OAuth Strong understanding of database design, indexing, and query optimization Proficient with version control tools like Git and platforms like GitHub/GitLab Experience with DevOps tools, CI/CD pipelines, and containerization (Docker) is a plus",,,,
4212854972,Celonis Data Engineer/Consultant,Infosys,"Bengaluru East, Karnataka, India (On-site)",On-site,Full-time,,"About the job Celonis You have 2+ years of relevant work experience in process and data modelling. You have worked with data from ERP systems like SAP. You have a proven track record in using SQL and Python. You are a team player and can communicate data structural concepts and ideas to both technical and non-technical stakeholders. You have strong analytical skills and have an affinity with business concepts. Celonis Data Engineer/Implementation Professional certification will be an advantage. Celonis project experience will be a big plus. You will be part of an innovative team that drives our Celonis initiatives and to dive into business processes to determine root causes, quantify potential, and establish and drive improvement initiatives that make businesses more efficient. You will set up and maintain data models that will be the basis of the analyses and work together closely with the business analysts to generate the customized set of analytics that serve as a single source of truth for business performance measurement as well as data-driven decision making. You are responsible for setting data dictionary and maintaining data governance on the created structure. You identify the best possible strategy for data collection, ensure the data quality and work together with the stakeholders responsible for the data input to ensure we can correctly measure and track all necessary information. Collaborate with source system experts to ensure the source systems are set up correctly to gather all relevant information and support the most effective data structures. Create and maintain comprehensive documentation for data models, processes, and systems to facilitate knowledge sharing.",,,"Python, SQL",
4241210672,Senior Machine Learning Engineer,HARMAN India,"Bengaluru, Karnataka, India",,Full-time,,"About the job Job Title: Lead Machine Learning Engineer Location: Bangalore Job Type: Full Time We are seeking a skilled and experienced Data Scientist with expertise in Natural Language Processing (NLP), Python programming, Generative AI, Large Language Models, Machine Learning, Deep Learning, and associated frameworks. The ideal candidate will play a key role in leading the development and implementation of AI and GenAI solutions for our Clients. Key Responsibilities: Design, develop, and implement Natural Language Processing solutions leveraging Python and associated frameworks. Work on Generative AI models, specifically Retrieval Augmented Generation (RAG), Agentic workflows, LLM finetuning etc to create innovative and effective solutions, ensuring alignment with business goals. Utilize Large Language Models for text generation, summarization, and related applications. Development, and implementation of machine learning models and algorithms. Evaluate the LLM and the solutions leveraging LLMs for their effectiveness. Develop and deploy solutions on the Azure/AWS cloud platform, ensuring scalability, reliability, and efficiency. Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. Deploy machine learning models into production environments and monitor their performance. Document methodologies, processes, and results to ensure reproducibility and knowledge sharing. Mentor and guide ML engineers and data scientists, fostering a collaborative and growth-oriented team culture. Stay up to date with the latest advancements in machine learning, Generative AI and related technologies. Required Skills and Qualifications: Master’s or Ph.D. degree in Computer Science, Data Science, Statistics, Mathematics, or a related field. 5-7 years of hands-on experience in machine learning, data analysis, or software development. Strong fundamental knowledge of statistical modeling, machine learning, deep learning, Generative AI, natural language processing, computer vision etc. Proficient in programming languages such as Python and development with the opensource machine learning and Generative AI stack like pytorch, keras, scikit-learn, langchain, llamaIndex, chromaDB, qdrant, SQL, MongoDB etc. Experience and reasonable understanding of setting up LLM evaluations, frameworks like deepeval and approaches like LLM-as-a-Juge Experience with developing use-cases related to Conversational AI or Vision AI or AI enabled automation. Handson with software development best practices, including version control (Git), DevOps tools and Agile methodologies. Handson with MLOps/LLMOps tools and toolchain and their implementation for orchestration, automation, monitoring and retraining covering CI/CD/CT. Excellent problem-solving skills and ability to think critically and creatively. Strong communication and presentation skills, with the ability to explain complex concepts to both technical and non-technical audiences. Ability to work independently and as part of a team in a fast-paced, dynamic environment. Preferred Skills and Qualifications: Experience with big data tools and platforms, such as Hadoop, Spark, or Hive Experience with latest technologies in natural language processing or computer vision or Generative AI (RAG, Agentic workflows, multi-modal models etc) Good understanding of Responsible AI aspects like explainability , privacy preservation, bias detection etc. Published research papers or contributions to the AI/NLP community.",associate,,"Python, SQL, Machine Learning, Data Analysis",
4228838857,Senior AI Engineer - REMOTE,Uplers,"Chandigarh, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4255445114,AI / ML Engineer,Accenture in India,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Large Language Models Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: As an AI / ML Engineer, you will engage in the development of applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve designing and implementing production-ready solutions, ensuring that they meet quality standards. You will work with various AI models, including generative AI, and may also explore deep learning, neural networks, chatbots, and image processing technologies. Collaboration with cross-functional teams will be essential to integrate these solutions effectively into existing systems and workflows. Roles & Responsibilities: - Expected to be an SME. - Collaborate and manage the team to perform. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Provide solutions to problems for their immediate team and across multiple teams. - Facilitate knowledge sharing and training sessions to enhance team capabilities. - Monitor project progress and ensure alignment with strategic goals. Professional & Technical Skills: - Must To Have Skills: Proficiency in Large Language Models. - Good To Have Skills: Experience with cloud-based AI services. - Strong understanding of deep learning frameworks such as TensorFlow or PyTorch. - Familiarity with natural language processing techniques and tools. - Experience in developing and deploying chatbots and conversational agents. Additional Information: - The candidate should have minimum 5 years of experience in Large Language Models. - This position is based in Chennai. - A 15 years full time education is required. 15 years full time education",,,,
4255311586,"Mid Data Science & AIML, GenAI Lead/Engineer",NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 312513 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Mid Data Science & AIML, GenAI Lead/Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Job Title: Data Science & AIML, GenAI Lead/Engineer Key Responsibilities: Develop and implement traditional machine learning algorithms. Deploy at least one model in a production environment. Write and maintain Python code for data science and machine learning projects. Minimum Skills Required: Preferred Qualifications: Knowledge of Deep Learning (DL) techniques. Experience working with Generative AI (GenAI) and Large Language Models (LLM). Exposure to Langchain. #GenAINTT About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4251652511,AI / ML Developer,AmpleLogic,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Responsibilities Build and fine-tune models for NLP, computer vision, predictions, and more. Engineer intelligent pipelines that are used in production. Collaborate across teams to bring AI solutions to life (not just in Jupyter Notebooks). Embrace MLOps with tools like MLflow, Docker, and Kubernetes. Stay on the AI cutting edge and share what you learnmentorship mindset is a big plus. Champion code quality and contribute to a future-focused dev culture. Requirements 3-4 years in hardcore AI/ML or applied data science. Pro-level Python skills (R is cool too, but Python is king here). Mastery over ML frameworks: scikit-learn, XGBoost, LightGBM, TensorFlow/Keras, PyTorch. Hands-on with real-world data wrangling, feature engineering, and model deployment. DevOps-savvy: Docker, REST APIs, Git, and maybe even some MLOps sparkle. Cloud comfort: AWS, GCP, or Azure - take your pick. Solid grasp of Agile, good debugging instincts, and a hunger for optimization. This job was posted by Sampurna Pal from AmpleLogic. Desired Skills and Experience Python",,,"Python, R",
4251639580,"Senior Machine Learning Engineer - Content and Ad platform Team, Bangalore",Warner Bros. Discovery,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Welcome to Warner Bros. Discovery… the stuff dreams are made of. Who We Are… When we say, “the stuff dreams are made of,” we’re not just referring to the world of wizards, dragons and superheroes, or even to the wonders of Planet Earth. Behind WBD’s vast portfolio of iconic content and beloved brands, are the storytellers bringing our characters to life, the creators bringing them to your living rooms and the dreamers creating what’s next… From brilliant creatives, to technology trailblazers, across the globe, WBD offers career defining opportunities, thoughtfully curated benefits, and the tools to explore and grow into your best selves. Here you are supported, here you are celebrated, here you can thrive. Senior ML Engineer -(Content and Ad platform), Bangalore About Warner Bros. Discovery Warner Bros. Discovery, a premier global media and entertainment company, offers audiences the world's most differentiated and complete portfolio of content, brands and franchises across television, film, streaming and gaming. The new company combines Warner Media’s premium entertainment, sports and news assets with Discovery's leading non-fiction and international entertainment and sports businesses. For more information, please visit www.wbd.com . Meet Our Team When we say, “the stuff dreams are made of,” we’re not just referring to the world of wizards, dragons. and superheroes, or even to the wonders of Planet Earth. Behind WBD’s vast portfolio of iconic content and beloved brands, are the storytellers bringing our characters to life, the creators bringing them to your living rooms and the dreamers creating what’s next… From brilliant creatives to technology trailblazers, across the globe, WBD offers career defining opportunities, thoughtfully curated benefits, and the tools to explore and grow into your best selves. Here you are supported, here you are celebrated, here you can thrive. Roles & Responsibilities The role will focus on building out machine learning solutions for WBD’s content and Ad platform. Primary focus will be on unlocking machine learning opportunities in media supply chain, captioning services, ad conditioning, metadata extraction and building foundational machine learning training and inference pipelines at scale. You have a successful track record for ambitious projects across cross-functional teams. You are passionate and results oriented. You strive for technical excellence and are very hands-on. Your co-workers love working with you. You have built respect in your career through concrete accomplishments. Build cutting-edge capabilities utilizing machine learning and data science (e.g., large language models, computer vision models, advanced ad & content targeting, etc.) Build end to end ML pipelines to train, deploy and server ML models at scale. Leverage industry best practices and tools to continually improve teams' ability to build, operate and maintain products. Ensure that technical solutions are in line with established WBD Digital strategy, standards in respect to architecture, security, corporate governance, coding standards, monitoring, logging, unit test, and service enablement. What To Bring 5-8 years of experience designing, building machine learning algorithms and systems. Proficiency in programming languages such as Java, Golang, Python or Scala. Working experiemce in AWS or GCP and ML platforms like sagemaker or Vertex AI. Good understaning of distributed systems, alogorithms and data structures. Proficiency in operating machine learning solutions at scale, covering the end-to-end ML workflow. Strong understanding of modern ML approaches (GBDT, CNN, LSTM, GRU, HRNN, transformers, variational auto-encoders, ...). Experience using of ML tools and frameworks (TensorFlow, Keras, pyTorch, scikit-learn, Spark,...). Familiarity with real-world ML systems (configuration, data collection, data verification, feature extraction, resource and process management, analytics, training, serving, validation, experimentation, monitoring). Experience with offline experimentation and A/B testing. Understanding of batch and streaming data processing techniques. PhD or Masters in Computer Science or related discipline. What We Offer A Great Place to work. Equal opportunity employer Fast track growth opportunities How We Get Things Done… This last bit is probably the most important! Here at WBD, our guiding principles are the core values by which we operate and are central to how we get things done. You can find them at www.wbd.com/guiding-principles/ along with some insights from the team on what they mean and how they show up in their day to day. We hope they resonate with you and look forward to discussing them during your interview. Championing Inclusion at WBD Warner Bros. Discovery embraces the opportunity to build a workforce that reflects a wide array of perspectives, backgrounds and experiences. Being an equal opportunity employer means that we take seriously our responsibility to consider qualified candidates on the basis of merit, regardless of sex, gender identity, ethnicity, age, sexual orientation, religion or belief, marital status, pregnancy, parenthood, disability or any other category protected by law. If you’re a qualified candidate with a disability and you require adjustments or accommodations during the job application and/or recruitment process, please visit our accessibility page for instructions to submit your request.",,,"Python, Machine Learning",
4217274170,Machine Learning Engineer (Remote),Uplers,"Cuttack, Odisha, India (Remote)",Save Machine Learning Engineer (Remote) at Uplers,Full-time,,"About the job Experience : 5.00 + years Salary : INR 5000000.00 / year (based on experience) Expected Notice Period : 15 Days Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full Time Permanent position(Payroll and Compliance to be managed by: Precanto) (*Note: This is a requirement for one of Uplers' client - A fast-growing, VC-backed B2B SaaS platform revolutionizing financial planning and analysis for modern finance teams.) What do you need for this opportunity? Must have skills required: async workflows, MLOps, Ray Tune, Data Engineering, MLFlow, Supervised Learning, Time-Series Forecasting, Docker, machine_learning, NLP, Python, SQL A fast-growing, VC-backed B2B SaaS platform revolutionizing financial planning and analysis for modern finance teams. is Looking for: We are a fast-moving startup building AI-driven solutions to the financial planning workflow. We’re looking for a versatile Machine Learning Engineer to join our team and take ownership of building, deploying, and scaling intelligent systems that power our core product. Job Description- Full-time Team: Data & ML Engineering We’re looking for 5+ years of experience as a Machine Learning or Data Engineer (startup experience is a plus) What You Will Do- Build and optimize machine learning models — from regression to time-series forecasting Work with data pipelines and orchestrate training/inference jobs using Ray, Airflow, and Docker Train, tune, and evaluate models using tools like Ray Tune, MLflow, and scikit-learn Design and deploy LLM-powered features and workflows Collaborate closely with product managers to turn ideas into experiments and production-ready solutions Partner with Software and DevOps engineers to build robust ML pipelines and integrate them with the broader platform Basic Skills Proven ability to work creatively and analytically in a problem-solving environment Excellent communication (written and oral) and interpersonal skills Strong understanding of supervised learning and time-series modeling Experience deploying ML models and building automated training/inference pipelines Ability to work cross-functionally in a collaborative and fast-paced environment Comfortable wearing many hats and owning projects end-to-end Write clean, tested, and scalable Python and SQL code Leverage async workflows and cloud-native infrastructure (S3, Docker, etc.) for high-throughput data processing. Advanced Skills Familiarity with MLOps best practices Prior experience with LLM-based features or production-level NLP Experience with LLMs, vector stores, or prompt engineering Contributions to open-source ML or data tools TECH STACK Languages: Python, SQL Frameworks & Tools: scikit-learn, Prophet, pyts, MLflow, Ray, Ray Tune, Jupyter Infra: Docker, Airflow, S3, asyncio, Pydantic How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience async workflows, MLOps, Ray Tune, Data Engineering, MLFlow, Supervised Learning, Time-Series Forecasting, Docker, machine_learning, NLP, Python, SQL",manager,,"Python, SQL, Machine Learning",
4195229554,Python ML developer,Infosys,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Excellent Python programming and debugging skills. (Refer to Pytho JD given below) - Proficiency with SQL, relational databases, & non-relational databases - Passion for API design and software architecture. - Strong communication skills and the ability to naturally explain difficult technical topics to everyone from data scientists to engineers to business partners - Experience with modern neural-network architectures and deep learning libraries (Keras, TensorFlow, PyTorch). - Experience unsupervised ML algorithms. - Experience in Timeseries models and Anomaly detection problems. - Experience with modern large language model (Chat GPT/BERT) and applications. - Expertise with performance optimization. - Experience or knowledge in public cloud AWS services - S3, Lambda. - Familiarity with distributed databases, such as Snowflake, Oracle. - Experience with containerization and orchestration technologies, such as Docker and Kubernetes. Managing large machine learning applications and designing and implementing new frameworks to build scalable and efficient data processing workflows and machine learning pipelines. - Build the tightly integrated pipeline that optimizes and compiles models and then orchestrates their execution. - Collaborate with CPU, GPU, and Neural Engine hardware backends to push inference performance and efficiency - Work closely with feature teams to facilitate and debug the integration of increasingly sophisticated models, including large language models - Automate data processing and extraction - Engage with sales team to find opportunities, understand requirements, and translate those requirements into technical solutions. - Develop reusable ML models and assets into production.",,,"Python, SQL, Machine Learning",
4259095694,Frontend Developer SDE - 1,Botsync,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Responsibilities Develop and maintain dynamic web applications using React.js & Next.js . Optimize server-side rendering (SSR) and static site generation (SSG) for better performance. Work with Redux for efficient state management and seamless UI interactions. Collaborate with backend teams using Node.js to integrate APIs. Debug, test, and enhance frontend performance for a seamless user experience. Requirements 1-3 years of hands-on experience with React.js, Next.js, JavaScript, Redux, and Node.js . Strong understanding of UI/UX principles, component-driven development, and responsive design. Familiarity with RESTful APIs and frontend performance optimization. Ability to work onsite in a fast-paced, collaborative environment. Bonus: Experience with TypeScript and modern frontend tooling. This job was posted by Sonali Adity from Botsync. Desired Skills and Experience CSS,HTML,JavaScript,React.js",,,,
4248917513,Lead AI Engineer,Hitachi Vantara,"Itanagar, Arunachal Pradesh, India",,Full-time,,"About the job Our Company We’re Hitachi Digital, a company at the forefront of digital transformation and the fastest growing division of Hitachi Group. We’re crucial to the company’s strategy and ambition to become a premier global player in the massive and fast-moving digital transformation market. Our group companies, including GlobalLogic, Hitachi Digital Services, Hitachi Vantara and more, offer comprehensive services that span the entire digital lifecycle, from initial idea to full-scale operation and the infrastructure to run it on. Hitachi Digital represents One Hitachi, integrating domain knowledge and digital capabilities, and harnessing the power of the entire portfolio of services, technologies, and partnerships, to accelerate synergy creation and make real-world impact for our customers and society as a whole. Imagine the sheer breadth of talent it takes to unleash a digital future. We don’t expect you to ‘fit’ every requirement – your life experience, character, perspective, and passion for achieving great things in the world are equally as important to us. The Team: Hitachi Digital is a leader in digital transformation, leveraging advanced AI technologies to drive innovation and efficiency across various operational companies (OpCos) and departments. We are seeking an experienced Lead AI Engineer to spearhead our new AI initiatives and enhance our existing Agentic AI capabilities. This role will involve building new AI products and refining current models to meet the evolving needs of our business. The Role Lead the design, development, and implementation of AI models and algorithms using Agentic AI and Agent Workspace for Google Gemini and EMa.AI. Drive new AI initiatives across different OpCos and departments, ensuring seamless integration and functionality. Enhance and refine existing Agentic AI capabilities to improve performance and scalability. Collaborate with cross-functional teams to integrate AI solutions into existing systems and workflows. Conduct research and stay updated on the latest advancements in AI technologies and methodologies. Optimize AI models for performance, scalability, and accuracy. Troubleshoot and resolve complex issues related to AI systems and applications. Document AI development processes, methodologies, and best practices. Mentor junior developers and participate in code reviews, providing constructive feedback to team members. What you’ll bring: Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. 7+ years of experience in AI model development, with a focus on Agentic AI and Agent Workspace for Google Gemini and EMa.AI. Strong programming skills in languages such as Python, Java, or C++. Primary experience with Google Cloud Platform (GCP); experience with AWS and Azure is a plus. Experience with GPU-based AI model development is a plus. Prior experience with Generative AI (GenAI) and Large Language Models (LLMs) is required. Experience with AI frameworks and libraries such as TensorFlow, PyTorch, or similar. Knowledge of machine learning algorithms, neural networks, and natural language processing. Excellent problem-solving skills and the ability to work independently and as part of a team. Strong communication skills and the ability to convey complex technical concepts to non-technical stakeholders. Preferred Qualifications: Familiarity with data science tools and techniques. Previous experience in a similar role within a tech-driven company. About Us We’re a global, 1000-strong, diverse team of professional experts, promoting and delivering Social Innovation through our One Hitachi initiative (OT x IT x Product) and working on projects that have a real-world impact. We’re curious, passionate and empowered, blending our legacy of 110 years of innovation with our shaping our future. Here you’re not just another employee; you’re part of a tradition of excellence and a community working towards creating a digital future. Championing diversity, equity, and inclusion Diversity, equity, and inclusion (DEI) are integral to our culture and identity. Diverse thinking, a commitment to allyship, and a culture of empowerment help us achieve powerful results. We want you to be you, with all the ideas, lived experience, and fresh perspective that brings. We support your uniqueness and encourage people from all backgrounds to apply and realize their full potential as part of our team. How We Look After You We help take care of your today and tomorrow with industry-leading benefits, support, and services that look after your holistic health and wellbeing. We’re also champions of life balance and offer flexible arrangements that work for you (role and location dependent). We’re always looking for new ways of working that bring out our best, which leads to unexpected ideas. So here, you’ll experience a sense of belonging, and discover autonomy, freedom, and ownership as you work alongside talented people you enjoy sharing knowledge with. We’re proud to say we’re an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran, age, disability status or any other protected characteristic. Should you need reasonable accommodations during the recruitment process, please let us know so that we can do our best to set you up for success.",,,"Python, Machine Learning",
4251106998,Senior ML Engineer,TEKsystems,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,"knowledge [Responsibilities and Duties]: Lead dedicated team of software engineers to architect, build, deploy and support best-in-class software services that are always available to provide the best gaming experience for our customers. Build and develop a high energy, committed, motivated engineering team focusing on engineering and operational excellence to deliver awesome business results. Collaborate across business units and product teams to develop and execute against the team's vision, strategy, and roadmap. Use technical expertise and industry trends to influence software development standard methodologies. Handle day-to-day activities of engineering team using Agile/Scrum methodology. [Keywords] Data Science , Machine Learning , Artificial Intelligence , Statistics , Deep Learning About the company TEKsystems 1,171,416 followers Follow IT Services and IT Consulting 10,001+ employees 25,950 on LinkedIn We’re TEKsystems and TEKsystems Global Services. We accelerate business transformation for our customers, so they can capitalize on change and master the momentum of technology. Our expertise in strategy, design, execution and operations unlocks business value through a range of solutions. We’re building tomorrow by delivering business outcomes and making positive impacts in our global communities. TEKsystems and TEKsystems Global Services are Allegis Group companies. … show more Interested in working with us in the future? Members who share that they’re interested in a company may be 2x as likely to get a message from a recruiter than those who don’t. Learn more Learn more about Interested in working for our company I’m interested Show more","About the job We are looking for an experienced AI/ML Engineer, who can execute projects end to end and take then to production pipeline. The candidate is expected to lead the AI/ML work across multiple projects, working along with other Data Scientists, ensuring clear understanding and translation of requirements for the team and proposing optimized solutions. He / She would also need to work on Ad hoc timebound POC’s. Capability building and team upskill would also be expected from him / her. We would want him / her to share the knowledge with other team members and bring them up to the same level , which includes conducting learning sessions across teams and monitoring the progress of the team members. Experience:- 7-9 years Primary Skills: ● Design and develop various machine learning and deep learning models and systems for high impact consumer applications ranging from predictive safety, content personalization’s, search, virtual assistant, time series forecasting and more. ● Work with a broad spectrum of state-of-the-art machine learning and deep learning technologies, in the areas of various machine learning problems such as multilingual text classification, language modelling and multi-modal learning. ● Create metrics and configure A/B testing to evaluate model performance offline and online to inform and convey our impacts to diverse groups of stakeholders. ● Analyse and produce insights from a large amount of dynamic structured and unstructured data using modern big data and streaming technologies ● Produce reusable code according to standard methodologies in Python, Scala or Java ● Collaborate with cross-functional teams of technical members and non-technical members in architecture, design, and code reviews. [Good to have Skills]: SQL, Data Analysis , Gaming Industry knowledge [Responsibilities and Duties]: Lead dedicated team of software engineers to architect, build, deploy and support best-in-class software services that are always available to provide the best gaming experience for our customers. Build and develop a high energy, committed, motivated engineering team focusing on engineering and operational excellence to deliver awesome business results. Collaborate across business units and product teams to develop and execute against the team's vision, strategy, and roadmap. Use technical expertise and industry trends to influence software development standard methodologies. Handle day-to-day activities of engineering team using Agile/Scrum methodology. [Keywords] Data Science , Machine Learning , Artificial Intelligence , Statistics , Deep Learning",,,"Python, SQL, Machine Learning, Data Analysis",
4234451899,"SDE 2, Machine Learning",Poppulo,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction: Are you searching for an opportunity to play a key role in driving the dramatic growth of a highly successful software company? At Poppulo, we’re working on what’s next in communications and workplace technology. As a pioneer in this industry, we understand that meaningfully reaching every employee is hard. And so is managing office space in a hybrid world. And so is improving the customer and guest experience. We exist to make each of these things easier. We exist to bring harmony to our customers. And we do that at enterprise scale. Our omnichannel employee communications, customer communications, and workplace experience platform is trusted by over 6,000 organizations today, reaching more than 35M employees and delivering content to 500,000+ digital signs. We know there’s no such thing as a “perfect"" candidate - we’re all a work in progress and are growing new skills and capabilities all the time. We encourage you to apply for a position with Poppulo even if you don’t meet 100% of the requirements. We believe in fostering an environment where there is a diversity of perspectives, in hopes that we can all thrive. Job Summary We are looking for a SDE 2, Machine Learning Engineer with a strong sense of ownership. If you are an ML practitioner who thrives in an environment where innovation meets practical application to build disruptive products, this role is for you. At Poppulo, we intend to redefine boundaries and reshape Employee Communications through the power of cutting-edge machine learning and AI. We are not just building products; we are disrupting the status-quo with transformative solutions that challenge conventional thinking, create competitive edge and create new market opportunities. SDE 2, Machine Learning Engineer is pivotal to the success of our AI team. It is the backbone of our ML initiatives. This role bridges the gap between research and production by leveraging cutting-edge AI technology into leading, world-class solutions. As a SDE 2, Machine Learning Engineer, you be the key driver for innovative problem solving by combining technical excellence with creative application of ML. Your expertise will be crucial in uncovering hidden opportunities within product ideas. Additionally, you will stay at the forefront of emerging technologies, continuously evaluating new AI/ML frameworks, tools, and best practices to help guide the evolution of our software solutions. Key Responsibilities Solve challenges with AI/ML: Design, develop new AI-powered products that deliver the product roadmap. Build AI/ML systems – Build AI and GenAI solutions using existing frameworks and pre-trained models. Extend frameworks or finetune models, when necessary. Productionise full-stack AI/ML solutions: Translate emerging techs like GenAI into innovative, practical solutions that transform customer experiences. Align with Product Strategy: Create proof of concepts at high cadence to demonstrate/validate potential solutions as per our product strategy. Optimise Model and system performance: Fine-tune, optimise training and inference performances. Wider collaboration: Partner with cross-functional teams to demonstrate the impact of ML innovations and bring them to life. Research Savvy: Staying up-to-date with SOTA and industry trends in AI/ML. Technical Skills / Competencies Strong AI/ML background: Experience in developing and deploying real-world ML applications (Computer Vision, Classification, etc.) Foundation in GenAI: Understanding of generative models (LLMs, etc.), prompt engineering RAG, vector databases. Technical Expertise: Proficiency in ML frameworks, shell scripts, databases and programming languages. MLOps experience: Hands-on experience in configuring MLOps on AWS, Azure and GCP. Full-stack expertise: Proficiency in data pipelines, APIs, web front-end, mobile apps, automated testing and cloud platforms (AWS, GCP, etc.). Exceptional problem-solving skills: Ability to simplify and breakdown complex technical and business challenges to create innovative and practical solutions. Continuous learning: Ability to learn quickly and apply new technologies to solve problems practically. Education & Experience BSc/MSc/PhD in AI, Statistics, Computer Science or a related field At least 4 years’ experience in a building complex, distributed software and AI systems Strong understanding of entire end-to-end software development lifecycle Who We Are We are a values-driven organization that encourages our employees to bring their authentic selves to work every day and empowers everyone to make a tangible impact on our products, clients, and culture. We offer a dynamic environment with driven, fun, and flexible individuals who thrive on challenge and responsibility. This is an opportunity to contribute to our culture and join a company that’s on the move. We live the Poppulo values each day, as they are key to everything we do. Bring Your Best Self We show up authentically, are self-aware and always strive to be better. See it. Own it. Solve it. We proactively innovate and solve for our customers and each other. We set an example with high standards for our work. We foster a culture of learning, acknowledging our successes and our failures. Together We’re Better We value and celebrate our diversity. We learn from others, respecting their expertise, and focus on building trust. That's what makes us a team. Named a Great Place to Work in 2015, 2016, 2017, 2018, 2019, 2020, and 2021, we are a fast-growing global technology company, with offices in Ireland, the US, and the UK. Poppulo is an equal opportunity employer. We are committed to protecting your privacy. For details on how we collect, use, and protect your personal information, please refer to our Job Applicant Privacy Policy.",,,Machine Learning,
4253226110,Principal ML Engineer,Lagrange Point International,"Gurugram, Haryana, India (On-site)",On-site,Full-time,,"About the job About Company Our client is a Gurgaon-based, venture-backed consumer technology startup that aims to develop a next-generation platform and revolutionize user behavior through the integration of AI. They are looking to hire their Machine Learning leader to shape and deploy core recommendation and personalization systems. Role and Responsibilities Develop recommendation, ranking, and personalization systems. Create adaptive, real-time matchmaking engines learning from user interactions. Design algorithms to deliver personalized content feeds. Implement cold-start solutions and collaborate with Data, Product, and Backend teams. Deploy models efficiently, leveraging observability tools and model registries. Lead the growth of the ML engineering team and foster a strong ML culture. Skills and Qualifications 5–10 years of experience in personalization, recommendations, search, or ranking at scale. Background in B2C platforms such as social, ecommerce, gaming, or video with top-tier educational pedigree Proficient in recommendation techniques like collaborative filtering, deep retrieval models, learning-to-rank, embeddings, and LLMs. Capable of both training and deploying models within end-to-end pipelines. Skilled in offline/online evaluation, A/B testing, and metric optimization. Experience with vector search, graph algorithms, and LLM-based methods is preferred but not mandatory What's On Offer Opportunity to own the full lifecycle—from design to deployment—building a scalable, real-time ranking infrastructure Opportunity to be a founding member of a well-funded consumer-tech start-up looking to disrupt a prime market Competitive compensation with a strong equity upside",Executive,,Machine Learning,
4228837898,Senior AI Engineer - REMOTE,Uplers,"Amritsar, Punjab, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4259212381,Back End Developer (Golang),VisionPlus,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Position Overview: We are seeking a Senior Golang Developer – API Development to join our Bangalore office. This individual will play a key role in developing, maintaining, and scaling the APIs that power VisionPlus’ crypto payment system. You will ensure our APIs are secure, scalable, and high-performing while adhering to best practices. The role requires expertise in both Python and Golang for backend development, strong experience with API design, and an ability to communicate effectively within the team and with external partners. Key Responsibilities : • API Development: Design, build, and maintain APIs for VisionPlus' crypto payment system, ensuring high performance, scalability, and reliability. • API Security: Implement robust security measures for the APIs, ensuring they are protected against vulnerabilities and follow industry best practices for data protection. • Scalable Architecture: Build APIs and services that can scale seamlessly as the platform grows, optimizing for both performance and cost-efficiency. • Documentation: Maintain clear, up-to-date API documentation for both internal developers and external partners, ensuring ease of use and clear communication of system features and security protocols. • Collaboration: Work closely with cross-functional teams (backend, frontend, product, and operations) to deliver high-quality, fully integrated solutions. • Code Reviews: Lead by example in writing clean, maintainable code and conduct regular code reviews to ensure the overall quality of the team’s work. • Continuous Improvement: Stay current with the latest trends in API development, blockchain, and crypto technologies, and continuously improve the architecture, security, and performance of our platform. • External Communication: Act as a point of contact for external API integrations, liaising with third-party partners and service providers when necessary to ensure smooth integration. • Technical Leadership: Mentor and guide junior developers, promoting knowledge sharing and fostering a collaborative development environment. • Agile Development: Participate in sprint planning, retrospectives, and daily standups. Help define and execute the technical roadmap in collaboration with the product and leadership teams. Requirements: • Experience: 5+ years of experience in backend development with a focus on API design, development, and maintenance. o Strong experience with Golang for building scalable, secure, and high-performance APIs. o Expertise in building APIs for complex, distributed systems, with a focus on high availability and scalability. Technical Expertise: o Extensive experience in API design and development (REST, GraphQL, gRPC, etc.). o In-depth knowledge of security best practices for API development (e.g., OAuth, JWT, rate limiting, and encryption). o Strong understanding of scalable architecture, including experience with cloud infrastructure (AWS, GCP, Azure) and containerization (Docker, Kubernetes). o Experience with crypto payment systems and blockchain technology is highly desirable, though not mandatory. o Proficient in working with databases such as PostgreSQL, MySQL, and NoSQL databases (e.g., MongoDB). o Familiarity with CI/CD pipelines and automated testing frameworks. o Knowledge of microservices architecture and its implementation in real-world production environments. • Start-Up Mindset: o Strong sense of ownership and the ability to work independently while collaborating effectively within a small, agile team. o Ability to thrive in a fast-paced, dynamic startup environment where priorities can shift rapidly. o High agency and the ability to make decisions and take action in uncertain situations. Communication Skills : o Excellent verbal and written communication skills. Ability to communicate effectively with both technical and non-technical stakeholders. o Comfort with external communication, including liaising with third-party service providers and external developers. • Problem-Solving : o Ability to troubleshoot complex technical issues, quickly identify root causes, and implement effective solutions. o A passion for optimizing code, improving architecture, and refining APIs to meet evolving product and business needs. Nice-to-Have Skills: • Experience in blockchain technologies, specifically in cryptocurrency payment systems. • Knowledge of modern authentication mechanisms like OAuth 2.0, OpenID Connect, or JWT. • Familiarity with the Web3 ecosystem and decentralized finance (DeFi) protocols. • Experience working with event-driven architectures and message queues (e.g., Kafka, RabbitMQ). • Contribution to open-source projects related to fintech or crypto payment systems. What We Offer : • Ownership & Impact : This is a high-impact role where you’ll have significant ownership over the platform’s core architecture and API development, directly influencing the product’s success. • Growth Opportunities : As a key member of a rapidly growing startup, you’ll have ample opportunities for career advancement, technical leadership, and personal growth. • Collaborative Culture : Work alongside passionate, motivated, and talented individuals in a collaborative environment that values transparency, innovation, and accountability. • Competitive Salary & Benefits : Receive a competitive salary and equity in a high growth fintech startup with the potential for substantial financial upside. This role is Purely an Office-Based Role in Bangalore: Join a dynamic, office-based team in our Bangalore office and be a part of building something transformative in the fintech space.",Manager,,Python,
4255438926,AI / ML Engineer,Accenture in India,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Large Language Models Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: As an AI / ML Engineer, you will engage in the development of applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve designing and implementing production-ready solutions, ensuring that they meet quality standards. You will work with various AI models, including generative AI, and may also explore deep learning, neural networks, chatbots, and image processing technologies. Collaboration with cross-functional teams will be essential to integrate these solutions effectively into existing systems and workflows. Roles & Responsibilities: - Expected to be an SME. - Collaborate and manage the team to perform. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Provide solutions to problems for their immediate team and across multiple teams. - Facilitate knowledge sharing and training sessions to enhance team capabilities. - Monitor project progress and ensure alignment with strategic goals. Professional & Technical Skills: - Must To Have Skills: Proficiency in Large Language Models. - Good To Have Skills: Experience with cloud-based AI services. - Strong understanding of deep learning frameworks such as TensorFlow or PyTorch. - Familiarity with natural language processing techniques and tools. - Experience in developing and deploying chatbots and conversational agents. Additional Information: - The candidate should have minimum 5 years of experience in Large Language Models. - This position is based in Chennai. - A 15 years full time education is required. 15 years full time education",,,,
4257270742,"Mid Data Science & AIML, GenAI Lead/Engineer",NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 312507 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Mid Data Science & AIML, GenAI Lead/Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Job Title: Data Science & AIML, GenAI Lead/Engineer Key Responsibilities: Develop and implement traditional machine learning algorithms. Deploy at least one model in a production environment. Write and maintain Python code for data science and machine learning projects. Minimum Skills Required: Preferred Qualifications: Knowledge of Deep Learning (DL) techniques. Experience working with Generative AI (GenAI) and Large Language Models (LLM). Exposure to Langchain. #GenAINTT About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4253647362,AI Engineer,Zenduty,"Bangalore Urban, Karnataka, India (On-site)",On-site,Full-time,,"About the job Overview: AI is pivotal to the transformation of the Service and Operations Management space. As Xurrent’s AI Engineer you’ll play a critical role in developing platforms and solutions that transform how work is done in this space. You’ll be responsible for collaborating with other members of the R&D organisation to deliver AI software in the form of data engineering, prompt engineering, algorithms and APIs. You’ll be measured on your ability to produce production ready code and create rapid prototyping opportunities presented to relevant stakeholders. As a senior engineer with the team, you’ll also maintain high code quality and perform code reviews. You’ll also collaborate with DevOps and MLOps to maintain a modern, well architected and well instrumented deployment and testing pipeline. Responsibilities: Collaborates with other members within the Research & Development department to determine functional and non-functional requirements for proposed software adjustments or extensions that are related to artificial intelligence and incorporate into A.I. RFCs Assists product management to develop high-level product specifications that are related to artificial intelligence with attention to system integration and feasibility Develops software adjustments and extensions that meets the agreed on specifications and requirements and adheres to coding standards Provide technical guidance and coaching related to artificial intelligence to other members within the Research & Development department Ensure that artificial intelligence software use within the Xurrent services meets all requirements of quality, security, modifiability, extensibility etc. Continuously improve the artificial intelligence software of the Xurrent services by actively participating in its development Requirements: Proven ability to develop AI features via LLM Atleast 2-6 years of experience in relevant field Proven ability to develop, deploy, maintain and enhance machine learning models Proven ability to develop and maintain corresponding data systems such as feature stores and data pipelines for AI and machine learning Proven ability to translate product requirements into technical specifications Experience in a production engineering environment",Manager,,"R, Machine Learning",
4188609471,AI Engineer,Vahan.ai,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job About Us At Vahan.ai, we are building India’s first AI powered recruitment marketplace for India’s 300 million strong Blue Collar workforce, opening doors to economic opportunities and brighter futures. Already India’s largest recruitment platform, Vahan.ai is supported by marquee investors like Khosla Ventures, Bharti Airtel, Vijay Shekhar Sharma (CEO, Paytm), and leading executives from Google and Facebook. Our customers include names like Swiggy, Zomato, Rapido, Zepto, and many more. We leverage cutting-edge technology and AI to recruit for the workforces of some of the most recognized companies in the country. Our vision is ambitious: to become the go-to platform for blue-collar professionals worldwide, empowering them with not just earning opportunities but also the tools, benefits, and support they need to thrive. We aim to impact over a billion lives worldwide, creating a future where everyone has access to economic prosperity. If our vision excites you, Vahan.ai might just be your next adventure. We’re on the hunt for driven individuals who love tackling big challenges. If this sounds like your kind of journey, dive into the details and see where you can make your mark. What You Will Be Doing Stay at the Cutting Edge: Continuously research, evaluate, and implement the latest AI technologies and state-of-the-art algorithms to ensure our platform remains innovative and effective. Develop and Optimize: Design, develop, and maintain AI systems and applications that enhance our recruitment marketplace. Prototype and Document: Create proof-of-concept models, write technical specifications, and document AI systems and processes. Test, Debug and Optimize: Conduct thorough testing of AI models, debug issues, and optimize for performance and scalability. Collaborate: Work closely with cross-functional teams, including data scientists, software engineers, and product managers. Own and Deliver: Take ownership of major product areas end-to-end, becoming a subject matter expert in your domain. Communicate Effectively: Translate complex technical concepts into clear, understandable terms for diverse stakeholders. Deploy and Scale: Implement production-ready AI solutions that can scale to meet our growing user base. You Will Thrive In This Role If You Stay current with the latest AI developments and demonstrate ability to quickly adapt and implement cutting-edge technologies Have 2+ years of experience in AI projects with strong proficiency in Python and frameworks like PyTorch, Hugging Face, and LangChain Possess strong skills in testing, debugging, and optimizing AI models for performance and scalability Can communicate complex technical concepts in an easy-to-understand manner and adapt quickly to changing priorities Excel at creating prototypes and documenting AI systems, including writing comprehensive technical specifications Demonstrate strong familiarity with implementing state-of-the-art AI technologies and algorithms Show ownership capabilities to handle large product areas end-to-end and become an SME in your domain Have experience with voice data and conversational bots Possess creative problem-solving skills with the ability to find scrappy solutions under tight timelines Expertise in Large Language Models (LLMs), evals and fine-tuning techniques, and Retrieval-Augmented Generation (RAG), AI agents. At Vahan.ai, you’ll have the opportunity to make a real impact in a sector that touches millions of lives. We’re committed to not only advancing the livelihoods of our workforce but also, in taking care of the people who make this mission possible. Here’s What We Offer Unlimited PTO: Trust and flexibility to manage your time in the way that works best for you. Comprehensive Medical Insurance: We’ve got you covered with plans designed to support you and your loved ones. Monthly Wellness Leaves: Regular time off to recharge and focus on what matters most. Competitive Pay: Your contributions are recognized and rewarded with a compensation package that reflects your impact. Join us, and be part of something bigger—where your work drives real, positive change in the world.",executive,,"Python, Excel",
4258024848,AI / Innovation Engineer,"NTT DATA, Inc.","Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Make an impact with NTT DATA Join a company that is pushing the boundaries of what is possible. We are renowned for our technical excellence and leading innovations, and for making a difference to our clients and society. Our workplace embraces diversity and inclusion – it’s a place where you can grow, belong and thrive. Your day at NTT DATA The Senior Software Applications Development Engineer is an advanced subject matter expert, responsible for developing new applications and improve upon existing applications based on the needs of the internal organization and / or external clients. Key responsibilities: Develops applications that effectively accomplish client objectives and user needs Designs and writes code for applications and maintain applications databases Analyzes and edits existing software applications to improve and optimize functionality, fix problems, and enable their use on new hardware platforms Remodels and adapts applications as needed to optimize performance Identifies specific client needs and preferences related to the application Tests applications extensively to ensure they are error and bug-free Installs applications and acts as technical advisor Communicates with relevant internal technical stakeholders to obtain information on project limitations, performance requirements, and interfaces Consults with clients in the design phase to determine client needs Produces software documentation following company software process and templates Participates in software product review meetings and team meetings Performs any other related task To thrive in this role, you need to have: Advanced understanding of computer science, with specific knowledge of computer programming, application design, and user-focused features. Good team player who maintains the integrity of the team. Excellent attention to detail capabilities. Ability to understand and analyze complex systems. Advanced proficiency in writing software using the Java Programming Language and a standard object library. Advanced knowledge of software development process Advanced proficiency with agile development such as Scrum Advanced knowledge of software integrated development environments Advanced knowledge in various programming languages such as (but not limited to) Java, Perl, Python, C++. Demonstrated analytical, organizational, and project management skills, using relevant information to make timely and critical decisions that affect cross-functional teams. Ability to handle client and customer issues tactfully and professionally. Academic qualifications and certifications: Bachelor's degree or equivalent in computer science or software engineering or related field. Certification in various programming languages, for example (but not limited to) Java, Perl, Python, C++ preferred. Scrum / Project Management certification preferred. Required experience: Advanced Software Applications Engineering, Software Development experience, or related work experience. Advanced experience with Programming Languages such as (but not limited to) C, C++, Java, Python. Advanced experienced with Linux or Unix and Windows operating systems. Advanced experience working with SQL. Advanced project management experience and/or experience working in an Agile environment. Workplace type: Hybrid Working About NTT DATA NTT DATA is a $30+ billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long-term success. We invest over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure, and connectivity. We are also one of the leading providers of digital and AI infrastructure in the world. NTT DATA is part of NTT Group and headquartered in Tokyo. Equal Opportunity Employer NTT DATA is proud to be an Equal Opportunity Employer with a global culture that embraces diversity. We are committed to providing an environment free of unfair discrimination and harassment. We do not discriminate based on age, race, colour, gender, sexual orientation, religion, nationality, disability, pregnancy, marital status, veteran status, or any other protected category. Join our growing global team and accelerate your career with us. Apply today.",,,"Python, SQL, R",
4250486850,Data Engineer,PrismHR,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job We are a proud work-from-office company. If you're ready to work on-site in a dynamic, global company, we’d love to hear from you. Position Summary Do you have a passion for building data architectures that enable smooth and seamless product experiences? Are you an all-around data enthusiast with a knack for ETL? We're hiring Data Engineers to help build and optimize the foundational architecture of our product's data. We’ve built a strong data engineering team to date, but have a lot of work ahead of us, including: Migrating from relational databases to a streaming and big data architecture, including a complete overhaul of our data feeds Defining streaming event data feeds required for real-time analytics and reporting Leveling up our platform, including enhancing our automation, test coverage, observability, alerting, and performance As a Data Engineer, you will work with the development team to construct a data streaming platform and data warehouse that serves as the data foundations for our product. Help us scale our business to meet the needs of our growing customer base and develop new products on our platform. You'll be a critical part of our growing company, working on a cross-functional team to implement best practices in technology, architecture, and process. You’ll have the chance to work in an open and collaborative environment, receive hands-on mentorship and have ample opportunities to grow and accelerate your career! Responsibilities Build our next generation data warehouse Build our event stream platform Translate user requirements for reporting and analysis into actionable deliverables Enhance automation, operation, and expansion of real-time and batch data environment Manage numerous projects in an ever-changing work environment Extract, transform, and load complex data into the data warehouse using cutting-edge technologies Build processes for topnotch security, performance, reliability, and accuracy Provide mentorship and collaborate with fellow team members Qualifications Bachelor’s or Master’s degree in Computer Science, Information Systems, Operations Research, or related field required 3+ years of experience building data pipelines 3+ years of experience building data frameworks for unit testing, data lineage tracking, and automation Fluency in Scala is required Working knowledge of Apache Spark Familiarity with streaming technologies (e.g., Kafka, Kinesis, Flink) Nice-to-Haves Experience with Machine Learning Familiarity with Looker a plus Knowledge of additional server-side programming languages (e.g. Golang, C#, Ruby) PrismHR is a fast-paced SaaS company which provides customers with a cloud-based payroll process software application. PrismHR also provides professional services including system implementation consulting, custom configurations, and training. Lastly, via the Company’s Marketplace platform customers and end users access other human resources and employee benefits applications from PrismHR’s Marketplace Partners. Diversity, Equity And Inclusion Program/Affirmative Action Plan We have transformed our company into an inclusive environment where individuals are valued for their talents and empowered to reach their fullest potential. At PrismHR, we strive to continually lead with our values and beliefs that enable our employees to develop their potential, bring their full self to work, and engage in a world of inclusion. Ensuring an inclusive environment for our employees is an integral part of the PrismHR culture. We aren't just checking a box, we are truly committed to creating a workplace that celebrates the diversity of our employees and fosters a sense of belonging for everyone. This is essential to our success. We are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about our roles but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for these open roles or other open roles. We particularly encourage applicants from traditionally under-represented groups as we seek to increase the diversity of our workforce and provide fair opportunities for all. As a proud Equal Opportunity and Affirmative Action Employer, PrismHR encourages talent from all backgrounds to join our team. Employment decisions are based on an individual’s qualifications as they relate to the job under consideration. The Company’s policy prohibits unlawful discrimination based on sex (which includes pregnancy, childbirth, breastfeeding, or related medical conditions, the actual sex of the individual, or the gender identity or gender expression), race, color, religion, including religious dress practices and religious grooming practices, sexual orientation, national origin, ancestry, citizenship, marital status, familial status, age, physical disability, mental disability, medical condition, genetic information, protected veteran or military status, or any other consideration made unlawful by federal, state or local laws, ordinances, or regulations. The Company is committed to complying with all applicable laws providing equal employment opportunities. This commitment applies to all persons involved in the operations of the Company and prohibits unlawful discrimination by any employee of the Company, including supervisors and co-workers. Privacy Policy: For information about how we collect and use your personal information, please see our privacy statement available at https://www.prismhr.com/about/privacy-policy. PrismHR provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need a reasonable accommodation due to a disability, you may use the following alternative email address to contact us about your interest in employment at PrismHR: taglobal@prismhr.com. Please indicate in the subject line of your email that you are requesting accommodation. Only candidates being considered for a position who require an accommodation will receive a follow-up response.",,,Machine Learning,
4246238517,Lead AI Engineer,Replicant Systems,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Job Title: Lead AI Engineer Location: Hyderabad Type: Full-Time Experience: 4-7 years preferred Company Description Replicant Systems is a technology company deploying purpose-built AI solutions. We enable real-time intelligence at the edge through our scalable platform — delivering actionable insights for manufacturing, automotive, defense, and process industries. Our solutions integrate hardware, software and AI capabilities to drive smarter decisions, faster operations, and measurable business impact. Promoted by a well-known business family and established in 2024 in Hyderabad. Role Summary We’re looking for a hands-on Lead AI Engineer to lead product development and actively contribute to building our core systems. This is a high-impact role for someone who enjoys writing code, solving architectural challenges, and mentoring developers—while working closely with founders, product, and design. You will spearhead deployment of AI products and pipelines while leading-by-example in a highly engaging work environment. What You’ll Do Design, Develop and Deploy ML powered products and pipelines. Own the tech roadmap in collaboration with product and leadership teams. Design and implement integrations with third-party systems, APIs, and customer tools. Work directly with customers to understand needs and translate them into product features. Mentor and guide the engineering team, fostering a culture of ownership and high performance. Set up scalable, secure, and maintainable architecture for a growing SaaS product. Collaborate across product and business teams to ship quickly and iteratively. What We’re Looking For 4+ years of hands-on engineering experience (preferably in startups or fast-moving environments). Familiarity with AI/ML concepts, models, applications or AI/ML integrations Strong in backend frameworks like FastAPI, Flask, Django, or Node.js. Solid experience with frontend frameworks like React or Vue.js. Hands-on expertise in databases (SQL and/or NoSQL), including schema design, query optimization, and performance tuning. Strong understanding of SaaS architecture, API design, and system integrations. Experience with PostgreSQL, Docker, and cloud services (e.g., AWS, GCP, or Azure). Ability to translate business needs into clean, scalable code and systems. Excellent communication skills; comfortable engaging with customers or stakeholders. Prior experience in leading small teams or projects is a strong plus. Nice to Have Excellent knowledge of ML & Deep Learning domain Experience building multi-tenant SaaS applications Prior startup or founding experience is a positive",,,SQL,
4205210831,DET - RCE - Python developer - Senior,EY,"Kolkata, West Bengal, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. Requirements (Qualifications): Bachelor or Master degree with 3+ years of strong Python development experience Core skills: Bachelor or Master degree with 3+ years of strong Python development experience OOPs concepts: Functions, Classes, Decorators Python and experience in anyone frameworks Flask/Django/Fast API Python Libraries (Pandas, TensorFlow, Numpy, SciPy) AWS Cloud Experience Docker, Kubernetes and microservices Postgres/MySQL GIT, SVN or any Code repository tools Design Patterns SQL Alchemy/ any ORM libraries (Object Relational Mapper) EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",,,"Python, SQL",
4135035938,Machine Learning Engineer,Genrobotics,"Thiruvananthapuram, Kerala, India (On-site)",On-site,Full-time,,"About the job Job Description We are looking for a Machine Learning Engineer with a strong focus on computer vision, who has approximately 1 to 2 years of hands-on experience in the field. The ideal candidate should have a solid understanding of machine learning (ML) and deep learning (DL) algorithms beyond computer vision to contribute to the development of efficient AI systems. The candidate should also possess a good working knowledge on other ML/DL algorithms to develop an efficient AI systems. As a machine learning engineer, you will be working on collecting data, process it as per the requirement, develop, test, optimize and analyse different ML/DL such algorithms which can turn visual data into actionable insighs Responsibilities Ability to understand business requirements Write clean, efficient, and reusable code following best practices Investigate and assess different potential solutions for artificial intelligence tasks gaining a thorough understanding of the most efficient approach Collect data from various sources, preprocess and augment data as part of developing efficient models Develop, test, analyse, and optimize different ML/DL algorithms Collaborate with different stakeholders of the team to gather requirements,develop POCs, and implement the best possible solution Develop a user interface for the application so that the end user can make use of the AI system Stay update with latest trends, tools, and technologies in machine learning and computer vision . Document the work processes, methodologies, and results to ensure transparency and facilitate knowledge sharing . Skills Required Proficient in python programming language .Experience in developing ML and computer vision algorithms using OpenCV and YOLO Knowledge on media pipe (not mandatory) Knowledge in ML/DL Should have knowledge on python libraries such as numpy, pandas, sklearn and matplotlib Understanding of machine learning concepts and techniques Strong analytical skills to analyse and ability to troubleshoot and optimize algorithms Qualifications Bachelors or Masters degree in Computer Science, Information Technology, or related fields Experience 1 to 2 years of experience in developing machine learning/deep learning algorithms specifically focused on computer vision algorithms . Job Location : Technopark , Thiruvananthapuram Skills: yolo,numpy,python,computer vision,opencv,scikit-learn,ml,machine learning,pandas,matplotlib,algorithms,deep learning",,,"Python, Machine Learning",
4247147142,AI ML Engineer,Chiselon Technologies Private Limited,"Chennai, Tamil Nadu, India (Hybrid)",Hybrid,Full-time,,"About the job Skills: Python, NLP, LLM, GEN AI, API, AWS, Linear Regression, Statistical Modeling, Qualifications And Skills Proficient in Python for developing robust machine learning algorithms and tools (Mandatory skill). Hands-on experience with Generative AI for creating advanced learning models and applications (Mandatory skill). Skilled in utilizing AWS cloud services for deploying and scaling machine learning models (Mandatory skill). Experience with Natural Language Processing techniques to enhance machine interaction. Understanding of Large Language Models to implement conversational AI systems effectively. Ability to design APIs enabling smooth communication between different machine learning systems. Competent in linear regression and other statistical modeling techniques for data analysis. Strong analytical skills to interpret complex datasets and draw insightful conclusions. Roles And Responsibilities Design and develop scalable machine learning models and algorithms that meet client needs. Collaborate with cross-functional teams to integrate machine learning solutions into existing systems. Monitor, maintain, and optimize machine learning models to ensure high performance and reliability. Work with large datasets to extract meaningful insights and contribute to data-driven decision making. Stay updated with the latest advancements in AI, machine learning, and technology trends. Mentor junior engineers and provide technical guidance to improve team capabilities. Implement and uphold best practices in model training and evaluation across various projects. Participate in code reviews and contribute to the development of high-quality codebase. Desired Skills and Experience Python, NLP, LLM, GEN AI, API, AWS, Linear Regression, Statistical Modeling",,,"Python, Machine Learning, Data Analysis",
4228842495,Senior AI Engineer - REMOTE,Uplers,"Agra, Uttar Pradesh, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4255440913,AI / ML Engineer,Accenture in India,"Coimbatore, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Data Science Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: As an AI / ML Engineer, you will engage in the development of applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve designing and implementing production-ready solutions, ensuring that they meet quality standards. You will work with various AI models, including generative AI, deep learning, and neural networks, while also exploring innovative applications such as chatbots and image processing. Collaboration with cross-functional teams will be essential to integrate these advanced technologies into existing systems and workflows, driving efficiency and enhancing user experiences. Roles & Responsibilities: - Expected to be an SME. - Collaborate and manage the team to perform. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Provide solutions to problems for their immediate team and across multiple teams. - Facilitate knowledge sharing sessions to enhance team capabilities. - Monitor project progress and ensure alignment with strategic goals. Professional & Technical Skills: - Must To Have Skills: Proficiency in Data Science. - Strong analytical skills to interpret complex data sets. - Experience with machine learning frameworks such as TensorFlow or PyTorch. - Familiarity with cloud platforms like AWS, Azure, or Google Cloud. - Ability to develop and deploy AI models in production environments. Additional Information: - The candidate should have minimum 5 years of experience in Data Science. - This position is based at our Bengaluru office. - A 15 years full time education is required. 15 years full time education",,,Machine Learning,
4252292947,AI Data Scientist - Digital Engineering Sr. Engineer,NTT DATA North America,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Req ID: 327884 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a AI Data Scientist - Digital Engineering Sr. Engineer to join our team in Hyderabad, Telangana (IN-TG), India (IN). ARTIFICIAL INTELLIGENCE AI Data Scientist | Focused on Generative AI & LLMs Design and develop AI/ML models with a focus on LLMs (e.g., GPT, LLaMA, Mistral, Falcon, Claude). Apply prompt engineering, fine-tuning, and transfer learning techniques to customize models for enterprise use cases. Work with vector databases and retrieval-augmented generation (RAG) pipelines for contextual response generation. Collaborate with data engineers, AI Engineers and MLOps teams to deploy models in production environments About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,R,
4232805529,Machine Learning(Ops) - Engineer,Technip Energies,"Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Job Description Be part of the solution at Technip Energies and embark on a one-of-a-kind journey. You will be helping to develop cutting-edge solutions to solve real-world energy problems. About us: Technip Energies is a global technology and engineering powerhouse. With leadership positions in LNG, hydrogen, ethylene, sustainable chemistry, and CO2 management, we are contributing to the development of critical markets such as energy, energy derivatives, decarbonization, and circularity. Our complementary business segments, Technology, Products and Services (TPS) and Project Delivery, turn innovation into scalable and industrial reality. Through collaboration and excellence in execution, our 17,000+ employees across 34 countries are fully committed to bridging prosperity with sustainability for a world designed to last. About the role: We are currently seeking a Machine Learning (Ops) - Engineer , to join our Digi team based in Noida. Key Responsibilities: ML Pipeline Development and Automation: Design, build, and maintain end-to-end AI/ML CI/CD pipelines using Azure DevOps and leveraging Azure AI Stack (e.g., Azure ML, AI Foundry …) and Dataiku Model Deployment and Monitoring: Deliver tooling to deploy AI/ML products into production, ensuring they meet performance, reliability, and security standards. Implement and maintain a transversal monitoring solutions to track model performance, detect drift, and trigger retraining when necessary Collaboration and Support: Work closely with data scientists, AI/ML engineers, and platform team to ensure seamless integration of products into production. Provide technical support and troubleshooting for AI/ML pipelines and infrastructure, particularly in Azure and Dataiku environments Operational Excellence : Define and implement MLOps best practices with a strong focus on governance, security, and quality, while monitoring performance metrics and cost-efficiency to ensure continuous improvement and delivering optimized, high-quality deployments for Azure AI services and Dataiku Documentation and Reporting: Maintain comprehensive documentation of AI/ML pipelines, and processes, with a focus on Azure AI and Dataiku implementations. Provide regular updates to the AI Platform Lead on system status, risks, and resource needs About you: Proven track record of experience in MLOps, DevOps, or related roles Strong knowledge of machine learning workflows, data analytics, and Azure cloud Hands-on experience with tools and technologies such as Dataiku, Azure ML, Azure AI Services, Docker, Kubernetes, and Terraform Proficiency in programming languages such as Python, with experience in ML and automation libraries (e.g., TensorFlow, PyTorch, Azure AI SDK …) Expertise in CI/CD pipeline management and automation tools using Azure DevOps Familiarity with monitoring tools and logging frameworks Catch this opportunity and invest in your skills development, should your profile meet these requirements. Additional attributes: A proactive mindset with a focus on operationalizing AI/ML solutions to drive business value Experience with budget oversight and cost optimization in cloud environments. Knowledge of agile methodologies and software development lifecycle (SDLC). Strong problem-solving skills and attention to detail Work Experience: 3-5 years of experience in MLOps Minimum Education: Advanced degree (Master’s or PhD preferred) in Computer Science, Data Science, Engineering, or a related field. What’s next? Once receiving your application, our Talent Acquisition professionals will screen and match your profile against the role requirements. We ask for your patience as the team completes the volume of applications with reasonable timeframe. Check your application progress periodically via personal account from created candidate profile during your application. We invite you to get to know more about our company by visiting and follow us on LinkedIn, Instagram, Facebook, X and YouTube for company updates.",,,"Python, Machine Learning",
4258029386,AI / Innovation Engineer,"NTT DATA, Inc.","Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Make an impact with NTT DATA Join a company that is pushing the boundaries of what is possible. We are renowned for our technical excellence and leading innovations, and for making a difference to our clients and society. Our workplace embraces diversity and inclusion – it’s a place where you can grow, belong and thrive. Your day at NTT DATA The Senior Software Applications Development Engineer is an advanced subject matter expert, responsible for developing new applications and improve upon existing applications based on the needs of the internal organization and / or external clients. Key responsibilities: Develops applications that effectively accomplish client objectives and user needs Designs and writes code for applications and maintain applications databases Analyzes and edits existing software applications to improve and optimize functionality, fix problems, and enable their use on new hardware platforms Remodels and adapts applications as needed to optimize performance Identifies specific client needs and preferences related to the application Tests applications extensively to ensure they are error and bug-free Installs applications and acts as technical advisor Communicates with relevant internal technical stakeholders to obtain information on project limitations, performance requirements, and interfaces Consults with clients in the design phase to determine client needs Produces software documentation following company software process and templates Participates in software product review meetings and team meetings Performs any other related task To thrive in this role, you need to have: Advanced understanding of computer science, with specific knowledge of computer programming, application design, and user-focused features. Good team player who maintains the integrity of the team. Excellent attention to detail capabilities. Ability to understand and analyze complex systems. Advanced proficiency in writing software using the Java Programming Language and a standard object library. Advanced knowledge of software development process Advanced proficiency with agile development such as Scrum Advanced knowledge of software integrated development environments Advanced knowledge in various programming languages such as (but not limited to) Java, Perl, Python, C++. Demonstrated analytical, organizational, and project management skills, using relevant information to make timely and critical decisions that affect cross-functional teams. Ability to handle client and customer issues tactfully and professionally. Academic qualifications and certifications: Bachelor's degree or equivalent in computer science or software engineering or related field. Certification in various programming languages, for example (but not limited to) Java, Perl, Python, C++ preferred. Scrum / Project Management certification preferred. Required experience: Advanced Software Applications Engineering, Software Development experience, or related work experience. Advanced experience with Programming Languages such as (but not limited to) C, C++, Java, Python. Advanced experienced with Linux or Unix and Windows operating systems. Advanced experience working with SQL. Advanced project management experience and/or experience working in an Agile environment. Workplace type: Hybrid Working About NTT DATA NTT DATA is a $30+ billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long-term success. We invest over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure, and connectivity. We are also one of the leading providers of digital and AI infrastructure in the world. NTT DATA is part of NTT Group and headquartered in Tokyo. Equal Opportunity Employer NTT DATA is proud to be an Equal Opportunity Employer with a global culture that embraces diversity. We are committed to providing an environment free of unfair discrimination and harassment. We do not discriminate based on age, race, colour, gender, sexual orientation, religion, nationality, disability, pregnancy, marital status, veteran status, or any other protected category. Join our growing global team and accelerate your career with us. Apply today.",,,"Python, SQL, R",
4256422095,Junior Frontend Developer,Lead India,India (Remote),Remote,Full-time,,"About the job Position: Frontend Developer Intern (Full-Time) Company: Lead India Location: Remote Stipend: ₹25,000/month Duration: 1–3 months (Full-Time Internship) About Lead India: Lead India is a technology-driven organization focused on delivering seamless, responsive, and scalable digital solutions. We are committed to developing fresh talent through real-world projects, mentorship, and hands-on training in a remote-friendly environment. Role Overview: We are looking for a Frontend Developer Intern to assist in building and enhancing web applications with responsive design and intuitive user interfaces. This role is perfect for someone passionate about user experience, design, and frontend technologies. Key Responsibilities: Develop and maintain frontend components using HTML, CSS, and JavaScript Build responsive and mobile-friendly web interfaces Integrate frontend code with backend APIs Collaborate with UI/UX designers and developers to improve user experience Debug and optimize code for performance and cross-browser compatibility Contribute to design discussions and implement visual enhancements Skills We're Looking For: Strong foundation in HTML5, CSS3, and JavaScript Familiarity with frontend libraries or frameworks (e.g., React, Vue, or Angular is a plus) Understanding of responsive design and cross-browser compatibility Ability to work with design tools (like Figma or Adobe XD) Good communication skills and a collaborative attitude Eagerness to learn and grow in a fast-paced environment What You’ll Gain: ₹25,000/month stipend Experience working on live frontend projects Mentorship from experienced frontend and full-stack developers Fully remote, flexible work setup Opportunity for a Pre-Placement Offer (PPO) based on performance",,,,
4252379655,AI/ML Developer Associate - Operate,PwC Acceleration Centers in India,"Bengaluru, Karnataka, India",,Full-time,,"About the job At PwC, our people in data and analytics engineering focus on leveraging advanced technologies and techniques to design and develop robust data solutions for clients. They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth. Those in artificial intelligence and machine learning at PwC will focus on developing and implementing advanced AI and ML solutions to drive innovation and enhance business processes. Your work will involve designing and optimising algorithms, models, and systems to enable intelligent decision-making and automation. Driven by curiosity, you are a reliable, contributing member of a team. In our fast-paced environment, you are expected to adapt to working with a variety of clients and team members, each presenting varying challenges and scope. Every experience is an opportunity to learn and grow. You are expected to take ownership and consistently deliver quality work that drives value for our clients and success as a team. As you navigate through the Firm, you build a brand for yourself, opening doors to more opportunities. Skills Examples of the skills, knowledge, and experiences you need to lead and deliver value at this level include but are not limited to: Apply a learning mindset and take ownership for your own development. Appreciate diverse perspectives, needs, and feelings of others. Adopt habits to sustain high performance and develop your potential. Actively listen, ask questions to check understanding, and clearly express ideas. Seek, reflect, act on, and give feedback. Gather information from a range of sources to analyse facts and discern patterns. Commit to understanding how the business works and building commercial awareness. Learn and apply professional and technical standards (e.g. refer to specific PwC tax and audit guidance), uphold the Firm's code of conduct and independence requirements. Job Title: AI/ML Associate Location : Bangalore (Hybrid) Department : Managed Services – Core Automation Team Job Overview We are seeking an experienced AI/ML Senior Associate to join our team focused on leveraging AI technologies to enhance operational efficiency in SAP managed services. The ideal candidate will have strong programming expertise in Python and hands-on experience in building AI solutions using market-leading large language models (LLMs) , as well as native cloud services (primarily AWS or Azure AI services ). Your role will center on developing intelligent solutions that automate processes, integrate AI models, and improve overall system performance within SAP environments. Key Responsibilities Design and implement AI solutions using Python and market-leading LLMs to drive automation and improve operational efficiency within SAP-managed services. Develop and integrate AI-powered applications using native AWS services (e.g., AWS Lex, AWS Lambda, Amazon Polly) or Azure AI services, focusing on process optimization and automation. Build and deploy conversational bots and AI-powered tools to support business processes in SAP environments, integrating AWS Lex, AWS Connect, or Azure Bot Services with existing systems. Leverage Python programming for building, testing, and deploying AI models, APIs, and automation workflows to enhance SAP system reliability and performance. Collaborate with cross-functional teams to integrate AI solutions with DevOps pipelines and ensure smooth deployments using CI/CD tools and cloud-native infrastructure. Design and manage serverless applications using AWS Lambda or Azure Functions to handle AI/ML workloads with scalability and high performance. Work with RESTful or GraphQL APIs to enable AI services, ensuring high standards for performance, security, and seamless integration with SAP systems. Contribute to the development of AI models, focusing on using LLMs for natural language understanding, predictive analytics, and automated decision-making. Collaborate with DevOps and integration teams to integrate AI solutions into SAP processes, ensuring end-to-end service excellence and operational success. Required Skills And Qualifications Minimum 2 years of experience in AI/ML development, focusing on Python programming and AI model development. Proven experience with Python for building AI solutions, API development, and automation. Hands-on experience with market-leading LLMs (e.g., OpenAI GPT, Google BERT, or similar) and applying these models in business process automation and optimization. Experience with AWS or Azure AI services, such as AWS Lex, AWS Lambda, Azure Cognitive Services, and Azure Bot Services (AWS expertise is preferred but Azure experience is also acceptable). Experience building and deploying conversational bots and IVR systems using AWS Lex or Azure Bot Services. Strong understanding of serverless architectures and cloud-native technologies such as AWS Lambda or Azure Functions. Experience with RESTful or GraphQL API design for seamless integration of AI models into business processes. DevOps background, with hands-on experience in CI/CD pipelines, containerization, and cloud deployment practices using AWS DevOps tools or Azure DevOps. Collaborative mindset with the ability to work cross-functionally with DevOps, integration, and automation teams to drive project success. Desired Skills And Qualifications Familiarity with machine learning frameworks (e.g., TensorFlow, PyTorch, Scikit-learn) and the ability to develop and fine-tune AI models. Knowledge of Agile methodologies for project management and team collaboration. Strong problem-solving skills, with the ability to troubleshoot and optimize AI models and cloud integrations. Certifications in AWS AI, Azure AI, or related AI/ML technologies are a plus. Experience Requirements A minimum of 2 years of experience in AI/ML, with expertise in Python, AI model development, and cloud-native AI services (AWS or Azure). Proven ability to design and deploy AI solutions using LLMs, serverless architectures, and cloud-based AI services. Education Requirements Bachelor’s degree in Computer Science, Engineering, Information Technology, or a related field. Relevant AI/ML certifications (e.g., AWS Certified Machine Learning, Azure AI Fundamentals) are a plus. Work Environment Collaborative and dynamic team environment with an opportunity to work on cutting-edge AI/ML projects. Hybrid working model with a base in Bangalore, offering flexibility in working from the office and remotely. Cross-functional collaboration with DevOps, automation, and integration teams.",Associate,,"Python, Machine Learning",
4259094597,Backend Developer,RTPL.Digital,"Patna, Bihar, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Responsibilities Designing and developing back-end website applications. Creating servers and databases for functionality. Maintaining high-level coding structure. Designing and developing APIs. Staying abreast of developments in web applications and programming languages. Requirements 0-4 years of working experience as a back-end developer. Proficiency with server-side languages such as. NET, . NET Core. Familiarity with database technology such as MS SQL, PostgreSQL, MySQL, and MongoDB. Proficiency using Bitbucket/Git version control. This job was posted by Vidya Shankar Ray from Rai Techintro. Desired Skills and Experience NET,ASP.NET,C#",,,SQL,
4122153043,Machine Learning Engineer,BeautifulCode,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Experience: 3+ years of experience Location: Hyderabad We are looking for a talented and motivated Machine Learning Engineer to join Data Science and Machine Learning projects to help improve the performance of our targeting and optimization products. You will be part of a team that manages the full data product life-cycle: from prototyping to production development to A/B testing and measurements - providing each team member the opportunity to work with technologies such as Tensorflow, Vertex AI on Google Cloud Platform. Responsibilities Design, implement and maintain machine learning pipelines on Google Cloud Platform Improve systems that optimize campaign performance and pacing Write and ship production-level Python code and Go code Write and execute complex SQL queries to extract and transform data from various sources Collaborate with other applied scientists, software engineers and product managers to design and implement solutions based on business requirements Document code and processes for future reference and maintainability. Participate in the entire Agile development lifecycle, including sprint planning, stand-ups, and retrospectives Requirements Bachelor’s or Master’s Degree in Computer Science At least two years experience as an ML engineer or in a similar role. Proficient in writing and deploying Python code to production environments using Docker. Experience with at least one other language, preferably Golang, is desirable. Hands-on experience building production-level ML and data products. Hands-on experience with a cloud platform, preferably Google Cloud Platform (GCP), but experience with other providers (AWS, Azure) is also acceptable. Ability to collaborate with applied (modeling) scientists to design and apply machine learning pipelines (supervised, unsupervised, reinforcement learning etc.) to solve business problems. Strong communication skills to work across teams of applied scientists, data scientists, engineers and product managers. Self-motivated and proactive in addressing challenges and driving projects to completion. About BeautifulCode BeautifulCode (www.beautifulcode.co) is a product engineering services company. We build high quality and scalable products for our clients. 95+% of our company are developers and we have a strong developer DNA that results in high quality software engineering. Why BeautifulCode We hire high performers and pay above market compensation. You will be learning from the best. We have a clear career progression path resulting in exciting outcomes. We work hard and play hard. We travel and learn as a team. Check out where all we’ve been to.",manager,,"Python, SQL, Machine Learning",
4145472681,AI/ML Engineer,Wing Assistant,"Delhi Cantonment, Delhi, India (Remote)",Remote,Full-time,,"About the job Wing is hiring elite talent for M32 Labs , an innovative venture-backed company based in Silicon Valley dedicated to building cutting-edge AI-powered products for business clients worldwide. At M32, we're not just another tech company- we’re creating world-class AI solutions that redefine industries. If you’re looking for a challenging and high-impact engineering role, this is it. What it'll be like working at M32: Move fast and break things: This is a company with 0 bureaucracy, and maximum impact. We are building world-class products, hiring a world-class team, and putting large resources behind the products you're building. We are looking for engineers who are willing to go above and beyond. Deadlines will be tight, expectations will be high. If you're looking for a standard 9-5 job, this is not the place for you. Autonomy & Creativity: We value decision-makers and innovators. You’ll have the control to make both technical and product decisions, and our goal is to let you lead entire product builds. Exponential Career Growth: Exceptional performance will be rewarded far beyond normal. If you excel at M32, expect your compensation to double within a year and your role to grow rapidly. Small, Elite Teams: You’ll work in tight-knit teams of 1–3 exceptional engineers to build full products from scratch. Every week will feel like a hackathon! High Impact: Your work will directly influence thousands of users, with immediate deployment and feedback. You’ll never work on insignificant internal tools or tiny features. You will work directly with C-level executives. Fast track to leadership. Are you ambitious AND hard working? We reward that here, promoting top performers to elevated positions quickly, at a faster rate than industry standards. Job Overview We are seeking a Machine Learning / AI Engineer to drive innovation in building domain-specific AI agents for our next-generation product suite. As part of a fast-paced, agile R&D environment , you will explore state-of-the-art methodologies—such as Retrieval Augmented Generation (RAG) , LangChain -based pipelines, and PhiData —to create intelligent, context-aware solutions tailored to specific industry verticals. You’ll have the freedom to experiment rapidly, iterate on ideas, and play a key role in delivering groundbreaking AI experiences that address real-world business challenges. Key Responsibilities : AI Agent & NLP Development Design, build, and refine NLP models (intent recognition, entity extraction, dialogue management) for advanced conversational or task-focused AI agents. Integrate speech recognition (STT) and text-to-speech (TTS) capabilities when needed, leveraging cloud APIs or open-source solutions. Retrieval Augmented Generation (RAG) Architect and implement pipelines that retrieve relevant context from knowledge bases or document stores, enhancing LLM outputs with accurate, domain-specific information. Utilize vector databases (e.g., Pinecone, Weaviate, Chroma) to index content for semantic search and real-time retrieval. LangChain & Prompt Orchestration Use LangChain or similar frameworks to organize multi-step AI workflows, combining prompts, data retrieval, and dynamic decision-making in a coherent pipeline. Develop strategies for prompt engineering , error handling, and iterative refinement to improve user interactions and AI accuracy. PhiData & Data Governance Integrate PhiData (or comparable tools) to ensure strong data governance, security, and privacy across all stages of model training and deployment. Contribute to best practices for handling sensitive or proprietary data, adhering to compliance requirements in various industries. Model Development & Deployment Train, fine-tune, and deploy LLMs or custom ML models using frameworks like PyTorch , TensorFlow , or Hugging Face Transformers . Leverage containerization (Docker) and orchestration (Kubernetes) on cloud platforms (AWS, GCP, Azure) to ensure scalable, low-latency deployments. Rapid Prototyping & Iteration Embrace a lightweight, iterative workflow to quickly develop proofs-of-concept, validate assumptions, and pivot based on user or stakeholder feedback. Conduct ongoing experiments to benchmark performance, refine models, and stay ahead of emerging AI/ML trends. Collaboration & Communication Work closely with cross-functional teams (backend, product, design) to integrate AI solutions seamlessly into our vertical-focused platforms. Document and share best practices in NLP, retrieval methods, and AI model deployment across the organization. Qualifications : Education & Experience Bachelor’s or Master’s degree in Computer Science, Data Science, Machine Learning, or related field—or equivalent practical experience. Proven track record (2+ years) in NLP , conversational AI , or machine learning roles, ideally with hands-on deployment experience. Core Technical Skills : Programming : Proficiency in Python ; familiarity with frameworks like PyTorch , TensorFlow , or Hugging Face . NLP/Conversational AI : Experience with libraries such as spaCy, Rasa, or NLTK, and an understanding of dialog systems. RAG & Vector Databases : Hands-on experience designing retrieval-augmented architectures and working with vector stores (Pinecone, Weaviate, Chroma). LangChain : Knowledge of orchestrating multi-step AI workflows, prompt engineering, and advanced conversation management. Data & Infrastructure Comfort with data engineering tasks—managing and preprocessing large text corpora or domain-specific datasets. Familiarity with containerization (Docker) and Kubernetes-based deployments on AWS, GCP, or Azure. Experience implementing CI/CD pipelines and using infrastructure-as-code (Terraform, CloudFormation) is a plus. Governance & Security Awareness of PhiData or similar data governance/privacy solutions, and compliance requirements (GDPR, HIPAA, etc.) relevant to enterprise AI. Understanding of secure coding and data handling practices. Soft Skills & Mindset Innovation-Driven : Thrives on exploring novel techniques and pushing the boundaries of what AI can achieve for specific industry verticals. Agile Mindset : Comfortable with short iteration cycles, rapid prototyping, and a minimal-bureaucracy culture. Collaboration & Communication : Excellent at sharing ideas with both technical and non-technical stakeholders, and open to feedback and knowledge sharing. Preferred Skills. : Familiarity with Cursor AI or similar rapid development tools. Remote-First Experience : Comfortable with distributed teams, asynchronous communication, and remote collaboration. Strong Communication : Excellent verbal and written communication in English. Critical Thinking & Creativity : Demonstrated ability to tackle problems from multiple angles and propose innovative solutions. Proficiency with Node.js : Experience in backend JavaScript/TypeScript development is a plus. Knowledge of PHP : Exposure to or hands-on experience with PHP frameworks is also a plus. Full-Scale Web Applications : Prior exposure to building or integrating large-scale web platforms and familiarity with modern web technologies. Working Location: This will be a remote role. Benefits: Competitive Pay: Above-market compensation for exceptional talent Rapid Pay Increases for top performers: For exceptional performance, we are willing to double your compensation within 1 year Health Benefits: Reimbursement for health insurance premiums Performance Bonuses: Significant rewards for exceptional contributions Upskilling Budget: Support for online professional development Flexible Work Environment: Remote-first flexibility with in-office collaboration when needed AI software licenses for faster development Food Delivery Reimbursement: Late night Swiggy/Zomato reimbursement of 2,000 INR per month Gym Reimbursement: Gym reimbursement of 4,000 INR per month Tech Setup: Budget for tech set up provided after 6 months of employment US HQ Opportunities: Top performers may have the opportunity to explore international roles within our US-based headquarters, including potential emigration opportunities, subject to availability and company needs, and after at least 2 years of employment Salary Range: 12-25 LPA Please note : Immediate joiners are preferred.",executive,,"Python, Excel, R, Machine Learning",
4259096556,Application Developer,Re Sustainability Limited,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Responsibilities Contribute to all stages of the software development lifecycle. Analyse user requirements to define business objectives. Envisioning system features and functionality. Define application objectives and functionality. Ensure application designs conform to business goals. Identify and resolve any technical issues arising. Conducting software analysis, programming, testing, and debugging. Manage Java and Java EE application development. Develop documentation to help users. Transforming requirements into stipulations. Prepare and produce releases of software components. Support continuous improvement, investigating alternatives and technologies, and presenting for architectural review. Create and maintain monthly/weekly reports to track progress and performance. Requirements Proficiency in Java. Core Java, J2EE, Spring MVC, Spring REST APIs, Spring Security, JSP, Web application, Redis, Oauth2 Angular, JQuery, HTML, JavaScript. Knowledge of MySQL. Good experience in SQL Server enabled understanding and writing complex stored procedures. Web frameworks like Spring Boot. This job was posted by Deepa Challa from Re Sustainability. Desired Skills and Experience Java,Node.js,J2EE,Spring",,,SQL,
4248763909,AI/ML Engineer – Intelligent Automation,Beco,Mumbai Metropolitan Region (On-site),On-site,Full-time,,"About the job About Beco Beco ( letsbeco.com ) is a fast-growing Mumbai-based consumer-goods company on a mission to replace everyday single-use plastics with planet-friendly, bamboo- and plant-based alternatives. From reusable kitchen towels to biodegradable garbage bags, we make sustainable living convenient, affordable and mainstream. Our founding story began with a Mumbai beach clean-up that opened our eyes to the decades-long life of a single plastic wrapper—sparking our commitment to “Be Eco” every day. Our mission: “To craft, support and drive positive change with sustainable & eco-friendly alternatives—one Beco product at a time.” Backed by marquee climate-focused VCs and now 50 + employees, we are scaling rapidly across India’s top marketplaces, retail chains and D2C channels. Why we’re hiring Sustainability at scale demands operational excellence. As volumes explode, we need data-driven, self-learning systems that eliminate manual grunt work, unlock efficiency and delight customers. You will be the first dedicated AI/ML Engineer at Beco—owning the end-to-end automation roadmap across Finance, Marketing, Operations, Supply Chain and Sales. Responsibilities Partner with functional leaders to translate business pain-points into AI/ML solutions and automation opportunities. Own the complete lifecycle: data discovery, cleaning, feature engineering, model selection, training, evaluation, deployment and monitoring. Build robust data pipelines (SQL/BigQuery, Spark) and APIs to integrate models with ERP, CRM and marketing automation stacks. Stand up CI/CD + MLOps (Docker, Kubernetes, Airflow, MLflow, Vertex AI/SageMaker) for repeatable training and one-click releases. Establish data-quality, drift-detection and responsible-AI practices (bias, transparency, privacy). Mentor analysts & engineers; evangelise a culture of experimentation and “fail-fast” learning—core to Beco’s GSD (“Get Sh#!t Done”) values. Must-have Qualifications 3 + years hands-on experience delivering ML, data-science or intelligent-automation projects in production. Proficiency in Python (pandas, scikit-learn, PyTorch/TensorFlow) and SQL; solid grasp of statistics, experimentation and feature engineering. Experience building and scaling ETL/data pipelines on cloud (GCP, AWS or Azure). Familiarity with modern Gen-AI & NLP stacks (OpenAI, Hugging Face, RAG, vector databases). Track record of collaborating with cross-functional stakeholders and shipping iteratively in an agile environment. Nice-to-haves Exposure to e-commerce or FMCG supply-chain data. Knowledge of finance workflows (Reconciliation, AR/AP, FP&A) or RevOps tooling (HubSpot, Salesforce). Experience with vision models (Detectron2, YOLO) and edge deployment. Contributions to open-source ML projects or published papers/blogs. What Success Looks Like After 1 Year 70 % reduction in manual reporting hours across finance and ops. Forecast accuracy > 85 % at SKU level, slashing stock-outs by 30 %. AI chatbot resolves 60 % of tickets end-to-end, with CSAT > 4.7/5. At least two new data-products launched that directly boost topline or margin. Life at Beco Purpose-driven team obsessed with measurable climate impact. Entrepreneurial, accountable, bold” culture—where winning minds precede outside victories.",,,"Python, SQL",
4245524808,AI Fullstack Engineer,Uplers,"Dehradun, Uttarakhand, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - HurixDigital) What do you need for this opportunity? Must have skills required: Python, LLM, Rag (retrieval-augmented generation), AWS HurixDigital is Looking for: Job Summary We are seeking a highly skilled and innovative AI Engineer with Full Stack capabilities to join our dynamic team. The ideal candidate will bring a strong blend of expertise in artificial intelligence, modern software engineering practices, and cloud infrastructure. You will be responsible for designing, developing, and deploying intelligent applications that are scalable, resilient, and deliver real business value. Key Responsibilities Develop and deploy end-to-end AI-powered applications leveraging full-stack development best practices. Architect and integrate AI/ML models and pipelines using tools like LangChain, Hugging Face, OpenAI, and Anthropic Claude APIs. Design and implement microservices, RESTful APIs, and backend systems with scalability and maintainability in mind. Leverage cloud platforms (AWS, Azure, GCP) for hosting, automation, and scaling services. Integrate CI/CD pipelines to ensure smooth and frequent deployment cycles. Collaborate with cross-functional teams to translate business requirements into technical solutions. Apply techniques such as content chunking, vector search, embedding models, and retrievers to build advanced AI retrieval systems. Ensure robust architecture that can withstand variable load conditions, focusing on fault tolerance and high availability. Maintain documentation and adhere to best practices in software development and AI model integration. Required Qualifications Bachelor's or Master's degree in Computer Science, Engineering, or a related field. 5+ years of hands-on experience in AI engineering and full-stack development. Strong proficiency with AI/ML tools including LangChain, Hugging Face, OpenAI, and Claude APIs. Deep understanding of vector databases, retrievers, and modern NLP workflows. Proficient in one or more full-stack frameworks (e.g., Node.js, Django, React, Angular). Experience with Python Experience with cloud platforms (AWS, Azure, GCP) and infrastructure automation tools (e.g., Terraform, CloudFormation). Solid experience with CI/CD pipelines, GitOps, and container orchestration (e.g., Docker, Kubernetes). Proven ability to architect resilient systems and optimize performance under fluctuating workloads. Preferred Skills Knowledge of prompt engineering and LLM fine-tuning techniques. Familiarity with DevSecOps practices and AI compliance requirements. Exposure to multimodal models and real-time inference systems. What We Offer Opportunity to work on cutting-edge AI products and tools. Collaborative and inclusive team environment. Flexible work schedule and remote work options. Competitive salary and performance bonuses. How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Python, LLM, Rag (retrieval-augmented generation), AWS",,,Python,
4241157408,AI Engineer,Ascendion,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Location: Chennai, TN/ Hyderabad, TG/ Bangalore, KA/ Pune, MH Must-Have Skills: Backend Development: Python (FastAPI / Flask) AI Integration: OpenAI API (GPT-4o) Cloud Services: Azure Functions, Azure Storage Account, Cosmos DB Database & Caching: NoSQL (Cosmos DB) APIs & Authentication: RESTful APIs, OAuth, JWT DevOps & Deployment: CI/CD pipelines, Azure DevOps Code Quality: Unit Testing, Debugging, Performance Optimization Good-to-have Skills: Vector Databases for AI: Azure AI Search Logging & Monitoring: Application Insights, Azure Monitor Security: Azure Active Directory (AAD), Role-Based Access Control (RBAC) Retrieval-Augmented Generation with vector databases LLM Orchestration: LangChain or Semantic Kernel Experience in OCR, Automation, Natural language data analytics and AI agents is preferred. Experience in CRM, Personalization, Virtual Agents, and Self-service AI apps is preferred Work Hours: 04:00AM - 12:00PM PST",Director,,Python,
4242549101,Machine Learning Engineer,VOIS,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,,"About the job About VOIS: VO IS (Vodafone Intelligent Solutions) is a strategic arm of Vodafone Group Plc, creating value and enhancing quality and efficiency across 28 countries, and operating from 7 locations: Albania, Egypt, Hungary, India, Romania, Spain and the UK. Over 29,000 highly skilled individuals are dedicated to being Vodafone Group’s partner of choice for talent, technology, and transformation. We deliver the best services across IT, Business Intelligence Services, Customer Operations, Business Operations, HR, Finance, Supply Chain, HR Operations, and many more. Established in 2006, VO IS has evolved into a global, multi-functional organisation, a Centre of Excellence for Intelligent Solutions focused on adding value and delivering business outcomes for Vodafone. About VOIS India: In 2009, VO IS started operating in India and now has established global delivery centres in Pune, Bangalore and Ahmedabad. With more than 14,500 employees, VO IS India supports global markets and group functions of Vodafone, and delivers best-in-class customer experience through multi-functional services in the areas of Information Technology, Networks, Business Intelligence and Analytics, Digital Business Solutions (Robotics & AI), Commercial Operations (Consumer & Business), Intelligent Operations, Finance Operations, Supply Chain Operations and HR Operations and more Role: ML/GenAI Engineer Experience: 7-10 Years Job Location: Pune, EON IT Park (Hybrid) Must have skills: ML/AI/GenAI, Python, GCP, Github, LLM Job Summary: We are seeking a highly skilled and motivated Machine Learning Engineer / GenAI Engineer to join our AI/ML team. The ideal candidate will have hands-on experience in building, deploying, and maintaining machine learning models and GenAI solutions using modern cloud platforms and MLOps practices. You will work closely with cross-functional teams to design scalable AI pipelines and integrate LLM-based solutions into production environments. Key Responsibilities: Design, develop, and deploy ML and GenAI solutions using Python and LLM frameworks. Build and manage ML pipelines using Vertex AI Pipelines and CI/CD tools like Cloud Build and GitHub Actions. Containerize applications using Docker and manage deployments on Google Cloud Platform (GCP) and Azure. Collaborate with data engineers and DevOps teams to ensure seamless integration and deployment. Write and maintain infrastructure as code using YAML. Implement and manage CI/CD pipelines for ML workflows. Work with GitHub for version control and collaboration. Ensure model governance and compliance using protocols like Model Context Protocol and A2A Protocol. Participate in code reviews, design discussions, and team planning sessions. Mandatory Skills: Strong hands-on experience with Python. Proficiency in Google Cloud Platform (GCP) and Azure Cloud. Experience with Vertex AI Pipelines. Expertise in CI/CD setup, Cloud Build, and GitHub Actions. Proficient in Docker and container orchestration. Experience with YAML for configuration and infrastructure. Familiarity with LLM models and GenAI tools. Strong team collaboration and version control using GitHub. Good-to-Have Skills: GCP Certifications (e.g., Professional ML Engineer, Cloud Architect). Strong communication skills for cross-functional collaboration. Experience with Azure Data Factory. Knowledge of Model Context Protocol and A2A Protocol. Familiarity with Google ADK (AI Development Kit). Exposure to React for building front-end interfaces. VOIS Equal Opportunity Employer Commitment India: VOIS is proud to be an Equal Employment Opportunity Employer. We celebrate differences and we welcome and value diverse people and insights. We believe that being authentically human and inclusive powers our employees’ growth and enables them to create a positive impact on themselves and society. We do not discriminate based on age, colour, gender (including pregnancy, childbirth, or related medical conditions), gender identity, gender expression, national origin, race, religion, sexual orientation, status as an individual with a disability, or other applicable legally protected characteristics. As a result of living and breathing our commitment, our employees have helped us get certified as a Great Place to Work in India for four years running. We have been also highlighted among the Top 5 Best Workplaces for Diversity, Equity, and Inclusion, Top 10 Best Workplaces for Women, Top 25 Best Workplaces in IT & IT-BPM and 14th Overall Best Workplaces in India by the Great Place to Work Institute in 2023. These achievements position us among a select group of trustworthy and high-performing companies which put their employees at the heart of everything they do. By joining us, you are part of our commitment. We look forward to welcoming you into our family which represents a variety of cultures, backgrounds, perspectives, and skills! Apply now, and we’ll be in touch!",Manager,,"Python, Machine Learning",
4207718668,ML Developer,Virtusa,"Andhra Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job JD:ML Developers to build prod-ready models that will help with content extraction and classification from images and text based sources. Should have worked on projects related to Intelligent document processing using open source models. Work with business and transformation teams to understand & formulate application specific design. Collaborative with product managers, technical teams. Create, test and iterate new and existing products and features. Design and Build Python/ML/OCR-based components. Completes applications development by coordinating requirements, schedules, and activities; contributing to team meetings, troubleshooting development and production problems across multiple environments and operating platforms. Should be able to troubleshoot development and production problems across multiple environments and operating platforms. Desired Skills and Experience ML Ops",manager,,Python,
4258506283,"Mid Data Science & AIML, GenAI Lead/Engineer",NTT DATA North America,Pune/Pimpri-Chinchwad Area,,Full-time,,"About the job Req ID: 312427 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Mid Data Science & AIML, GenAI Lead/Engineer to join our team in Pune, Mahārāshtra (IN-MH), India (IN). Job Duties: Job Title: Data Science & AIML, GenAI Lead/Engineer Responsibilities: Conduct data analysis using Python. Develop AI models leveraging Langchain, LlamaIndex, and Azure OpenAI Services. Utilize Generative AI models and Natural Language Processing techniques. Implement Retrieval-Augmented Generation (RAG) solutions. Apply machine learning algorithms, data pre-processing, and manage AI lifecycle (model training, validation, monitoring). Minimum Skills Required: Qualifications: 2+ years of experience with AI Python development Bachelor’s degree in computer science, Information Technology, or related field. Strong analytical skills and attention to detail. Ability to work independently or as part of a team. #GenAINTT About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning, Data Analysis",
4259097370,Backend Developer,Invictus,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More We're looking for a highly autonomous and technically versatile Senior Software Engineer / Technical Lead to take ownership of backend services and contribute directly to architecture and strategy across the entire stack. This role requires someone who can make sound technical decisions independently, drive discussions across multiple disciplines, and lead the delivery of scalable solutions from design to release. The ideal candidate is comfortable working with various technologies such as Scala, Spring Boot, Rust, and AWSand can quickly assess trade-offs while building robust systems. You'll collaborate with frontend, DevOps, and product teams to orchestrate releases and drive business impact. Responsibilities Technical Ownership: Lead development across services built in Scala, Spring Boot, and Rust, maintaining code quality, performance, and reliability. Architecture and Strategy: Actively contribute to system design and architecture decisions. Drive long-term technical strategy in collaboration with product and engineering leadership. Roadmapping and Planning: Participate in product discussions and translate business needs into clear, actionable technical roadmaps. Ensure feasibility and help shape planning with realistic timelines and milestones. Cross-functional Collaboration: Work closely with frontend developers, DevOps engineers, and backend peers to deliver end-to-end solutions. Lead technical discussions across the stack to ensure cohesive system design. Release Orchestration: Design and oversee the release process for new features, ensuring smooth rollouts and minimal disruption across environments. Requirements Tech Stack: Scala, Spring Boot, Rust, AWS, Docker, PostgreSQL, REST APIs, CI/CD, Frontend, and DevOps collaboration. 5+ years of experience across multiple backend stacks (Scala/Play, Spring Boot, Rust, etc. ). Strong understanding of distributed systems, system design, and API architecture. Comfortable working independently and owning critical paths in software delivery. Experience with AWS, Docker, CI/CD pipelines, PostgreSQL, and infrastructure-level concerns. Proven ability to communicate technical decisions clearly in product and cross-team contexts. Experience leading feature delivery from ideation to production release. Bonus: Familiarity with frontend development workflows (React, Vue, or similar). This job was posted by Harika K from Invictus. Desired Skills and Experience AWS,Rust,Scala",,,,
4259095684,Full - Stack Developer (Backend - Focused),The Fast Way,"Navi Mumbai, Maharashtra, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More We're seeking a skilled Full-Stack Developer with a strong focus on backend development to join our dynamic team. The ideal candidate is experienced in building scalable applications using modern web technologies and has hands-on expertise with both traditional and blockchain stacks. Requirements Proven experience with back-end development, especially with NestJS, Laravel, and GraphQL. Solid front-end skills with ReactJS and NextJS. Proficiency in PostgreSQL and designing scalable APIs. Experience with Solidity or Rust is a strong plus. Strong problem-solving and collaboration skills. Plus Points: If you know data architecture and blockchain. Tech Stack Frontend: JavaScript, ReactJS, NextJS, Redux, GSAP. Backend: PHP, JavaScript, Laravel, NestJS, Filament-PHP, GraphQL. Database: PostgreSQL. This job was posted by Chinmaya Badgujar from The Fast Way. Desired Skills and Experience JavaScript,PHP,Laravel,React.js",,,,
4223228611,TatvaCare - Artificial Intelligence Engineer - Data Modeling,TatvaCare,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Role Overview As an AI Engineer, this role will be responsible for designing, building, and maintaining scalable applications. Work on multi-modal technologies including voice and image recognition to solve for AI first use cases of HealthTech ecosystem and Enterprise Pharma. The engineer will work with modern frameworks such as Python along with hands- on expertise in Python, Prompt Engineering, and LLMs (OpenAI, Gemini and Claude). A strong emphasis is placed on integrating machine learning solutions into production environments, fine-tuning and deployment of Large Language Models (LLMs) to enhance application performance and user experience. The ideal candidate is highly adaptable, results-oriented, and comfortable operating across the stack and stepping into ambiguous problem spaces. This role requires not only strong technical proficiency, but also a proactive mindset, a willingness to take initiative beyond formal responsibilities, and a drive to deliver impactful, high-quality solutions. Responsibilities Responsible to lead the design, development, and deployment of LLM-powered features, including Retrieval-Augmented Generation (RAG) pipelines. Architect scalable solutions that integrate LLMs with custom data sources, vector databases, and retrieval systems to improve context-aware responses. Collaborate cross-functionally with product managers, ML engineers, data engineers, and backend/frontend teams to turn AI concepts into production-ready features. Manage the full development lifecycle from data preprocessing and prompt engineering to deployment and post-launch monitoring. Will be responsible for building and maintaining high quality test cases. Requirement Bachelors or masters in computer science or related fields. 4+ years of experience building scalable applications with extensive experience in research and development, especially in software-based solutions and products. Hands-on experience in training ML models and fine-tuning LLMs. Hands -on experience in Python, LangChain, LangGraph, MongoDB, Mem0 Proficient in machine learning frameworks such as TensorFlow or PyTorch is preferred. Excited about leveraging LLMs to build intelligent, high-impact applications. Understanding of neural networks and deep learning concepts. Ability to learn and apply new technologies in a fast-paced environment. (ref:hirist.tech)",manager,,"Python, Machine Learning",
4252378868,AI/ML Developer Associate - Operate,PwC Acceleration Centers in India,"Bengaluru, Karnataka, India",,Full-time,,"About the job At PwC, our people in data and analytics engineering focus on leveraging advanced technologies and techniques to design and develop robust data solutions for clients. They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth. Those in artificial intelligence and machine learning at PwC will focus on developing and implementing advanced AI and ML solutions to drive innovation and enhance business processes. Your work will involve designing and optimising algorithms, models, and systems to enable intelligent decision-making and automation. Driven by curiosity, you are a reliable, contributing member of a team. In our fast-paced environment, you are expected to adapt to working with a variety of clients and team members, each presenting varying challenges and scope. Every experience is an opportunity to learn and grow. You are expected to take ownership and consistently deliver quality work that drives value for our clients and success as a team. As you navigate through the Firm, you build a brand for yourself, opening doors to more opportunities. Skills Examples of the skills, knowledge, and experiences you need to lead and deliver value at this level include but are not limited to: Apply a learning mindset and take ownership for your own development. Appreciate diverse perspectives, needs, and feelings of others. Adopt habits to sustain high performance and develop your potential. Actively listen, ask questions to check understanding, and clearly express ideas. Seek, reflect, act on, and give feedback. Gather information from a range of sources to analyse facts and discern patterns. Commit to understanding how the business works and building commercial awareness. Learn and apply professional and technical standards (e.g. refer to specific PwC tax and audit guidance), uphold the Firm's code of conduct and independence requirements. Job Title: AI/ML Associate Location : Bangalore (Hybrid) Department : Managed Services – Core Automation Team Job Overview We are seeking an experienced AI/ML Senior Associate to join our team focused on leveraging AI technologies to enhance operational efficiency in SAP managed services. The ideal candidate will have strong programming expertise in Python and hands-on experience in building AI solutions using market-leading large language models (LLMs) , as well as native cloud services (primarily AWS or Azure AI services ). Your role will center on developing intelligent solutions that automate processes, integrate AI models, and improve overall system performance within SAP environments. Key Responsibilities Design and implement AI solutions using Python and market-leading LLMs to drive automation and improve operational efficiency within SAP-managed services. Develop and integrate AI-powered applications using native AWS services (e.g., AWS Lex, AWS Lambda, Amazon Polly) or Azure AI services, focusing on process optimization and automation. Build and deploy conversational bots and AI-powered tools to support business processes in SAP environments, integrating AWS Lex, AWS Connect, or Azure Bot Services with existing systems. Leverage Python programming for building, testing, and deploying AI models, APIs, and automation workflows to enhance SAP system reliability and performance. Collaborate with cross-functional teams to integrate AI solutions with DevOps pipelines and ensure smooth deployments using CI/CD tools and cloud-native infrastructure. Design and manage serverless applications using AWS Lambda or Azure Functions to handle AI/ML workloads with scalability and high performance. Work with RESTful or GraphQL APIs to enable AI services, ensuring high standards for performance, security, and seamless integration with SAP systems. Contribute to the development of AI models, focusing on using LLMs for natural language understanding, predictive analytics, and automated decision-making. Collaborate with DevOps and integration teams to integrate AI solutions into SAP processes, ensuring end-to-end service excellence and operational success. Required Skills And Qualifications Minimum 2 years of experience in AI/ML development, focusing on Python programming and AI model development. Proven experience with Python for building AI solutions, API development, and automation. Hands-on experience with market-leading LLMs (e.g., OpenAI GPT, Google BERT, or similar) and applying these models in business process automation and optimization. Experience with AWS or Azure AI services, such as AWS Lex, AWS Lambda, Azure Cognitive Services, and Azure Bot Services (AWS expertise is preferred but Azure experience is also acceptable). Experience building and deploying conversational bots and IVR systems using AWS Lex or Azure Bot Services. Strong understanding of serverless architectures and cloud-native technologies such as AWS Lambda or Azure Functions. Experience with RESTful or GraphQL API design for seamless integration of AI models into business processes. DevOps background, with hands-on experience in CI/CD pipelines, containerization, and cloud deployment practices using AWS DevOps tools or Azure DevOps. Collaborative mindset with the ability to work cross-functionally with DevOps, integration, and automation teams to drive project success. Desired Skills And Qualifications Familiarity with machine learning frameworks (e.g., TensorFlow, PyTorch, Scikit-learn) and the ability to develop and fine-tune AI models. Knowledge of Agile methodologies for project management and team collaboration. Strong problem-solving skills, with the ability to troubleshoot and optimize AI models and cloud integrations. Certifications in AWS AI, Azure AI, or related AI/ML technologies are a plus. Experience Requirements A minimum of 2 years of experience in AI/ML, with expertise in Python, AI model development, and cloud-native AI services (AWS or Azure). Proven ability to design and deploy AI solutions using LLMs, serverless architectures, and cloud-based AI services. Education Requirements Bachelor’s degree in Computer Science, Engineering, Information Technology, or a related field. Relevant AI/ML certifications (e.g., AWS Certified Machine Learning, Azure AI Fundamentals) are a plus. Work Environment Collaborative and dynamic team environment with an opportunity to work on cutting-edge AI/ML projects. Hybrid working model with a base in Bangalore, offering flexibility in working from the office and remotely. Cross-functional collaboration with DevOps, automation, and integration teams.",Associate,,"Python, Machine Learning",
4248382427,mokSa.ai - Computer Vision Engineer - Deep Learning,mokSa.ai,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Job Description We are seeking a talented Computer Vision Engineer with strong expertise in microservice deployment architecture to join our team. In this role, you will be responsible for developing and deploying computer vision models to analyze retail surveillance footage for use cases such as theft detection, employee efficiency monitoring, and store traffic analysis. Responsibilities You will work on designing and implementing scalable, cloud-based microservices to deliver real-time and post-event analytics to improve retail Responsibilities : Develop computer vision models : Build, train, and optimize deep learning models to analyze surveillance footage for detecting theft, monitoring employee productivity, tracking store busy hours, and other relevant use cases. Microservice architecture : Design and deploy scalable microservice-based solutions that allow seamless integration of computer vision models into cloud or on-premise environments. Data processing pipelines : Develop data pipelines to process real-time and batch video data streams, ensuring efficient extraction, transformation, and loading (ETL) of video data. Integrate with existing systems : Collaborate with backend and frontend engineers to integrate computer vision services with existing retail systems such as POS, inventory management, and employee scheduling. Performance optimization : Fine-tune models for high accuracy and real-time inference on edge devices or cloud infrastructure, optimizing for latency, power consumption, and resource constraints. Monitor and improve : Continuously monitor model performance in production environments, identify potential issues, and implement improvements to accuracy and efficiency. Security and privacy : Ensure compliance with industry standards for security and data privacy, particularly regarding the handling of video footage and sensitive : 5+ years of proven experience in computer vision, including object detection, action recognition, and multi-object tracking, preferably in retail or surveillance applications. Hands-on experience with microservices deployment on cloud platforms (e.g., AWS, GCP, Azure) using Docker, Kubernetes, or similar technologies. Experience with real-time video analytics, including working with large-scale video data and camera Skills : Proficiency in programming languages like Python, C++, or Java. Expertise in deep learning frameworks (e.g., TensorFlow, PyTorch, Keras) for developing computer vision models. Strong understanding of microservice architecture, REST APIs, and serverless computing. Knowledge of database systems (SQL, NoSQL), message queues (Kafka, RabbitMQ), and container orchestration (Kubernetes). Familiarity with edge computing and hardware acceleration (e.g., GPUs, TPUs) for running inference on embedded Qualifications : Experience with deploying models to edge devices (NVIDIA Jetson, Coral, etc.) Understanding of retail operations and common challenges in surveillance. Knowledge of data privacy regulations such as GDPR or Skills : Strong analytical and problem-solving skills. Ability to work independently and in cross-functional teams. Excellent communication skills to convey technical concepts to non-technical : Competitive salary and stock options. Health insurance. If you're passionate about creating cutting-edge computer vision solutions and deploying them at scale to transform retail operations, wed love to hear from you! Apply Now. (ref:hirist.tech)",,,"Python, SQL",
4259077273,Senior Autosar Comm stack developer,Amrapali Services,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Skills Required: ? Bachelor's or Master’s degree in electronics or similar ? Proficient in configuration and Integration of AUTOSAR Communication Stack. ? Experience in configuration and Integration of AUTOSAR Diagnostics Stack would be add on ? Proficient in Automotive Embedded Software development using Embedded C programming. ? Experience in working in Application SWCs for CAN message/signal handling, AUTOSAR Application SW integration processes and RTE generation. ? Experience in working with AUTOSAR Base software development and Configuration would be add on. ? Experience with ISO-14229 UDS protocol or KWP protocols & Diagnostics Service Implementation and Boot-loader Development. ? Experience in working with CAN, Flexray, LIN, SENT, SPI Bus-Systems. ? Experience in the following areas: static analysis tools (such as QA_C, Polyspace), MISRA and generally accepted embedded coding practices. ? Good knowledge with Debugger tools (TRACE-32, UDE). ? Good knowledge with Vector tools (CANalyzer, CANoe & CANape). ? Knowledge of requirement management tools (DOORS). ? Knowledge of SW Design using UML. ? Knowledge of configuration management tools: MKS/PTC. ? Knowledge of V cycle development and review methods ? Good to have experience with SW development process following (Automotive) SPICE ? Experience with standards related to safety like ISO26262, IEC61508, etc. is prefered Mandatory Skills:- At least 5+ years of experience in AUTOSAR Communication Stack development within the automotive domain Proven expertise in embedded software development using Embedded C A minimum of a Bachelor's degree is required If you meet the requirements outlined in the job description and are interested in this opportunity, please email your resume to admin@amrapaliservices.in, mentioning your current CTC, expected CTC, and Notice Period.",,,,
4247962338,AI / ML Engineer,Accenture in India,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Large Language Models Good to have skills : NA Minimum 7.5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: As an AI / ML Engineer, you will engage in the development of applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve designing and implementing production-ready solutions, ensuring that they meet quality standards. You will work with various AI models, including generative AI, deep learning, and neural networks, while also exploring innovative applications such as chatbots and image processing. Collaboration with cross-functional teams will be essential to integrate these advanced technologies into effective solutions that address real-world challenges. Roles & Responsibilities: - Expected to be an SME. - Collaborate and manage the team to perform. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Provide solutions to problems for their immediate team and across multiple teams. - Mentor junior team members to enhance their skills and knowledge. - Continuously evaluate and improve existing processes and systems to optimize performance. Professional & Technical Skills: - Must To Have Skills: Proficiency in Large Language Models. - Good To Have Skills: Experience with cloud-based AI services. - Strong understanding of deep learning frameworks such as TensorFlow or PyTorch. - Familiarity with natural language processing techniques and tools. - Experience in developing and deploying chatbots and conversational agents. Additional Information: - The candidate should have minimum 7.5 years of experience in Large Language Models. - This position is based at our Bengaluru office. - A 15 years full time education is required. 15 years full time education",,,,
4254846596,Generative AI Engineer,Infogain,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Job Summary We are seeking a highly skilled and self-motivated AI Engineer to join us as we establish our AI Center of Excellence (CoE). As an early team member, you will play a critical role in shaping the foundation, strategy, and implementation of AI and ML solutions across the organization. This role offers a unique opportunity to work at the forefront of AI innovation, contribute to impactful use cases, and collaborate with cross-functional teams to build intelligent agentic systems. You will work with both Microsoft technologies (Copilot Studio, AI Foundry, Azure OpenAI) and open-source frameworks to design, deploy, and manage enterprise-ready AI solutions. Key Responsibilities a. Design, develop, and deploy AI agents using Microsoft Copilot Studio and AI Foundry. b. Build and fine-tune machine learning models for NLP, prediction, classification, and recommendation tasks. c. Conduct exploratory data analysis (EDA) to extract insights and support model development. d. Implement and manage LLM workflows, including prompt engineering, fine-tuning, evaluation, deployment, and monitoring. e. Utilize open-source frameworks such as LangChain, Hugging Face, MLflow, and RAG pipelines to build scalable, modular AI solutions. f. Integrate AI solutions with business workflows using APIs and cloud-native deployment methods. g. Use Azure AI services, including AI Foundry and Azure OpenAI, for secure and scalable model operations. h. Contribute to the creation of an AI governance framework, including Responsible AI principles, model explainability, fairness, and accountability. i. Support the creation of standards, reusable assets, and documentation as the CoE grows. j. Collaborate with engineering, data, and business teams to define problems, build solutions, and demonstrate value. k. Stay up to date with emerging AI capabilities such as Model Context Protocol (MCP), Agent-to-Agent (A2A) frameworks, and Agent Communication Protocols (ACP), and proactively evaluate opportunities to integrate them into enterprise solutions. Required Qualifications · Bachelor's or master's degree in computer science, Data Science, Engineering, or a related field. · 5+ years of experience in AI, machine learning, or data science with production-level deployments. · Strong foundation in statistics, ML algorithms, and data analysis techniques. · Hands-on experience building with LLMs, GenAI platforms, and AI copilots. · Proficient in Python, with experience using libraries such as Pandas, Scikit-learn, PyTorch, TensorFlow, and Transformers. · Experience with Microsoft Copilot Studio, AI Foundry, and Azure OpenAI. · Working knowledge of open-source GenAI tools (LangChain, Haystack, MLflow). · Understanding of cloud deployment, API integration, and version control (Git).",Executive,,"Python, Machine Learning, Data Analysis",
4245530174,AI Fullstack Engineer,Uplers,"Raipur, Chhattisgarh, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - HurixDigital) What do you need for this opportunity? Must have skills required: Python, LLM, Rag (retrieval-augmented generation), AWS HurixDigital is Looking for: Job Summary We are seeking a highly skilled and innovative AI Engineer with Full Stack capabilities to join our dynamic team. The ideal candidate will bring a strong blend of expertise in artificial intelligence, modern software engineering practices, and cloud infrastructure. You will be responsible for designing, developing, and deploying intelligent applications that are scalable, resilient, and deliver real business value. Key Responsibilities Develop and deploy end-to-end AI-powered applications leveraging full-stack development best practices. Architect and integrate AI/ML models and pipelines using tools like LangChain, Hugging Face, OpenAI, and Anthropic Claude APIs. Design and implement microservices, RESTful APIs, and backend systems with scalability and maintainability in mind. Leverage cloud platforms (AWS, Azure, GCP) for hosting, automation, and scaling services. Integrate CI/CD pipelines to ensure smooth and frequent deployment cycles. Collaborate with cross-functional teams to translate business requirements into technical solutions. Apply techniques such as content chunking, vector search, embedding models, and retrievers to build advanced AI retrieval systems. Ensure robust architecture that can withstand variable load conditions, focusing on fault tolerance and high availability. Maintain documentation and adhere to best practices in software development and AI model integration. Required Qualifications Bachelor's or Master's degree in Computer Science, Engineering, or a related field. 5+ years of hands-on experience in AI engineering and full-stack development. Strong proficiency with AI/ML tools including LangChain, Hugging Face, OpenAI, and Claude APIs. Deep understanding of vector databases, retrievers, and modern NLP workflows. Proficient in one or more full-stack frameworks (e.g., Node.js, Django, React, Angular). Experience with Python Experience with cloud platforms (AWS, Azure, GCP) and infrastructure automation tools (e.g., Terraform, CloudFormation). Solid experience with CI/CD pipelines, GitOps, and container orchestration (e.g., Docker, Kubernetes). Proven ability to architect resilient systems and optimize performance under fluctuating workloads. Preferred Skills Knowledge of prompt engineering and LLM fine-tuning techniques. Familiarity with DevSecOps practices and AI compliance requirements. Exposure to multimodal models and real-time inference systems. What We Offer Opportunity to work on cutting-edge AI products and tools. Collaborative and inclusive team environment. Flexible work schedule and remote work options. Competitive salary and performance bonuses. How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Python, LLM, Rag (retrieval-augmented generation), AWS",,,Python,
4256418559,Python Ai ml faculty,TechnoScripts Embedded,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Role Description This is a full-time on-site role for a Python AI ML Faculty at Technoscripts Embedded located in Pune. The Faculty will be responsible for teaching advanced courses in Python, AI, and Machine Learning, as well as guiding students through hands-on projects and practical applications of the technologies. Qualifications Proficiency in Python programming Knowledge of Artificial Intelligence and Machine Learning concepts Experience in teaching or training in the field of AI and ML Strong communication and presentation skills Ability to work with students of varying skill levels Experience in developing curriculum or course materials Master's degree in Computer Science, AI, ML, or related field",,,"Python, Machine Learning",
4252296571,Python with ML/AI - Digital Engineering Lead Engineer,NTT DATA North America,India (Remote),Remote,Full-time,,"About the job Req ID: 309479 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a Python with ML/AI - Digital Engineering Lead Engineer to join our team in Remote, Karnātaka (IN-KA), India (IN). GenAI- Review and optimization of LLMs output, Learn the AI Models, RAG based model Learning Job Description Machine Learning LLM Python Responsibilities: Architecting, designing, and developing (along with counterparts and distinguished Architects) solutions for new and existing problems in the supply chain space. Work closely with a team of data scientists and collaborate with stakeholders from application teams to research solutions, identify go-forward approaches, develop POCs, and determine final solutions. Requirements: Bachelor's degree (STEM preferred) and minimum 3-6 years of experience in Software development; ideally a candidate that has started as a Software Engineer and has been working in the data science, AI/ML space for at least 3-6 years. Demonstrated ability to identify and design solutions using AI/ML. Hands-on development skills along with architecture/design experience; should not have moved away from software development. Experience with API management platforms and providing/consuming RESTful APIs. About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,"Python, R, Machine Learning",
4230192256,Amplelogic - Developer - Artificial Intelligence/Machine Learning,AmpleLogic,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Responsibilities Build, train, and fine-tune machine learning models for a variety of applications, including but not limited to Natural Language Processing (NLP), Computer Vision, and predictive modeling. Design and implement intelligent and scalable data and model pipelines to ensure AI solutions are effectively deployed and utilized in production environments. Collaborate closely with data scientists, engineers, product managers, and other stakeholders to translate business requirements into tangible AI solutions. Embrace and implement MLOps best practices, utilizing tools such as MLflow, Docker, and Kubernetes to streamline the development, deployment, and monitoring of machine learning models. Stay at the forefront of AI/ML advancements, actively explore new techniques and technologies, and share your knowledge and insights with the team. A mentorship mindset is highly valued. Champion clean code principles, contribute to the improvement of our development processes, and foster a future-focused engineering culture. Required Skills Experience : 3-4 years of hands-on experience in hardcore AI/ML or applied data science. Programming : Pro-level proficiency in Python. ML Frameworks : Mastery of core machine learning frameworks, including scikit-learn, XGBoost, LightGBM, TensorFlow/Keras, and PyTorch. Data Handling : Proven experience in real-world data wrangling, feature engineering, and model deployment. DevOps : Solid understanding of DevOps principles and tools, including Docker, REST APIs, and Git. Familiarity with MLOps practices is a plus. Cloud Computing : Practical experience with at least one major cloud platform : AWS, GCP, or Azure. Software Development : Solid grasp of Agile development methodologies, strong debugging skills, and a proactive approach to performance optimization. (ref:hirist.tech)",manager,,"Python, Machine Learning",
4259099142,iOS Developer,Appzlogic,"Gurgaon, Haryana, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More We are seeking an experienced iOS Developer with strong expertise in SwiftUI to join our mobile development team. The ideal candidate will have a solid background in iOS app development, with a deep understanding of SwiftUI, iOS SDKs, and Apple's Human Interface Guidelines. Responsibilities Design and develop advanced applications for the iOS platform using Swift and SwiftUI. Collaborate with cross-functional teams to define, design, and ship new features. Ensure the performance, quality, and responsiveness of applications. Identify and correct bottlenecks and fix bugs. Continuously discover, evaluate, and implement new technologies to maximize development efficiency. Maintain code quality, organization, and automation. Write clean, maintainable, and scalable code following best practices. Requirements 5+ years of hands-on experience in iOS application development. Strong command of Swift and SwiftUI (minimum 2 years in SwiftUI). Experience with UIKit, Combine, CoreData, and MVVM architecture. Proficient in RESTful API integration, JSON parsing, and data storage solutions. Familiar with Xcode, TestFlight, and App Store deployment. Good understanding of Apple Human Interface Guidelines. Experience with version control systems like Git. Strong problem-solving and debugging skills. Knowledge of CI/CD tools and practices is a plus. Strong hands-on experience in Swift and SwiftUI. Familiar with iOS frameworks and modern architectural patterns. Ability to build responsive and adaptive UIs. This job was posted by Isha Mahajan from Appzlogic Mobility Solutions. Desired Skills and Experience iOS",,,,
4259093690,Android Developer,Powerplay,"Bengaluru, Karnataka, India (On-site)",On-site,Internship,,"About the job This job is sourced from a job board. Learn More Responsibilities Developing new user-facing features using XML and Kotlin. Building reusable components and maintaining modularity for future use. Translating designs and wireframes into high-quality code. Optimizing components to avoid memory leaks and improve rendering time. Ensuring availability across with range of devices and Android versions. Maintaining quality and ensuring the responsiveness of applications. Design-driven development. Requirements Language - Kotlin and XML. MVP/MVVM design pattern, Repository, and Factory design patterns. Familiarity with Retrofit and RESTful APIs. Knowledge of maintaining a local database - Room. UI Elements: Coordinator Layout, Constraint Layout, Chips, RecyclerView, etc. Know-how of Unit testing and kt-linter. Version control, CI/CD, and writing clean code. This job was posted by Swathi Prakash from Powerplay. Desired Skills and Experience Android",manager,,,
4259079739,Application Engineer C++,Concentrix Limited Company,"Bengaluru, Karnataka, India (Remote)",Remote,Full-time,,"About the job Apply Now Job Title Application Engineer C++ Job Description We're Concentrix. The intelligent transformation partner. Solution-focused. Tech-powered. Intelligence-fueled. The global technology and services leader that powers the world’s best brands, today and into the future. We’re solution-focused, tech-powered, intelligence-fueled. With unique data and insights, deep industry expertise, and advanced technology solutions, we’re the intelligent transformation partner that powers a world that works, helping companies become refreshingly simple to work, interact, and transact with. We shape new game-changing careers in over 70 countries, attracting the best talent. The Concentrix Technical Products and Services team is the driving force behind Concentrix’s transformation, data, and technology services. We integrate world-class digital engineering, creativity, and a deep understanding of human behavior to find and unlock value through tech-powered and intelligence-fueled experiences. We combine human-centered design, powerful data, and strong tech to accelerate transformation at scale. You will be surrounded by the best in the world providing market leading technology and insights to modernize and simplify the customer experience. Within our professional services team, you will deliver strategic consulting, design, advisory services, market research, and contact center analytics that deliver insights to improve outcomes and value for our clients. Hence achieving our vision. Our game-changers around the world have devoted their careers to ensuring every relationship is exceptional. And we’re proud to be recognized with awards such as ""World's Best Workplaces,"" “Best Companies for Career Growth,” and “Best Company Culture,” year after year. Join us and be part of this journey towards greater opportunities and brighter futures. This position requires the following technical skills: Essential Tertiary qualification in Computer Science, Software Development, or Engineering Proficient in C++ 5+ years of development and/or testing experience – developing code using C++ Experience with Version Control Systems (Git) Technical skills including high level understanding of software development, network systems, software test Problem investigation and resolution experience in a software environment Desirable Payments and/or Retail Petroleum industry experience Embedded Linux x86 / ARM C, Java, Assembler, Python, Bash scripting Ability to promote a test-driven development approach Experience using embedded tools; compilers, debuggers, JTAG, protocol analysers, RTOS or OSes No need to target Assembler skills for the Application Engineer, good C++ & Linux Application development skillsets are important but experience in the payment domain is an truly an advantage some of payment domain experience/expertise would be - understanding of ISO8583 type messaging, payment transaction types, payment software development exposure, EMV understanding, Payments security and certification etc. Location: IND Work-at-Home Language Requirements Time Type: Full time If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents Apply Now",,,Python,
4252376884,AI/ML Developer Associate - Operate,PwC Acceleration Centers in India,"Bengaluru, Karnataka, India",,Full-time,,"About the job At PwC, our people in data and analytics engineering focus on leveraging advanced technologies and techniques to design and develop robust data solutions for clients. They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth. Those in artificial intelligence and machine learning at PwC will focus on developing and implementing advanced AI and ML solutions to drive innovation and enhance business processes. Your work will involve designing and optimising algorithms, models, and systems to enable intelligent decision-making and automation. Driven by curiosity, you are a reliable, contributing member of a team. In our fast-paced environment, you are expected to adapt to working with a variety of clients and team members, each presenting varying challenges and scope. Every experience is an opportunity to learn and grow. You are expected to take ownership and consistently deliver quality work that drives value for our clients and success as a team. As you navigate through the Firm, you build a brand for yourself, opening doors to more opportunities. Skills Examples of the skills, knowledge, and experiences you need to lead and deliver value at this level include but are not limited to: Apply a learning mindset and take ownership for your own development. Appreciate diverse perspectives, needs, and feelings of others. Adopt habits to sustain high performance and develop your potential. Actively listen, ask questions to check understanding, and clearly express ideas. Seek, reflect, act on, and give feedback. Gather information from a range of sources to analyse facts and discern patterns. Commit to understanding how the business works and building commercial awareness. Learn and apply professional and technical standards (e.g. refer to specific PwC tax and audit guidance), uphold the Firm's code of conduct and independence requirements. Job Title: AI/ML Associate Location : Bangalore (Hybrid) Department : Managed Services – Core Automation Team Job Overview We are seeking an experienced AI/ML Senior Associate to join our team focused on leveraging AI technologies to enhance operational efficiency in SAP managed services. The ideal candidate will have strong programming expertise in Python and hands-on experience in building AI solutions using market-leading large language models (LLMs) , as well as native cloud services (primarily AWS or Azure AI services ). Your role will center on developing intelligent solutions that automate processes, integrate AI models, and improve overall system performance within SAP environments. Key Responsibilities Design and implement AI solutions using Python and market-leading LLMs to drive automation and improve operational efficiency within SAP-managed services. Develop and integrate AI-powered applications using native AWS services (e.g., AWS Lex, AWS Lambda, Amazon Polly) or Azure AI services, focusing on process optimization and automation. Build and deploy conversational bots and AI-powered tools to support business processes in SAP environments, integrating AWS Lex, AWS Connect, or Azure Bot Services with existing systems. Leverage Python programming for building, testing, and deploying AI models, APIs, and automation workflows to enhance SAP system reliability and performance. Collaborate with cross-functional teams to integrate AI solutions with DevOps pipelines and ensure smooth deployments using CI/CD tools and cloud-native infrastructure. Design and manage serverless applications using AWS Lambda or Azure Functions to handle AI/ML workloads with scalability and high performance. Work with RESTful or GraphQL APIs to enable AI services, ensuring high standards for performance, security, and seamless integration with SAP systems. Contribute to the development of AI models, focusing on using LLMs for natural language understanding, predictive analytics, and automated decision-making. Collaborate with DevOps and integration teams to integrate AI solutions into SAP processes, ensuring end-to-end service excellence and operational success. Required Skills And Qualifications Minimum 2 years of experience in AI/ML development, focusing on Python programming and AI model development. Proven experience with Python for building AI solutions, API development, and automation. Hands-on experience with market-leading LLMs (e.g., OpenAI GPT, Google BERT, or similar) and applying these models in business process automation and optimization. Experience with AWS or Azure AI services, such as AWS Lex, AWS Lambda, Azure Cognitive Services, and Azure Bot Services (AWS expertise is preferred but Azure experience is also acceptable). Experience building and deploying conversational bots and IVR systems using AWS Lex or Azure Bot Services. Strong understanding of serverless architectures and cloud-native technologies such as AWS Lambda or Azure Functions. Experience with RESTful or GraphQL API design for seamless integration of AI models into business processes. DevOps background, with hands-on experience in CI/CD pipelines, containerization, and cloud deployment practices using AWS DevOps tools or Azure DevOps. Collaborative mindset with the ability to work cross-functionally with DevOps, integration, and automation teams to drive project success. Desired Skills And Qualifications Familiarity with machine learning frameworks (e.g., TensorFlow, PyTorch, Scikit-learn) and the ability to develop and fine-tune AI models. Knowledge of Agile methodologies for project management and team collaboration. Strong problem-solving skills, with the ability to troubleshoot and optimize AI models and cloud integrations. Certifications in AWS AI, Azure AI, or related AI/ML technologies are a plus. Experience Requirements A minimum of 2 years of experience in AI/ML, with expertise in Python, AI model development, and cloud-native AI services (AWS or Azure). Proven ability to design and deploy AI solutions using LLMs, serverless architectures, and cloud-based AI services. Education Requirements Bachelor’s degree in Computer Science, Engineering, Information Technology, or a related field. Relevant AI/ML certifications (e.g., AWS Certified Machine Learning, Azure AI Fundamentals) are a plus. Work Environment Collaborative and dynamic team environment with an opportunity to work on cutting-edge AI/ML projects. Hybrid working model with a base in Bangalore, offering flexibility in working from the office and remotely. Cross-functional collaboration with DevOps, automation, and integration teams.",Associate,,"Python, Machine Learning",
4256413989,Junior Frontend Developer,Lead India,India (Remote),Remote,Full-time,,"About the job Position: Frontend Developer Intern (Full-Time) Company: Lead India Location: Remote Stipend: ₹25,000/month Duration: 1–3 months (Full-Time Internship) About Lead India: Lead India is a technology-driven organization focused on delivering seamless, responsive, and scalable digital solutions. We are committed to developing fresh talent through real-world projects, mentorship, and hands-on training in a remote-friendly environment. Role Overview: We are looking for a Frontend Developer Intern to assist in building and enhancing web applications with responsive design and intuitive user interfaces. This role is perfect for someone passionate about user experience, design, and frontend technologies. Key Responsibilities: Develop and maintain frontend components using HTML, CSS, and JavaScript Build responsive and mobile-friendly web interfaces Integrate frontend code with backend APIs Collaborate with UI/UX designers and developers to improve user experience Debug and optimize code for performance and cross-browser compatibility Contribute to design discussions and implement visual enhancements Skills We're Looking For: Strong foundation in HTML5, CSS3, and JavaScript Familiarity with frontend libraries or frameworks (e.g., React, Vue, or Angular is a plus) Understanding of responsive design and cross-browser compatibility Ability to work with design tools (like Figma or Adobe XD) Good communication skills and a collaborative attitude Eagerness to learn and grow in a fast-paced environment What You’ll Gain: ₹25,000/month stipend Experience working on live frontend projects Mentorship from experienced frontend and full-stack developers Fully remote, flexible work setup Opportunity for a Pre-Placement Offer (PPO) based on performance",,,,
4259207291,Java Backend developer || 1-4 Yrs || Chennai,Capgemini,"Chennai, Tamil Nadu, India",,Full-time,,"About the job At Capgemini Engineering, the world leader in engineering services, we bring together a global team of engineers, scientists, and architects to help the world’s most innovative companies unleash their potential. From autonomous cars to life-saving robots, our digital and software technology experts think outside the box as they provide unique R&D and engineering services across all industries. Join us for a career full of opportunities. Where you can make a difference. Where no two days are the same. Job Description Job Description: Good knowledge in Java 1.8, Reactive Technology is must: Spring 5/ Spring Boot Experience in Microservices Architecture (REST services) is mandatory Knowledge in any of the database Oracle/ No SQL/ Maria DB / My SQL Understanding of design patterns Exposure to tools - Bit bucket, GIT, Maven, Jira, Intellij, Eclise Familiarity with Agile methods and Continuous Integration including but not limited to Program and Release Backlog Management (Jira), Defect Tracking (Jira), Collaboration (Confluence, Jive, others) Code Review tools (Sonar, Findbugs) Experience in Swagger classes Experience in Authorization and Authentication modules Experience in JPA and Spring Security Experience in RabbitMQ Job Description - Grade Specific Focus on Industrial Operations Engineering. Develops competency in own area of expertise. Shares expertise and provides guidance and support to others. Interprets clients needs. Completes own role independently or with minimum supervision. Identifies problems and relevant issues in straight forward situations and generates solutions. Contributes in teamwork and interacts with customers. Skills (competencies) Capgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, generative AI, cloud and data, combined with its deep industry expertise and partner ecosystem.",,,"SQL, R",
4255533152,Machine Learning Engineer II (Big-Data Heavy),Expedia Group,"Gurgaon, Haryana, India (On-site)",On-site,Full-time,,"About the job Expedia Group brands power global travel for everyone, everywhere. We design cutting-edge tech to make travel smoother and more memorable, and we create groundbreaking solutions for our partners. Our diverse, vibrant, and welcoming community is essential in driving our success. Why Join Us? To shape the future of travel, people must come first. Guided by our Values and Leadership Agreements, we foster an open culture where everyone belongs, differences are celebrated and know that when one of us wins, we all win. We provide a full benefits package, including exciting travel perks, generous time-off, parental leave, a flexible work model (with some pretty cool offices), and career development resources, all to fuel our employees' passion for travel and ensure a rewarding career journey. We’re building a more open world. Join us. Machine Learning Engineer II (Big-Data Heavy) Are you fascinated by data and building robust data and machine learning pipelines which process massive amounts of data at scale and speed to provide crucial insights to the end customer? This is exactly what we, Data & AI ML organization in Expedia, do. Our team is looking for a Machine Learning Engineer to join our Machine Learning Engineering team in Gurgaon. Our team works very closely with Machine Learning Scientists in a fast-paced Agile environment to create and productionize algorithms that directly impacts the traveler journey and experience. We believe in being Different. We seek new ideas, different ways of thinking, diverse backgrounds and approaches, because averages can lie and sameness is dangerous. Expedia is committed to crafting an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, gender, sexual orientation, national origin, disability or age. Experience 4+ years for Bachelor's 2+ years for Master's What You'll Do Work in a cross-functional team of Machine Learning engineers and ML Scientists to design and code large scale batch and real-time data pipelines on the AWS. Prototype creative solutions quickly by developing minimum viable products and work with seniors and peers in crafting and implementing the technical vision of the team Communicate and work effectively with geographically distributed cross functional teams Participate in code reviews to assess overall code quality and flexibility Resolve problems and roadblocks as they occur with peers and help unblock junior members of the team. Follow through on details and drive issues to closure Define, develop and maintain artifacts like technical design or partner documentation Drive for continuous improvement in software and development process within an agile development team Participate in user story creation in collaboration with the team Support and troubleshoot data and/or system issues as needed Who You Are Degree in software engineering, computer science, informatics or a similar field. Developed software in a team environment of at least 5 engineers (agile, version control, etc.). Built and maintained a software project/product in production environments in public/hybrid cloud infrastructure. Comfortable programming in Python and Scala. Hands-on experience with OOAD, design patterns, SQL and NoSQL. Knowledgeable in big data technologies, in particular Spark, Hive, Hue, Qubole and Databricks. Experience in crafting real-time streaming applications, preferably in Spark streaming, and Kafka/KStreams. Must-have experience: solid experience working on Big Data, good understanding of ML pipelines and ML lifecycle, Batch processing and Inferencing applications, PySpark, SQL Experience of using cloud services (e.g. AWS). Experience with workflow orchestration tools (e.g. Airflow). Passionate about learning, especially in the areas of micro-services, system architecture, Data Science and Machine Learning. Experience working with Agile/Scrum methodologies. Good-to-have experience: in real-time / live processing and inferencing applications Accommodation requests If you need assistance with any part of the application or recruiting process due to a disability, or other physical or mental health conditions, please reach out to our Recruiting Accommodations Team through the Accommodation Request . We are proud to be named as a Best Place to Work on Glassdoor in 2024 and be recognized for award-winning culture by organizations like Forbes, TIME, Disability:IN, and others. Expedia Group's family of brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Vrbo®, trivago®, Orbitz®, Travelocity®, Hotwire®, Wotif®, ebookers®, CheapTickets®, Expedia Group™ Media Solutions, Expedia Local Expert®, CarRentals.com™, and Expedia Cruises™. © 2024 Expedia, Inc. All rights reserved. Trademarks and logos are the property of their respective owners. CST: 2029030-50 Employment opportunities and job offers at Expedia Group will always come from Expedia Group’s Talent Acquisition and hiring teams. Never provide sensitive, personal information to someone unless you’re confident who the recipient is. Expedia Group does not extend job offers via email or any other messaging tools to individuals with whom we have not made prior contact. Our email domain is @expediagroup.com. The official website to find and apply for job openings at Expedia Group is careers.expediagroup.com/jobs . Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, gender, sexual orientation, national origin, disability or age.",,,"Python, SQL, Machine Learning",
4240769189,Artificial Intelligence Engineer,Quantanite,"Thane, Maharashtra, India (Hybrid)",Hybrid,Full-time,,"About the job About the Company Implement Architecture and design from definition phase to go-live phase. About the Role Work with the business analyst and SMEs to understand the current landscape priorities. Define conceptual and low-level model of using AI technology. Review design to make sure design is aligned with Architecture. Handson development of AI lead solution. Implement entire data pipeline of data crawling, ETL, creating Fact Tables, Data quality management etc. Integrate with multiple system using API or Web Services or data exchange mechanism. Build interfaces that gather data from various data sources such as: flat files, data extracts & incoming feeds from various data sources as well as directly interfacing with enterprise applications. Ensure that the solution is scalable, maintainable, and meet the best practices for security, performance and data management. Owning research assignments and development. Leading, developing and assisting developers & other team members. Collaborate, validate, and provide frequent updates to internal stakeholders throughout the project. Define and deliver against the solution benefits statement. Positively and constructively engage with clients and operations teams’ efforts where required. Responsibilities Implement Architecture and design from definition phase to go-live phase. Work with the business analyst and SMEs to understand the current landscape priorities. Define conceptual and low-level model of using AI technology. Review design to make sure design is aligned with Architecture. Handson development of AI lead solution. Implement entire data pipeline of data crawling, ETL, creating Fact Tables, Data quality management etc. Integrate with multiple system using API or Web Services or data exchange mechanism. Build interfaces that gather data from various data sources such as: flat files, data extracts & incoming feeds from various data sources as well as directly interfacing with enterprise applications. Ensure that the solution is scalable, maintainable, and meet the best practices for security, performance and data management. Owning research assignments and development. Leading, developing and assisting developers & other team members. Collaborate, validate, and provide frequent updates to internal stakeholders throughout the project. Define and deliver against the solution benefits statement. Positively and constructively engage with clients and operations teams’ efforts where required. Qualifications A Bachelor's degree in Computer Science, Software Engineering, or a related field Required Skills Minimum 5 years of IT experience including 3+ years of experience as Full stack developer preferably using Python skills 2+ years of hands-on experience in Azure Data factory, Azure Databricks / Spark (familiarity with fabric), Azure Data Lake storage (Gen1/Gen2), Azure Synapse/SQL DW Expertise in designing/deploying data pipeline, from data crawling, ETL, Data warehousing, data applications on Azure Experienced in AI technology including: Machine Learning algorithms, Natural Language Processing, Deep Learning, Image Recognition, Speech Recognition etc. Proficient in programming languages like Python (Full Stack exposure) Proficient in dealing with all the layers in solution; multi-channel presentation, business logic in middleware, data access layer, RDBMS | NO-SQL; E.g. MySQL, MongoDB, Cassendra, SQL Server DBs Familiar with Vector DB such as: FAISS, CromaDB, PineCone, Weaveate, Feature Store Experience in implementing and deploying applications on Azure Proficient in creating technical documents like Architecture views, Technology Architecture blueprint and design specification Experienced in using tools like Rational suite, Enterprise Architect, Eclipse, and Source code versioning systems like Git Experience with different development methodologies (RUP | Scrum | XP) Preferred Skills None specified Pay range and compensation package None specified Equal Opportunity Statement Include a statement on commitment to diversity and inclusivity.",,,"Python, SQL, Machine Learning",
4240759830,Computer Scientist 1,Adobe,"Noida, Uttar Pradesh, India",,Full-time,,"About the job Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! Adobe is in search of an experienced engineer to join the Fulfillment Center Service team. We’re seeking candidates to help us design, construct, and operate high traffic, critically important back end services. You will design and own critical parts of the services and deliver to production. We are looking for a passionate engineer with high potential, eager to learn new technologies and to help us design, construct, and operate our service at scale. What You Will Do What you need to succeed Responsible for multiple phases of engineering - from early specs, design/architecture, development, unit-testing/integration automation, and deployment. Collaborate with architects, product management and other engineering teams to build the technical vision and road map for the team. Build technical specifications, prototypes and presentations to communicate your ideas. Be proficient in emerging industry technologies and trends, and have the ability to communicate that knowledge to the team and use it to influence product direction. Apply innovation and creativity to solve engineering and coding problems using new and emerging tech like GenAI. B.Tech / M.Tech in Computer Science & Engineering or a related field. 4-6 years of experience in software development and automation. Skilled and experienced in Java with the ability to produce clean, performant and maintainable Object oriented code. Strong computer science fundamentals, OOPS, Data Structures, Algorithms and performance optimization. Excellent understanding of the SDLC, Agile Development, Microservice design, CI/CD processes etc. Knowledge of Azure, AWS, JavaScript and familiarity with RESTful APIs, Docker, Jenkins, Splunk, Git etc. Knowledge of GenAI tools and technology would be a bonus. Should be able to quickly adapt to new programming paradigms, languages, tools, and problem areas. Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more about our vision here. Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.",,,,
4251939611,Data Engineer-Data Modeling,IBM,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology. Your Role And Responsibilities As an Data Engineer at IBM you will harness the power of data to unveil captivating stories and intricate patterns. You'll contribute to data gathering, storage, and both batch and real-time processing. Collaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis. As a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets. In this role, your responsibilities may include: Implementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques Designing and implementing various enterprise search applications such as Elasticsearch and Splunk for client requirements Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviours. Build teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modelling results Preferred Education Master's Degree Required Technical And Professional Expertise 4+ years of experience in data modelling, data architecture. Proficiency in data modelling tools ERwin, IBM Infosphere Data Architect and database management systems Familiarity with different data models like relational, dimensional and NoSQl databases. Understanding of business processes and how data supports business decision making. Strong understanding of database design principles, data warehousing concepts, and data governance practices Preferred Technical And Professional Experience Excellent analytical and problem-solving skills with a keen attention to detail. Ability to work collaboratively in a team environment and manage multiple projects simultaneously. Knowledge of programming languages such as SQL",,,"SQL, Machine Learning",
4251661754,AI/ML engineer,Chubb,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Purpose of Role Chubb is seeking a highly skilled and experienced Deep Learning Engineer with Generative AI experience to develop and scale our Generative AI capabilities. The ideal candidate will be responsible for designing, finetuning and training large language models and developing Generative AI systems that can create and improve conversational abilities and decision-making skills of our machines. Key Accountabilities & Responsibilities Develop and improve Generative AI systems to enable high quality decision making, to refine answers for queries, and to enhance automated communication capabilities. Own the entire process of data collection, training, and deploying machine learning models. Continuous research and implementation of cutting-edge techniques in deep learning, NLP and Generative AI to build state-of-the-art models. Work closely with Data Scientists and other Machine Learning Engineers to design and implement end-to-end solutions. Optimize and streamline deep learning training pipelines. Develop performance metrics to track the efficiency and accuracy of deep learning models. Skills & Experience Minimum of 4 years of industry experience in developing deep learning models with a focus on NLP and Generative AI. Expertise in deep learning frameworks such as Tensorflow, PyTorch and Keras. Experience working with cloud-based services such as Azure for training and deployment of deep learning models. Experience with Hugging Face's Transformer libraries. Expertise in developing and scaling Generative AI systems. Experience in large dataset processing, including pre-processing, cleaning and normalization. Proficient in programming languages such as Python ( preferred ) /R. Experience with natural language processing (NLP) techniques and libraries Excellent analytical and problem-solving skills.",executive,,"Python, R, Machine Learning",
4249499705,Lead AI Engineer,Veltris,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,"transformations. We are a Digital Product Engineering Services partner that delivers next-generation technology and industry solutions across the healthcare, technology, communications, manufacturing and financial sectors. Veltris enables clients to build, modernize, and monetize smarter products and platforms powered by Connected Industry AI solutions. Through an experience-centric approach, agile delivery, and differentiated talent, Veltris helps businesses optimize product development cycles, monetize platform investments, and drive transformative outcomes in niche micro industries. … show more Show more","About the job Relevant Experience: 7+ Years Work Location: Hyderabad Working Days: 5 Days Notice Period: Immediate or 15 Days Mandatory Skills • 4+ years of hand on work experience in writing code in Python • Experience in using various Python libraries like Pandas, NumPy • Experience in writing good quality code in Python and code refactoring techniques (e.g., IDE’s – PyCharm, Visual Studio Code; Libraries – Pylint, pycodestyle, pydocstyle, Black) • Strong experience on AI assisted coding experience. • AI assisted coding for existing IDE's like vscode. • Experimented multiple AI assisted tools and done research around it. • Deep understanding of data structures, algorithms, and excellent problem-solving skills • Experience in Python, Exploratory Data Analysis (EDA), Feature Engineering, Data Visualisation • Machine Learning libraries like Scikit-learn, XGBoost • Experience in CV, NLP or Time Series. • Experience in building models for ML tasks (Regression, Classification) • Should have Experience into LLM, LLM Fine Tuning, Chatbot, RAG Pipeline Chatbot, LLM Solution, Multi Modal LLM Solution, GPT, Prompt, Prompt Engineering, Tokens, Context Window, Attention Mechanism, Embeddings • Experience of model training and serving on any of the cloud environments (AWS, GCP, Azure) • Experience in distributed training of models on Nvidia GPU’s • Familiarity in Dockerizing the model and create model end points (Rest or gRPC) • Strong working knowledge of source code control tools such as Git, Bitbucket • Prior experience of designing, developing and maintaining Machine Learning solution through its Life Cycle is highly advantageous • Strong drive to learn and master new technologies and techniques • Strong communication and collaboration skills • Good attitude and self-motivated",,,"Python, Machine Learning, Data Analysis",
4247120739,ML Engineer 2,Groww,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job About Groww: We are a passionate group of people focused on making financial services accessible to every Indian through a multi-product platform. Each day, we help millions of customers take charge of their financial journey. Customer obsession is in our DNA. Every product, every design, every algorithm down to the tiniest detail is executed keeping the customers’ needs and convenience in mind. Our people are our greatest strength. Everyone at Groww is driven by ownership, customer-centricity, integrity and the passion to constantly challenge the status quo. Are you as passionate about defying conventions and creating something extraordinary as we are? Let’s chat. Our Vision Every individual deserves the knowledge, tools, and confidence to make informed financial decisions. At Groww, we are making sure every Indian feels empowered to do so through a cutting-edge multi-product platform offering a variety of financial services. Our long-term vision is to become the trusted financial partner for millions of Indians. Our Values Our culture enables us to be what we are — India’s fastest-growing financial services company. It fosters an environment where collaboration, transparency, and open communication take center-stage and hierarchies fade away. There is space for every individual to be themselves and feel motivated to bring their best to the table, as well as craft a promising career for themselves. The values that form our foundation are: Radical customer centricity Ownership-driven culture Keeping everything simple Long-term thinking Complete transparency Key Responsibilities: Design and implement scalable machine learning solutions aligned with product and business objectives Develop, test, and optimize ML models for deployment in production environments Contribute to the development of Generative AI features such as conversational interfaces and personalization modules Collaborate with product managers, data scientists, and engineers to integrate ML solutions into customer-facing products Monitor performance of deployed models and iterate to improve accuracy, latency, and user experience Follow best practices in model development, experimentation, and deployment Participate in code reviews, technical discussions, and architectural design sessions Translate business requirements into technical specifications in partnership with stakeholders Required Skills and Experience: 4–5 years of experience in applied machine learning and model deployment Hands-on experience with Generative AI, NLP, or conversational AI technologies Proficiency in Python and commonly used ML frameworks (e.g., PyTorch, TensorFlow, Hugging Face) Experience building and deploying models using cloud services (AWS, GCP, or Azure) Strong grasp of ML pipelines, feature engineering, and basic MLOps practices Ability to work collaboratively and communicate technical concepts clearly Experience contributing to production-level ML solutions that deliver measurable value Preferred Qualifications: Master’s degree in Computer Science, Machine Learning, or related discipline Exposure to fintech or financial services domain is a plus Familiarity with recommendation engines or personalization techniques Contributions to open-source ML projects or community",manager,,"Python, Machine Learning",
4244572321,ML / Data Science Engineer,Uplers,Pune/Pimpri-Chinchwad Area (On-site),On-site,Full-time,,"About the job Experience : 2.00 + years Salary : INR 1500000-2500000 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Office (Pune) Placement Type : Full Time Permanent position(Payroll and Compliance to be managed by: Anervea.AI) (*Note: This is a requirement for one of Uplers' client - Anervea.AI) What do you need for this opportunity? Must have skills required: Airflow, LLMs, NLP, Statistical Modeling, Predictive Analysis, Forecasting, Python, SQL, MLFlow, pandas, Scikit-learn, XgBoost Anervea.AI is Looking for: As an ML / Data Science Engineer at Anervea, you’ll work on designing, training, deploying, and maintaining machine learning models across multiple products. You’ll build models that predict clinical trial outcomes, extract insights from structured and unstructured healthcare data, and support real-time scoring for sales or market access use cases. You’ll collaborate closely with AI engineers, backend developers, and product owners to translate data into product features that are explainable, reliable, and impactful. Key Responsibilities Develop and optimize predictive models using algorithms such as XGBoost, Random Forest, Logistic Regression, and ensemble methods Engineer features from real-world healthcare data (clinical trials, treatment adoption, medical events, digital behavior) Analyze datasets from sources like ClinicalTrials.gov, PubMed, Komodo, Apollo.io, and internal survey pipelines Build end-to-end ML pipelines for inference and batch scoring Collaborate with AI engineers to integrate LLM-generated features with traditional models Ensure explainability and robustness of models using SHAP, LIME, or custom logic Validate models against real-world outcomes and client feedback Prepare clean, structured datasets using SQL and Pandas Communicate insights clearly to product, business, and domain teams Document all processes, assumptions, and model outputs thoroughly Technical Skills Required : Strong programming skills in Python (NumPy, Pandas, scikit-learn, XGBoost, LightGBM) Experience with statistical modeling and classification algorithms Solid understanding of feature engineering, model evaluation, and validation techniques Exposure to real-world healthcare, trial, or patient data (strong bonus) Comfortable working with unstructured data and data cleaning techniques Knowledge of SQL and NoSQL databases Familiarity with ML lifecycle tools (MLflow, Airflow, or similar) Bonus: experience working alongside LLMs or incorporating generative features into ML Bonus: knowledge of NLP preprocessing, embeddings, or vector similarity methods Personal Attributes : Strong analytical and problem-solving mindset Ability to convert abstract questions into measurable models Attention to detail and high standards for model quality Willingness to learn life sciences concepts relevant to each use case Clear communicator who can simplify complexity for product and business teams Independent learner who actively follows new trends in ML and data science Reliable, accountable, and driven by outcomes—not just code Bonus Qualities : Experience building models for healthcare, pharma, or biotech Published work or open-source contributions in data science Strong business intuition on how to turn models into product decisions Interview Process: 1 Technical round with Head of Engineering How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Airflow, LLMs, NLP, Statistical Modeling, Predictive Analysis, Forecasting, Python, SQL, MLFlow, pandas, Scikit-learn, XgBoost",,,"Python, SQL, Machine Learning",
4244538063,Artificial Intelligence Engineer,Uplers,"Gurugram, Haryana, India (Hybrid)",Hybrid,Full-time,,"About the job Computer Vision Engineer Experience: 3-5 Years Exp Salary: Competitive Preferred Notice Period: less than or equal to 30 days Shift: 10:00 AM to 6:00 PM IST Opportunity Type: Hybrid (Gurugram, Haryana) Placement Type: Full Time, Permanent (*Note: This is a requirement for one of Uplers' Clients) Must have skills required : Computer Vision , Camera Calibration, 3d vision Stupa Sports Analytics (One of Uplers' Clients) is Looking for: Computer Vision Engineer who is passionate about their work, eager to learn and grow, and who is committed to delivering exceptional results. If you are a team player, with a positive attitude and a desire to make a difference, then we want to hear from you. Role Overview Description About Stupa Sports Analytics Stupa is a global sports technology company, driven by our love for table tennis, badminton, padel and pickleball. Our core services include digitized event management systems for sport federations, performance analytics for athletes, OTT for fans and live streaming for betting and media houses. Through our AI enabled video solutions used by national federations and broadcasters, we enhance the viewing experience for fans across the world. About The Role: We are seeking an experienced Computer Vision Engineer to join our team and contribute to cutting-edge projects in 3D vision and reconstruction. The ideal candidate will have a strong background in camera calibration, stereo vision, multi-view geometry, and 3D reconstruction techniques. Key Responsibilities ● Develop and implement advanced computer vision algorithms for 3D reconstruction and analysis ● Design and optimize camera calibration procedures for various imaging systems ● Create robust stereo vision solutions for depth estimation and object localization ● Implement multi-view geometry techniques for scene understanding and 3D modeling ● Develop efficient triangulation methods for 3D point cloud generation ● Collaborate with cross-functional teams to integrate computer vision solutions into larger systems ● Stay current with the latest advancements in computer vision and contribute to research initiatives Required Qualifications- ● Bachelors in Computer Science, Computer Engineering, or a related field ● 3+ years of experience in computer vision, with a focus on 3D vision techniques ● Strong proficiency in camera calibration methods and tools ● Extensive experience with stereo vision algorithms and epipolar geometry ● In-depth knowledge of multi-view geometry and structure-from-motion techniques ● Proven track record in developing 3D reconstruction pipelines ● Expert-level programming skills in C++ and Python ● Experience with OpenCV, PCL, or similar computer vision libraries ● Familiarity with deep learning frameworks (e.g., TensorFlow, PyTorch) for vision tasks About Uplers: Our goal is to make hiring and getting hired reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant product and engineering job opportunities and progress in their career. (Note: There are many more opportunities apart from this on the portal.) So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",Executive,,Python,
4244461480,"Software Developer 2, Machine Learning",Kinaxis,"Chennai, Tamil Nadu, India (Hybrid)",Hybrid,Full-time,,"About the job About Kinaxis Elevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis. In 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers. Our journey in India began in 2020 and we have been growing steadily since then! Building a high-trust and high-performance culture is important to us and we are proud to be Great Place to Work® CertifiedTM. Our state-of-the-art office, located in the World Trade Centre in Chennai, offers our growing team space for expansion and collaboration. Location Chennai, India About The Team Kinaxis is looking for a talented data engineer to work within the Machine Learning R&D team. The team is responsible for applying machine learning algorithms to develop intelligent supply chains. The uniqueness of the team is that it performs at the intersection of technology and real business problems. You will contribute to the product that delights customers world-wide! What you will do If you love solving complex problems, analyzing complex datasets, finding insights from data, creating data model and learning new technologies, this role is for you. As a software developer, you are passionate about shipping large-scale software systems in a fast-paced environment but can balance longer term issues such as maintainability, scalability, and quality. You are an experienced software engineer who is passionate about delivering software that supports and facilitates business operations of ML & AI solutions. You have a strong understanding of Cloud technologies and Cloud agnostic software architecture and have experience troubleshooting high scale solutions that are deployed and upgraded on a regular cadence. You have a passion for software reliability and know how to ensure user needs are met through cross-functional stakeholder understanding and engagement. You enjoy understanding both the details of the use cases that end-users are performing using the solution as well as the architecture and implementation of the system end to end. You have a strong interest in resolving issues as well as designing effective methods for troubleshooting, preventing, and debugging problems in software systems, getting to the root cause of issues, meeting the users’ needs and influencing the product development roadmap. You are excited about finding ways to develop product capabilities and tools that increase robustness of the user experience, reduce the cost of troubleshooting, or reduce the time required to address issues. You are fluent in Python, have experience working with distributed computing, big data frameworks and are very knowledgeable about Kubernetes and Docker. You also have experience working with and building Machine Learning pipelines and models. You have the ability and enthusiasm to learn new technologies whether they are infrastructure or language or platform and easily adapt to change. You excel as a team player, a quick starter, and a problem solver. You thrive in cross-functional teams, actively listening and contributing to discussions. Your expertise lies in engineering solutions for complex machine learning challenges, developing Python-based applications, containerizing apps with Docker, orchestrating container swarms in Kubernetes, and building Argo Workflows. These efforts play a key role in creating ML software systems that deliver critical value to the business and its customers. What We Are Looking For BS or MS in Computer Science/Software Engineering or equivalent work experience. 6 to 9 years of relevant experience. You have excellent communication skills with the ability to clearly explain technical terms to non-technical audience. Strong software engineering skills and strong programming skills in Python/Pandas/ML Libs. Experience in working with any cloud provider, Azure/GCP/AWS. Strong expertise in Docker, Kuberenetes, Argo Workflows and Helm. Expertise in version control systems – GitHub. Experience in developing CI/CD pipelines – GitHub Actions. Experience in developing REST APIs – Flask/Fast API. Proven understanding of distributed computing architectures. Experience with Machine Learning Solutions and productization. Understanding of the ML / Modelling process, Feature Generation, Training, Hyper-parameter tuning, predictions (scoring) You enjoy solving puzzles and troubleshooting issues. You enjoy multi-tasking and providing significant positive impact to the business through your work. Nice To Have Data manipulations in python – wrangling & manipulating large datasets in spark & pandas dataframes. Supply chain domain knowledge - Supply Chain Management, especially demand planning aspects, CPG, Manufacturing etc. Knowledge of how drivers influence demand, e.g., pricing, promotions, initiatives, external factors like weather patterns etc. Exposure to Databricks. #Associate #Fulltime Work With Impact: Our platform directly helps companies power the world’s supply chains. We see the results of what we do out in the world every day—when we see store shelves stocked, when medications are available for our loved ones, and so much more. Work with Fortune 500 Brands: Companies across industries trust us to help them take control of their integrated business planning and digital supply chain. Some of our customers include Ford, Unilever, Yamaha, P&G, Lockheed-Martin, and more. Social Responsibility at Kinaxis: Our Diversity, Equity, and Inclusion Committee weighs in on hiring practices, talent assessment training materials, and mandatory training on unconscious bias and inclusion fundamentals. Sustainability is key to what we do and we’re committed to net-zero operations strategy for the long term. We are involved in our communities and support causes where we can make the most impact. People matter at Kinaxis and these are some of the perks and benefits we created for our team: Flexible vacation and Kinaxis Days (company-wide day off on the last Friday of every month) Flexible work options Physical and mental well-being programs Regularly scheduled virtual fitness classes Mentorship programs and training and career development Recognition programs and referral rewards Hackathons For more information, visit the Kinaxis web site at www.kinaxis.com or the company’s blog at http://blog.kinaxis.com . Kinaxis welcomes candidates to apply to our inclusive community. We provide accommodations upon request to ensure fairness and accessibility throughout our recruitment process for all candidates, including those with specific needs or disabilities. If you require an accommodation, please reach out to us at recruitmentprograms@kinaxis.com. Please note that this contact information is strictly for accessibility requests and cannot be used to inquire about application statuses. Kinaxis is committed to ensuring a fair and transparent recruitment process. We use artificial intelligence (AI) tools in the initial step of the recruitment process to compare submitted resumes against the job description, to identify candidates whose education, experience and skills most closely match the requirements of the role. After the initial screening, all subsequent decisions regarding your application, including final selection, are made by our human recruitment team. AI does not make any final hiring decisions.",Associate,,"Python, Excel, R, Machine Learning",
4243705911,AI / ML Developer (Lead),Infogain,"Mumbai, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Roles & Responsibilities Key Responsibilities Design, develop, and optimize Machine Learning & Deep Learning models using Python and libraries such as TensorFlow, PyTorch, and Scikit-learn Work with Large Language Models (e.g., GPT, BERT, T5) to solve NLP tasks such as, semantic search, summarization, chatbots, conversational agents, and document intelligence. Lead the development of scalable AI solution including data preprocessing, embedding generation, vector search, and prompt orchestration. Build and manage vector databases and metadata stores to support high-performance semantic retrieval and contextual memory. Implement caching, queuing, and background processing systems to ensure performance and reliability at scale. Conduct independent R&D to implement cutting-edge AI methodologies, evaluate open-source innovations, and prototype experimental solutions Apply predictive analytics and statistical techniques to mine actionable insights from structured and unstructured data. Build and maintain robust data pipelines and infrastructure for end-to-end ML model training, testing, and deployment Collaborate with cross-functional teams to integrate AI solutions into business processes Contribute to the MLOps lifecycle, including model versioning, CI/CD, performance monitoring, retraining strategies, and deployment automation Stay updated with the latest developments in AI/ML by reading academic papers, and experimenting with novel tools or frameworks Required Skills & Qualifications Proficient in Python, with hands-on experience in key ML libraries: TensorFlow, PyTorch, Scikit-learn, and HuggingFace Transformers Strong understanding of machine learning fundamentals, deep learning architectures (CNNs, RNNs, transformers), and statistical modeling Practical experience working with and fine-tuning LLMs and foundation models Deep understanding of vector search, embeddings, and semantic retrieval techniques. Expertise in predictive modeling, including regression, classification, time series, clustering, and anomaly detection Comfortable working with large-scale datasets using Pandas, NumPy, SciPy etc. Experience with cloud platforms (AWS, GCP, or Azure) for training and deployment is a plus Preferred Qualifications Master’s or Ph.D. in Computer Science, Machine Learning, Data Science, or related technical discipline. Experience with MLOps tools and workflows (e.g., Docker, Kubernetes, MLflow, SageMaker, Vertex AI). Ability to build and expose APIs for models using FastAPI, Flask, or similar frameworks. Familiarity with data visualization (Matplotlib, Seaborn) and dashboarding (Plotly) tools or equivalent Working knowledge of version control, experiment tracking, and team collaboration Experience 8-11 Years Skills Primary Skill: AI/ML Development Sub Skill(s): AI/ML Development Additional Skill(s): TensorFlow, NLP, Pytorch, Large Language Models (LLM) About The Company Infogain is a human-centered digital platform and software engineering company based out of Silicon Valley. We engineer business outcomes for Fortune 500 companies and digital natives in the technology, healthcare, insurance, travel, telecom, and retail & CPG industries using technologies such as cloud, microservices, automation, IoT, and artificial intelligence. We accelerate experience-led transformation in the delivery of digital platforms. Infogain is also a Microsoft (NASDAQ: MSFT) Gold Partner and Azure Expert Managed Services Provider (MSP). Infogain, an Apax Funds portfolio company, has offices in California, Washington, Texas, the UK, the UAE, and Singapore, with delivery centers in Seattle, Houston, Austin, Kraków, Noida, Gurgaon, Mumbai, Pune, and Bengaluru.",,,"Python, R, Machine Learning",
4203767624,Data Engineer,Impetus,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job About Impetus Impetus Technologies is a digital engineering company focused on delivering expert services and products to help enterprises achieve their transformation goals. We solve the analytics, AI, and cloud puzzle, enabling businesses to drive unmatched innovation and growth. Founded in 1991, we are cloud and data engineering leaders providing solutions to fortune 100 enterprises, headquartered in Los Gatos, California, with development centers in NOIDA, Indore, Gurugram, Bengaluru, Pune, and Hyderabad with over 3000 global team members. We also have offices in Canada and collaborate with a number of established companies, including American Express, Bank of America, Capital One, Toyota, United Airlines, and Verizon. Experience- 3-8 years Location- Gurgaon & Bangalore Job Description You should have extensive production experience in GCP, Other cloud experience would be a strong bonus. - Strong background in Data engineering 2-3 Years of exp in Big Data technologies including, Hadoop, NoSQL, Spark, Kafka etc. - Exposure to enterprise application development is a must Roles & Responsibilities Able to effectively use GCP managed services e.g. Dataproc, Dataflow, pub/sub, Cloud functions, Big Query, GCS - At least 4 of these Services. Good to have knowledge on Cloud Composer, Cloud SQL, Big Table, Cloud Function. Strong experience in Big Data technologies – Hadoop, Sqoop, Hive and Spark including DevOPs. Good hands on expertise on either Python or Java programming. Good Understanding of GCP core services like Google cloud storage, Google compute engine, Cloud SQL, Cloud IAM. Good to have knowledge on GCP services like App engine, GKE, Cloud Run, Cloud Built, Anthos. Ability to drive the deployment of the customers’ workloads into GCP and provide guidance, cloud adoption model, service integrations, appropriate recommendations to overcome blockers and technical road-maps for GCP cloud implementations. Experience with technical solutions based on industry standards using GCP - IaaS, PaaS and SaaS capabilities. Extensive, real-world experience designing technology components for enterprise solutions and defining solution architectures and reference architectures with a focus on cloud technologies. Act as a subject-matter expert OR developer around GCP and become a trusted advisor to multiple teams.",,,"Python, SQL",
4240759830,Computer Scientist 1,Adobe,"Noida, Uttar Pradesh, India",,Full-time,,"About the job Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! Adobe is in search of an experienced engineer to join the Fulfillment Center Service team. We’re seeking candidates to help us design, construct, and operate high traffic, critically important back end services. You will design and own critical parts of the services and deliver to production. We are looking for a passionate engineer with high potential, eager to learn new technologies and to help us design, construct, and operate our service at scale. What You Will Do What you need to succeed Responsible for multiple phases of engineering - from early specs, design/architecture, development, unit-testing/integration automation, and deployment. Collaborate with architects, product management and other engineering teams to build the technical vision and road map for the team. Build technical specifications, prototypes and presentations to communicate your ideas. Be proficient in emerging industry technologies and trends, and have the ability to communicate that knowledge to the team and use it to influence product direction. Apply innovation and creativity to solve engineering and coding problems using new and emerging tech like GenAI. B.Tech / M.Tech in Computer Science & Engineering or a related field. 4-6 years of experience in software development and automation. Skilled and experienced in Java with the ability to produce clean, performant and maintainable Object oriented code. Strong computer science fundamentals, OOPS, Data Structures, Algorithms and performance optimization. Excellent understanding of the SDLC, Agile Development, Microservice design, CI/CD processes etc. Knowledge of Azure, AWS, JavaScript and familiarity with RESTful APIs, Docker, Jenkins, Splunk, Git etc. Knowledge of GenAI tools and technology would be a bonus. Should be able to quickly adapt to new programming paradigms, languages, tools, and problem areas. Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more about our vision here. Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.",,,,
4256541383,Machine Learning Engineer – RAG & Fine-Tuning,ABC Fitness,"Hyderabad, Telangana, India (Hybrid)",Hybrid,Full-time,,"About the job It's fun to work in a company where people truly BELIEVE in what they're doing! We're committed to bringing passion and customer focus to the business. Job Description Machine Learning Engineer – RAG & Fine-Tuning This role requires working from our local Hyderabad office 2-3x a week. Location: Hyderabad, Telangana, India About Abc Fitness ABC Fitness (ABC) is the global market leader in providing technology solutions to the fitness industry. Built on a 40+ year reputation of excellence, ABC helps fitness providers of all sizes and backgrounds to turn their visions into seamless reality. Founded in 1981, ABC serves 40 million+ members globally, processing over $11B+ in payments annually for 31,000 clubs across 92+ countries. Our integrated suite includes best-of-breed platforms: Evo, Glofox, Ignite, and Trainerize. As a Thoma Bravo portfolio company, ABC is backed by the leading private equity firm focused on enterprise software. Learn more at abcfitness.com . About The Team The AI Platform Engineering team at ABC builds scalable, high-performance AI systems that power next-generation fitness technology. We specialize in retrieval-augmented generation (RAG) architectures and fine-tuning methodologies to deliver context-aware, cost-efficient AI solutions. As our Machine Learning Engineer, you will be responsible for all retrieval and intelligence behind the LLM, delivering performant, low-cost, high-context AI features. At ABC, we love entrepreneurs because we are entrepreneurs. We roll our sleeves up, we act fast, and we learn together. What You’ll Do Handle embeddings and chunking strategies to optimize document and data retrieval for GenAI-powered features. Manage vector stores and retrieval workflows using leading vector databases (Pinecone, FAISS, Weaviate, Azure AI Search) to ensure efficient, scalable access to unstructured and structured data. Fine-tune small and large language models using frameworks such as HuggingFace and OpenAI APIs, tailoring models to domain-specific requirements and improving performance on targeted tasks. Optimize cost and reduce latency by implementing best practices for token management, model evaluation, and cloud resource utilization. Collaborate with engineering, product, and data teams to integrate RAG pipelines into production systems, ensuring reliability, scalability, and security. Stay up-to-date with the latest advancements in retrieval-augmented generation, vector search, and LLM fine-tuning, applying new techniques to improve system performance and user experience. What You’ll Need 4–7 years of experience in machine learning or AI engineering, with a proven track record in RAG, vector search, and LLM fine-tuning. Deep expertise with vector databases such as Pinecone, FAISS, Weaviate, or Azure AI Search, including experience designing retrieval workflows and managing embeddings. Familiarity with HuggingFace and OpenAI fine-tuning APIs, and strong understanding of chunking strategies for optimizing retrieval. Proficiency in Python and experience with ML frameworks (PyTorch, TensorFlow) and cloud platforms (AWS, Azure). Understanding of token management, evaluation tuning, and cost optimization for large-scale AI deployments. Strong problem-solving skills, a collaborative mindset, and the ability to communicate complex technical concepts to both technical and non-technical stakeholders. AND IT’S GREAT TO HAVE Experience with NLP, NLU, and NLG techniques for conversational AI or information retrieval. Exposure to ML Ops tools for model monitoring, evaluation, and deployment (ML flow, Weights & Biases). Experience with model compression, quantization, or other efficiency techniques. Certifications in AWS Machine Learning Specialty or Microsoft AI Engineer. WHAT’S IN IT FOR YOU: Purpose led company with a Values focused culture – Best Life, One Team, Growth Mindset Time Off – competitive PTO plans with 15 Earned accrued leave, 12 days Sick leave, and 12 days Casual leave per year 11 Holidays plus 4 Days of Disconnect – once a quarter, we take a collective breather and enjoy a day off together around the globe. #oneteam Group Mediclaim insurance coverage of INR 500,000 for employee + spouse, 2 kids, and parents or parent-in-laws, and including EAP counseling Life Insurance and Personal Accident Insurance Best Life Perk – we are committed to meeting you wherever you are in your fitness journey with a quarterly reimbursement Premium Calm App – enjoy tranquility with a Calm App subscription for you and up to 4 dependents over the age of 16 Support for working women with financial aid towards crèche facility, ensuring a safe and nurturing environment for their little ones while they focus on their careers. We’re committed to diversity and passion, and encourage you to apply, even if you don’t demonstrate all the listed skillsets! ABC’S COMMITMENT TO DIVERSITY, EQUALITY, BELONGING AND INCLUSION: ABC is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We are intentional about creating an environment where employees, our clients and other stakeholders feel valued and inspired to reach their full potential and make authentic connections. We foster a workplace culture that embraces each person’s diversity, including the extent to which they are similar or different. ABC leaders believe that an equitable and inclusive culture is not only the right thing to do, it is a business imperative. Read more about our commitment to diversity, equality, belonging and inclusion at abcfitness.com ABOUT ABC: ABC Fitness (abcfitness.com) is the premier provider of software and related services for the fitness industry and has built a reputation for excellence in support for clubs and their members. ABC is the trusted provider to boost performance and create a total fitness experience for over 41 million members of clubs of all sizes whether a multi-location chain, franchise or an independent gym. Founded in 1981, ABC helps over 31,000 gyms and health clubs globally perform better and more profitably offering a comprehensive SaaS club management solution that enables club operators to achieve optimal performance. ABC Fitness is a Thoma Bravo portfolio company, a private equity firm focused on investing in software and technology companies (thomabravo.com). If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",,,"Python, Machine Learning",
4240224551,AI Agentic Engineer,Tata Consultancy Services,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job TCS is Having vacancy for AI Agentic Engineer At Tcs Bangalore, Chennai, Hyderabad, Pune, Kolkata location Exp Req:10+ yrs JD Must-Have 1. Strong experience in Java Spring boot / .Net 2. Experience in AI/ML model training, deployment 3. Extensive knowledge of AI/ML techniques including large Language models 4. Experience in Microservices Architecture 5. Exposure to DevOps, integration with QA tools Good-to-Have 1. Experience in using agentic libraries like llamaindex 2. Knowledge of Agentic Frameworks like Langgraph/Semantic Kernel/Google Agentic Development Kit 3. Understanding to Finetuning concepts 4. Good presentations skills.",Associate,,,
4245321140,MLOps Engineer / AI Infrastructure Specialist,Tata Consultancy Services,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Join the virtual drive at TCS Chennai, Bangalore, Hyderabad & Kolkata location on 13 jun-2025 for skill MLOps Engineer / AI Infrastructure Specialist exp req:5 to 8 yrs jd Primary skills:MLOps & Pipeline Engineering, Model Deployment & Scalability, Model Monitoring & Performance Analysis, AI Infrastructure Management Creates scalable and automated pipelines for deploying and managing machine learning models in production environments. Monitors model performance, maintains enterprise AI platforms, and ensures reliable AI infrastructure. Focuses on the operationalization of AI through robust and scalable systems.",Associate,,Machine Learning,
4245529182,AI Fullstack Engineer,Uplers,"Amritsar, Punjab, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - HurixDigital) What do you need for this opportunity? Must have skills required: Python, LLM, Rag (retrieval-augmented generation), AWS HurixDigital is Looking for: Job Summary We are seeking a highly skilled and innovative AI Engineer with Full Stack capabilities to join our dynamic team. The ideal candidate will bring a strong blend of expertise in artificial intelligence, modern software engineering practices, and cloud infrastructure. You will be responsible for designing, developing, and deploying intelligent applications that are scalable, resilient, and deliver real business value. Key Responsibilities Develop and deploy end-to-end AI-powered applications leveraging full-stack development best practices. Architect and integrate AI/ML models and pipelines using tools like LangChain, Hugging Face, OpenAI, and Anthropic Claude APIs. Design and implement microservices, RESTful APIs, and backend systems with scalability and maintainability in mind. Leverage cloud platforms (AWS, Azure, GCP) for hosting, automation, and scaling services. Integrate CI/CD pipelines to ensure smooth and frequent deployment cycles. Collaborate with cross-functional teams to translate business requirements into technical solutions. Apply techniques such as content chunking, vector search, embedding models, and retrievers to build advanced AI retrieval systems. Ensure robust architecture that can withstand variable load conditions, focusing on fault tolerance and high availability. Maintain documentation and adhere to best practices in software development and AI model integration. Required Qualifications Bachelor's or Master's degree in Computer Science, Engineering, or a related field. 5+ years of hands-on experience in AI engineering and full-stack development. Strong proficiency with AI/ML tools including LangChain, Hugging Face, OpenAI, and Claude APIs. Deep understanding of vector databases, retrievers, and modern NLP workflows. Proficient in one or more full-stack frameworks (e.g., Node.js, Django, React, Angular). Experience with Python Experience with cloud platforms (AWS, Azure, GCP) and infrastructure automation tools (e.g., Terraform, CloudFormation). Solid experience with CI/CD pipelines, GitOps, and container orchestration (e.g., Docker, Kubernetes). Proven ability to architect resilient systems and optimize performance under fluctuating workloads. Preferred Skills Knowledge of prompt engineering and LLM fine-tuning techniques. Familiarity with DevSecOps practices and AI compliance requirements. Exposure to multimodal models and real-time inference systems. What We Offer Opportunity to work on cutting-edge AI products and tools. Collaborative and inclusive team environment. Flexible work schedule and remote work options. Competitive salary and performance bonuses. How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Python, LLM, Rag (retrieval-augmented generation), AWS",,,Python,
4227617554,Data Engineer,Acuity Knowledge Partners,"Gurugram, Haryana, India (On-site)",On-site,Full-time,,"About the job We're seeking a skilled Software Engineer with expertise in Python and it would be nice to have experience of working on Large Language Models (LLM) to join our team. Essential skills Minimum of a bachelor’s degree in a technical or quantitative field with strong academic background Demonstrated ability to implement data engineering pipelines and real-time applications in python (C++ is a plus) Proficiency with object oriented programming in python is a must Experience with Linux/Unix shell/ scripting languages and Git is a must Experience with python based tools like Jupyter notebook, coding standards like pep8 is a plus Strong problem-solving skills and understanding of data structures and algorithms Experience with large-scale data processing and pipeline development Understanding of various LLM frameworks and experience with prompt engineering using Python or other scripting languages Nice to have Knowledge of natural language processing (NLP) concepts, familiarity with integrating and leveraging LLM APIs for various applications Key Responsibilities Design, develop, and maintain projects using Python along with operational support Transform a wide range of structured and unstructured data into standardized outputs for quantitative analysis and financial engineering Participate in code reviews, ensure coding standards, and contribute to the improvement of the codebase Develop the utility tools that can further automate the software development, testing and deployment workflow Collaborate with internal and external cross-functional teams",Executive,,Python,
4257551431,Java Software Engineer,Three Across,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Job Title: Ref Data Software Engineer Location: Pune Employment Type: Full-Time Experience: 5-8 Years Role Overview We are seeking a skilled and driven Ref Data Software Engineer to design, develop, and enhance enterprise-grade software solutions. This role is ideal for a proactive developer who thrives in cross-functional environments, embraces innovation, and can contribute to the evolution of data-driven platforms using modern technologies and secure engineering practices. Key Responsibilities Design and deliver high-quality software using Java, Spring Boot, and cloud-native technologies. Develop scalable, maintainable, and performance-optimized solutions aligned with business goals. Collaborate with product managers, designers, and engineers to translate requirements into technical solutions. Participate in code reviews and promote a culture of code quality, reusability, and knowledge sharing. Follow secure coding standards to safeguard data and mitigate vulnerabilities. Apply unit testing and CI/CD practices to ensure solution reliability and quality. Stay updated on emerging technologies and actively contribute to internal engineering communities. Take ownership of delivery outcomes, risk mitigation, and continuous improvement within your domain. Technical Requirements Essential Qualifications & Experience Proficient in Java 8/11 or higher Strong hands-on experience with Spring Boot, Spring MVC, and JPA Expertise in RESTful API development and Web Services Experience with message queueing systems such as Kafka or Solace PubSub+ Solid experience with AWS services (e.g., Lambda, S3, CloudWatch) Working knowledge of Unix/Linux systems and shell scripting Experience with NoSQL and relational databases like Oracle , SQL Server , or PostgreSQL Hands-on experience with Goldensource EDM platform Familiarity with multithreading, concurrency, and performance tuning Proficiency with Git, Maven/Gradle, and CI/CD tools Desirable Skills Experience with Elasticsearch Familiarity with aPaaS/OpenShift and containerized deployments Exposure to Infrastructure-as-Code (CloudFormation/Terraform) Understanding of MVC design patterns and secure software lifecycle best practices Behavioral Expectations & Leadership Deliver work with high standards of precision, responsibility, and integrity Collaborate effectively with cross-functional teams and business stakeholders Demonstrate leadership by mentoring peers or leading small teams (if applicable) Embrace and foster a culture of continuous improvement, innovation, and resilience Take ownership for embedding compliance, risk management, and quality assurance practices in development processes Why Join Us? You’ll be part of a collaborative engineering team shaping the digital transformation of our data and technology platforms. This is a unique opportunity to work on high-impact projects that directly support our customers and colleagues.",manager,,SQL,
4257552462,Java Software Engineer,Health Catalyst,"Hyderabad, Telangana, India (Hybrid)",Hybrid,Full-time,,"About the job About us : The healthcare industry is the next great frontier of opportunity for software development, and Health Catalyst is one of the most dynamic and influential companies in this space. We are working on solving national-level healthcare problems, and this is your chance to improve the lives of millions of people, including your family and friends. Health Catalyst is a fast-growing company that values smart, hardworking, and humble individuals. Each product team is a small, mission-critical team focused on developing innovative tools to support Catalyst’s mission to improve healthcare performance, cost, and quality. Health Catalyst is expanding and maintains a large suite of Improvement Apps that contribute to healthcare analytics and process improvement solutions. This includes products that manage the care of health system populations, better serve patients at the point of care, reduce health system costs, and reduce clinician workload. Job Description: What you'll do and own in this role: High level of responsibility and Ownership from ideation through to execution. Ability to lead a team and implement best practices in every aspect of project deliverables. Stay up to date with new frameworks and tools and enable the team to use them. Ability to thrive under pressure & work in a fast-paced, timeline-oriented environment Give topmost priority to the quality of deliverables of the team Co-ordinate with various teams such as monitoring, backup, and Network to ensure the proper functioning of all servers and their services A genuine intention to work cooperatively with others, to be part of a team, to work together as opposed to working separately or competitively. Encourages and facilitates cooperation, pride, trust, and group identity; fosters commitment and team spirit; works with others to achieve goals. Develop and own solutions, ensuring the viability of proposed solutions and providing support on the appropriate approach throughout the project. Drive end-to-end solution development. Subject matter expert in assigned technology domain (i.e. infrastructure, data, application, etc.) Remain current on industry-specific technologies and emerging trends. Other duties as assigned. What you bring to this role: Strong hands-on development skills in J2EE Technologies, Spring framework, Spring Boot, JavaScript, and Git. 6+ years of experience designing, deploying, and maintaining software solutions. Experience with the installation of COTS products and the ability to evaluate different tools. Strong concepts in Microservice Architecture (MSA) and SOAP & REST web services. Require experience in the following areas: Eclipse, Apache Tomcat, hibernate ORM, JDBC, PostgreSQL, SQL, Bitbucket, Linux, HTML5, CSS3, Spring framework 4.x (including Spring MVC), Spring ecosystem components like Netflix Eureka, Swagger Codegen, etc., POI Framework, XMLBeans, regular expressions, XML, Java 1.8, Java IO processing. Working knowledge on Continuous Integration (CI) and Continuous Delivery (CD) setup, leveraging tools like SonarQube, Maven, Jenkins, Nexus, EKS, etc. Java test automation experience with testing toolkits. The candidate will ensure the conversion of mission-critical requirements into enterprise systems solutions that account for the design and technology maturity constraints of the system. The scope of these assignments will include software development tool and server system administration, process improvement, design review, and code review. Experience in AWS could platform. Knowledge and experience in Security controls and the architecture of secure applications.",,,SQL,
4222045266,EY - GDS Consulting - AI Enabled Automation - AI Engineer - Staff,EY,"Kolkata, West Bengal, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. AI Engineer Role Overview: We are seeking a highly skilled and experienced AI Engineers with a minimum of 2 years of experience in Data Science and Machine Learning, preferably with experience in NLP, Generative AI, LLMs, MLOps, Optimization techniques, and AI solution Architecture. In this role, you will play a key role in the development and implementation of AI solutions, leveraging your technical expertise. The ideal candidate should have a deep understanding of AI technologies and experience in designing and implementing cutting-edge AI models and systems. Additionally, expertise in data engineering, DevOps, and MLOps practices will be valuable in this role. Your technical responsibilities: Assist in the development and implementation of AI models and systems, leveraging techniques such as Large Language Models (LLMs) and generative AI. Design, develop, and maintain efficient, reusable, and reliable Python code Stay updated with the latest advancements in generative AI techniques, such as LLMs, and evaluate their potential applications in solving enterprise challenges. Utilize generative AI techniques, such as LLMs, Agentic Framework to develop innovative solutions for enterprise industry use cases. Integrate with relevant APIs and libraries, such as Azure Open AI GPT models and Hugging Face Transformers, to leverage pre-trained models and enhance generative AI capabilities. Utilize vector databases, such as Redis, and NoSQL databases to efficiently handle large-scale generative AI datasets and outputs. Implement similarity search algorithms and techniques to enable efficient and accurate retrieval of relevant information from generative AI outputs. Ensure compliance with data privacy, security, and ethical considerations in AI applications. Leverage data engineering skills to curate, clean, and preprocess large-scale datasets for generative AI applications. Write unit tests and conduct code reviews to ensure high-quality, bug-free software. Troubleshoot and debug applications to optimize performance and fix issues. Work with databases (SQL, NoSQL) and integrate third-party APIs. Requirements: Bachelor's or Master's degree in Computer Science, Engineering, or a related field. Minimum 2 years of experience in Python, Data Science, Machine Learning, OCR and document intelligence In-depth knowledge of machine learning, deep learning, and generative AI techniques. Proficiency in programming languages such as Python, R, and frameworks like TensorFlow or PyTorch. Strong understanding of NLP techniques and frameworks such as BERT, GPT, or Transformer models. Familiarity with computer vision techniques for image recognition, object detection, or image generation. Strong knowledge of Python frameworks such as Django, Flask, or FastAPI. Experience with RESTful API design and development. Experience with cloud platforms such as Azure, AWS, or GCP and deploying AI solutions in a cloud environment. Expertise in data engineering, including data curation, cleaning, and preprocessing. Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions. Strong communication and interpersonal skills, with the ability to collaborate effectively with stakeholders at various levels. Understanding of data privacy, security, and ethical considerations in AI applications. Good to Have Skills: Understanding of agentic AI concepts and frameworks Proficiency in designing or interacting with agent-based AI architectures Apply trusted AI practices to ensure fairness, transparency, and accountability in AI models and systems. Utilize optimization tools and techniques, including MIP (Mixed Integer Programming). Implement CI/CD pipelines for streamlined model deployment and scaling processes. Utilize tools such as Docker, Kubernetes, and Git to build and manage AI pipelines. Apply infrastructure as code (IaC) principles, employing tools like Terraform or CloudFormation. Implement monitoring and logging tools to ensure AI model performance and reliability. EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",,,"Python, SQL, R, Machine Learning",
4253104049,"Software Development Engineer-Finance AI and ML Dev, PXT Finance - ML Forecasting and Core Engineering",Amazon,"Bengaluru, Karnataka, India",,Full-time,,"About the job Description Amazon Finance Tech team leads innovation to combine data-driven finance with the AI approach driving accuracy, next gen forecasting capabilities, speed, efficiency, and reliability by exploring new techniques in ML and GenAI and building full stack services in AWS. This AI-First Finance builders team will lead AI Application Architecture, designs for predicting outcomes, forecasting values with high degree of automation and ML Ops for existing science pipelines and frameworks. Key job responsibilities As an software engineer on the team, you will own components of an integrated system. You will design and develop these components using AI builder tools, AWS and serverless infrastructure in the cloud that will need to be deployed for use by our financial stakeholders. You will work on a secured data management service that will allow the storage and usage of financial data with the highest standard of privacy. You will create a system that will allow the team to monitor the efficiencies of the designs. You will utilize GenAI-assisted software development on a daily basis that integrates with artificial intelligence tools like Amazon Q Developer into builder workflows to generate & optimize code, build tests, explain unfamiliar code, and learn new languages or APIs, effectively boosting your team’s productivity and code quality. Throughout the software development lifecycle, you will deploy AI tools, agents, use Model Context Protocol (MCP) and large language models (LLMs) to assist in multiple phases - from requirements analysis to coding and testing. You will be execute AI tools on Claude and Nova models for vibe coding and testing. We are looking for individuals who thrive in a collaborative environment where they will have a high level of independence, autonomy, and ownership in what they deliver. The right candidate will wear many hats and work in a highly collaborative environment that is more startup than big company. You will work on cutting edge technology not legacy. As a Software Development Engineer, you will work with a team of talented engineers to build low-latency solutions for frontend, middle tier and backend as well as identify and evaluate new technology options for the challenges we are trying to solve. You will work with a variety of core languages, microservices, and technologies including Java, Javascript, Python, Dynamo DB, Lambda, SQS, SNS and many other AWS services. We are looking for a smart engineer who can effectively deal with ambiguity and work independently to clarify requirements, build prototypes and deliver results quickly. Come join a team in which builders build software and delight customers! You will learn, have fun, and make a positive impact for our customers. A day in the life You Will Design and develop scalable financial systems using distributed computing technologies while collaborating with cross-functional teams Write and review high-quality code for mission-critical applications that process millions of transactions and impact customers globally Participate in daily agile ceremonies including stand-ups, sprint planning, and retrospectives while managing rapid development cycles Debug, optimize, and maintain complex distributed systems to ensure fault tolerance, performance, and reliability at massive scale Create and contribute to technical documentation, architecture designs, and implementation strategies while mentoring junior team members and participating in code reviews Partner closely with customers, product leaders, and stakeholders to understand business requirements, influence product roadmap decisions, and deliver innovative solutions that drive business value Basic Qualifications 3+ years of non-internship professional software development experience 2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience 3+ years of computer science fundamentals (object-oriented design, data structures, algorithm design, problem solving and complexity analysis) experience Experience programming with at least one software programming language Preferred Qualifications 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience Bachelor's degree in computer science or equivalent Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI - Karnataka Job ID: A3011439",,,Python,
4259209028,ERP Senior Specialist Developer - SAP PI,NTT DATA North America,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Req ID: 331091 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a ERP Senior Specialist Developer - SAP PI to join our team in HYDERABAD, Telangana (IN-TG), India (IN). ERP - Sr.Developer - SAP PI Key Responsibilities of an SAP PI/PO Developer: Designing and Developing Integration Interfaces: This involves creating objects in the Enterprise Service Repository (ESR) like data types, message types, service interfaces, and mappings. Configuring Communication Channels: Setting up and configuring communication channels in the Integration Directory (ID) to enable message exchange between different systems. Developing Message Mappings: Creating mappings to transform data formats between different systems. Monitoring and Troubleshooting: Monitoring the PI/PO system for errors and troubleshooting any issues related to message processing. Collaboration with Stakeholders: Working with business users, functional consultants, and other development teams to gather requirements and ensure successful integration. Staying Updated with Technologies: Keeping up with the latest features and functionalities of SAP PI/PO and related technologies. Skills and Qualifications: Experience with SAP PI/PO: Proven experience in designing, developing, and implementing integration solutions using SAP PI/PO. Strong Understanding of Integration Concepts: Knowledge of middleware concepts, message protocols (like SOAP, RFC, JDBC, JMS, etc.), and integration patterns. ABAP and Java Development Skills: Familiarity with ABAP and Java programming languages, especially in the context of SAP PI/PO. Experience with ESR and ID: Proficiency in using the Enterprise Service Repository (ESR) and Integration Directory (ID) for development and configuration. Problem-Solving and Analytical Skills: Ability to analyze integration issues and develop effective solutions. Communication and Collaboration Skills: Ability to communicate effectively with technical and non-technical stakeholders. Strong Expertise in SAP PI Interface Developments Translate high level functional requirements into technical requirements in a clear manner that is comprehensible for other developers and other team members Strong Knowledge and experience with Adobe Forms & Workflows. Facilitate and participate in User Demos of Development Units Provide technical assistance to the process teams in debugging functional issues as needed Work closely with SAP functional teams to analyze and test the effect of system changes as needed Facilitate and participate in User Demos of Development Units. SAP PI Must have SAP PI/PO Certification (preferred) with at least 6+ yrs. of experience in SAP as SAP Middleware Technical Consultant with expertise in XI/PI/PO technology. Multiple project experience in SAP PI/PO Development/Integration projects, Upgrades and Production support. Experience working on S4HANA Migration/ Implementation/ Upgrade. Managed Onsite and Offshore SAP PI/PO and other Middleware (such as Dell Boomi, MuleSoft, webMethods, etc.) teams SME in ABAP/EDI/ALE/PI/Net Weaver/Workflow. J2EE Administration experience Expertise in Integrations using Add-on, EDI and PI which involves order to cash and procure to pay. Prior integration experience architecting solutions for SAP with 3rd party applications such as MES, OpenText, IBP, SuccessFactors, Ariba Network Hands-on experience in SAP Application Interface Framework (AIF) Must have Developed technical, mapping specs Interfaces and EDI messages. Good understanding of various Business processes and SAP processes in OTC, P2P. Worked extensively in Cross Application using EDI/IDOC/BAPI/RFC technology. Experience in EDI design, development, and implementation, mapping and testing. Worked on projects Integrating SAP with PI/PO and other middleware’s like Gentran or SeeBurger. Worked on FILE, IDOC, RFC, XI, SOAP, JDBC, AS2, SFTP, RNIF and B2B Adapters. Having very good project experience in SAP Net Weaver Integration - (Design, Configuration and Deployment) with Java, XSLT mapping knowledge. Knowledge of Cloud app integration using SAP Cloud Platform Integration or Open Connections services would be added advantage. Worked extensively with graphical mapping, user-defined functions, Proxies, BPM, and Alerts. Experience in Runtime Workbench for Message Monitoring, Component Monitoring. Extensive experience in IDOCs, ALE, RFC, BAPI, ALV, LSMW, Data Dictionary, Reports (Classical and Interactive Report), BDC (Batch-Input and Call Transaction Methods), SAPScripts, Adobe Forms, Enhancements. Expertise in developing ABAP Proxies,and Web services integration. Involved in Data Extraction and Conversion between SAP system and legacy system. Excellent Inter-personal Skills, verbal and written communication Possesses a solid understanding of various Web/form techniques using the latest technologies available. Must have strong analytical skills and teamwork 8+ years exp in SAP PI / PO (Process Integration and Process Orchestration) About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",Director,,R,
4232871007,Senior Machine Learning Engineer,Oracle,"Trivandrum, Kerala, India (On-site)",On-site,Full-time,,"About the job Job Description Oracle Cloud Infrastructure (OCI) is a strategic growth area for Oracle. It is a comprehensive cloud service offering in the enterprise software industry, spanning Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). OCI is currently building a future-ready Gen2 cloud Data Science service platform. At the core of this platform, lies Cloud AI Cloud Service. What OCI AI Cloud Services are: A set of services on the public cloud, that are powered by ML and AI to meet the Enterprise modernization needs, and that work out of the box. These services and models can be easily specialized for specific customers/domains by demonstrating existing OCI services. Key Points: Enables customers to add AI capabilities to their Apps and Workflows easily via APIs or Containers, Useable without needing to build AI expertise in-house and Covers key gaps – Decision Support, NLP, for Public Clouds and Enterprise in NLU, NLP, Vision and Conversational AI. You’re Opportunity: As we innovate to provide a single collaborative ML environment for data-science professionals, we will be extremely happy to have you join us and share the very future of our Machine Learning platform - by building an AI Cloud service. We are addressing exciting challenges at the intersection of artificial intelligence and innovative cloud infrastructure. We are building cloud services in Computer vision for Image/Video and Document Analysis, Decision Support (Anomaly Detection, Time series forecasting, Fraud detection, Content moderation, Risk prevention, predictive analytics), Natural Language Processing (NLP), and, Speech that works out of the box for enterprises. Our product vision includes the ability for enterprises to be able to customize the services for their business and train them to specialize in their data by creating micro models that enhance the global AI models. What You’ll Do Develop scalable infrastructure, including microservices and a backend, that automates training, deployment, and optimization of ML model inference. Building a core of Artificial Intelligence and AI services such as Vision, Speech, Language, Decision, and others. Brainstorm and design various POCs using AI Perpetual AI Services for new or existing enterprise problems. Collaborate with fellow data scientists/SW engineers to build out other parts of the infrastructure, effectively communicating your needs, understanding theirs, and addressing external and internal shareholder product challenges. Lead research and development efforts to explore new tools, frameworks, and methodologies to improve backend development processes. Experiment with ML models in Python/C++ using machine learning libraries (Pytorch, ONNX, TensorRT, Triton, TensorFlow, Jax), etc. Leverage Cloud technology – Oracle Cloud (OCI), AWS, GCP, Azure, or similar technology. Qualifications Master’s degree or equivalent experience (preferred) in computer science, Statistics or Mathematics, artificial intelligence, machine learning, Computer vision, operations research, or related technical field. 3+ years for PhD or equivalent experience, 5+ years for Masters, or demonstrated ability designing, implementing, and deploying machine learning models in production environments. Practical experience in design, implementation, and production deployment of distributed systems using microservices architecture and APIs using common frameworks like Spring Boot (Java), etc. Practical experience working in a cloud environment: Oracle Cloud (OCI), AWS, GCP, Azure, and containerization (Docker, Kubernetes). Working knowledge of current techniques, approaches, and inference optimization strategies in machine learning models. Experience with performance tuning, scalability, and load balancing techniques. Expert in at least one high-level language such as Java/C++ (Java preferred). Expert in at least one scripting language such as Python, Javascript, and Shell . Deep understanding of data structures, and algorithms, and excellent problem-solving skills. Experience or willingness to learn and work in Agile and iterative development and DevOps processes. Strong drive to learn and master new technologies and techniques. You enjoy a fast-paced work environment. Additional Preferred Qualifications Experience with Cloud Native Frameworks tools and products is a plus Experience in Computer vision tasks like Image Classification, Object Detection, Segmentation, Text detection & recognition, Information extraction from documents, etc. Having an impressive set of GitHub projects or contributions to open-source technologies is a plus Hands-on experience with horizontally scalable data stores such as Hadoop and other NoSQL technologies like Cassandra is a plus. Our vision is to provide an immersive AI experience on Oracle Cloud. Aggressive as it might sound, our growth journey is fueled by highly energetic, technology-savvy engineers like YOU who are looking to grow with us to meet the demands of building a powerful next-generation platform. Are you ready to do something big? Career Level - IC3 About Us As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s challenges. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. We know that true innovation starts when everyone is empowered to contribute. That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States. Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.",manager,,"Python, Machine Learning",
4251939611,Data Engineer-Data Modeling,IBM,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology. Your Role And Responsibilities As an Data Engineer at IBM you will harness the power of data to unveil captivating stories and intricate patterns. You'll contribute to data gathering, storage, and both batch and real-time processing. Collaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis. As a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets. In this role, your responsibilities may include: Implementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques Designing and implementing various enterprise search applications such as Elasticsearch and Splunk for client requirements Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviours. Build teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modelling results Preferred Education Master's Degree Required Technical And Professional Expertise 4+ years of experience in data modelling, data architecture. Proficiency in data modelling tools ERwin, IBM Infosphere Data Architect and database management systems Familiarity with different data models like relational, dimensional and NoSQl databases. Understanding of business processes and how data supports business decision making. Strong understanding of database design principles, data warehousing concepts, and data governance practices Preferred Technical And Professional Experience Excellent analytical and problem-solving skills with a keen attention to detail. Ability to work collaboratively in a team environment and manage multiple projects simultaneously. Knowledge of programming languages such as SQL",,,"SQL, Machine Learning",
4242242973,"Senior Machine Learning Engineer – MLOps, VertexAI, LLMs, GenAI, ML Model Management",UPS,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Before you apply to a job, select your language preference from the options available at the top right of this page. Explore your next opportunity at a Fortune Global 500 organization. Envision innovative possibilities, experience our rewarding culture, and work with talented teams that help you become better every day. We know what it takes to lead UPS into tomorrow—people with a unique combination of skill + passion. If you have the qualities and drive to lead yourself or teams, there are roles ready to cultivate your skills and take you to the next level. Job Description Job Summary: We are seeking a highly skilled MLOps Engineer to design, deploy, and manage machine learning pipelines in Google Cloud Platform (GCP). In this role, you will be responsible for automating ML workflows, optimizing model deployment, ensuring model reliability, and implementing CI/CD pipelines for ML systems. You will work with Vertex AI, Kubernetes (GKE), BigQuery, and Terraform to build scalable and cost-efficient ML infrastructure. The ideal candidate must have a good understanding of ML algorithms, experience in model monitoring, performance optimization, Looker dashboards and infrastructure as code (IaC), ensuring ML models are production-ready, reliable, and continuously improving. You will be interacting with multiple technical teams, including architects and business stakeholders to develop state of the art machine learning systems that create value for the business. Responsibilities Managing the deployment and maintenance of machine learning models in production environments and ensuring seamless integration with existing systems. Monitoring model performance using metrics such as accuracy, precision, recall, and F1 score, and addressing issues like performance degradation, drift, or bias. Troubleshoot and resolve problems, maintain documentation, and manage model versions for audit and rollback. Analyzing monitoring data to preemptively identify potential issues and providing regular performance reports to stakeholders. Optimization of the queries and pipelines. Modernization of the applications whenever required Qualifications Expertise in programming languages like Python, SQL Solid understanding of best MLOps practices and concepts for deploying enterprise level ML systems. Understanding of Machine Learning concepts, models and algorithms including traditional regression, clustering models and neural networks (including deep learning, transformers, etc.) Understanding of model evaluation metrics, model monitoring tools and practices. Experienced with GCP tools like BigQueryML, MLOPS, Vertex AI Pipelines (Kubeflow Pipelines on GCP), Model Versioning & Registry, Cloud Monitoring, Kubernetes, etc. Solid oral and written communication skills and ability to prepare detailed technical documentation of new and existing applications. Strong ownership and collaborative qualities in their domain. Takes initiative to identify and drive opportunities for improvement and process streamlining. Bachelor’s Degree in a quantitative field of mathematics, computer science, physics, economics, engineering, statistics (operations research, quantitative social science, etc.), international equivalent, or equivalent job experience. Bonus Qualifications Experience in Azure MLOPS, Familiarity with Cloud Billing. Experience in setting up or supporting NLP, Gen AI, LLM applications with MLOps features. Experience working in an Agile environment, understanding of Lean Agile principles. Employee Type Permanent UPS is committed to providing a workplace free of discrimination, harassment, and retaliation.",,,"Python, SQL, Machine Learning",
4245304838,Senior AI Engineer – Computer Vision and Azure Cloud (MUST have OpenCV Experience),INNOFarms.AI,"Gurugram, Haryana, India (On-site)",On-site,Full-time,,"About the job Senior AI Engineer – Computer Vision & Azure Cloud Location: Gurugram, India Type: Full-Time | Permanent Availability: Immediate Joiner or Short Notice Preferred Experience: 4+ Years in AI, Computer Vision, Azure Cloud | SaaS/AI/AgTech Startups Why You Should Join INNOFarms.AI? INNOFarms.AI is a category-defining Agri DeepTech startup building the AI + Robotics stack for next-generation, climate-resilient smart farming . At INNOFarms.AI, we are addressing the urgent challenge of climate-resilient, sustainable food production in urban and resource-constrained regions. Our solution combines AI, robotics, and market intelligence into a modular, plug-and-play intelligence infrastructure that enables next-generation indoor vertical farming & CEA, solving critical pain points like crop unpredictability, labor intensity, and broken supply-demand alignment. We are scaling across GCC, SEA, and India; Our mission aligns with food security, ESG, and Net-Zero goals — enabling profitable, data-driven, resource-efficient food systems globally. What You'll Own and Build? Computer Vision Systems: Design and deploy advanced object detection, segmentation, and multi-head tracking models. Data Pipelines: Build and manage scalable training pipelines from diverse field and sensor datasets. Cross-Disciplinary Collaboration: Integrate CV models with robotics, drones, and IoT systems. Cloud AI Deployment: Leverage Azure Cloud (IoT Hub, Functions, CosmosDB, Event Hubs) for production-grade model deployment. Algorithm Optimization: Apply math and ML theory to continuously improve speed, accuracy, and edge performance. Platform Architecture: Co-architect INNOFarms.AI’s Azure-powered smart farming platform. Secure AI Systems: Ensure compliance with AI ethics, data privacy, and global security standards. AI-Driven Decisions: Build real-time control systems that enable autonomous decision-making in farms. Strategic Collaboration: Work closely with business/product teams to scale AI-led features into global markets. What You Bring to the Table ? Bachelor’s or Master’s in Computer Science, AI, or a related field. 5+ years in AI, SaaS, Cloud, or IoT development. 3-5 years of specialized experience in Computer Vision – object detection, tracking, segmentation. Proficient in OpenCV, TensorFlow, PyTorch, and modern MLOps workflows. Deep experience in Azure Cloud – IoT Hub, Event Hubs, Functions, CosmosDB, Blob, etc. Strong experience with image data pipelines and multi-head CV model development. Startup mindset – self-starter, agile, and collaborative in fast-paced environments. Bonus: Experience with global SaaS product scaling. Nice to Have (But Awesome if You Do) Background in AgriTech, Smart Automation, or IoT-heavy ecosystems. Knowledge of global data compliance, cybersecurity, and AI governance best practices. Experience mentoring junior engineers or leading small teams. Ready to Grow the Future of Food? Join us in building a scalable, intelligent agriculture platform from the ground up. At INNOFarms.AI, your work won’t just be code – it will be a catalyst for sustainable innovation across continents. 👉 Apply now and be a force behind the AgriTech revolution",,,,
4245526803,AI Fullstack Engineer,Uplers,"Guwahati, Assam, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - HurixDigital) What do you need for this opportunity? Must have skills required: Python, LLM, Rag (retrieval-augmented generation), AWS HurixDigital is Looking for: Job Summary We are seeking a highly skilled and innovative AI Engineer with Full Stack capabilities to join our dynamic team. The ideal candidate will bring a strong blend of expertise in artificial intelligence, modern software engineering practices, and cloud infrastructure. You will be responsible for designing, developing, and deploying intelligent applications that are scalable, resilient, and deliver real business value. Key Responsibilities Develop and deploy end-to-end AI-powered applications leveraging full-stack development best practices. Architect and integrate AI/ML models and pipelines using tools like LangChain, Hugging Face, OpenAI, and Anthropic Claude APIs. Design and implement microservices, RESTful APIs, and backend systems with scalability and maintainability in mind. Leverage cloud platforms (AWS, Azure, GCP) for hosting, automation, and scaling services. Integrate CI/CD pipelines to ensure smooth and frequent deployment cycles. Collaborate with cross-functional teams to translate business requirements into technical solutions. Apply techniques such as content chunking, vector search, embedding models, and retrievers to build advanced AI retrieval systems. Ensure robust architecture that can withstand variable load conditions, focusing on fault tolerance and high availability. Maintain documentation and adhere to best practices in software development and AI model integration. Required Qualifications Bachelor's or Master's degree in Computer Science, Engineering, or a related field. 5+ years of hands-on experience in AI engineering and full-stack development. Strong proficiency with AI/ML tools including LangChain, Hugging Face, OpenAI, and Claude APIs. Deep understanding of vector databases, retrievers, and modern NLP workflows. Proficient in one or more full-stack frameworks (e.g., Node.js, Django, React, Angular). Experience with Python Experience with cloud platforms (AWS, Azure, GCP) and infrastructure automation tools (e.g., Terraform, CloudFormation). Solid experience with CI/CD pipelines, GitOps, and container orchestration (e.g., Docker, Kubernetes). Proven ability to architect resilient systems and optimize performance under fluctuating workloads. Preferred Skills Knowledge of prompt engineering and LLM fine-tuning techniques. Familiarity with DevSecOps practices and AI compliance requirements. Exposure to multimodal models and real-time inference systems. What We Offer Opportunity to work on cutting-edge AI products and tools. Collaborative and inclusive team environment. Flexible work schedule and remote work options. Competitive salary and performance bonuses. How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Python, LLM, Rag (retrieval-augmented generation), AWS",,,Python,
4218282651,EY - GDS Consulting - AI Enabled Automation - AI Engineer - Senior,EY,"Kanayannur, Kerala, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. Job Description: Senior AI Engineer (Tech Lead) Role Overview: We are seeking a highly skilled and experienced Senior AI Engineers with a minimum of 4 years of experience in Data Science and Machine Learning, preferably with experience in NLP, Generative AI, LLMs, MLOps, Optimization techniques, and AI solution Architecture. In this role, you will play a key role in the development and implementation of AI solutions, leveraging your technical expertise. The ideal candidate should have a deep understanding of AI technologies and experience in designing and implementing cutting-edge AI models and systems. Additionally, expertise in data engineering, DevOps, and MLOps practices will be valuable in this role. Responsibilities: Your technical responsibilities: Contribute to the design and implementation of state-of-the-art AI solutions. Leading a team of 4-6 developers Assist in the development and implementation of AI models and systems, leveraging techniques such as Large Language Models (LLMs) and generative AI. Collaborate with stakeholders to identify business opportunities and define AI project goals. Stay updated with the latest advancements in generative AI techniques, such as LLMs, and evaluate their potential applications in solving enterprise challenges. Utilize generative AI techniques, such as LLMs, Agentic Framework to develop innovative solutions for enterprise industry use cases. Integrate with relevant APIs and libraries, such as Azure Open AI GPT models and Hugging Face Transformers, to leverage pre-trained models and enhance generative AI capabilities. Implement and optimize end-to-end pipelines for generative AI projects, ensuring seamless data processing and model deployment. Utilize vector databases, such as Redis, and NoSQL databases to efficiently handle large-scale generative AI datasets and outputs. Implement similarity search algorithms and techniques to enable efficient and accurate retrieval of relevant information from generative AI outputs. Collaborate with domain experts, stakeholders, and clients to understand specific business requirements and tailor generative AI solutions accordingly. Conduct research and evaluation of advanced AI techniques, including transfer learning, domain adaptation, and model compression, to enhance performance and efficiency. Establish evaluation metrics and methodologies to assess the quality, coherence, and relevance of generative AI outputs for enterprise industry use cases. Ensure compliance with data privacy, security, and ethical considerations in AI applications. Leverage data engineering skills to curate, clean, and preprocess large-scale datasets for generative AI applications. Requirements: Bachelor's or Master's degree in Computer Science, Engineering, or a related field. Minimum 4 years of experience in Python, Data Science, Machine Learning, OCR and document intelligence Experience in leading a team of 4-6 developers Demonstrated ability to conceptualize technical solutions, apply accurate estimation techniques, and effectively engage with customer stakeholders In-depth knowledge of machine learning, deep learning, and generative AI techniques. Proficiency in programming languages such as Python, R, and frameworks like TensorFlow or PyTorch. Strong understanding of NLP techniques and frameworks such as BERT, GPT, or Transformer models. Familiarity with computer vision techniques for image recognition, object detection, or image generation. Strong knowledge of Python frameworks such as Django, Flask, or FastAPI. Experience with RESTful API design and development. Experience with cloud platforms such as Azure, AWS, or GCP and deploying AI solutions in a cloud environment. Expertise in data engineering, including data curation, cleaning, and preprocessing. Knowledge of trusted AI practices, ensuring fairness, transparency, and accountability in AI models and systems. Strong collaboration with software engineering and operations teams to ensure seamless integration and deployment of AI models. Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions. Strong communication and interpersonal skills, with the ability to collaborate effectively with stakeholders at various levels. Understanding of data privacy, security, and ethical considerations in AI applications. Track record of driving innovation and staying updated with the latest AI research and advancements. Good to Have Skills: Understanding of agentic AI concepts and frameworks Proficiency in designing or interacting with agent-based AI architectures Apply trusted AI practices to ensure fairness, transparency, and accountability in AI models and systems. Utilize optimization tools and techniques, including MIP (Mixed Integer Programming). Drive DevOps and MLOps practices, covering continuous integration, deployment, and monitoring of AI models. Implement CI/CD pipelines for streamlined model deployment and scaling processes. Utilize tools such as Docker, Kubernetes, and Git to build and manage AI pipelines. Apply infrastructure as code (IaC) principles, employing tools like Terraform or CloudFormation. Implement monitoring and logging tools to ensure AI model performance and reliability. Collaborate seamlessly with software engineering and operations teams for efficient AI model integration and deployment. Familiarity with DevOps and MLOps practices, including continuous integration, deployment, and monitoring of AI models. EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",,,"Python, R, Machine Learning",
4250646294,"Software Development Engineer, Alexa Customer Journeys",Amazon,"Hyderabad, Telangana, India",,Full-time,"(supporting title Development, Release, or Live Ops) experience Experience programming with at least one software programming language Preferred Qualifications 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience Bachelor's degree in computer science or equivalent Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI HYD 13 SEZ Job ID: A3008497 Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company Amazon 34,483,890 followers Follow Software Development 10,001+ employees 735,395 on LinkedIn Amazon is guided by four principles: customer obsession rather than competitor focus, passion for invention, commitment to operational excellence, and long-term thinking. We are driven by the excitement of building technologies, inventing products, and providing services that change lives. We embrace new ways of doing things, make decisions quickly, and are not afraid to fail. We have the scope and capabilities of a large company, and the spirit and heart of a small one. Together, Amazonians research and develop new technologies from Amazon Web Services to Alexa on behalf of our customers: shoppers, sellers, content creators, and developers around the world. Our mission is to be Earth's most customer-centric company. Our actions, goals, projects, programs, and inventions begin and end with the customer top of mind. You'll also hear us say that at Amazon, it's always ""Day 1.""​ What do we mean? That our approach remains the same as it was on Amazon's very first day - to make smart, fast decisions, stay nimble, invent, and focus on delighting our customers. … show more Commitments Career growth and learning We offer a variety of career mobility and development opportunities that are designed to help employees move into higher-paying roles at Amazon or elsewhere. Our ten upskilling programs offer employees access to pre-paid education, technical and non-technical skills training, industry certifications, virtual and on-the-job learning and more to help them grow their skills. These programs, as well as career development opportunities like mentoring, internal transfers and promotions, are just one of the one we strive to be Earth's best employer. … Show more Diversity, equity, and inclusion Amazon’s ability to innovate on behalf of our customers relies on the perspectives and knowledge of people from all backgrounds. We actively recruit people from diverse backgrounds to build a","About the job Description Are you passionate about inventing experiences that help customers discover ways to incorporate Generative AI in their daily lives? Do you want to work in a fast paced environment surrounded by the smartest and most customer obsessed product, engineering, marketing, and data science leaders on the planet, where the future is still to be defined? Alexa Customer Journeys team is looking for a Software Development Engineer in the mission to make Alexa an expert on itself, providing useful information and experiences to customers seeking to take advantage of all of their devices’ features and capabilities. You will be building solutions and systems working with Large Language Model (LLM) and other generative technologies. You will be working with an interdisciplinary team of Software Development Engineers, Data Scientists and Quality Assurance Engineers, and working with Product Managers to design customer-facing experiences with Alexa, and building solutions to make Alexa an expert in itself. Key job responsibilities As a SDE, you will be responsible for designing, developing, testing, and deploying distributed machine learning systems and large-scale solutions for our world-wide customer base. In this, you will collaborate closely with a team of Data/Applied scientists to influence our overall strategy and define the team’s roadmap. You will also drive the system architecture, spearhead best practices that enable a quality product, and help coach and develop junior engineers. A successful candidate will have an established background in engineering large scale software systems, a strong technical ability, great communication skills, and a motivation to achieve results in a fast paced environment. We are a growing multi-disciplinary team addressing everyday customer needs through a combination of software engineering, web development and applied research. About The Team The Alexa Customer Journeys team builds products and technology that simplifies customers lives. Our products are used by millions of customer, across Amazon devices, WW. Our teams invent on behalf of our customers and have a ton of fun along the way! Basic Qualifications 3+ years of non-internship professional software development experience 2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience 3+ years of Video Games Industry (supporting title Development, Release, or Live Ops) experience Experience programming with at least one software programming language Preferred Qualifications 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience Bachelor's degree in computer science or equivalent Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI HYD 13 SEZ Job ID: A3008497",Manager,,Machine Learning,
4223540297,Data Engineer,Virtusa,"Andhra Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job Sr Developer with special emphasis and experience of 8 to 10 years on Python and Pyspark along with hands on experience on AWS Data components like AWS Glue, Athena etc.,. Also have good knowledge on Data ware house tools to understand the existing system. Candidate should also have experience on Datalake, Teradata and Snowflake. Should be good at terraform. 8-10 years of experience in designing and developing Python and Pyspark applications Creating or maintaining data lake solutions using Snowflake,taradata and other dataware house tools. Should have good knowledge and hands on experience on AWS Glue , Athena etc., Sound Knowledge on all Data lake concepts and able to work on data migration projects. Providing ongoing support and maintenance for applications, including troubleshooting and resolving issues. Expertise in practices like Agile, Peer reviews and CICD Pipelines. Desired Skills and Experience PySpark, Snowflake, UNIX, AWS Glue, Python, CI & CD",,,Python,
4255443769,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4242248354,"Senior Machine Learning Engineer – MLOps, VertexAI, LLMs, GenAI, ML Model Management",UPS,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Avant de postuler à un emploi, sélectionnez votre langue de préférence parmi les options disponibles en haut à droite de cette page. Découvrez votre prochaine opportunité au sein d'une organisation qui compte parmi les 500 plus importantes entreprises mondiales. Envisagez des opportunités innovantes, découvrez notre culture enrichissante et travaillez avec des équipes talentueuses qui vous poussent à vous développer chaque jour. Nous savons ce qu’il faut faire pour diriger UPS vers l'avenir : des personnes passionnées dotées d’une combinaison unique de compétences. Si vous avez les qualités, de la motivation, de l'autonomie ou le leadership pour diriger des équipes, il existe des postes adaptés à vos aspirations et à vos compétences d'aujourd'hui et de demain. Job Summary Fiche de poste : We are seeking a highly skilled MLOps Engineer to design, deploy, and manage machine learning pipelines in Google Cloud Platform (GCP). In this role, you will be responsible for automating ML workflows, optimizing model deployment, ensuring model reliability, and implementing CI/CD pipelines for ML systems. You will work with Vertex AI, Kubernetes (GKE), BigQuery, and Terraform to build scalable and cost-efficient ML infrastructure. The ideal candidate must have a good understanding of ML algorithms, experience in model monitoring, performance optimization, Looker dashboards and infrastructure as code (IaC), ensuring ML models are production-ready, reliable, and continuously improving. You will be interacting with multiple technical teams, including architects and business stakeholders to develop state of the art machine learning systems that create value for the business. Responsibilities Managing the deployment and maintenance of machine learning models in production environments and ensuring seamless integration with existing systems. Monitoring model performance using metrics such as accuracy, precision, recall, and F1 score, and addressing issues like performance degradation, drift, or bias. Troubleshoot and resolve problems, maintain documentation, and manage model versions for audit and rollback. Analyzing monitoring data to preemptively identify potential issues and providing regular performance reports to stakeholders. Optimization of the queries and pipelines. Modernization of the applications whenever required Qualifications Expertise in programming languages like Python, SQL Solid understanding of best MLOps practices and concepts for deploying enterprise level ML systems. Understanding of Machine Learning concepts, models and algorithms including traditional regression, clustering models and neural networks (including deep learning, transformers, etc.) Understanding of model evaluation metrics, model monitoring tools and practices. Experienced with GCP tools like BigQueryML, MLOPS, Vertex AI Pipelines (Kubeflow Pipelines on GCP), Model Versioning & Registry, Cloud Monitoring, Kubernetes, etc. Solid oral and written communication skills and ability to prepare detailed technical documentation of new and existing applications. Strong ownership and collaborative qualities in their domain. Takes initiative to identify and drive opportunities for improvement and process streamlining. Bachelor’s Degree in a quantitative field of mathematics, computer science, physics, economics, engineering, statistics (operations research, quantitative social science, etc.), international equivalent, or equivalent job experience. Bonus Qualifications Experience in Azure MLOPS, Familiarity with Cloud Billing. Experience in setting up or supporting NLP, Gen AI, LLM applications with MLOps features. Experience working in an Agile environment, understanding of Lean Agile principles. Type De Contrat en CDI Chez UPS, égalité des chances, traitement équitable et environnement de travail inclusif sont des valeurs clefs auxquelles nous sommes attachés.",,,"Python, SQL, Machine Learning",
4240091064,Data Engineer-Enterprise Content Management,IBM,"Hyderabad, Telangana, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology Your Role And Responsibilities Design and Development of ECM Solutions FileNet API Integration Configure and manage Events, Subscriptions, and Triggers in the Content Engine to support business process automation. Define and enforce security policies, including Access Control Lists (ACLs), role-based access control (RBAC), and document-level security configurations Preferred Education Master's Degree Required Technical And Professional Expertise FileNet Developer with IBM FileNet P8 platform. The ideal candidate will be responsible for designing, developing, implementing, and supporting enterprise content management solutions using FileNet, including customization of IBM Content Navigator (ICN), working with FileNet APIs, managing Records Manager configurations, and executing large-scale content migrations. Required Skills and Experience: Experience in IBM FileNet P8 platform (5.2/5.5 or higher). Strong hands-on experience with FileNet Java APIs (CE/PE APIs) Understanding, configuration and management of Event, Triggers in Content Engine to automate business logic. Implement and maintain FileNet security, including ACLs, role-based access control (RBAC), and document-level security Good communication skills and ability to work independently or as part of a team Preferred Technical And Professional Experience IBM FileNet certification (e.g., IBM Certified Specialist - FileNet Content Manager). Experience with workflow design using FileNet BPM/Case Manager. Experience integrating FileNet with other enterprise systems via REST/SOAP APIs",Manager,,,
4218975475,Elastic Search Developer,Infosys,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Technology->DevOps->Continuous delivery - Continuous deployment and release->Elastic Logstash and Kibana (ELK) A day in the life of an Infoscion As part of the Infosys delivery team, your primary role would be to interface with the client for quality assurance, issue resolution and ensuring high customer satisfaction. You will understand requirements, create and review designs, validate the architecture and ensure high levels of service offerings to clients in the technology domain. You will participate in project estimation, provide inputs for solution delivery, conduct technical risk planning, perform code reviews and unit test plan reviews. You will lead and guide your teams towards developing optimized high quality code deliverables, continual knowledge management and adherence to the organizational guidelines and processes. You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! Knowledge of more than one technology Basics of Architecture and Design fundamentals Knowledge of Testing tools Knowledge of agile methodologies Understanding of Project life cycle activities on development and maintenance projects Understanding of one or more Estimation methodologies, Knowledge of Quality processes Basics of business domain to understand the business requirements Analytical abilities, Strong Technical Skills, Good communication skills Good understanding of the technology and domain Ability to demonstrate a sound understanding of software quality assurance principles, SOLID design principles and modelling methods Awareness of latest technologies and trends Excellent problem solving, analytical and debugging skills",,,,
4217273195,Machine Learning Engineer (Remote),Uplers,"Ranchi, Jharkhand, India (Remote)",Save Machine Learning Engineer (Remote) at Uplers,Full-time,,"About the job Experience : 5.00 + years Salary : INR 5000000.00 / year (based on experience) Expected Notice Period : 15 Days Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full Time Permanent position(Payroll and Compliance to be managed by: Precanto) (*Note: This is a requirement for one of Uplers' client - A fast-growing, VC-backed B2B SaaS platform revolutionizing financial planning and analysis for modern finance teams.) What do you need for this opportunity? Must have skills required: async workflows, MLOps, Ray Tune, Data Engineering, MLFlow, Supervised Learning, Time-Series Forecasting, Docker, machine_learning, NLP, Python, SQL A fast-growing, VC-backed B2B SaaS platform revolutionizing financial planning and analysis for modern finance teams. is Looking for: We are a fast-moving startup building AI-driven solutions to the financial planning workflow. We’re looking for a versatile Machine Learning Engineer to join our team and take ownership of building, deploying, and scaling intelligent systems that power our core product. Job Description- Full-time Team: Data & ML Engineering We’re looking for 5+ years of experience as a Machine Learning or Data Engineer (startup experience is a plus) What You Will Do- Build and optimize machine learning models — from regression to time-series forecasting Work with data pipelines and orchestrate training/inference jobs using Ray, Airflow, and Docker Train, tune, and evaluate models using tools like Ray Tune, MLflow, and scikit-learn Design and deploy LLM-powered features and workflows Collaborate closely with product managers to turn ideas into experiments and production-ready solutions Partner with Software and DevOps engineers to build robust ML pipelines and integrate them with the broader platform Basic Skills Proven ability to work creatively and analytically in a problem-solving environment Excellent communication (written and oral) and interpersonal skills Strong understanding of supervised learning and time-series modeling Experience deploying ML models and building automated training/inference pipelines Ability to work cross-functionally in a collaborative and fast-paced environment Comfortable wearing many hats and owning projects end-to-end Write clean, tested, and scalable Python and SQL code Leverage async workflows and cloud-native infrastructure (S3, Docker, etc.) for high-throughput data processing. Advanced Skills Familiarity with MLOps best practices Prior experience with LLM-based features or production-level NLP Experience with LLMs, vector stores, or prompt engineering Contributions to open-source ML or data tools TECH STACK Languages: Python, SQL Frameworks & Tools: scikit-learn, Prophet, pyts, MLflow, Ray, Ray Tune, Jupyter Infra: Docker, Airflow, S3, asyncio, Pydantic How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience async workflows, MLOps, Ray Tune, Data Engineering, MLFlow, Supervised Learning, Time-Series Forecasting, Docker, machine_learning, NLP, Python, SQL",manager,,"Python, SQL, Machine Learning",
4259096930,Python Developer Intern,Innovate Solutions,India (Remote),Remote,Full-time,,"About the job Job Title: Python Developer Trainee Location: Remote Job Type: Internship (Full-Time) Duration: 1–3 Months Stipend: ₹25,000/month Department: Software Development Job Summary: We are seeking a passionate and detail-oriented Python Developer Trainee to join our remote development team. This internship is ideal for individuals looking to strengthen their backend development skills by working on real-world projects involving APIs, automation, and data-driven applications using Python. Key Responsibilities: Write clean, scalable, and efficient Python code Assist in developing backend components, services, and integrations Work with databases (SQL/NoSQL) for data storage and access Debug, test, and optimize code for performance and reliability Support the development and integration of APIs and web services Collaborate with senior developers on software design and architecture Qualifications: Bachelor’s degree (or final-year student) in Computer Science, Software Engineering, or a related field Strong understanding of Python fundamentals and object-oriented programming Familiarity with Python frameworks such as Flask, Django, or FastAPI Basic understanding of RESTful APIs and database operations Good problem-solving and logical thinking skills Ability to work independently in a remote environment Preferred Skills (Nice to Have): Experience with Git and version control tools Familiarity with Docker, cloud platforms, or CI/CD pipelines Knowledge of frontend basics (HTML, CSS, JavaScript) Understanding of testing frameworks (e.g., pytest, unittest) What We Offer: ₹25,000/month stipend 100% remote work Real-world experience in Python-based development projects Mentorship from experienced developers Certificate of Completion Opportunity for full-time placement based on performance",,,"Python, SQL",
4145358436,Staff Engineer MLOps & ML Engineering,Pattern®,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Job Description: As a machine learning operations leader, together with Pattern's Data Science and Engineering teams, you will lead a team that creates and maintains impactful solutions for our brands across the world. From traditional machine learning to large language models, you will work and lead throughout the model lifecycle. Responsibilities: Leadership: MLOps is a team sport, and we require a leader who can elevate everyone in the MLOps organization. While technical skills and vision are required, your leadership skills will take AI and machine learning from theoretical to operational, delivering tangible value to both customers and internal teams. Pipeline Management: Architect, implement, and maintain scalable ML pipelines, with seamless integration from data ingestion to production deployment. Model Monitoring: Lead the operationalization of machine learning models, ensuring hundreds of models are continuously monitored, retrained, and optimized in real-time environments Deployment: Deploy machine learning solutions in the cloud, securely and cost effectively. Reporting: Effectively communicate actionable insights across teams using both automatic (e.g., alerts) and non-automatic methods. The type of game changing candidate we are looking for: Seasoned: Demonstrated experience successfully leading teams both formally and informally. Transparent: Willingness to identify and admit errors and seek out opportunities to continually improve both in their own work and across the team. Communication: MLOps is a central node in a complex system. Clear, actionable, and concise communication, both written and verbal is a must. Coaching and Team Advancement: An MLOps leader is continually developing team members and fostering a constant flow of communication and improvement across team members. Master's/PhD degree or a strong demonstration of technical expertise in Computer Science, Machine Learning, Data Science, or a related field Multiple years of direct extensive experience with AWS Multiple years of experience with MLOps monitoring and testing tools Ability to prioritize projects effectively once clear vision and goals are identified Excited to empower DS with tools, practices, and training that simplify MLOps enough for Data Science to increasingly practice MLOps on their own and own products in production. Pattern is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",,,Machine Learning,
4241887583,Lead Analyst - AI Engineer (Full Stack),Eaton,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,"4.0 Experience with AI platforms like Palantir, Snowflake, and DataIku is advantageous ]]> Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company Eaton 1,822,816 followers Follow Appliances, Electrical, and Electronics Manufacturing 10,001+ employees 53,349 on LinkedIn Eaton is an intelligent power management company dedicated to improving the quality of life and protecting the environment for people everywhere. We are guided by our commitment to do business right, to operate sustainably and to help our customers manage power ─ today and well into the future. By capitalizing on the global growth trends of electrification and digitalization, we’re accelerating the planet’s transition to renewable energy and helping to solve the world’s most urgent power management challenges. Eaton is an Equal Opportunity Employer. Eaton is committed to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of an applicant's race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, marital status, genetic information, protected veteran status, or any other status protected by law. … show more Interested in working with us in the future? Members who share that they’re interested in a company may be 2x as likely to get a message from a recruiter than those who don’t. Learn more Learn more about Interested in working for our company I’m interested Company photos Page 1 of 3 Previous Next April 24, 2023 April 24, 2023 May 24, 2024 Show more","About the job What You’ll Do Must have proven experience in Building front-end and back-end components for AI applications, building/consuming APIs, building customer centric user interfaces and designing integrations with other systems using .Net, JavaScript, Angular or React, SQL Must have proven experience in solution deployment by packaging trained AI models as services using Azure deployment services, Kubernetes, and GitHub for version control. Should have in depth understanding of Azure AI services such as Azure Machine Learning and Cognitive Services along with other AI technologies, natural language processing (NLP), computer vision and GPT models Should have strong expertise in articulating and documenting solution architecture for AI projects by collaborating with solution architect and enterprise architects. Must have abilities to collaborate with business leaders to understand their pain points and identify key areas where AI solutions can drive significant business benefit. Must have strong analytical and problem-solving skills, with the ability to translate business requirements into effective AI solutions. Must have excellent communication skills, with the ability to convey complex AI technical concepts to non-technical stakeholders Qualifications Bachelors in engineering/ B.E/B. Tech and/or required equivalent MCA. Overall 10+ years’ experience with proven track record of 5+ years in Solutioning and deploying end to end AI Technical skills : Net, JavaScript, Angular or React, SQL Server, Azure deployment services, Kubernetes, GitHub , Azure Cognitive Services , GPT models, added advantage with GitHub Copilot Skills Proficiency in front-end technologies (React or Angular) and back-end technologies (e.g., Node.js, Python, .NET). Strong understanding of AI and machine learning frameworks (e.g., TensorFlow, PyTorch). Experience with cloud and hybrid infrastructures. Proficiency in scripting and automation tools (e.g., PowerShell, Azure CLI) Expertise in cloud native development specialized in Microsoft Azure tech stack Experience of working on AI use cases involving in Salesforce AI (Einstein and Agentforce), ServiceNow AI (NowAssist and AI Agents), SAP AI (Joule) , Oracle Cloud AI, AI applications in Industry 4.0 Experience with AI platforms like Palantir, Snowflake, and DataIku is advantageous ]]>",,,"Python, SQL, Machine Learning",
4245530174,AI Fullstack Engineer,Uplers,"Raipur, Chhattisgarh, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - HurixDigital) What do you need for this opportunity? Must have skills required: Python, LLM, Rag (retrieval-augmented generation), AWS HurixDigital is Looking for: Job Summary We are seeking a highly skilled and innovative AI Engineer with Full Stack capabilities to join our dynamic team. The ideal candidate will bring a strong blend of expertise in artificial intelligence, modern software engineering practices, and cloud infrastructure. You will be responsible for designing, developing, and deploying intelligent applications that are scalable, resilient, and deliver real business value. Key Responsibilities Develop and deploy end-to-end AI-powered applications leveraging full-stack development best practices. Architect and integrate AI/ML models and pipelines using tools like LangChain, Hugging Face, OpenAI, and Anthropic Claude APIs. Design and implement microservices, RESTful APIs, and backend systems with scalability and maintainability in mind. Leverage cloud platforms (AWS, Azure, GCP) for hosting, automation, and scaling services. Integrate CI/CD pipelines to ensure smooth and frequent deployment cycles. Collaborate with cross-functional teams to translate business requirements into technical solutions. Apply techniques such as content chunking, vector search, embedding models, and retrievers to build advanced AI retrieval systems. Ensure robust architecture that can withstand variable load conditions, focusing on fault tolerance and high availability. Maintain documentation and adhere to best practices in software development and AI model integration. Required Qualifications Bachelor's or Master's degree in Computer Science, Engineering, or a related field. 5+ years of hands-on experience in AI engineering and full-stack development. Strong proficiency with AI/ML tools including LangChain, Hugging Face, OpenAI, and Claude APIs. Deep understanding of vector databases, retrievers, and modern NLP workflows. Proficient in one or more full-stack frameworks (e.g., Node.js, Django, React, Angular). Experience with Python Experience with cloud platforms (AWS, Azure, GCP) and infrastructure automation tools (e.g., Terraform, CloudFormation). Solid experience with CI/CD pipelines, GitOps, and container orchestration (e.g., Docker, Kubernetes). Proven ability to architect resilient systems and optimize performance under fluctuating workloads. Preferred Skills Knowledge of prompt engineering and LLM fine-tuning techniques. Familiarity with DevSecOps practices and AI compliance requirements. Exposure to multimodal models and real-time inference systems. What We Offer Opportunity to work on cutting-edge AI products and tools. Collaborative and inclusive team environment. Flexible work schedule and remote work options. Competitive salary and performance bonuses. How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Python, LLM, Rag (retrieval-augmented generation), AWS",,,Python,
4222042567,EY - GDS Consulting - AI Enabled Automation - AI Engineer - Staff,EY,"Trivandrum, Kerala, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. AI Engineer Role Overview: We are seeking a highly skilled and experienced AI Engineers with a minimum of 2 years of experience in Data Science and Machine Learning, preferably with experience in NLP, Generative AI, LLMs, MLOps, Optimization techniques, and AI solution Architecture. In this role, you will play a key role in the development and implementation of AI solutions, leveraging your technical expertise. The ideal candidate should have a deep understanding of AI technologies and experience in designing and implementing cutting-edge AI models and systems. Additionally, expertise in data engineering, DevOps, and MLOps practices will be valuable in this role. Your technical responsibilities: Assist in the development and implementation of AI models and systems, leveraging techniques such as Large Language Models (LLMs) and generative AI. Design, develop, and maintain efficient, reusable, and reliable Python code Stay updated with the latest advancements in generative AI techniques, such as LLMs, and evaluate their potential applications in solving enterprise challenges. Utilize generative AI techniques, such as LLMs, Agentic Framework to develop innovative solutions for enterprise industry use cases. Integrate with relevant APIs and libraries, such as Azure Open AI GPT models and Hugging Face Transformers, to leverage pre-trained models and enhance generative AI capabilities. Utilize vector databases, such as Redis, and NoSQL databases to efficiently handle large-scale generative AI datasets and outputs. Implement similarity search algorithms and techniques to enable efficient and accurate retrieval of relevant information from generative AI outputs. Ensure compliance with data privacy, security, and ethical considerations in AI applications. Leverage data engineering skills to curate, clean, and preprocess large-scale datasets for generative AI applications. Write unit tests and conduct code reviews to ensure high-quality, bug-free software. Troubleshoot and debug applications to optimize performance and fix issues. Work with databases (SQL, NoSQL) and integrate third-party APIs. Requirements: Bachelor's or Master's degree in Computer Science, Engineering, or a related field. Minimum 2 years of experience in Python, Data Science, Machine Learning, OCR and document intelligence In-depth knowledge of machine learning, deep learning, and generative AI techniques. Proficiency in programming languages such as Python, R, and frameworks like TensorFlow or PyTorch. Strong understanding of NLP techniques and frameworks such as BERT, GPT, or Transformer models. Familiarity with computer vision techniques for image recognition, object detection, or image generation. Strong knowledge of Python frameworks such as Django, Flask, or FastAPI. Experience with RESTful API design and development. Experience with cloud platforms such as Azure, AWS, or GCP and deploying AI solutions in a cloud environment. Expertise in data engineering, including data curation, cleaning, and preprocessing. Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions. Strong communication and interpersonal skills, with the ability to collaborate effectively with stakeholders at various levels. Understanding of data privacy, security, and ethical considerations in AI applications. Good to Have Skills: Understanding of agentic AI concepts and frameworks Proficiency in designing or interacting with agent-based AI architectures Apply trusted AI practices to ensure fairness, transparency, and accountability in AI models and systems. Utilize optimization tools and techniques, including MIP (Mixed Integer Programming). Implement CI/CD pipelines for streamlined model deployment and scaling processes. Utilize tools such as Docker, Kubernetes, and Git to build and manage AI pipelines. Apply infrastructure as code (IaC) principles, employing tools like Terraform or CloudFormation. Implement monitoring and logging tools to ensure AI model performance and reliability. EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",,,"Python, SQL, R, Machine Learning",
4234988250,Data Engineer,Virtusa,"Andhra Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job This role will be instrumental in building and maintaining robust, scalable, and reliable data pipelines using Confluent Kafka, ksqlDB, Kafka Connect, and Apache Flink. The ideal candidate will have a strong understanding of data streaming concepts, experience with real-time data processing, and a passion for building high-performance data solutions. This role requires excellent analytical skills, attention to detail, and the ability to work collaboratively in a fast-paced environment. Essential Responsibilities Design & develop data pipelines for real time and batch data ingestion and processing using Confluent Kafka, ksqlDB, Kafka Connect, and Apache Flink. Build and configure Kafka Connectors to ingest data from various sources (databases, APIs, message queues, etc.) into Kafka. Develop Flink applications for complex event processing, stream enrichment, and real-time analytics. Develop and optimize ksqlDB queries for real-time data transformations, aggregations, and filtering. Implement data quality checks and monitoring to ensure data accuracy and reliability throughout the pipeline. Monitor and troubleshoot data pipeline performance, identify bottlenecks, and implement optimizations. Automate data pipeline deployment, monitoring, and maintenance tasks. Stay up-to-date with the latest advancements in data streaming technologies and best practices. Contribute to the development of data engineering standards and best practices within the organization. Participate in code reviews and contribute to a collaborative and supportive team environment. Work closely with other architects and tech leads in India & US and create POCs and MVPs Provide regular updates on the tasks, status and risks to project manager The experience we are looking to add to our team Required Bachelors degree or higher from a reputed university 8 to 10 years total experience with majority of that experience related to ETL/ELT, big data, Kafka etc. Proficiency in developing Flink applications for stream processing and real-time analytics. Strong understanding of data streaming concepts and architectures. Extensive experience with Confluent Kafka, including Kafka Brokers, Producers, Consumers, and Schema Registry. Hands-on experience with ksqlDB for real-time data transformations and stream processing. Experience with Kafka Connect and building custom connectors. Extensive experience in implementing large scale data ingestion and curation solutions Good hands on experience in big data technology stack with any cloud platform - Excellent problemsolving, analytical, and communication skills. Ability to work independently and as part of a team Good to have Experience in Google Cloud Healthcare industry experience Experience in Agile Desired Skills and Experience AWS Native Data Services, CI/CD, Hive, Kafka, Scala, PySpark",manager,,,
4251691177,"Business Intel Engineer II, Global Operations - Artificial Intelligence",Amazon,"Hyderabad, Telangana, India",,Full-time,,"About the job Description Want to join the Earth’s most customer centric company? Do you like to dive deep to understand problems? Are you someone who likes to challenge Status Quo? Do you strive to excel at goals assigned to you? If yes, we have opportunities for you. Global Operations – Artificial Intelligence (GO-AI) at Amazon is looking to hire candidates who can excel in a fast-paced dynamic environment. Are you somebody that likes to use and analyze big data to drive business decisions? Do you enjoy converting data into insights that will be used to enhance customer decisions worldwide for business leaders? Do you want to be part of the data team which measures the pulse of innovative machine vision-based projects? If your answer is yes, join our team. GO-AI is looking for a motivated individual with strong skills and experience in resource utilization planning, process optimization and execution of scalable and robust operational mechanisms, to join the GO-AI Ops DnA team. In this position you will be responsible for supporting our sites to build solutions for the rapidly expanding GO-AI team. The role requires the ability to work with a variety of key stakeholders across job functions with multiple sites. We are looking for an entrepreneurial and analytical program manager, who is passionate about their work, understands how to manage service levels across multiple skills/programs, and who is willing to move fast and experiment often. Key job responsibilities Ability to maintain and refine straightforward ETL and write secure, stable, testable, maintainable code with minimal defects and automate manual processes. Proficiency in one or more industry analytics visualization tools (e.g. Excel, Tableau/Quicksight/PowerBI) and, as needed, statistical methods (e.g. t-test, Chi-squared) to deliver actionable insights to stakeholders. Building and owning small to mid-size BI solutions with high accuracy and on time delivery using data sets, queries, reports, dashboards, analyses or components of larger solutions to answer straightforward business questions with data incorporating business intelligence best practices, data management fundamentals, and analysis principles. Good understanding of the relevant data lineage: including sources of data; how metrics are aggregated; and how the resulting business intelligence is consumed, interpreted and acted upon by the business where the end product enables effective, data-driven business decisions. Having high responsibility for the code, queries, reports and analyses that are inherited or produced and having analyses and code reviewed periodically. Effective partnering with peer BIEs and others in your team to troubleshoot, research root causes, propose solutions, by either take ownership for their resolution or ensure a clear hand-off to the right owner. About The Team The Global Operations – Artificial Intelligence (GO-AI) team is an initiative, which remotely handles exceptions in the Amazon Robotic Fulfillment Centers Globally. GO-AI seeks to complement automated vision based decision-making technologies by providing remote human support for the subset of tasks which require higher cognitive ability and cannot be processed through automated decision making with high confidence. This team provides end-to-end solutions through inbuilt competencies of Operations and strong central specialized teams to deliver programs at Amazon scale. It is operating multiple programs and other new initiatives in partnership with global technology and operations teams. Basic Qualifications 5+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience Experience with data visualization using Tableau, Quicksight, or similar tools Experience with data modeling, warehousing and building ETL pipelines Experience in Statistical Analysis packages such as R, SAS and Matlab Experience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling Preferred Qualifications Experience with AWS solutions such as EC2, DynamoDB, S3, and Redshift Experience in data mining, ETL, etc. and using databases in a business environment with large-scale, complex datasets Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI HYD 16 SEZ Job ID: A3009412",manager,,"Python, SQL, Excel, Tableau, R",
4239056787,Data Engineer-Enterprise Content Management,IBM,"Hyderabad, Telangana, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology Your Role And Responsibilities Design and Development of ECM Solutions FileNet API Integration Configure and manage Events, Subscriptions, and Triggers in the Content Engine to support business process automation. Define and enforce security policies, including Access Control Lists (ACLs), role-based access control (RBAC), and document-level security configurations Preferred Education Master's Degree Required Technical And Professional Expertise FileNet Developer with IBM FileNet P8 platform. The ideal candidate will be responsible for designing, developing, implementing, and supporting enterprise content management solutions using FileNet, including customization of IBM Content Navigator (ICN), working with FileNet APIs, managing Records Manager configurations, and executing large-scale content migrations. Required Skills and Experience: Experience in IBM FileNet P8 platform (5.2/5.5 or higher). Strong hands-on experience with FileNet Java APIs (CE/PE APIs) Understanding, configuration and management of Event, Triggers in Content Engine to automate business logic. Implement and maintain FileNet security, including ACLs, role-based access control (RBAC), and document-level security Good communication skills and ability to work independently or as part of a team Preferred Technical And Professional Experience IBM FileNet certification (e.g., IBM Certified Specialist - FileNet Content Manager). Experience with workflow design using FileNet BPM/Case Manager. Experience integrating FileNet with other enterprise systems via REST/SOAP APIs",Manager,,,
4255446048,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4242248452,"Senior Machine Learning Engineer – MLOps, VertexAI, LLMs, GenAI, ML Model Management",UPS,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Before you apply to a job, select your language preference from the options available at the top right of this page. Explore your next opportunity at a Fortune Global 500 organization. Envision innovative possibilities, experience our rewarding culture, and work with talented teams that help you become better every day. We know what it takes to lead UPS into tomorrow—people with a unique combination of skill + passion. If you have the qualities and drive to lead yourself or teams, there are roles ready to cultivate your skills and take you to the next level. Job Description Job Summary: We are seeking a highly skilled MLOps Engineer to design, deploy, and manage machine learning pipelines in Google Cloud Platform (GCP). In this role, you will be responsible for automating ML workflows, optimizing model deployment, ensuring model reliability, and implementing CI/CD pipelines for ML systems. You will work with Vertex AI, Kubernetes (GKE), BigQuery, and Terraform to build scalable and cost-efficient ML infrastructure. The ideal candidate must have a good understanding of ML algorithms, experience in model monitoring, performance optimization, Looker dashboards and infrastructure as code (IaC), ensuring ML models are production-ready, reliable, and continuously improving. You will be interacting with multiple technical teams, including architects and business stakeholders to develop state of the art machine learning systems that create value for the business. Responsibilities Managing the deployment and maintenance of machine learning models in production environments and ensuring seamless integration with existing systems. Monitoring model performance using metrics such as accuracy, precision, recall, and F1 score, and addressing issues like performance degradation, drift, or bias. Troubleshoot and resolve problems, maintain documentation, and manage model versions for audit and rollback. Analyzing monitoring data to preemptively identify potential issues and providing regular performance reports to stakeholders. Optimization of the queries and pipelines. Modernization of the applications whenever required Qualifications Expertise in programming languages like Python, SQL Solid understanding of best MLOps practices and concepts for deploying enterprise level ML systems. Understanding of Machine Learning concepts, models and algorithms including traditional regression, clustering models and neural networks (including deep learning, transformers, etc.) Understanding of model evaluation metrics, model monitoring tools and practices. Experienced with GCP tools like BigQueryML, MLOPS, Vertex AI Pipelines (Kubeflow Pipelines on GCP), Model Versioning & Registry, Cloud Monitoring, Kubernetes, etc. Solid oral and written communication skills and ability to prepare detailed technical documentation of new and existing applications. Strong ownership and collaborative qualities in their domain. Takes initiative to identify and drive opportunities for improvement and process streamlining. Bachelor’s Degree in a quantitative field of mathematics, computer science, physics, economics, engineering, statistics (operations research, quantitative social science, etc.), international equivalent, or equivalent job experience. Bonus Qualifications Experience in Azure MLOPS, Familiarity with Cloud Billing. Experience in setting up or supporting NLP, Gen AI, LLM applications with MLOps features. Experience working in an Agile environment, understanding of Lean Agile principles. Employee Type Permanent UPS is committed to providing a workplace free of discrimination, harassment, and retaliation.",,,"Python, SQL, Machine Learning",
4257576585,Software Engineer - SharePoint Job,YASH Technologies,"Pune, Maharashtra, India (Remote)",Remote,Full-time,,"About the job YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation. At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future. We are looking forward to hire SharePoint On Primise Professionals in the following areas : Job Description Required experience : 2 to 3 years Mode: Offshore Key Skills - SharePoint On-premise SharePoint Online. SharePoint Migration (Sharegate Tool) Period: Initially 3 months, can be extended further.. At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale. Our Hyperlearning workplace is grounded upon four principles Flexible work arrangements, Free spirit, and emotional positivity Agile self-determination, trust, transparency, and open collaboration All Support needed for the realization of business goals, Stable employment with a great atmosphere and ethical corporate culture",associate,,,
4224210467,Power Programmer - Python - Q1-26,Infosys,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Python, Elasticsearch, PostgreSQL infrastructure as a code, one-click deployment, C4 diagrams Javascript, React Git, Scrum, Pair Programming, Peer Reviewing CI/CD with Jenkins pipeline Grafana, ELK stack, Docker, Kubernetes AWS and Terraform , Amazon Web Services and cloud deployments (S3, SNS, SQS, RDS, DynamoDB, etc.), using tools such as Terraform or AWS CLI Power Programmer is an important initiative within Global Delivery to develop a team of Full Stack Developers who will be working on complex engineering projects, platforms and marketplaces for our clients using emerging technologies., They will be ahead of the technology curve and will be constantly enabled and trained to be Polyglots., They are Go-Getters with a drive to solve end customer challenges and will spend most of their time in designing and coding, End to End contribution to technology oriented development projects., Providing solutions with minimum system requirements and in Agile Mode., Collaborate with Power Programmers., Open Source community and Tech User group., Custom Development of new Platforms & Solutions ,Opportunities., Work on Large Scale Digital Platforms and marketplaces., Work on Complex Engineering Projects using cloud native architecture ., Work with innovative Fortune 500 companies in cutting edge technologies., Co creates and develop New Products and Platforms for our clients., Contribute to Open Source and continuously upskill in latest technology areas., Incubating tech user group",,,Python,
4254846556,Generative AI Engineer,Infogain,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Job Summary We are seeking a highly skilled and self-motivated AI Engineer to join us as we establish our AI Center of Excellence (CoE). As an early team member, you will play a critical role in shaping the foundation, strategy, and implementation of AI and ML solutions across the organization. This role offers a unique opportunity to work at the forefront of AI innovation, contribute to impactful use cases, and collaborate with cross-functional teams to build intelligent agentic systems. You will work with both Microsoft technologies (Copilot Studio, AI Foundry, Azure OpenAI) and open-source frameworks to design, deploy, and manage enterprise-ready AI solutions. Key Responsibilities a. Design, develop, and deploy AI agents using Microsoft Copilot Studio and AI Foundry. b. Build and fine-tune machine learning models for NLP, prediction, classification, and recommendation tasks. c. Conduct exploratory data analysis (EDA) to extract insights and support model development. d. Implement and manage LLM workflows, including prompt engineering, fine-tuning, evaluation, deployment, and monitoring. e. Utilize open-source frameworks such as LangChain, Hugging Face, MLflow, and RAG pipelines to build scalable, modular AI solutions. f. Integrate AI solutions with business workflows using APIs and cloud-native deployment methods. g. Use Azure AI services, including AI Foundry and Azure OpenAI, for secure and scalable model operations. h. Contribute to the creation of an AI governance framework, including Responsible AI principles, model explainability, fairness, and accountability. i. Support the creation of standards, reusable assets, and documentation as the CoE grows. j. Collaborate with engineering, data, and business teams to define problems, build solutions, and demonstrate value. k. Stay up to date with emerging AI capabilities such as Model Context Protocol (MCP), Agent-to-Agent (A2A) frameworks, and Agent Communication Protocols (ACP), and proactively evaluate opportunities to integrate them into enterprise solutions. Required Qualifications · Bachelor's or master's degree in computer science, Data Science, Engineering, or a related field. · 5+ years of experience in AI, machine learning, or data science with production-level deployments. · Strong foundation in statistics, ML algorithms, and data analysis techniques. · Hands-on experience building with LLMs, GenAI platforms, and AI copilots. · Proficient in Python, with experience using libraries such as Pandas, Scikit-learn, PyTorch, TensorFlow, and Transformers. · Experience with Microsoft Copilot Studio, AI Foundry, and Azure OpenAI. · Working knowledge of open-source GenAI tools (LangChain, Haystack, MLflow). · Understanding of cloud deployment, API integration, and version control (Git).",Executive,,"Python, Machine Learning, Data Analysis",
4243564679,AI Prompt Engineer – Finance Domain Expert (PhD/Masters),TELUS Digital AI Data Solutions,"Hyderabad, Telangana, India (Remote)",Remote,Part-time,,"About the job We are seeking a highly skilled Finance Specialists who possess a PhD/Masters to join our AI team as a Prompt Engineer. In this role, you will develop complex user prompts that incorporate pairs of mathematical skills in a non-trivial manner. Your work will contribute to cutting-edge approaches in AI data development and help illuminate the limitations of modern AI models. Key Responsibilities Develop intricate, domain-specific mathematical questions to probe AI model capabilities Create content that combine multiple mathematical concepts in innovative ways. You will create and review model responses to contribute to the improvement of AI model performance in mathematical reasoning. Project Details Duration: March to June 2025 Work Schedule: 3-4 hours per day in a freelance capacity. Location: Remote India residents only Mandatory: As part of your application you must have your CV and relevant qualifications uploaded in your application as it will impact your ability to undertake work with us if not provided. Payment rate The payment rate is in USD. If you are a holder of a PhD Degree USD 30 If you hold a Master Degree USD 20 This is an Independent Contractor opportunity. Payments will be issued through our TELUS Digital AI Community Platform. Qualification path Requirements PhD or Master's Degree in Finance, Business, Economics or a related field Strong background in advanced mathematics Excellent analytical and problem-solving skills Ability to think creatively and develop challenging mathematical scenarios Familiarity with AI and machine learning concepts (preferred) Strong written communication skills in English Desktop or Laptop Stable Internet Connection for the duration of the task If interested, please apply here: https://www.telusinternational.ai/cmp/contributor/jobs/available/126437?utm_source=Linkedin&utm_medium=Ads&utm_campaign=SHTArianne_APAC_Paid+Site_Linkedin_Ads_126437 Once you’ve completed your application through the link, kindly notify us by emailing Jazmin.dalisay@telusdigital.com so we can assist in tracking the progress of your application.",,,Machine Learning,
4256419165,SQL Developer Intern,Lead India,India (Remote),Remote,Full-time,,"About the job About Lead India: Lead India is a forward-thinking IT company offering end-to-end digital solutions, software development, and data-driven services. We believe in nurturing fresh talent and giving them the opportunity to work on meaningful, real-world projects in a supportive remote environment. Internship Overview: We are seeking a motivated and detail-oriented SQL Developer Intern to join our team. In this role, you’ll be working with databases, writing and optimizing SQL queries, and contributing to the development and maintenance of our data systems. Key Responsibilities: Write, test, and optimize SQL queries and stored procedures Assist in the design and maintenance of database schemas Perform data extraction, transformation, and loading (ETL) tasks Collaborate with the data and development teams to troubleshoot and improve database performance Document database processes and ensure data accuracy and integrity Support reporting needs with custom queries and data exports Required Skills: Good understanding of SQL and relational databases (MySQL, PostgreSQL, SQL Server, etc.) Basic knowledge of database design and normalization Familiarity with tools like MySQL Workbench, SSMS, or pgAdmin Strong problem-solving and analytical skills Attention to detail and ability to work independently in a remote setup Nice to Have: Exposure to ETL tools or processes Basic knowledge of performance tuning and query optimization Understanding of data warehousing concepts Experience with scripting languages (Python, Shell) for automation What You’ll Gain: Practical experience working on real SQL/database projects Guidance from experienced developers and mentors Remote work flexibility Internship certificate and Letter of Recommendation Opportunity for a full-time role or pre-placement offer (based on performance) You will get salary upto 25,000/- per month.",,,"Python, SQL",
4228844188,Senior AI Engineer - REMOTE,Uplers,"Ghaziabad, Uttar Pradesh, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4233766709,EY - GDS Consulting - AI Enabled Automation - AI Engineer - Senior,EY,"Kanayannur, Kerala, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. EY-Consulting – AI Enabled Automation – Senior - Full Stack Developer At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture, and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. Key Responsibilities: Requires 3-5 years minimum prior experience. Develop and maintain applications using Python. Collaborate with cross-functional teams to define, design, and ship new features. Optimize applications for maximum speed and scalability. Troubleshoot and debug applications. Work on both the front-end and back-end of the application stack. Relevant Experience of more than 2 years Required Skills: Strong proficiency in Python with at least 2 years of relevant experience. Experience with web frameworks such as Django or Flask. Familiarity with front-end technologies like HTML, CSS, and JavaScript. Preferred Skills: Knowledge of React JS, Node JS, or Angular. Understanding of RESTful APIs and web services. Experience with version control systems like Git. Knowledge of database technologies such as SQL and NoSQL. Additional Requirements: Excellent problem-solving skills. Strong communication and teamwork abilities. Ability to work in an agile development environment. What Working At EY Offers At EY, we’re dedicated to helping our clients, from start–ups to Fortune 500 companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",,,"Python, SQL",
4241889319,Data Engineer,Virtusa,"Andhra Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job Responsibilities Design and Develop Scalable Data Pipelines: Build and maintain robust data pipelines using Python to process, transform, and integrate large-scale data from diverse sources. Orchestration and Automation: Implement and manage workflows using orchestration tools such as Apache Airflow to ensure reliable and efficient data operations. Data Warehouse Management: Work extensively with Snowflake to design and optimize data models, schemas, and queries for analytics and reporting. Queueing Systems: Leverage message queues like Kafka, SQS, or similar tools to enable real-time or batch data processing in distributed environments. Collaboration: Partner with Data Science, Product, and Engineering teams to understand data requirements and deliver solutions that align with business objectives. Performance Optimization: Optimize the performance of data pipelines and queries to handle large scales of data efficiently. Data Governance and Security: Ensure compliance with data governance and security standards to maintain data integrity and privacy. Documentation: Create and maintain clear, detailed documentation for data solutions, pipelines, and workflows. Qualifications Required Skills: 5+ years of experience in data engineering roles with a focus on building scalable data solutions. Proficiency in Python for ETL, data manipulation, and scripting. Hands-on experience with Snowflake or equivalent cloud-based data warehouses. Strong knowledge of orchestration tools such as Apache Airflow or similar. Expertise in implementing and managing messaging queues like Kafka, AWS SQS, or similar. Demonstrated ability to build and optimize data pipelines at scale, processing terabytes of data. Experience in data modeling, data warehousing, and database design. Proficiency in working with cloud platforms like AWS, Azure, or GCP. Strong understanding of CI/CD pipelines for data engineering workflows. Experience working in an Agile development environment, collaborating with cross-functional teams. Preferred Skills Familiarity with other programming languages like Scala or Java for data engineering tasks. Knowledge of containerization and orchestration technologies (Docker, Kubernetes). Experience with stream processing frameworks like Apache Flink. Experience with Apache Iceberg for data lake optimization and management. Exposure to machine learning workflows and integration with data pipelines. Soft Skills Strong problem-solving skills with a passion for solving complex data challenges. Excellent communication and collaboration skills to work with cross-functional teams. Ability to thrive in a fast-paced, innovative environment. Desired Skills and Experience CI & CD, ETL",,,"Python, Machine Learning",
4256826176,"Software Development Engineer-Finance AI and ML Dev, PXT Finance - ML Forecasting and Core Engineering",Amazon,"Bengaluru, Karnataka, India",,Full-time,,"About the job Description Amazon Finance Tech team leads innovation to combine data-driven finance with the AI approach driving accuracy, next gen forecasting capabilities, speed, efficiency, and reliability by exploring new techniques in ML and GenAI and building full stack services in AWS. This AI-First Finance builders team will lead AI Application Architecture, designs for predicting outcomes, forecasting values with high degree of automation and ML Ops for existing science pipelines and frameworks. Key job responsibilities As an software engineer on the team, you will own components of an integrated system. You will design and develop these components using AI builder tools, AWS and serverless infrastructure in the cloud that will need to be deployed for use by our financial stakeholders. You will work on a secured data management service that will allow the storage and usage of financial data with the highest standard of privacy. You will create a system that will allow the team to monitor the efficiencies of the designs. You will utilize GenAI-assisted software development on a daily basis that integrates with artificial intelligence tools like Amazon Q Developer into builder workflows to generate & optimize code, build tests, explain unfamiliar code, and learn new languages or APIs, effectively boosting your team’s productivity and code quality. Throughout the software development lifecycle, you will deploy AI tools, agents, use Model Context Protocol (MCP) and large language models (LLMs) to assist in multiple phases - from requirements analysis to coding and testing. You will be execute AI tools on Claude and Nova models for vibe coding and testing. We are looking for individuals who thrive in a collaborative environment where they will have a high level of independence, autonomy, and ownership in what they deliver. The right candidate will wear many hats and work in a highly collaborative environment that is more startup than big company. You will work on cutting edge technology not legacy. As a Software Development Engineer, you will work with a team of talented engineers to build low-latency solutions for frontend, middle tier and backend as well as identify and evaluate new technology options for the challenges we are trying to solve. You will work with a variety of core languages, microservices, and technologies including Java, Javascript, Python, Dynamo DB, Lambda, SQS, SNS and many other AWS services. We are looking for a smart engineer who can effectively deal with ambiguity and work independently to clarify requirements, build prototypes and deliver results quickly. Come join a team in which builders build software and delight customers! You will learn, have fun, and make a positive impact for our customers. A day in the life You Will Design and develop scalable financial systems using distributed computing technologies while collaborating with cross-functional teams Write and review high-quality code for mission-critical applications that process millions of transactions and impact customers globally Participate in daily agile ceremonies including stand-ups, sprint planning, and retrospectives while managing rapid development cycles Debug, optimize, and maintain complex distributed systems to ensure fault tolerance, performance, and reliability at massive scale Create and contribute to technical documentation, architecture designs, and implementation strategies while mentoring junior team members and participating in code reviews Partner closely with customers, product leaders, and stakeholders to understand business requirements, influence product roadmap decisions, and deliver innovative solutions that drive business value Basic Qualifications 3+ years of non-internship professional software development experience 2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience 3+ years of computer science fundamentals (object-oriented design, data structures, algorithm design, problem solving and complexity analysis) experience Experience programming with at least one software programming language Preferred Qualifications 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience Bachelor's degree in computer science or equivalent Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI - Karnataka Job ID: A3017207",,,Python,
4255441822,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4256586175,Machine Learning Engineer Expert,Infosys,"Bengaluru East, Karnataka, India",,Full-time,"trends Education and Experience: Overall, 6 to 8 years of experience in Data driven software engineering with 3-5 years of experience designing, building and deploying enterprise AI or ML applications with at least 2 years of experience implementing full lifecycle ML automation using MLOps(scalable development to deployment of complex data science workflows) Bachelors or Master’s degree in Computer Science Engineering or equivalent Domain experience in Retail, CPG and Logistics etc. Azure Certified – DP100, AZ/AI900 Logical thinking and problem solving skills along with an ability to collaborate Two or three industry domain knowledge Understanding of the financial processes for various types of projects and the various pricing models available Client Interfacing skills Knowledge of SDLC and agile methodologies Project and Team management Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company Infosys 10,092,775 followers Follow IT Services and IT Consulting 10,001+ employees 349,063 on LinkedIn Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over three decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem. Visit www.infosys.com to see how Infosys (NYSE: INFY) can help your enterprise navigate your next. … show more Interested in working with us in the future? Members who share that they’re interested in a company may be 2x as likely to get a message from a recruiter than those who don’t. Learn more Learn more about Interested in working for our company I’m interested Company photos Page 1 of 7 Previous Next February 6, 2023 February 6, 2023 December 29, 2022 Show more","About the job Primary skills:Technology->OpenSystem->Python - OpenSystem Responsible for successful delivery of MLOps solutions and services in client consulting environments; Define key business problems to be solved; formulate high level solution approaches and identify data to solve those problems, develop, analyze/draw conclusions and present to client. Assist clients with operationalization metrics to track performance of ML Models Agile trained to manage team effort and track through JIRA High Impact Communication- Assesses the target audience need, prepares and practices a logical flow, answers audience questions appropriately and sticks to timeline. Technical knowledge- has expertise in cloud technologies, specifically MS Azure, and services with hands on coding to – Expertise in Object Oriented Python Programming with 6 -8 years’ experience. DevOps Working knowledge with implementation experience - 1 or 2 projects a minimum Hands-On MS Azure Cloud knowledge Understand and take requirements on Operationalization of ML Models from Data Scientist Help team with ML Pipelines from creation to execution List Azure services required for deployment, Azure Data bricks and Azure DevOps Setup Assist team to coding standards (flake8 etc) Guide team to debug on issues with pipeline failures Engage with Business / Stakeholders with status update on progress of development and issue fix Automation, Technology and Process Improvement for the deployed projects Setup Standards related to Coding, Pipelines and Documentation Adhere to KPI / SLA for Pipeline Run, Execution Research on new topics, services and enhancements in Cloud Technologies Domain / Technical / Tools Knowledge: Object oriented programming, coding standards, architecture & design patterns, Config management, Package Management, Logging, documentation Experience in Test Driven Development and experience in using Pytest frameworks, git version control, Rest APIs Python programming with OOPs concept, SQL, XML, YAML, Bash, JSON, Pydantic models, Class based frameworks, Dependency injections FastAPI, Flask, Streamlit, Python, Azure API management, API Gateways, Traffic Manager, Load Balancers Nginx, Uvicorn, Gunicorn, Azure ML best practices in environment management, run time configurations (Azure ML & Databricks clusters), alerts. Experience designing and implementing ML Systems & pipelines, MLOps practices and tools such a MLFlow, Kubernetes, etc. Exposure to event driven orchestration, Online Model deployment Contribute towards establishing best practices in MLOps Systems development Proficiency with data analysis tools (e.g., SQL, R & Python) High level understanding of database concepts/reporting & Data Science concepts Hands on experience in working with client IT/Business teams in gathering business requirement and converting into requirement for development team Experience in managing client relationship and developing business cases for opportunities Azure AZ-900 Certification with Azure Architect Good knowledge on software configuration management systems Strong business acumen, strategy and cross-industry thought leadership Awareness of latest technologies and Industry trends Education and Experience: Overall, 6 to 8 years of experience in Data driven software engineering with 3-5 years of experience designing, building and deploying enterprise AI or ML applications with at least 2 years of experience implementing full lifecycle ML automation using MLOps(scalable development to deployment of complex data science workflows) Bachelors or Master’s degree in Computer Science Engineering or equivalent Domain experience in Retail, CPG and Logistics etc. Azure Certified – DP100, AZ/AI900 Logical thinking and problem solving skills along with an ability to collaborate Two or three industry domain knowledge Understanding of the financial processes for various types of projects and the various pricing models available Client Interfacing skills Knowledge of SDLC and agile methodologies Project and Team management",Manager,,"Python, SQL, R, Data Analysis",
4246064492,Cognite Data Engineer,Virtusa,"Chennai, Tamil Nadu, India (Hybrid)",Hybrid,Full-time,,"About the job Job Description We are looking to onboard a strong offshore Data Engineer for the Asset Twin project, with specialized expertise in Cognite. The candidate should have hands-on experience in: Cognite Data Fusion (CDF) - specifically in data loading, modelling, and contextualization In addition to Cognite expertise, it would be advantageous if the candidate also has skills in: SnapLogic Snowflake Python",,,Python,
4240272253,"Lead developer-Python, ML",Tata Consultancy Services,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Experience: 5-10years Location: Hyderabad/Chennai Must-Have** (Ideally should not be more than 3-5): 1.In depth knowledge on PySpark such as reading data from external sources, merging data, performing data enrichment and loading into target data destinations 2. In depth knowledge of developing, training & deploying ML Models 3. Knowledge on Machine learning concepts & ML algorithms Good-to-Have: 1. Exposure to job scheduling & monitoring environments(E.gControl-M) 2. Any ETL tool exposure 3. Cloud migration experience Responsibility of / Expectations from the Role Developing data processing tasks using PySpark such as reading data from external sources, merging data, performing data enrichment and loading into target data destinations Build scalable and reusable code for optimized data retrieval & movement across sources Develop libraries and maintain processes for business to access data and write MapReduce programs Write scalable and maintainable scripts using Python for data transfers Assessing, prioritizing and guiding team in designing & development of features as per business Requirements Ability to fetche data from various sources and analyzes it for better understanding about how the business performs, and builds AI tools that automate certain processes within the environment Deep technical understanding of how to communicate complex data in an accessible way while also having the ability to visualize their findings Ability to build, train, and deploy ML models into a production-ready hosted environment like AWS Sagemaker",Associate,,"Python, Machine Learning",
3954674496,"Lead Software Engineer (Python, GenAI, LLM)",EPAM Systems,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job We are seeking a skilled Lead Software Engineer to join our team and lead a project focused on developing GenAI applications using Large Language Models (LLMs) and Python programming . In this role, you will be responsible for designing and optimizing Al-generated text prompts to maximize effectiveness for various applications. You will also collaborate with cross-functional teams to ensure seamless integration of optimized prompts into the overall product or system. Your expertise in prompt engineering principles and techniques will allow you to guide models to desired outcomes and evaluate prompt performance to identify areas for optimization and iteration. Responsibilities Design, develop, test and refine AI-generated text prompts to maximize effectiveness for various applications Ensure seamless integration of optimized prompts into the overall product or system Rigorously evaluate prompt performance using metrics and user feedback Collaborate with cross-functional teams to understand requirements and ensure prompts align with business goals and user needs Document prompt engineering processes and outcomes, educate teams on prompt best practices and keep updated on the latest AI advancements to bring innovative solutions to the project Requirements 7 to 12 years of relevant professional experience Expertise in Python programming including experience with Al/machine learning frameworks like TensorFlow, PyTorch, Keras, Langchain, MLflow, Promtflow 2-5 years of working knowledge of NLP and LLMs like BERT, GPT-3/4, T5, etc. Knowledge of how these models work and how to fine-tune them Expertise in prompt engineering principles and techniques like chain of thought, in-context learning, tree of thought, etc. Knowledge of retrieval augmented generation (RAG) Strong analytical and problem-solving skills with the ability to think critically and troubleshoot issues Excellent communication skills, both verbal and written in English at a B2+ level for collaborating across teams, explaining technical concepts, and documenting work outcomes",,,"Python, Machine Learning",
4248031007,AI Prompt Engineer – Finance Domain Expert (PhD/Masters),TELUS Digital AI Data Solutions,"Kolkata, West Bengal, India (Remote)",Remote,Part-time,,"About the job We are seeking a highly skilled Finance Specialists who possess a PhD/Masters to join our AI team as a Prompt Engineer. In this role, you will develop complex user prompts that incorporate pairs of mathematical skills in a non-trivial manner. Your work will contribute to cutting-edge approaches in AI data development and help illuminate the limitations of modern AI models. Key Responsibilities Develop intricate, domain-specific mathematical questions to probe AI model capabilities Create content that combine multiple mathematical concepts in innovative ways. You will create and review model responses to contribute to the improvement of AI model performance in mathematical reasoning. Project Details Duration: March to June 2025 Work Schedule: 3-4 hours per day in a freelance capacity. Location: Remote India residents only Mandatory: As part of your application you must have your CV and relevant qualifications uploaded in your application as it will impact your ability to undertake work with us if not provided. Payment rate The payment rate is in USD. If you are a holder of a PhD Degree USD 30 If you hold a Master Degree USD 20 This is an Independent Contractor opportunity. Payments will be issued through our TELUS Digital AI Community Platform. Qualification path Requirements PhD or Master's Degree in Finance, Business, Economics or a related field Strong background in advanced mathematics Excellent analytical and problem-solving skills Ability to think creatively and develop challenging mathematical scenarios Familiarity with AI and machine learning concepts (preferred) Strong written communication skills in English Desktop or Laptop Stable Internet Connection for the duration of the task If interested, please apply here: https://www.telusinternational.ai/cmp/contributor/jobs/available/126437?utm_source=Linkedin&utm_medium=Ads&utm_campaign=SHTArianne_APAC_Paid+Site_Linkedin_Ads_126437 Once you’ve completed your application through the link, kindly notify us by emailing tip_ai_crowdsourcing_apac@telusinternational.com so we can assist in tracking the progress of your application.",,,Machine Learning,
4223614905,Senior Machine Learning Engineer - 2 (Architect) - Express AI Assistant,Adobe,"Noida, Uttar Pradesh, India",,Full-time,,"About the job Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! About The Team The Adobe Express team is building a path-breaking, all-in-one creative application for all platforms - web, desktop, and mobile. This platform combines the power of Adobe’s creative technologies with intuitive, AI-enhanced workflows that empower anyone to create standout content quickly and effortlessly. The Opportunity We’re looking for a Senior Machine Learning Engineer (Architect) to play a key role in shaping the next generation of AI-powered creative experiences in Adobe Express. This role will build high-impact AI Workflows for Adobe Express in Image editing space. Concentrating on brand new generative AI workflows, including personalized assistants and intelligent creative tools. Speed up AI culture by sharing knowledge, encouraging experimentation, and improving developer efficiency. Experience Requirements: 15+ years of proven experience in hands-on Machine Learning work. As a Machine Learning Engineer, you will: Build and scale advanced ML models to make Image editing easy and seamless for users Develop AI Agents for Adobe Express in Imaging space Partner closely with product, design and engineering teams across Adobe to integrate Adobe’s latest generative AI capabilities user-facing features. Help drive a culture of AI innovation and learning through internal knowledge-sharing, best-practice documentation, and experimentation frameworks that boost team productivity. Detailed Responsibilities: Research, design, and implement advanced ML models and scalable pipelines across training, inference, and deployment stages, using techniques in computer vision, NLP, deep learning, and generative AI. Integrate Large Language Models (LLMs) and agent-based frameworks to support multimodal creative workflows—enabling rich, context-aware, dynamic user experiences. Design, implement, and optimize subagent architectures for supporting modular and intelligent assistance across various creative tasks in Adobe Express. Collaborate with multi-functional teams to translate product requirements into ML solutions—especially those related to Harmony GenAI, smart recommendations, and generative tooling. Contribute to the development of internal platforms for model experimentation, A/B testing, performance monitoring, and continuous improvement. Stay up-to-date with evolving ML/GenAI research, tools, and frameworks—including federated learning, retrieval-augmented generation, and optimization for real-time inference. Champion an AI-first culture by mentoring peers, promoting learning opportunities, and encouraging innovation at both technical and organizational levels. Special Skills Requirements: Proficiency in Python for model development and C++ for systems integration. Strong hands-on experience with TensorFlow, PyTorch, and emerging GenAI toolkits. Experience working with LLMs, agent architectures, and user interfaces powered by AI technology. Deep understanding of computer vision and NLP techniques, especially for multimodal AI applications. Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more about our vision here. Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.",,,"Python, Machine Learning",
4259070338,SQL Developer Intern,Workassist,"Chennai, Tamil Nadu, India (Remote)",Remote,Full-time,"Type : Information Technology Function : Database Administrator Key Skills : mSQL,SQL Writing,PLSQL Education : Graduate Note: This is a requirement for one of the Workassist Hiring Partner Responsibilities Write, optimize, and maintain SQL queries, stored procedures, and functions. This is a Remote Position. Assist in designing and managing relational databases. Perform data extraction, transformation, and loading (ETL) tasks. Ensure database integrity, security, and performance. Work with developers to integrate databases into applications. Support data analysis and reporting by writing complex queries. Document database structures, processes, and best practices. Company Description Workassist is an online recruitment and employment solution platform based in Lucknow, India. We provide relevant profiles to employers and connect job seekers with the best opportunities across various industries. With a network of over 10,000+ recruiters, we help employers recruit talented individuals from sectors such as Banking & Finance, Consulting, Sales & Marketing, HR, IT, Operations, and Legal. We have adapted to the new normal and strive to provide a seamless job search experience for job seekers worldwide. Our goal is to enhance the job seeking experience by leveraging technology and matching job seekers with the right employers. For a seamless job search experience, visit our website: https://bit.ly/3QBfBU2 (Note: There are many more opportunities apart from this on the portal. Depending on the skills, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Put your best foot forward with your application Put your best foot forward with your application Hire a resume writer Hire a resume writer Get a resume review About the company Workassist 77,978 followers Follow Staffing and Recruiting 51-200 employees 59 on LinkedIn Workassist is an online recruitment and employment solution providing a platform in India. Workassist provides relevant profiles to employers and relevant jobs to job seekers across different industries and with varying levels of experience leveraging the technology through e-recruitment. Workassist has quickly adapted to the new normal and assists job seekers with the best opportunities and employers with the best talent from all over the world. Get in touch to enhance the job seeking experience as we work with Recruiters from sectors such as Banking & Finance, Consulting, Sales & Marketing, Healthcare, IT and Operations and legal to help them recruit great emerging talents. >>>>For a seamless job search experience, >>>>Visit: https://bit.ly/3ztaKSi … show more Show more","About the job Work Level : Individual Core : Responsible Leadership : Team Alignment Industry Type : Information Technology Function : Database Administrator Key Skills : mSQL,SQL Writing,PLSQL Education : Graduate Note: This is a requirement for one of the Workassist Hiring Partner Responsibilities Write, optimize, and maintain SQL queries, stored procedures, and functions. This is a Remote Position. Assist in designing and managing relational databases. Perform data extraction, transformation, and loading (ETL) tasks. Ensure database integrity, security, and performance. Work with developers to integrate databases into applications. Support data analysis and reporting by writing complex queries. Document database structures, processes, and best practices. Company Description Workassist is an online recruitment and employment solution platform based in Lucknow, India. We provide relevant profiles to employers and connect job seekers with the best opportunities across various industries. With a network of over 10,000+ recruiters, we help employers recruit talented individuals from sectors such as Banking & Finance, Consulting, Sales & Marketing, HR, IT, Operations, and Legal. We have adapted to the new normal and strive to provide a seamless job search experience for job seekers worldwide. Our goal is to enhance the job seeking experience by leveraging technology and matching job seekers with the right employers. For a seamless job search experience, visit our website: https://bit.ly/3QBfBU2 (Note: There are many more opportunities apart from this on the portal. Depending on the skills, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",,,"SQL, Data Analysis",
4228841594,Senior AI Engineer - REMOTE,Uplers,"Nashik, Maharashtra, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4252678068,FS-RC- EY Comply and RVS-AI Engineer-Senior,EY,"Kolkata, West Bengal, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. Position: Senior - AI Engineer Job Summary: As an AI Engineer, you will be responsible for designing, developing, and implementing AI models and algorithms that solve complex problems and enhance our products and services. You will work closely with software engineers, business users and product managers to create intelligent systems that leverage machine learning and artificial intelligence. Responsibilities: Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. Proficiency in Generative AI: Strong understanding of GPT architecture, prompt engineering, embeddings , efficient token usage and agentic AI solutions (example async, batching, caching, piping solutions etc ). Hands-on Experience with Model Training: Demonstrated ability to train and fine-tune AI/ML models, particularly in natural language processing (NLP). Expertise in Deep Learning Frameworks: Familiarity with popular deep learning libraries such as TensorFlow, PyTorch, or similar tools. NLP Techniques: Experience with various NLP techniques, namely using AI to extract the contents from unstructured complex PDF documents. Knowledge of deep learning techniques and neural networks. Strong communication skills to convey complex technical concepts to non-technical stakeholders. Skills requirement: 4 – 6 years of hands on experience developing AI solutions. Strong programming skills in languages such as Python. Strong experience with SQL, RESTful API, JSON Experience with Azure Cloud resources is preferable. Familiarity with DevOps practices and tools. Exposure to any noSQL Databases (MongoDB, Cosmos DB and etc) is a plus EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",manager,,"Python, SQL, Machine Learning",
4256419293,Qlik sense Developer,Virtusa,"Chennai, Tamil Nadu, India (Hybrid)",Hybrid,Full-time,,"About the job Hands on design & development experience in Reporting following the process. Deeloping visual reports, dashboards and KPI scorecards using Qliksense Connecting to data sources, importing data and transforming data for Business Intelligence. Excellent in analytical thinking for translating data into informative visuals and reports. Building Analysis Services reporting models. Communicate effectively with both business, technical stakeholders Preparing complete documentation for the dashboard/Model developed. Analyze and optimize performance of the models/Dashboards. Ability to work independently to implement a solution with minimal guidance. Qualifications / Experience 4+ years Information Technology and Demonstrate experience with Agile (Scrum) and DevOps software development methodologies.Good Knowledge in SDLC life cycle and processes followed. Demonstrated Experience With The Following Developing dashboards in Qliksense Job Scheduling/Procedure Analysis Performance tuning Data source types: Oracle,PostGres RDBMS concepts and principles with advanced PL/SQL skills Bachelor of Science or equivalent in Computer Science, Computer / Electronics Engineering. Skills Demonstrated experience implementing Reporting Capabilies Qliksense Strong SQL skills and ability to analyse and backtrack for related issues. Results driven, with strong analytical and problem-solving skills Work Independently with minimal guidance. Excellent Communications skills Desired Skills and Experience Database Concepts",,,SQL,
4171844453,"Business Intelligence Engineer, DSP Analytics",Amazon,"Hyderabad, Telangana, India",,Full-time,,"About the job Description Do you enjoy diving deep into data, building data models and developing business metrics to generate actionable insights? Are you looking for an opportunity to define end to end analytics roadmap, work with cross functional teams and leverage cutting edge modern technologies and cloud solutions to develop analytics products. DSP Analytics team has an exciting opportunity for a Business Intelligence Engineer (BIE) to improve Amazon’s Delivery Service Partner (DSP) program through impactful data solutions. The goal of Amazon’s DSP organization is to exceed the expectations of our customers by ensuring that their orders, no matter how large or small, are delivered as quickly, accurately, and cost effectively as possible. To meet this goal, Amazon is continually striving to innovate and provide best in class delivery experience through the introduction of pioneering new products and services in the last mile delivery space. We are looking for an innovative, highly-motivated and experienced BIE who can think holistically about problems to understand how systems work together to identify and execute both tactical and strategic projects. You will work closely with engineering teams, product managers, program managers and org leaders to deliver end-to-end data solutions aimed at continuously enhancing overall DSP performance and delivery quality. The business coverage is broad, and you will identify and prioritize what matters most for the business, quantify what is (or is not) working, invent and simplify the current process and develop self-serve data and reporting solutions. You should have excellent business and communication skills to be able to work with business owners to define roadmap, develop milestones, define key business questions, and build data-sets that answers those questions. The ideal candidate should have hands-on SQL and scripting language experience and excel in designing, implementing, and operating stable, scalable, low-cost solutions to flow data from production systems into the data warehouse and into end-user facing applications. Key job responsibilities Lead the design, implementation, and delivery of BI solutions for the Sub-Same Day (SSD) DSP Performance. Manage and execute entire projects from start to finish including stakeholder management, data gathering and manipulation, modeling, problem solving, and communication of insights and recommendations. Extract, transform, and load data from many data sources using SQL, Scripting and other ETL tools. Design, build, and maintain automated reporting, dashboards, and ongoing analysis to enable data driven decisions across our team and with partner teams. Report key insight trends using statistical rigor to simplify and inform the larger team of noteworthy trends that impact the business. Retrieve and analyze data using a broad set of Amazon’s data technologies (ex. Redshift, AWS S3, Amazon Internal Platforms/Solutions) and resources, knowing how, when, and which to use. Earn the trust of your customers and stakeholders by continuing to constantly obsess over their business use cases and data needs, and helping them solve their problems by leveraging technology. Work closely with business stakeholders and senior leadership team to review roadmap and contributing to business strategy and how they can leverage analytics for success. About The Team We are the core Amazon DSP BI team with the vision to enable data, insights and science driven decision-making. We have exceptionally talented and fun loving team members. In our team, you will have the opportunity to dive deep into complex business and data problems, drive large scale technical solutions and raise the bar for operational excellence. We love to share ideas and learning with each other. We are a relatively new team and do not carry legacy operational burden. We believe in promoting and using ideas to disrupt the status quo. Per the internal transfers guidelines, please reach out to the hiring manager for an informational through the ""Request Informational"" button on the job page. Basic Qualifications 3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience Experience with data modeling, warehousing and building ETL pipelines Experience with data visualization using Tableau, Quicksight, or similar tools Experience writing complex SQL queries Experience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling Experience in Statistical Analysis packages such as R, SAS and Matlab Preferred Qualifications Experience with AWS solutions such as EC2, DynamoDB, S3, and Redshift Experience in data mining, ETL, etc. and using databases in a business environment with large-scale, complex datasets Experience developing and presenting recommendations of new metrics allowing better understanding of the performance of the business Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - Amazon Dev Center India - Hyderabad Job ID: A2915502",manager,,"Python, SQL, Excel, Tableau, R",
4255442803,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4252295511,AI Engineer Advisor,NTT DATA North America,"Bengaluru East, Karnataka, India",,Full-time,,"About the job Req ID: 327836 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a AI Engineer Advisor to join our team in Bangalore, Karnātaka (IN-KA), India (IN). Job Duties: Key Responsibilities: Define project scope, goals, deliverables, and timeline. Develop detailed project plans, schedules, and resource allocation. Manage the Statement of Work (SOW) to clearly define project requirements and deliverables. Monitor and track project progress, resolving any issues that arise. Communicate updates effectively with stakeholders and team members. Manage and track project budgets, ensuring cost-efficiency and alignment with financial goals. Oversee and approve timesheets to ensure accurate tracking of project hours and resource utilization. Conduct risk assessments and develop mitigation strategies. Ensure adherence to project standards, guidelines, and best practices. Lead cross-functional teams, fostering collaboration and productivity. Provide post-project evaluations and recommend process improvements. Minimum Skills Required: Qualifications: Bachelor’s degree in [relevant field, e.g., Business Administration, Engineering, or related]. 10 + years of experience in project management. Strong knowledge of project management tools and methodologies (e.g., Agile, Scrum, or Waterfall). Excellent communication, leadership, and organizational skills. Proficiency in tools like [list relevant software, e.g., Microsoft Project, Jira. Experience managing SOWs, budgets, and timesheets. Project Management Professional (PMP) certification is a plus About NTT DATA NTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com NTT DATA endeavors to make https://us.nttdata.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at https://us.nttdata.com/en/contact-us . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you'd like more information on your EEO rights under the law, please click here . For Pay Transparency information, please click here .",,,R,
4257566898,JAVA DEVELOPER,Tata Consultancy Services,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Hi {fullName} There is an opportunity for JAVA MICROSERVICES IN NOIDA for which WALKIN interview is there on 12th JULY 25 between 9:30 AM TO 12:30 PM PLS SHARE below details to mamidi.p@tcs.com with subject line as JAVA MICROSERVICES12TH JULY 25 if you are interested Email id: Contact no: Total EXP: Preferred Location: CURRENT CTC: EXPECTED CTC: NOTICE PERIOD: CURRENT ORGANIZATION: HIGHEST QUALIFICATION THAT IS FULL TIME : HIGHEST QUALIFICATION UNIVERSITY: ANY GAP IN EDUCATION OR EMPLOYMENT: IF YES HOW MANY YEARS AND REASON FOR GAP: ARE U AVAILABLE FOR WALKIN INTERVIEW AT NOIDA ON 12TH JULY 25(YES/NO): We will share a mail to you by tom Night if you are shortlisted. PLS FIND JD BELOW Java Developer Java 8, Spring, Hibernate/JPA, Micro Services Java 8, Spring, Hibernate/JPA, Micro Services API Thanks & Regards Priyanka Talent Acquisition Group Tata Consultancy Services",,,,
4244783886,Infra AI Automation Programmers,Infosys,"Bengaluru East, Karnataka, India",,Full-time,,"About the job At least 2+ years of programming experience in Python Handson experience in working on Gen AI Handson experience in Tensorflow, Pytorch, Langchain and Prompt Engineering Experience with vector databases and retrieval-augmented generation (RAG). Familiarity with MLOps principles and tools for deploying and managing Gen AI models. Understanding of ethical considerations and responsible AI frameworks. Understanding of data structures, data modelling , SQL & NOSQL Object oriented and functional programming & GIT Knowledge of basic algorithms and object-oriented and functional design principles Deep Knowledge of Mathematics, Probability, Statistics, and Algorithms Good Communication skills Good analytical and problem-solving skills As an Infra AI Automation Programmer you will work on design, development, and deployment of AI systems that generate content or data, often using techniques such as deep learning, neural networks, and generative models using Python backend coding. Meet with clients in and remotely to understand their business objectives, challenges, and identify potential use cases for Generative AI. Assess the client's existing technology infrastructure, data landscape, and AI maturity to determine the feasibility and best approaches for Gen AI adoption. Conduct workshops and discovery sessions to brainstorm Gen AI applications across various business functions (e.g., content creation, customer service, product development, marketing). Gen AI Strategy and Solution Design: Develop tailored Gen AI strategies and roadmaps for clients in outlining specific use cases, implementation plans, and expected business outcomes. Design Gen AI solutions architecture, considering factors such as model selection (e.g., large language models (LLMs), diffusion models), data requirements, integration with existing systems, and scalability. Evaluate and recommend appropriate Gen AI platforms, tools, and APIs (e.g., OpenAI, Google AI, Azure AI, open-source libraries) relevant to the client's needs and the Indian market. Advise on prompt engineering techniques to optimize the output and performance of Gen AI models for specific client applications. Besides the professional qualifications of the candidates, we place great importance in addition to various forms personality profile. These include: High analytical skills A high degree of initiative and flexibility High customer orientation High quality awareness Excellent verbal and written communication skills",,,"Python, SQL",
4248028428,AI Prompt Engineer – Finance Domain Expert (PhD/Masters),TELUS Digital AI Data Solutions,"Chennai, Tamil Nadu, India (Remote)",Remote,Part-time,,"About the job We are seeking a highly skilled Finance Specialists who possess a PhD/Masters to join our AI team as a Prompt Engineer. In this role, you will develop complex user prompts that incorporate pairs of mathematical skills in a non-trivial manner. Your work will contribute to cutting-edge approaches in AI data development and help illuminate the limitations of modern AI models. Key Responsibilities Develop intricate, domain-specific mathematical questions to probe AI model capabilities Create content that combine multiple mathematical concepts in innovative ways. You will create and review model responses to contribute to the improvement of AI model performance in mathematical reasoning. Project Details Duration: March to June 2025 Work Schedule: 3-4 hours per day in a freelance capacity. Location: Remote India residents only Mandatory: As part of your application you must have your CV and relevant qualifications uploaded in your application as it will impact your ability to undertake work with us if not provided. Payment rate The payment rate is in USD. If you are a holder of a PhD Degree USD 30 If you hold a Master Degree USD 20 This is an Independent Contractor opportunity. Payments will be issued through our TELUS Digital AI Community Platform. Qualification path Requirements PhD or Master's Degree in Finance, Business, Economics or a related field Strong background in advanced mathematics Excellent analytical and problem-solving skills Ability to think creatively and develop challenging mathematical scenarios Familiarity with AI and machine learning concepts (preferred) Strong written communication skills in English Desktop or Laptop Stable Internet Connection for the duration of the task If interested, please apply here: https://www.telusinternational.ai/cmp/contributor/jobs/available/126437?utm_source=Linkedin&utm_medium=Ads&utm_campaign=SHTArianne_APAC_Paid+Site_Linkedin_Ads_126437 Once you’ve completed your application through the link, kindly notify us by emailing tip_ai_crowdsourcing_apac@telusinternational.com so we can assist in tracking the progress of your application.",,,Machine Learning,
4169911924,AI / ML Engineer,Grootan Technologies,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Responsibilities Work with Python, LLM/GenAI frameworks, and tools for AI/ML end-to-end solutions development. CI/CD pipeline development, LLM model containerizing, and deployment on cloud or premise. Models testing and follow-up maintenance. All stages of the ML model life cycle ensure and support. Design prototypes and POCs to demonstrate solution feasibility and value. Provide architecture solution. Research, design, build, and train innovative applications of LLMs to solve complex real-world problems. Provide technical guidance to clients adopting LLM technologies. Requirements Experience in AI/ML technologies and software engineering, Minimum 1+ years of hands-on experience with Python and shell scripting. 1+ years of experience building and maintaining scalable API solutions. Experience with AWS, GCP, or Microsoft Azure. Experience with MLOps, CI/CD pipeline development, containerization, and model deployment in test and production environments. Be a team player, fluent in English, and ability to communicate complex LLM capabilities and limitations to non-technical stakeholders. This job was posted by Thamizh Selvan DK from Grootan Technologies. Desired Skills and Experience Generative AI,Machine Learning",,,"Python, Machine Learning",
3954673570,"Lead Software Engineer (Python, GenAI, LLM)",EPAM Systems,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job We are seeking a skilled Lead Software Engineer to join our team and lead a project focused on developing GenAI applications using Large Language Models (LLMs) and Python programming . In this role, you will be responsible for designing and optimizing Al-generated text prompts to maximize effectiveness for various applications. You will also collaborate with cross-functional teams to ensure seamless integration of optimized prompts into the overall product or system. Your expertise in prompt engineering principles and techniques will allow you to guide models to desired outcomes and evaluate prompt performance to identify areas for optimization and iteration. Responsibilities Design, develop, test and refine AI-generated text prompts to maximize effectiveness for various applications Ensure seamless integration of optimized prompts into the overall product or system Rigorously evaluate prompt performance using metrics and user feedback Collaborate with cross-functional teams to understand requirements and ensure prompts align with business goals and user needs Document prompt engineering processes and outcomes, educate teams on prompt best practices and keep updated on the latest AI advancements to bring innovative solutions to the project Requirements 7 to 12 years of relevant professional experience Expertise in Python programming including experience with Al/machine learning frameworks like TensorFlow, PyTorch, Keras, Langchain, MLflow, Promtflow 2-5 years of working knowledge of NLP and LLMs like BERT, GPT-3/4, T5, etc. Knowledge of how these models work and how to fine-tune them Expertise in prompt engineering principles and techniques like chain of thought, in-context learning, tree of thought, etc. Knowledge of retrieval augmented generation (RAG) Strong analytical and problem-solving skills with the ability to think critically and troubleshoot issues Excellent communication skills, both verbal and written in English at a B2+ level for collaborating across teams, explaining technical concepts, and documenting work outcomes",,,"Python, Machine Learning",
4259098534,Back End Developer Trainee,Innovate Solutions,India (Remote),Remote,Full-time,,"About the job Job Title: Back End Developer Trainee Location: Remote Job Type: Internship (Full-Time) Duration: 1–3 Months Stipend: ₹25,000/month Department: Software Development / Engineering Job Summary: We are looking for a highly motivated and technically driven Back End Developer Trainee to join our remote team. This internship is ideal for individuals with a strong foundation in server-side development who are eager to gain hands-on experience working on real-world applications, APIs, and databases. Key Responsibilities: Assist in building and maintaining server-side logic, APIs, and databases Write clean, scalable, and efficient code using languages such as Python, Node.js, or Java Help integrate front-end elements with server-side logic Work with databases (e.g., MySQL, PostgreSQL, MongoDB) to store and manage data Participate in testing, debugging, and performance tuning of backend systems Document code and backend processes for clarity and maintainability Qualifications: Bachelor’s degree (or final year student) in Computer Science, IT, or a related field Solid understanding of one or more backend languages (Python, Node.js, Java, etc.) Basic knowledge of RESTful API design and development Familiarity with relational and/or NoSQL databases Good problem-solving and analytical skills Ability to work independently in a remote environment Preferred Skills (Nice to Have): Experience with version control systems like Git Familiarity with frameworks (e.g., Express.js, Django, Spring Boot) Understanding of authentication, authorization, and secure coding practices Exposure to Docker, cloud platforms, or CI/CD pipelines is a plus What We Offer: Monthly stipend of ₹25,000 Remote work opportunity Mentorship and training from experienced backend engineers Involvement in real-world projects and live systems Certificate of Completion Potential for a full-time opportunity based on performance",,,Python,
4228838861,Senior AI Engineer - REMOTE,Uplers,"Dehradun, Uttarakhand, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4204050699,Data Engineer (PySpark),Virtusa,"Chennai, Tamil Nadu, India (Hybrid)",Hybrid,Full-time,,"About the job About The Role We are seeking a highly skilled Data Engineer with deep expertise in PySpark and the Cloudera Data Platform (CDP) to join our data engineering team. As a Data Engineer, you will be responsible for designing, developing, and maintaining scalable data pipelines that ensure high data quality and availability across the organization. This role requires a strong background in big data ecosystems, cloud-native tools, and advanced data processing techniques. The ideal candidate has hands-on experience with data ingestion, transformation, and optimization on the Cloudera Data Platform, along with a proven track record of implementing data engineering best practices. You will work closely with other data engineers to build solutions that drive impactful business insights. Responsibilities Data Pipeline Development: Design, develop, and maintain highly scalable and optimized ETL pipelines using PySpark on the Cloudera Data Platform, ensuring data integrity and accuracy. Data Ingestion: Implement and manage data ingestion processes from a variety of sources (e.g., relational databases, APIs, file systems) to the data lake or data warehouse on CDP. Data Transformation and Processing: Use PySpark to process, cleanse, and transform large datasets into meaningful formats that support analytical needs and business requirements. Performance Optimization: Conduct performance tuning of PySpark code and Cloudera components, optimizing resource utilization and reducing runtime of ETL processes. Data Quality and Validation: Implement data quality checks, monitoring, and validation routines to ensure data accuracy and reliability throughout the pipeline. Automation and Orchestration: Automate data workflows using tools like Apache Oozie, Airflow, or similar orchestration tools within the Cloudera ecosystem. Education and Experience Bachelors or Masters degree in Computer Science, Data Engineering, Information Systems, or a related field. 3+ years of experience as a Data Engineer, with a strong focus on PySpark and the Cloudera Data Platform. Technical Skills PySpark: Advanced proficiency in PySpark, including working with RDDs, DataFrames, and optimization techniques. Cloudera Data Platform: Strong experience with Cloudera Data Platform (CDP) components, including Cloudera Manager, Hive, Impala, HDFS, and HBase. Data Warehousing: Knowledge of data warehousing concepts, ETL best practices, and experience with SQL-based tools (e.g., Hive, Impala). Big Data Technologies: Familiarity with Hadoop, Kafka, and other distributed computing tools. Orchestration and Scheduling: Experience with Apache Oozie, Airflow, or similar orchestration frameworks. Scripting and Automation: Strong scripting skills in Linux. Desired Skills and Experience Operations Management",Manager,,SQL,
4255440925,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4236228657,Machine Learning Engineer,Infosys,"Bengaluru East, Karnataka, India (On-site)",On-site,Full-time,,"About the job Education and Experience: Overall, 6 to 8 years of experience in Data driven software engineering with 3-5 years of experience designing, building and deploying enterprise AI or ML applications with at least 2 years of experience implementing full lifecycle ML automation using MLOps(scalable development to deployment of complex data science workflows) Bachelors or Master’s degree in Computer Science Engineering or equivalent Domain experience in Retail, CPG and Logistics etc. Azure Certified – DP100, AZ/AI900 Technical knowledge- has expertise in cloud technologies, specifically MS Azure, and services with hands on coding to – Expertise in Object Oriented Python Programming with 4 -5 years’ experience. DevOps Working knowledge with implementation experience - 1 or 2 projects a minimum Hands-On MS Azure Cloud knowledge Understand and take requirements on Operationalization of ML Models from Data Scientist Help team with ML Pipelines from creation to execution List Azure services required for deployment, Azure Data bricks and Azure DevOps Setup Assist team to coding standards (flake8 etc) Guide team to debug on issues with pipeline failures Engage with Business / Stakeholders with status update on progress of development and issue fix Automation, Technology and Process Improvement for the deployed projects Setup Standards related to Coding, Pipelines and Documentation Adhere to KPI / SLA for Pipeline Run, Execution Research on new topics, services and enhancements in Cloud Technologies Domain / Technical / Tools Knowledge: Object oriented programming, coding standards, architecture & design patterns, Config management, Package Management, Logging, documentation Experience in Test Driven Development and experience in using Pytest frameworks, git version control, Rest APIs Azure ML best practices in environment management, run time configurations (Azure ML & Databricks clusters), alerts. Experience designing and implementing ML Systems & pipelines, MLOps practices and tools such a MLFlow, Kubernetes, etc. Exposure to event driven orchestration, Online Model deployment Contribute towards establishing best practices in MLOps Systems development Proficiency with data analysis tools (e.g., SQL, R & Python) High level understanding of database concepts/reporting & Data Science concepts Hands on experience in working with client IT/Business teams in gathering business requirement and converting into requirement for development team Experience in managing client relationship and developing business cases for opportunities Azure AZ-900 Certification with Azure Architecture understanding is a plus",,,"Python, SQL, R, Data Analysis",
4259083338,Salesforce Developer,TELUS Digital,"Noida, Uttar Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job Role: Salesforce Developer Location: Noida- Hybrid J ob Description: Must have specialized skills listed under the specializations tab. Follows company software development lifecycle to design, code, configure, test, debug, and document system and application programs. Assists in preparing technical design specifications based on functional requirements and analysis documents. Reviews functional requirements, analysis and design documents and provides feedback. Collaborates with other development staff to achieve quality and consistency. Participates in architecture, design and code reviews. Develops and maintains operational and system level documentation Use Apex to execute flow and transaction control statements on Salesforce servers in conjunction with calls to the API. Use Lightning Component, Visualforce, and JavaScript UI frameworks for developing single page applications for desktop and mobile in the Salesforce application. Use web services, including SOAP API, REST API, Bulk API, and Metadata API, to integrate Salesforce with systems and create APIs that can be consumed by external applications. Use SOQL and SOSL Salesforce database languages to search Salesforce data using field based and text-based search queries. Strong expertise in code optimization & various design pattern techniques Strong expertise in data modeling and backend logic(Apex) Strong expertise Lightning web component Experience working with Version control software (GIT, SVN etc.) Experience working in an agile environment Ability to deliver against several initiatives simultaneously Ability to prioritize and organize effectively Excellent written and verbal communication skills Excellent analytical and troubleshooting abilities About Us: At TELUS Digital, we enable customer experience innovation through spirited teamwork, agile thinking, and a caring culture that puts customers first. TELUS Digital is the global arm of TELUS Corporation, one of the largest telecommunications service providers in Canada. We deliver contact center and business process outsourcing (BPO) solutions to some of the world's largest corporations in the consumer electronics, finance, telecommunications and utilities sectors. With global call center delivery capabilities, our multi-shore, multi-language programs offer safe, secure infrastructure, value-based pricing, skills-based resources and exceptional customer service - all backed by TELUS, our multi-billion dollar telecommunications parent.",,,,
4250538895,Gen AI Senior Developer,Tata Consultancy Services,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Job Role - Gen AI Senior Developer Experience Range: 5 to 10 years Job Location: Hyderabad Job Description Must Have: Advanced programming knowledge , including mastery of programming languages such as Python, and especially AI-centric libraries like TensorFlow , PyTorch, and Keras. This includes the ability to implement and manipulate complex algorithms fundamental to developing generative AI models. Expertise in generative models such as generative adversarial networks (GANs) and variational autoencoders (VAEs). The candidate should be able to design, train, and optimize these models to generate high-quality, creative content. Natural language processing (NLP) for text generation projects. This includes familiarity with techniques for text parsing, sentiment analysis, and the use of transformers like GPT (generative pre-trained transformer) models. Data management knowledge, including data pre-processing, augmentation, and generation of synthetic data. This involves cleaning, labeling, and augmenting data to train and improve AI models. Cloud computing and deployment knowledge for deploying and managing AI applications on cloud platforms like AWS, Google Cloud, or Microsoft Azure . This includes understanding containerization technologies like Docker and orchestration tools like Kubernetes, which are important for scaling AI solutions.",,,Python,
4220651924,"Data Engineer, AFT BI Content",Amazon,"Hyderabad, Telangana, India",,Full-time,,"About the job Description Have you ever ordered a product from Amazon and been amazed at how fast it gets to you? Every day Amazon engineers are relentlessly working to decrease the time between Click to Deliver for your products. The Amazon Fulfillment Technologies (AFT) team owns all of the software and infrastructure which powers Amazon's world-class fulfillment engine. Our team is building complex, massive data systems to capture data during every step in the automated pipeline and use that data to proactively predict efficiency and cost improvements to deliver the packages fast to our customers. As an Amazon.com Big Data Engineer you will be working in one of the world's largest and most complex data warehouse environments. You should be skilled in the architecture of DW solutions for the Enterprise using multiple platforms (RDBMS, Columnar, Cloud). You should have experience in the design, creation, management, and business use of extremely large data-sets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all, you should be passionate about working with huge data sets and someone who loves to bring data-sets together to answer business questions and drive change. As a Big Data Engineer in this role, you will develop new data engineering patterns that leverage a new cloud architecture, and will extend or migrate our existing data pipelines to this architecture as needed. You will also be assisting with integrating the Redshift platform as our primary processing platform to create the curated Amazon.com data model for the enterprise to leverage. You will be part of a team that builds the next generation data warehouse platform and to drive the adoption of new technologies and new practices in existing implementations. You will be responsible for designing and implementing the complex ETL pipelines in data warehouse platform and other BI solutions to support the rapidly growing and dynamic business demand for data, and use it to deliver the data as service which will have an immediate influence on day-to-day decision-making at Amazon.com. About The Team Amazon Fulfillment Technologies (AFT) powers Amazon’s global fulfillment network. We invent and deliver software, hardware, and data science solutions that orchestrate processes, robots, machines, and people. We harmonize the physical and virtual world so Amazon customers can get what they want, when they want it. Basic Qualifications 3+ years of data engineering experience 4+ years of SQL experience Experience with data modeling, warehousing and building ETL pipelines Preferred Qualifications Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases) Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI HYD 13 SEZ Job ID: A2971024",,,SQL,
4256422217,Application Developer-SAP ABAP HANA,IBM,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology. As an Application Developer, you will lead IBM into the future by translating system requirements into the design and development of customized systems in an agile environment. The success of IBM is in your hands as you transform vital business needs into code and drive innovation. Your work will power IBM and its clients globally, collaborating and integrating code into enterprise systems. You will have access to the latest education, tools and technology, and a limitless career path with the world’s technology leader. Come to IBM and make a global impact! Your Role And Responsibilities Responsible to design, develop and/or re-engineer highly complex application components and integrate software packages, programs and reusable objects residing on multiple platforms. Responsible to Designs, development of applications in one or more of the areas like SAP Portal, SAP Fiori, SAP UI5, SAP Mobile Platform (SMP), SAP Cloud Platform Mobile Services (SCPMs). Customization to standard application in case required. Experience in working in Implementation, Upgrade, Maintenance and Postproduction support projects would be an advantage. Practitioner must willing to travel to client location for the Project duration Ability to create Screens, Controllers, OData DPC and MPC. Hands-on HTML5, JS, CSS3 coding experience. SAP Web IDE, SAP Frontend Server Experience. Preferred Education Master's Degree Required Technical And Professional Expertise BE / B Tech in any stream, M.Sc. (Computer Science/IT) / M.C.A, Min. 2-4 years of work experience in SAP Portal, SAP Fiori, SAP UI5, SAP Mobile Platform (SMP), SAP Cloud Platform Mobile Services (SCPMs Experience in Business Application Programming Interface and XI (Exchange Infrastructure) and Extensive experience in SAPUI5 application development Experience in MVC framework for UI, SAPUI5, HTML5, and JavaScript and Expertise in SAPUI5 controls and Fiori Design patterns Understanding of SAP functional requirement, conversion into technical design and development using ABAP Language for Report, Interface, Conversion, Enhancement and Forms in implementation or support project: Minimum 3-4 implementation experience Expertise in Fiori application and system architecture and Exposure in SAP Fiori Launchpad configuration and app integration Preferred Technical And Professional Experience Cement industry business knowledge is preferable. Knowledge and experience on SAP Workflow and Good experience in OData. Understanding of SAP functional requirement, conversion into technical design and development using ABAP Language for Report, Interface, Conversion, Enhancement and Forms in implementation or support project: Minimum 3-4 implementation experience",,,,
4222043356,EY - GDS Consulting - AI Enabled Automation - AI Engineer - Staff,EY,"Kanayannur, Kerala, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. AI Engineer Role Overview: We are seeking a highly skilled and experienced AI Engineers with a minimum of 2 years of experience in Data Science and Machine Learning, preferably with experience in NLP, Generative AI, LLMs, MLOps, Optimization techniques, and AI solution Architecture. In this role, you will play a key role in the development and implementation of AI solutions, leveraging your technical expertise. The ideal candidate should have a deep understanding of AI technologies and experience in designing and implementing cutting-edge AI models and systems. Additionally, expertise in data engineering, DevOps, and MLOps practices will be valuable in this role. Your technical responsibilities: Assist in the development and implementation of AI models and systems, leveraging techniques such as Large Language Models (LLMs) and generative AI. Design, develop, and maintain efficient, reusable, and reliable Python code Stay updated with the latest advancements in generative AI techniques, such as LLMs, and evaluate their potential applications in solving enterprise challenges. Utilize generative AI techniques, such as LLMs, Agentic Framework to develop innovative solutions for enterprise industry use cases. Integrate with relevant APIs and libraries, such as Azure Open AI GPT models and Hugging Face Transformers, to leverage pre-trained models and enhance generative AI capabilities. Utilize vector databases, such as Redis, and NoSQL databases to efficiently handle large-scale generative AI datasets and outputs. Implement similarity search algorithms and techniques to enable efficient and accurate retrieval of relevant information from generative AI outputs. Ensure compliance with data privacy, security, and ethical considerations in AI applications. Leverage data engineering skills to curate, clean, and preprocess large-scale datasets for generative AI applications. Write unit tests and conduct code reviews to ensure high-quality, bug-free software. Troubleshoot and debug applications to optimize performance and fix issues. Work with databases (SQL, NoSQL) and integrate third-party APIs. Requirements: Bachelor's or Master's degree in Computer Science, Engineering, or a related field. Minimum 2 years of experience in Python, Data Science, Machine Learning, OCR and document intelligence In-depth knowledge of machine learning, deep learning, and generative AI techniques. Proficiency in programming languages such as Python, R, and frameworks like TensorFlow or PyTorch. Strong understanding of NLP techniques and frameworks such as BERT, GPT, or Transformer models. Familiarity with computer vision techniques for image recognition, object detection, or image generation. Strong knowledge of Python frameworks such as Django, Flask, or FastAPI. Experience with RESTful API design and development. Experience with cloud platforms such as Azure, AWS, or GCP and deploying AI solutions in a cloud environment. Expertise in data engineering, including data curation, cleaning, and preprocessing. Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions. Strong communication and interpersonal skills, with the ability to collaborate effectively with stakeholders at various levels. Understanding of data privacy, security, and ethical considerations in AI applications. Good to Have Skills: Understanding of agentic AI concepts and frameworks Proficiency in designing or interacting with agent-based AI architectures Apply trusted AI practices to ensure fairness, transparency, and accountability in AI models and systems. Utilize optimization tools and techniques, including MIP (Mixed Integer Programming). Implement CI/CD pipelines for streamlined model deployment and scaling processes. Utilize tools such as Docker, Kubernetes, and Git to build and manage AI pipelines. Apply infrastructure as code (IaC) principles, employing tools like Terraform or CloudFormation. Implement monitoring and logging tools to ensure AI model performance and reliability. EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",,,"Python, SQL, R, Machine Learning",
4259072539,Software Engineer,Workassist,"Pune, Maharashtra, India (On-site)",On-site,Full-time,"Type : Information Technology Function : Quality Analyst Key Skills : Java,Python,Automation Testing,Manual Testing,Docker,Api,Cicd,AWS,Selenium,Kubernetes,JMeter,Karate framework Education : Graduate Note: This is a requirement for one of the Workassist Hiring Partner Your Role: Responsible for designing, developing, and executing comprehensive automation test strategies for microservices-based applications. You will play a critical role in maintaining our code quality and system reliability in CI/CD pipelines by owning both manual and automated quality assurance processes. Desired Technical Competencies & Skills: Develop robust automation frameworks using Java and Python to test APIs and web services. Design test plans and write test cases for microservices using tools such as Selenium/Cucumber/Tester man/Karate. Integrate automated tests within CI/CD pipelines using Jenkins. Perform API testing (manual and automated) for RESTful services. Conduct performance testing using Apache JMeter. Collaborate closely with DevOps to validate applications in Dockerized and Kubernetes environments. Troubleshoot, log, and document defects and improvements across cloud hosted services (preferably AWS). Company Description Workassist is an online recruitment and employment solution platform based in Lucknow, India. We provide relevant profiles to employers and connect job seekers with the best opportunities across various industries. With a network of over 10,000+ recruiters, we help employers recruit talented individuals from sectors such as Banking & Finance, Consulting, Sales & Marketing, HR, IT, Operations, and Legal. We have adapted to the new normal and strive to provide a seamless job search experience for job seekers worldwide. Our goal is to enhance the job seeking experience by leveraging technology and matching job seekers with the right employers. For a seamless job search experience, visit our website: https://bit.ly/3QBfBU2 (Note: There are many more opportunities apart from this on the portal. Depending on the skills, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company Workassist 77,978 followers Follow Staffing and Recruiting 51-200 employees 59 on LinkedIn Workassist is an online recruitment and employment solution providing a platform in India. Workassist provides relevant profiles to employers and relevant jobs to job seekers across different industries and with varying levels of experience leveraging the technology through e-recruitment. Workassist has quickly adapted to the new normal and assists job seekers with the best opportunities and employers with the best talent from all over the world. Get in touch to enhance the job seeking experience as we work with Recruiters from sectors such as Banking & Finance, Consulting, Sales & Marketing, Healthcare, IT and Operations and legal to help them recruit great emerging talents. >>>>For a seamless job search experience, >>>>Visit: https://bit.ly/3ztaKSi … show more Show more","About the job Work Level : Individual Core : Communication Skills, Organized, Adaptable Leadership : Building Work Relationships, Empathy, Working Independently Industry Type : Information Technology Function : Quality Analyst Key Skills : Java,Python,Automation Testing,Manual Testing,Docker,Api,Cicd,AWS,Selenium,Kubernetes,JMeter,Karate framework Education : Graduate Note: This is a requirement for one of the Workassist Hiring Partner Your Role: Responsible for designing, developing, and executing comprehensive automation test strategies for microservices-based applications. You will play a critical role in maintaining our code quality and system reliability in CI/CD pipelines by owning both manual and automated quality assurance processes. Desired Technical Competencies & Skills: Develop robust automation frameworks using Java and Python to test APIs and web services. Design test plans and write test cases for microservices using tools such as Selenium/Cucumber/Tester man/Karate. Integrate automated tests within CI/CD pipelines using Jenkins. Perform API testing (manual and automated) for RESTful services. Conduct performance testing using Apache JMeter. Collaborate closely with DevOps to validate applications in Dockerized and Kubernetes environments. Troubleshoot, log, and document defects and improvements across cloud hosted services (preferably AWS). Company Description Workassist is an online recruitment and employment solution platform based in Lucknow, India. We provide relevant profiles to employers and connect job seekers with the best opportunities across various industries. With a network of over 10,000+ recruiters, we help employers recruit talented individuals from sectors such as Banking & Finance, Consulting, Sales & Marketing, HR, IT, Operations, and Legal. We have adapted to the new normal and strive to provide a seamless job search experience for job seekers worldwide. Our goal is to enhance the job seeking experience by leveraging technology and matching job seekers with the right employers. For a seamless job search experience, visit our website: https://bit.ly/3QBfBU2 (Note: There are many more opportunities apart from this on the portal. Depending on the skills, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",,,Python,
4247104962,Data Engineer,Trillionloans,"Gurugram, Haryana, India (On-site)",On-site,Full-time,,"About the job Responsibilities will include Functional Expertise Collaborating closely with multiple teams to translate the requirements into technical specifications. Offering clear technical guidance and direction to ensure solutions meet user and tech requirements. Leading technical discussions, code reviews to maintain code quality, identify improvement opportunities, and ensure adherence to standards. Staying updated on the latest data engineering trends and applying them to solve complex challenges. Problem Solving & Communication : Strong analytical and problem-solving skills. Excellent communication and collaboration skills. Ability to work independently and as part of a team. Providing guidance and mentorship to other team members , fostering their professional growth and skill development. Experience working with Fintech institutions is a plus. Qualification & Experience (type & industry) B.Tech Degree Skills & know-how Experience level: 3-5 years Minimum 2 years relevant experience in AWS Cloud Data Warehousing experience - Cloud data warehouse - Redshift/SQL In-memory framework exp - Pyspark Data engineering pipeline use case experience : Ingestion of data from different sources to Cloud file system(S3 buckets) and then transforming/processing the data using AWS Glue and finally loading the same to cloud warehouse for Data analytics Big data use cases : Exposure to huge data volumes involving TBs of data for storage/migration/processing. Programming experience in Python Familiarity with Reports/Dashboards using cloud native applications Knowledge of data pipeline orchestration using Airflow - good to have. Understanding of API development",,,"Python, SQL",
4259098996,"Django, python  Trainer Required (only trainers apply)",Are you looking for Corporate Professionals? connect with CertED Technologies.,"Kanpur, Uttar Pradesh, India (On-site)",On-site,Contract,,"About the job Company Description CERTED TECHNOLOGIES is a forward-thinking organization based in Gwalior, Madhya Pradesh, India. They specialize in talent acquisition, corporate & technical training, software development, and CSR project implementation. Their core services include custom software development, corporate & technical training programs, fresher hiring, product prototyping, UI/UX design, and more. Role Description This is a full-time on-site role for a Django, Python Trainer Required at Certed Technologies for kanpur. The Trainer will be responsible for delivering training programs on Django and Python, conducting hands-on sessions, providing guidance to learners, and assessing their progress. Qualifications Expertise in Django and Python development Experience in delivering technical training programs Knowledge of Full Stack Development concepts Strong problem-solving and communication skills Ability to work well in a team environment Relevant certifications in Django, Python, or related technologies",,,Python,
4255103874,Senior Machine Learning Engineer,TRIARQ Health India,"Pune, Maharashtra, India (On-site)",On-site,Full-time,"Type: IT-Software, Software Services Location: Pune, & Nashik Employment Type: Full-Time, Permanent Your Responsibilities Include We are looking for an experienced Machine Learning Engineer to lead the development and deployment of ML models that power intelligent products and insights. You will collaborate with teams across Data Science, Engineering, and Product to build solutions that are scalable, efficient, and impactful. Candidates with exposure to the healthcare domain are encouraged to apply, although this is not a mandatory requirement . Key Responsibilities Architect, build, and maintain end-to-end ML systems — from data pipelines to model deployment. Develop and optimize machine learning models for use cases such as classification, prediction, recommendation, NLP, or computer vision. Implement MLOps best practices for model training, tracking, deployment, and monitoring. Collaborate with data scientists and domain experts to productionize prototypes and research. Evaluate and monitor model performance; ensure robustness, fairness, and explainability. Document architecture and processes; contribute to knowledge sharing and code reviews. (Preferred) Work with EHR data, claims data, clinical notes, or healthcare interoperability formats like HL7 or FHIR, if applicable. Required Skills & Qualifications Bachelor’s or Master’s degree in Computer Science, Machine Learning, Data Science, or related discipline. 5+ years of hands-on experience in ML engineering or applied data science. Strong command of Python and ML libraries (e.g., scikit-learn, TensorFlow, PyTorch, XGBoost). Experience deploying ML models in production using containerization (Docker, Kubernetes) and cloud platforms (AWS/GCP/Azure). Familiarity with MLOps tools like MLflow, DVC, or Kubeflow. Proficient in building ETL/ELT pipelines and handling large-scale datasets. Strong understanding of statistical methods, model evaluation metrics, and optimization techniques. Good software engineering practices (version control, testing, CI/CD). Preferred Qualifications: Exposure to healthcare datasets such as medical claims, EHR/EMR, HL7, FHIR, or medical coding (CPT, ICD-10). Experience with NLP models applied to clinical documentation or unstructured medical data. Understanding of HIPAA compliance, data anonymization, and PHI handling. Contributions to open-source ML projects or peer-reviewed publications. Experience working in regulated industries or mission-critical environments. Desired Skills and Experience Applications Of Artificial Intelligence, machine learning infrastructure Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company TRIARQ Health India 15,565 followers Follow Software Development 501-1,000 employees 340 on LinkedIn TRIARQ Health is a Physician Practice Services company that partners with doctors to run modern patient-centered practices so they can be rewarded for delivering high-value care. TRIARQ’s Physician-led partnerships simplify practices’ transition to value-based care by combining our proprietary, cloud-based practice and care management platform and patient engagement services to help doctors focus on better outcomes. … show more Show more","About the job TRIARQ Health is a Physician Practice Services company that partners with doctors to run modern patient-centered practices so they can be rewarded for delivering high-value care. TRIARQ’s Physician-led partnerships simplify practices’ transition to value-based care by combining our proprietary, cloud-based practice, care management technology platform, and patient engagement services to help doctors focus on better outcomes. Experience: 5+ years Industry Type: IT-Software, Software Services Location: Pune, & Nashik Employment Type: Full-Time, Permanent Your Responsibilities Include We are looking for an experienced Machine Learning Engineer to lead the development and deployment of ML models that power intelligent products and insights. You will collaborate with teams across Data Science, Engineering, and Product to build solutions that are scalable, efficient, and impactful. Candidates with exposure to the healthcare domain are encouraged to apply, although this is not a mandatory requirement . Key Responsibilities Architect, build, and maintain end-to-end ML systems — from data pipelines to model deployment. Develop and optimize machine learning models for use cases such as classification, prediction, recommendation, NLP, or computer vision. Implement MLOps best practices for model training, tracking, deployment, and monitoring. Collaborate with data scientists and domain experts to productionize prototypes and research. Evaluate and monitor model performance; ensure robustness, fairness, and explainability. Document architecture and processes; contribute to knowledge sharing and code reviews. (Preferred) Work with EHR data, claims data, clinical notes, or healthcare interoperability formats like HL7 or FHIR, if applicable. Required Skills & Qualifications Bachelor’s or Master’s degree in Computer Science, Machine Learning, Data Science, or related discipline. 5+ years of hands-on experience in ML engineering or applied data science. Strong command of Python and ML libraries (e.g., scikit-learn, TensorFlow, PyTorch, XGBoost). Experience deploying ML models in production using containerization (Docker, Kubernetes) and cloud platforms (AWS/GCP/Azure). Familiarity with MLOps tools like MLflow, DVC, or Kubeflow. Proficient in building ETL/ELT pipelines and handling large-scale datasets. Strong understanding of statistical methods, model evaluation metrics, and optimization techniques. Good software engineering practices (version control, testing, CI/CD). Preferred Qualifications: Exposure to healthcare datasets such as medical claims, EHR/EMR, HL7, FHIR, or medical coding (CPT, ICD-10). Experience with NLP models applied to clinical documentation or unstructured medical data. Understanding of HIPAA compliance, data anonymization, and PHI handling. Contributions to open-source ML projects or peer-reviewed publications. Experience working in regulated industries or mission-critical environments. Desired Skills and Experience Applications Of Artificial Intelligence, machine learning infrastructure",,,"Python, Machine Learning",
4245855655,AI Developer,Electrolux Group,"Bengaluru, Karnataka, India",,Full-time,,"About the job Be part of something bigger. Decode the future. At Electrolux, as a leading global appliance company, we strive every day to shape living for the better for our consumers, our people and our planet. We share ideas and collaborate so that together, we can develop solutions that deliver enjoyable and sustainable living. Come join us as you are. We believe diverse perspectives make us stronger and more innovative. In our global community of people from 100+ countries, we listen to each other, actively contribute, and grow together. Join us in our exciting quest to build the future home. All about the role: We are seeking a passionate and skilled AI Developer to join our Contact Center initiatives within the CDI Service Platforms team. This role will focus on designing, building, and deploying AI-powered solutions that enhance customer interaction, automate support workflows, and improve operational efficiency. You will work in a cross-functional team together with product owners, data scientists, and software engineers to integrate conversational AI, natural language processing (NLP), and machine learning into our digital post-purchase landscape. This is a high-impact role with opportunities to shape the technical direction of our AI strategy. In this role, you will be reporting to the Engineering Lead for Contact Center and AI. You will work on a daily basis with colleagues remotely that are based in other countries. About the CDI Experience Organization: The Consumer Direct Interaction Experience Organization is a Digital Product Organization responsible for delivering tech solutions to our end-users and consumers across both pre-purchase and post-purchase journeys. We are organized in 15+ digital product areas, providing solutions ranging from Contact Center, E-commerce, Marketing, and Identity to AI. You will play a key role in ensuring the right sizing, right skillset, and core competency across these product areas. What you’ll do: As AI developer at Electrolux, your main tasks will include: Design and develop AI-driven solutions for Contact Center platforms, including chatbots, voicebots, and intelligent routing engines. Contribute to AI architecture decisions and align solutions with enterprise standards and cloud infrastructure. To be constantly improving the functionality of our existing contact center solution. Deliver prototypes, proofs of concept (PoCs), and production-grade implementations that scale. Monitor and improve AI models through testing, tuning, and feedback loops. To collaborate cross-functionally in your own team and across related teams within the organization. To keep yourself updated with the latest developments within contact center AI and the fast-paced environment of generative AI You should be eager to take on new challenges when exploring these new technologies and to think outside of the box Who are you: University degree in computer science, NLP, data science, statistics or related field 3+ years of industry experience with dialog technology, preferably in Google Dialogflow, but similar technologies are also accepted. Profound theoretical understanding of machine learning algorithms, including but not limited to the newest versions of generative AI models. Hands-on experience with this technology is a major plus. Fluent in at least one of the following scripting languages: Python, Node.js, Javascript, Groovy, Perl. Experience with REST APIs, microservices, and cloud-native application design. Hand-on experience with DataScience is a big plus. Previous experience building or integrating AI into Contact Center systems (e.g., Genesys). Very good analytical and conceptual skills paired with a pronounced ability to structure and simplify complex relationships Excellent communication skills are a must due to the cross-functional nature of the roll. Thriving in a multi-lingual, multi-cultural environment Where you'll be: This is a full-time position, based in Bangalore , India Benefits Highlights: Flexible work hours and a hybrid work environment Discounts on our award-winning Electrolux products and services Family-friendly benefits Extensive learning opportunities and a flexible career path",,,"Python, Machine Learning",
4232636550,Artificial Intelligence Engineer,Valuebound,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Job Overview We are seeking a highly skilled and experienced Senior AI/ML Engineer to join our dynamic team. The ideal candidate will have a strong background in machine learning and artificial intelligence. You should have a proven track record of developing and deploying scalable ML solutions. In this role, you will collaborate closely with cross-functional teams to design, implement, and optimize AI-driven products and services. Key Responsibilities Machine Learning Model Development and Deployment: Design, develop, and deploy machine learning models to solve complex business problems. Implement MLOps practices to ensure robust and scalable model deployment. Optimize model performance to ensure scalability and efficiency. Data Analysis and Feature Engineering: Analyze large datasets to extract meaningful insights. Develop and select appropriate features to enhance model performance. Collaborate with data engineers to ensure seamless data integration. Collaboration and Leadership: Work closely with data scientists, software engineers, and product managers to integrate ML solutions into products. Mentor junior team members and provide technical guidance. Communicate technical concepts to both technical and non-technical stakeholders. Research and Innovation: Stay abreast of the latest developments in AI/ML technologies. Evaluate and implement new tools and frameworks to improve existing systems. Drive innovation and continuous improvement in AI/ML solutions. What You'll Do Innovate: Design, develop, and deploy state-of-the-art machine learning models that solve complex problems and drive strategic decisions. Collaborate: Work cross-functionally with data scientists, software engineers, and product managers to integrate AI solutions seamlessly into our products. Lead: Mentor junior team members, fostering a culture of continuous learning and innovation. Optimize: Implement MLOps best practices to ensure scalable, reliable, and efficient model deployment and monitoring. Explore: Stay abreast of the latest advancements in AI/ML, evaluating and integrating new technologies to keep us at the forefront of innovation. Required Qualifications Educational Background: Bachelor's or Master's degree in Computer Science, Data Science, or a related field. Professional Experience: Minimum of 5 years of experience in machine learning engineering or a similar role. Technical Skills: Proficiency in programming languages such as Python or R. Experience with ML frameworks like TensorFlow, PyTorch, or Scikit-learn. Familiarity with cloud platforms (e.g., AWS, GCP, Azure) and containerization tools (e.g., Docker, Kubernetes). Strong understanding of data structures, algorithms, and software engineering principles. Soft Skills: Excellent problem-solving and analytical abilities. Strong communication and teamwork skills. Preferred Qualifications Experience with big data technologies (e.g., Spark, Hadoop). Knowledge of NLP techniques and applications. Familiarity with CI/CD pipelines and version control systems like Git. Contributions to open-source projects or publications in reputable journals. What We Offer Competitive salary and benefits package. Opportunities for professional growth and development. A collaborative and inclusive work environment. Access to cutting-edge technologies and tools. Skills: aws,ai,nlp,tensorflow,machine learning,scikit-learn,data structures,pytorch,r,data analysis,python,algorithms,software engineering,gcp,mlops,ci/cd,gen ai,azure,kubernetes,feature engineering,big data technologies,git,docker,artificial intelligence",manager,,"Python, R, Machine Learning, Data Analysis",
4257579092,Sr. Software Engineer,iCIMS,Greater Hyderabad Area (On-site),On-site,Full-time,,"About the job Job Overview The Sr. Software Engineer will be part of a team of some of the best and brightest in the industry who are focused on full-cycle development of scalable web and responsive applications that touch our growing customer base every day.   As part of the Labs team, you will work collaboratively with agile team members to design new system functionality and to research and remedy complex issues as they arise, embodying a passion for continuous improvement and test-driven development. About Us When you join iCIMS, you join the team helping global companies transform business and the world through the power of talent. Our customers do amazing things: design rocket ships, create vaccines, deliver consumer goods globally, overnight, with a smile. As the Talent Cloud company, we empower these organizations to attract, engage, hire, and advance the right talent. We’re passionate about helping companies build a diverse, winning workforce and about building our home team. We're dedicated to fostering an inclusive, purpose-driven, and innovative work environment where everyone belongs. Responsibilities Expertise and proficiency in many technologies, domains and subsystems Design and implement new features and perform code reviews Develop, test and maintain a scalable web and responsive applications Devise automation strategies, test strategies and test cases to automate new features and enhance existing functionality Using engineering best practices, design, develop, analyze test plans and strategies to meet performance, usability, scalability, reliability and security needs Lead and collaborate with agile team members on achieving Sprint deliverables Ensure proper documentation exists for assigned products Research and resolve complex problems as they arise Proactively search for making improvements in respective modules/features Mentor Software Engineers (I-II) Consistently ensures that business is conducted with integrity at all times and that behavior aligns with iCIMS’ policies, procedures, and core competencies. Qualifications Domain expert in enterprise software development influencing organization best practices. begins to create external value Expertise in one or more of the following back-end or front-end: Java, Python, JavaScript, iOS development (Swift, Objective C), Android development Expertise in one or more of the following frameworks or libraries, such as: Hibernate and Spring, Reactjs and Redux, node.js Advanced proficiency with multiple design patterns including Strategy, Observer, and Bridge Advanced proficiency in test automation tools, such as Selenium Webdriver, Appium or similar tools Advanced proficiency in Java and JavaScript testing frameworks, such as JUnit, TestNG, JEST, Jasmine or similar Expertise in test design, test creation, test execution and defect analysis/root cause investigation Advanced proficiency in multiple best practices such as Test Driven Development (TDD), behavioral-driven development (BDD), Continuous Integration (CI) and Continuous Delivery (CD) Extensive experience utilizing Docker containerization, ability to set-up and modify build and release tools such as, Jenkins and AWS elastic beanstalk. Extensive understanding of software engineering practices, philosophies and techniques Mentor others in following Agile/SCRUM techniques Ability to influence, lead and organize projects across multiple agile teams with a focus on results Strong technologist who can anticipate issues/opportunities and build solutions EEO Statement iCIMS is a place where everyone belongs. We celebrate diversity and are committed to creating an inclusive environment for all employees. Our approach helps us to build a winning team that represents a variety of backgrounds, perspectives, and abilities. So, regardless of how your diversity expresses itself, you can find a home here at iCIMS. We are proud to be an equal opportunity and affirmative action employer. We prohibit discrimination and harassment of any kind based on race, color, religion, national origin, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, veteran status, genetic information, disability, or other applicable legally protected characteristics. If you would like to request an accommodation due to a disability, please contact us at careers@icims.com. Compensation And Benefits Competitive health and wellness benefits include medical insurance (employee and dependent family members), personal accident and group term life insurance, bonding and parental leave, lifestyle spending account reimbursements, wellness services offerings, sick and casual/emergency days, paid holidays, tuition reimbursement, retirals (PF - employer contribution) and gratuity. Benefits and eligibility may vary by location, role, and tenure. Learn more here: https://careers.icims.com/benefits",,,Python,
4255206922,Principal ML Engineer/ ML Scientist,Gloroots,"Gurugram, Haryana, India (On-site)",On-site,Full-time,,"About the job Role : Founding Principal ML Engineer/ ML Scientist Function : Applied AI Compensation : 50-100 LPA + ESOPs About the Company: A venture-backed, stealth-stage technology company building next-gen matchmaking and relationship platforms is hiring their founding AI/ML & Data Engineering Team. They are on a mission to reimagine how people connect, using AI, community, and content as the building blocks. They’re not building just another dating app — they’re creating an experience where users feel: “This app gets me.” At the core of the product are real-time, ML recommendation engines — similar to Spotify for song moods or TikTok for discovery. They are well funded and backed by marquee VCs in India and US. Company Philosophy: Core belief: Great data + Good models = Great recommendations Good data + Great models = Average recommendations That’s why they’re investing in data infrastructure from the inception and foundation. Position Overview: As the founding ML engineer, you’ll design and deploy the core recommendation and personalisation systems that power the matchmaking experience. You’ll own the full lifecycle - from design to deployment - while laying the foundation for scalable, real-time ranking infrastructure. Role & Responsibilities: Own and develop match-making, recommendation, ranking and personalisation systems. Work on creating a novel, real-time adaptive matchmaking engine that learns from user interactions and other signals Design ranking and recommendation algorithms that make each user's feed feel curated for them Build user embedding systems, similarity models, and graph-based match scoring frameworks Explore and integrate cold-start solutions Partner with Data + Product + Backend teams to deliver great customer experiences Deploy models to production using fast iteration loops, model registries, and observability tooling Build the ML engineering team and culture Ideal Profile: You are a full-stack ML data scientist-engineer who can design, model, and deploy recommendation systems and ideally have led initiatives in recsys, feed ranking, or search 3–10 years of experience working on personalisation, recommendations, search, or ranking at scale Prior experience in a B2C product – social, ecommerce, fashion, dating, gaming, or video platforms Exposure to a wide range of popular recommendation and personalisation techniques, including collaborative filtering, deep retrieval models (e.g., two-tower), learning-to-rank, embeddings with ANN search, and LLM approaches for sparse data personalisation. Can train models AND ship them – experience with end-to-end ML pipelines Understands offline and online evaluation, A/B testing, and metric alignment Experience with vector search, graph-based algorithms and LLM-based approaches is a big plus What the role offers: Join a founding team where your work is core to the product experience Shape the future of how humans connect in the AI era Significant ESOPs and wealth creation + competitive cash compensation",,,,
4218035617,Sr. ML Engineer,Visa,"Bengaluru East, Karnataka, India (On-site)",On-site,Full-time,,"About the job Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose – to uplift everyone, everywhere by being the best way to pay and be paid. Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa. Job Description Payments has become a very active/hot area in the last couple of years, creating a strong demand for innovation. This will be a very exciting area in the next 5 to 10 years. Not only is VISA a leader in the payment industry and has been for a long time, but it is also quickly transitioning into a technology company that is fostering an environment for applying the latest technology to solve exciting problems in this area. Visa AI as a Service (AIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, AIaS automates the updates to data, models, and applications. Combined with strong AI governance, AIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you! This position is for a Staff Data Engineer with solid development experience who will focus on creating new capabilities for AI as a Service while maturing our code base and development processes. In this position, you are first a passionate and talented developer that can work in a dynamic environment as a member of Agile Scrum teams. Your strong technical leadership, problem-solving abilities, coding, testing and debugging skills is just a start. You must be dedicated to filling product backlog and delivering production-ready code. You must be willing to go beyond the routine and prepared to do a little bit of everything. You will be an integral part of the development team, sometimes investigating new requirements and design and at times refactoring existing functionality for performance and maintainability, but always working on ways to make us more efficient and provide better solutions to our end customers. The role is for a self-organized individual with knowledge of web application and web service development. The candidate will perform hands-on activities including design, documentation, development and test of new functionality. Candidate must be flexible and willing to switch tasks based on team’s needs. This position will be based in Bangalore, India. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us. Essential Functions Collaborate with project teams, data science teams and development teams to drive the technical roadmap and guide development and implementation of new data driven business solutions. Drive technical standard and best practices, and continuously improve AI Platform engineering scalability. Architecture and design of AI Platform services including Machine Learning Engines, In Memory Computing Systems, Streaming Computing Systems, Distributed Data Systems and etc., in Golang, Java, and Python. Coordinate the implementation among development teams to ensure system performance, security, scalability and availability. Coaching and mentoring junior team members and evolving team talent pipeline. This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs. Qualifications Basic Qualifications 2+ years of relevant work experience and a Bachelors degree, OR 5+ years of relevant work experience Preferred Qualifications 3 plus or more years of work experience with a Bachelor’s Degree or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) • 5 or more years of relevant work experience with a Bachelor’s Degree or 2 or more relevant years of experience with an Advanced Degree (e.g. Masters, MBA, MD). • Experience working on distributed microservices systems. • Development experience with Golang/Rustlang (alternatively a strong background in C/C++ or Java) • Experience in real-time streaming systems (Spark/Flink/Kafka) • Skilled with Docker & Kubernetes and hands on Ansible/CI CD pipelines • Experience using and configuring operational tools such as Splunk, Humio, Prometheus & Grafana. • 5+ years of experience in leading development teams • Proven knowledge of successful design, architecture and development using Big Data Hadoop, J2EE and Spark with large data volumes and transaction systems • Possesses a deep understanding of benefits/drawbacks of different integration patterns • Ability to solve complex software development/design issues • Ability to write clean, coherent code following established coding guidelines • Strong interpersonal, facilitation, and effective communication skills (both written and verbal) and the ability to present complex ideas in a clear, concise way • Experience developing as part of Agile/Scrum team is preferred • Passionate about delivering zero defect code that meet or exceed the proposed defect SLA and have high sense of accountability for quality and timeliness of deliverables • Ability to deliver on multiple projects and manage priorities based on changing directions • Highly driven, resourceful and results oriented • Demonstrated ability to lead and navigate through ambiguity • Past experience in Payments knowledge is preferred Additional Information Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",,,"Python, Machine Learning",
4208960543,Staff Machine Learning Engineer (NLP),Suki,"Bengaluru, Karnataka, India",,Full-time,,"About the job What we want to accomplish and why we need you Suki is creating a new category in the health-tech space: the digital assistant. Our product will be the voice user interface for healthcare. What does that mean? Currently, doctors use electronic health record systems to take notes on patient encounters. This is a digital version of the paper charts that you may have seen in your doctor’s office or on TV. These systems can be hard to navigate and time-consuming to manage. Doctors would rather spend that time with patients. We are creating the solution. Doctors that use Suki already spend over 70% less time on administrative tasks, and we’re striving to do even better. Come and join us! We are a user-driven company and are committed to making sure every pixel of our product is in service of the doctor. We’re a team of technologists, clinicians, and industry experts working together to push the limits on technology used in medicine. We’re confident enough to move fast and talented enough not to break things. Check out this short video to learn more about our mission and our culture. Our tech stack includes GCP, Kubernetes, Golang, Python, React, C++, TypeScript, JavaScript, Swift, Kotlin, gRPC, and GraphQL. What will you do everyday? You will address the computational infrastructure with your knowledge and prior experience in NLP techniques and make improvements to our current processes. You will work directly on the platform that powers our microservices. You’ll help scale our platform for thousands of doctors and help improve usability. You’ll implement a microservices architecture and you’ll use Go to do it all. And you’ll be magnificent. Ok, you're sold, but what are we looking for in the perfect candidate? Action oriented: You love to build. You like to ship fast and quickly iterate. Creativity: You enjoy listening to user feedback and then building products in novel ways. You’re resourceful and enjoy finding alternate paths to success. Problem solving: you use data to help point you in the correct direction. You optimize relentlessly. You think business and engineering problems are like puzzles and you stick with them until they are solved. Humility: You’re humble and love working in a team without ego to deliver products Adaptability: You thrive in a fast-moving organization that uses light-weight processes and cutting-edge technology to have a huge impact. Confidence: You trust your abilities and you’re ready to push yourself to the next level. Requirements* 8+ years in overall Machine Learning experience, with at least Five years focused on NLP Proven record of an end to end workflow and with moving at least three NLP models to an enterprise production system. Expert in the understanding, practice, and deployment of state-of-the-art deep neural network models. Proven ability to build and maintain distributed backend services for ML/AI Applications Experience taking product technical design from inception to production Strong grasp of CS fundamentals including algorithms, data structures and design is preferred Requirements is such a strong word. We don’t necessarily expect to find a candidate that has done everything we’ve listed, but you should be able to make a credible case that you’ve done most of it and are ready for the challenge of adding some new things to your resume. Working at Suki: Our hybrid model offers the perfect balance of in-office collaboration and remote flexibility which includes three days in the office (Monday, Tuesday and Wednesday) and two days work from home (Thursday and Friday).The role is located in Bangalore and will require working from office three days a week. Tell Me More About Suki On a roll: Named by Fast Company as one of the most innovative companies, named Google’s Partner of the Year for AI/ML, named by Forbes as one of the top 50 companies in AI . Great team: Founded, managed, and backed by successful tech veterans from Google and Apple and medical leaders from UCSF and Stanford. We have technologists and doctors working side-by-side to solve complex problems. Great investors: We’re backed by Venrock, First Round Capital, Flare Capital, March Capital, Hedosophia and others. With our $165M raised so far, we have the resources to scale. Huge market: Disrupting a massive, growing $30+ billion market for transcription, dictation, and order-entry solutions. Our vision is to become the voice user interface for healthcare, relieving the administrative burden on doctors instead of adding to it. Great customers: Our solutions are used in health systems and clinics across the country, supporting clinicians across dozens of specialties. Check out what one of our users says about how Suki has helped his practice. Impact: You’ll make an impact from day one. You’ll join a team working towards a shared purpose with a culture built upon deep empathy for doctors and passion for making their lives better. Suki is an Equal Opportunity Employer. We are dedicated to building a company that fosters inclusion and belonging and reflects the diverse communities we serve across the country. We know we are stronger this way, and we look forward to growing our team with these shared values.",,,"Python, Machine Learning",
4206639210,Senior Machine Learning Engineer,Zycus,"Mumbai, Maharashtra, India",,Full-time,,"About the job About Us Zycus is a pioneer in Cognitive Procurement software and has been a trusted partner of choice for large global enterprises for two decades. Zycus has been consistently recognized by Gartner, Forrester, and other analysts for its Source to Pay integrated suite. Zycus powers its S2P software with the revolutionary Merlin AI Suite. Merlin AI takes over the tactical tasks and empowers procurement and AP officers to focus on strategic projects; offers data-driven actionable insights for quicker and smarter decisions, and its conversational AI offers a B2C type user-experience to the end-users. Zycus helps enterprises drive real savings, reduce risks, and boost compliance, and its seamless, intuitive, and easy-to-use user interface ensures high adoption and value across the organization. Start your #CognitiveProcurement journey with us, as you are #MeantforMore We Are An Equal Opportunity Employer Zycus is committed to providing equal opportunities in employment and creating an inclusive work environment. We do not discriminate against applicants on the basis of race, color, religion, gender, sexual orientation, national origin, age, disability, or any other legally protected characteristic. All hiring decisions will be based solely on qualifications, skills, and experience relevant to the job requirements. Job Description Zycus is seeking for talented Machine Learning Engineers to join our dynamic team. As a Machine Learning Engineer, you will be responsible for developing, implementing, and deploying cutting-edge machine learning models and algorithms to solve complex business problems and enhance our product offerings. Key Roles And Responsibilities Develop and implement AI solutions leveraging expertise in Analytics and Data Mining across Web, Social, and Big Data platforms. Good understanding and implementation of Generative AI for content generation, creative applications, and problem-solving across various domains. Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of data products. Utilize Machine Learning techniques for pattern recognition and inference to enhance existing products and develop new strategic initiatives. Solving complex problems with multi-layered data sets, as well as optimizing existing machine learning libraries and frameworks. Collaborate with cross-functional teams to integrate Natural Language Processing and Computational Linguistics into product development processes. Apply Statistical Modeling and Econometrics to analyze data and derive actionable insights for quantitative marketing strategies and to make predictions based on historical data. Contribute to the design and optimization of Large Scale Distributed Systems and Cloud Computing infrastructure. Enhance user experience through Human-Computer Interaction principles and Information Visualization techniques. Job Requirement Bachelor's, Master's, or Ph.D. degree in Computer Science, Engineering, Statistics, Mathematics, or a related field. Graduate/Post Graduate from Tier I institutes Strong background in Analytics, Data Mining, Machine Learning, and related disciplines. Experience with programming languages such as Python, R, Java, or C++. Experience in working with NLP, Computer Vision/Image Processing, Regression and Deep Learning algorithms. Proficiency in handling large datasets and implementing statistical models. Familiarity with Cloud Computing platforms and distributed systems architecture. Experience using Web Services like Redshift/S3/Spark/DigitalOcean, etc. Experience with Distributed Data and Computing tools. Experience in EDA (Exploratory Data Analysis.) Excellent Communication and Teamwork capabilities. Five Reasons Why You Should Join Zycus Cloud Product Company: We are a Cloud SaaS Company and our products are created by using the latest technologies like ML and AI. Our UI is in Angular JS and we are developing our mobile apps using React. A Market Leader: Zycus is recognized by Gartner (world's leading market research analyst) as a Leader in Procurement Software Suites. Move between Roles: We believe that change leads to growth and therefore we allow our employees to shift careers and move to different roles and functions within the organization Get a Global Exposure: You get to work and deal with our global customers. Create an Impact: Zycus gives you the environment to create an impact on the product and transform your ideas into reality. Even our junior engineers get the opportunity to work on different product features.",,,"Python, R, Machine Learning, Data Analysis",
4259216166,Front end engineer II,Indegene,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More We are a technology-led healthcare solutions provider. We are driven by our purpose to enable healthcare organizations to be future-ready. We offer accelerated, global growth opportunities for talent thats bold, industrious, and nimble. With Indegene, you gain a unique career experience that celebrates entrepreneurship and is guided by passion, innovation, collaboration, and empathy. To explore exciting opportunities at the convergence of healthcare and technology, check out www.careers.indegene.com. Looking to jump-start your career? We understand how important the first few years of your career are, which create the foundation of your entire professional journey. At Indegene, we promise you a differentiated career experience. You will not only work at the exciting intersection of healthcare and technology but also will be mentored by some of the most brilliant minds in the industry. We are offering a global fast-track career where you can grow along with Indegenes high-speed growth. We are purpose-driven. We enable healthcare organizations to be future-ready and our customer obsession is our driving force. We ensure that our customers achieve what they truly want. We are bold in our actions, nimble in our decision-making, and industrious in the way we work. Must Have The teams, products, and innovation are recognized by leading analyst firms, industry associations, and most importantly by customers winning in the marketplace. With over 50 industry awards across customer engagement, creative, and medical, Indegene's ability to drive real outcomes for our customers is unparalleled. For more details with regard to our capabilities, visit us at www.indegene.com. Job Summary A Software Engineer needs to work on technical innovation and should have both theoretical and practical knowledge of various business problems or projects. Needs to utilize established development tools, guidelines, and conventions, including but not limited to ASP.NET, SQL Server, HTML, CSS, JavaScript, and C#/VB.NET for various client projects or internal development projects/products. In light of this, the role holder in the Transformational Engineering Solutions Office would get an opportunity to learn and partner with healthcare clients on various technical projects. The Job Entails The Following But Not Limited To Multiskilled programmer will need to work on various client-based solutions or focus on building POCs and integrating them into products as assigned. One should be able to switch between programming languages if needed, primarily Python, NodeJS, etc. Be hands-on with databases such as MySQL, MongoDB, and having knowledge of front-end technologies such as Angular, KnockoutJS and client-side JavaScript is an added advantage. Develop working knowledge of any of the web scripting languages such as JSP, PHP, ASP, etc. Develop working knowledge of any web servers such as Nginx, Apache, Tomcat, IIS, etc. Develop working knowledge of Docker, Virtual Machines, AWS EC2, Git, SVN. Having knowledge of Machine Learning and data analytics will be an added advantage. Understand how to break down requirements and estimate effort to delivery within timelines. Collaborate with designers and usability experts to ensure a great client-side user experience. Actively participate in testing and support/maintenance activities. Interact with team members to blend the content with creative, analytics to make intelligent products. Create and maintain appropriate documentation. Demonstrate passion to learn different therapy areas and phases of product life-cycle. Job Specification Education: BE/BTech/Dual Degree candidates with a specialization in CS/IT or Circuit branches. Work environment: Willingness to work in a Global Working Model. Preferred: Strong written and verbal English communication/presentation skills. Working knowledge of NodeJS. Understanding of design principles for secure and scalable applications. Who are we looking for? We Are Looking For People Who Have/can Passion for the application of technology knowledge to the life science business context. Very good quantitative abilities. Strong problem-solving skills for all challenges. Good analytical ability. Strong communication skills to work with stakeholders. Drive and ambition to continuously learn and grow. Application of knowledge based on facts and data. Good understanding of technology development. Location: This position will be based out of India, Bangalore and will involve minimum travel. Good to have EQUAL OPPORTUNITY Indegene is proud to be an Equal Employment Employer and is committed to the culture of Inclusion and Diversity. We do not discriminate on the basis of race, religion, sex, colour, age, national origin, pregnancy, sexual orientation, physical ability, or any other characteristics. All employment decisions, from hiring to separation, will be based on business requirements, the candidates merit, and qualification. We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, national origin, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristics. Locations: Bangalore, KA, IN",,,"Python, SQL, Machine Learning",
4259094713,Software Development Engineer,ZopSmart,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More We're looking for a Software Development Engineer-2 (SDE-2) to join our core engineering team. You'll work on high-impact features, write robust and maintainable code, and contribute to the technical growth of the team. While you won't be leading the team, your experience will help shape our engineering practices and mentor junior developers around you. Responsibilities Design, implement, and maintain backend services and infrastructure components. Own system components end-to-end - from architecture to deployment and support. Improve system performance and optimize cloud compute, storage, and networking costs. Investigate and resolve production incidents with a root-cause mindset. Mentor junior engineers and share best practices within the team. Contribute to open-source projects, internal tooling, or developer experience improvements. Requirements Minimum 3 years of professional backend development experience building Enterprise applications Proficient in one or more backend programming languages (e. g., Go preferred). Proven ability to optimize systems for cost, performance, and maintainability. Strive for quality through maintainable code and comprehensive testing from development to deployment Solid knowledge of REST APIs, microservices, and distributed system principles. Clear and concise communication, with strong problem-solving ability. An eagerness to learn through humility and reflection Experience debugging live production services Preferred Qualifications Demonstrated contributions to open-source projects or technical blogs. Exposure to security practices in backend/cloud systems. Experience with cloud-native development on AWS, GCP, Azure, or Oracle Cloud is a plus. This job was posted by Gayathri S from ZopSmart Technology. Desired Skills and Experience C++,Golang,Java,Python",,,Python,
4126006402,Machine Learning Research Engineer - E5,Whatfix,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Who are we? Founded in 2014 by Khadim Batti and Vara Kumar, Whatfix is a leading global B2B SaaS provider and the largest pure-play enterprise digital adoption platform (DAP). Whatfix empowers companies to maximize the ROI of their digital investments across the application lifecycle, from ideation to training to the deployment of software. Driving user productivity, ensuring process compliance, and improving user experience of internal and customer-facing applications. Spearheading the category with serial innovation and unmatched customer-centricity, Whatfix is the only DAP innovating beyond the category, positioning itself as a comprehensive suite for GenAI-powered digital adoption, analytics, and application simulation. Whatfix product suite consists of 3 products - DAP, Product Analytics, and Mirror. This product suite helps businesses accelerate ROI on digital investments by streamlining application deployment across its lifecycle. Whatfix has seven offices across the US, India, UK, Germany, Singapore, and Australia and a presence across 40+ countries. Customers: 700+ enterprise customers, including over 80 Fortune 500 companies such as Shell, Microsoft, Schneider Electric, and UPS Supply Chain Solutions. Investors: Raised a total of ~$270 million. Most recently Series E round of $125 Million led by Warburg Pincus with participation from existing investor SoftBank Vision Fund 2. Other investors include Cisco Investments, Eight Roads Ventures (A division of Fidelity Investments), Dragoneer Investments, Peak XV Partners, and Stellaris Venture Partners. With over 45% YoY sustainable annual recurring revenue (ARR) growth, Whatfix is among the “Top 50 Indian Software Companies” as per G2 Best Software Awards. Recognized as a “Leader” in the digital adoption platforms (DAP) category for the past 4+ years by leading analyst firms like Gartner, Forrester, IDC, and Everest Group. The only vendor recognized as a Customers’ Choice in the 2024 Gartner® Voice of the Customer for Digital Adoption Platforms has once again earned the Customers’ Choice distinction in 2025. We also boast a star rating of 4.6 on G2 Crowd, 4.5 on Gartner Peer Insights, and a high CSAT of 99.8% Highest-Ranking DAP on 2023 Deloitte Technology Fast 500™ North America for Fourth Consecutive Year Won the Silver for Stevie's Employer of the Year 2023 – Computer Software category and also recognized as Great Place to Work 2022-2023 Only DAP to be among the top 35% companies worldwide in sustainability excellence with EcoVadis Bronze Medal On the G2 peer review platform, Whatfix has received 77 Leader badges across all market segments, including Small, Medium, and Enterprise, in 2024, among numerous other industry recognitions. About the Role: Whatfix is working on building an intelligent assistant that understands user actions and intent, acting as a helpful guide to enhance productivity. This assistant will anticipate user needs, provide actionable insights, and streamline task completion. We are seeking a rockstar AI/ML Engineers who have experience in building world-class products. The ideal candidate will have a strong passion for leveraging AI and machine learning to create cutting-edge solutions that transform user experiences. If you thrive in solving complex problems, pushing the boundaries of AI/ML technology, and working collaboratively in a fast-paced environment, this role is for you! Key Responsibilities: Develop advanced computer vision and state-of-the-art deep learning models to understand software applications and derive user intent. Research and implement ML and deep learning algorithms for production use. Build and maintain infrastructure for AI/ML systems, including model inference, automated (re-)training, monitoring, explainability, and more. Stay updated on cutting-edge AI research from leading labs by reading papers and experimenting with code. Assist AI product managers and business stakeholders in understanding the capabilities and limitations of AI for the products. Fine-tune, retrain, and scale existing model deployments. Conduct necessary ML tests and benchmarks for model validation. Our Ideal candidate: Experience: 4+ years of expertise in machine learning. Deep Learning Expertise: Strong understanding of deep learning principles in both Computer Vision and Natural Language Processing (NLP). LLM Knowledge: Familiarity with LLM architectures like BERT and GPT, with hands-on experience fine-tuning these models for enhanced performance. Model Development: Proven experience in developing deep learning models, such as CNNs and Vision Transformers, for image-based tasks in production systems. Research and Application: Extensive experience in algorithms for image processing, content-based video/image analysis, object detection, segmentation, and tracking. Libraries: Proficiency in machine learning and deep learning libraries like PyTorch and Hugging Face. Technical Skills: Demonstrated ability to implement, improve, debug, and maintain machine learning models. Nice to Have: Strong programming skills in Python. Expertise in optimization and debugging. Familiarity with version control systems such as Git. Self-motivated and responsible, with excellent written and verbal communication skills. Experience in handling and visualizing large datasets and creating performance reports. Note: We strive to live and breathe our Cultural Principles and encourage employees to demonstrate some of these core values - Customer First; Empathy; Transparency; Fail Fast & Scale Fast; No Hierarchies for Communication; Deep Dive & Innovate; Trust, Do it as you own it; We are an equal opportunity employer and value diverse people because of and not in spite of the differences. We do not discriminate on the basis of race, religion, color, national origin, ethnicity, gender, sexual orientation, age, marital status, veteran status, or disability status",manager,,"Python, Machine Learning",
4253134027,Machine Learning Engineer,Saarthee,"Bangalore Urban, Karnataka, India (On-site)",On-site,Full-time,,"About the job About Saarthee: Saarthee is a Global Strategy, Analytics, Technology and AI consulting company, where our passion for helping others fuels our approach and our products and solutions. Our diverse and global team work with one objective in mind: Our Customers’ Success. At Saarthee, we are passionate about guiding organizations towards insights fueled success. That’s why we call ourselves Saarthee–inspired by the Sanskrit word ‘Saarthi’, which means charioteer, trusted guide, or companion. Cofounded in 2015 by Mrinal Prasad and Shikha Miglani, Saarthee already encompasses all the components of Data Analytics consulting. Saarthee is based out of Philadelphia, USA with office in UK and India. Position Summary: We are looking for an experienced AI/ML Engineer, who can execute projects end to end and take then to production pipeline. The candidate is expected to lead the AI/ML work across multiple projects, working along with other ML Engineers, ensuring clear understanding and translation of requirements for the team and proposing optimized solutions. He / She would also need to work on Ad hoc timebound POC’s. Capability building and team upskill would also be expected from him / her. We would want him / her to share the knowledge with other team members and bring them up to the same level, which includes conducting learning sessions across teams and monitoring the progress of the team members. Responsibilities: Design and develop various machine learning and deep learning models and systems for high impact consumer applications ranging from predictive safety, content personalization’s, search, virtual assistant, time series forecasting and more. Work with a broad spectrum of state-of-the-art machine learning and deep learning technologies, in the areas of various machine learning problems such as multilingual text classification, language modelling and multi-modal learning. Create metrics and configure A/B testing to evaluate model performance offline and online to inform and convey our impacts to diverse groups of stakeholders. Analyse and produce insights from a large amount of dynamic structured and unstructured data using modern big data and streaming technologies Produce reusable code according to standard methodologies in Python, Scala or Java Collaborate with cross-functional teams of technical members and non-technical members in architecture, design, and code reviews. Strong Python programming skills Qualifications: Bachelor's or master's degree in computer science, Engineering, Mathematics, or a related field. Minimum of 4-6 years of experience in machine learning, with a proven track record of designing, developing, and deploying ML models in a production environment. Strong problem-solving skills and understanding of machine learning algorithms, including classification, regression, clustering, and deep learning. Proficiency in at least one programming language commonly used in machine learning, such as Python, R, and Javascript. Knowledge of popular machine learning frameworks and libraries, such as TensorFlow, PyTorch, or scikit-learn. Familiarity with cloud-based machine learning platforms, like AWS SageMaker, Google Cloud AI, or Azure Machine Learning. Expertise in data structures, algorithms, and software design patterns. Expertise in System Architecture, Image/Video Processing, Deep Learning, Statistics. Excellent communication and collaboration skills, with the ability to work effectively in cross-functional teams.",,,"Python, R, Machine Learning",
4212161726,Senior Machine Learning Engineer,Moveworks,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job What You Will Do Design, build and optimize scalable machine learning infrastructure to support training/fine-tuning, evaluation, and deployment of LLMs and their applications. Leverage LLMs to develop multi-turn multi-hop conversational search systems and products. Craft new machine learning features and optimize existing ones to enhance quality metrics to meet the product requirements. Research and productionize next-gen search platforms using RAG (Retrieval Augmented Generation) architecture. Optimize system performance of retrieval, ranking, reasoning, and generation modules. Develop tools, processes and metrics to measure and monitor the system performance and quality. Collaborate with cross functional teams from machine learning, engineering, data analytics, product management, and go-to-market to build new products and/or features. What You Bring To The Table A builder mentality. 5+ years of hands-on software engineering experience in building and scaling machine learning based search, recommendation, or social network products or their supporting platforms. Effective communication skills with experience collaborating cross-functionally. A BS/MS/PhD in Computer Science or related fields. Nice To Have Experience in NLP or Information Retrieval related fields. Experience in developing products in performant languages such as Golang. Our compensation package includes a market competitive salary, equity for all full time roles, exceptional benefits, and, for applicable roles, commissions or bonus plans. Ultimately, in determining pay, final offers may vary from the amount listed based on geography, the role’s scope and complexity, the candidate’s experience and expertise, and other factors. Moveworks Is An Equal Opportunity Employer Moveworks is proud to be an equal opportunity employer. We provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, veteran status, or any other characteristics protected by law. Who We Are Moveworks is an AI Assistant that helps all employees find information, automate tasks, and be more productive. We give the entire workforce one interface to get answers and take action across every enterprise system. And for developers, we make it easy to build and deploy AI agents that bring the power of Moveworks to every business process or workflow. It’s all powered by a pioneering Reasoning Engine paired with an Agentic Automation Engine that, together, are able to handle even the most complex requests by understanding queries, then building and executing intelligent plans to fulfill them — in seconds. Founded in 2016, Moveworks has raised $315M in funding, and eclipsed $100M in ARR in 2024 thanks to our award-winning product and team. Along the way, we’ve earned recognition as a leader in the Forrester Wave for Conversational AI Platforms for Employee Services, as a member of the Forbes Cloud 100 and AI 50 lists, and as one of America’s Most Loved Workplaces according to Newsweek. Today, Moveworks has over 500 employees in six offices globally, and is backed by some of the world's most prominent investors including Kleiner Perkins, Lightspeed, Bain Capital Ventures, Sapphire Ventures, Iconiq, and more. Over 350 leading organizations like Marriott, Databricks, Toyota, CVS Health, and Honeywell trust Moveworks to increase operational efficiency, enhance the employee experience, and drive lasting AI transformation. Come join one of the most innovative teams on the planet!",,,Machine Learning,
4228839740,Senior AI Engineer - REMOTE,Uplers,"Vijayawada, Andhra Pradesh, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4204047948,Data Engineer (PySpark),Virtusa,"Bangalore Urban, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job About The Role We are seeking a highly skilled Data Engineer with deep expertise in PySpark and the Cloudera Data Platform (CDP) to join our data engineering team. As a Data Engineer, you will be responsible for designing, developing, and maintaining scalable data pipelines that ensure high data quality and availability across the organization. This role requires a strong background in big data ecosystems, cloud-native tools, and advanced data processing techniques. The ideal candidate has hands-on experience with data ingestion, transformation, and optimization on the Cloudera Data Platform, along with a proven track record of implementing data engineering best practices. You will work closely with other data engineers to build solutions that drive impactful business insights. Responsibilities Data Pipeline Development: Design, develop, and maintain highly scalable and optimized ETL pipelines using PySpark on the Cloudera Data Platform, ensuring data integrity and accuracy. Data Ingestion: Implement and manage data ingestion processes from a variety of sources (e.g., relational databases, APIs, file systems) to the data lake or data warehouse on CDP. Data Transformation and Processing: Use PySpark to process, cleanse, and transform large datasets into meaningful formats that support analytical needs and business requirements. Performance Optimization: Conduct performance tuning of PySpark code and Cloudera components, optimizing resource utilization and reducing runtime of ETL processes. Data Quality and Validation: Implement data quality checks, monitoring, and validation routines to ensure data accuracy and reliability throughout the pipeline. Automation and Orchestration: Automate data workflows using tools like Apache Oozie, Airflow, or similar orchestration tools within the Cloudera ecosystem. Education and Experience Bachelors or Masters degree in Computer Science, Data Engineering, Information Systems, or a related field. 3+ years of experience as a Data Engineer, with a strong focus on PySpark and the Cloudera Data Platform. Technical Skills PySpark: Advanced proficiency in PySpark, including working with RDDs, DataFrames, and optimization techniques. Cloudera Data Platform: Strong experience with Cloudera Data Platform (CDP) components, including Cloudera Manager, Hive, Impala, HDFS, and HBase. Data Warehousing: Knowledge of data warehousing concepts, ETL best practices, and experience with SQL-based tools (e.g., Hive, Impala). Big Data Technologies: Familiarity with Hadoop, Kafka, and other distributed computing tools. Orchestration and Scheduling: Experience with Apache Oozie, Airflow, or similar orchestration frameworks. Scripting and Automation: Strong scripting skills in Linux. Desired Skills and Experience DevOps",Manager,,SQL,
4256415723,Site Reliability Engineer - Python scripting and Azure cloud,Ivanti,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Why We Need You! Site Reliability Engineering (SRE) is a growing team that partners closely with Product Engineering, Security, and Support. We are responsible for the reliability, deployment, and continuous operation of the Ivanti Cloud services. We need your help to take our existing platform to the next level with observability, release automation, chaos engineering, and more. The Senior SRE role is a blend of infrastructure, networking, operating systems, automation, development, and application administration. It is a hands-on technical position in a fast-paced atmosphere. The ideal candidate has prior experience managing cloud-based SaaS applications and strives to solve traditional operations problems through automation and software. More so, the candidate must possess a high standard of excellence, have a strong customer focus, and is capable of technical deep dives into code, app servers, databases, load balancers, operating systems, and networks. What You Will Be Doing Deploying, managing, and securing Ivanti’s production Software-as-a-Service (SaaS) environments in AWS and Azure Working with geographically dispersed, cross-departmental teams to solve difficult problems Automating common and repetitive tasks Write documentation and training material Train other colleagues. Participate in on-call rotations for 24x7 coverage (follow-the-sun model) for incident response, issue triage, and problem resolution Work 4 x 10 hour days (Friday through Monday, 8 AM to 7 PM India Standard Time) To Be Successful in The Role, You Will Have A BSc in Computer Science, a related field, or equivalent practical experience 3+ years of relevant industry experience (2+ with an achieved BSc in Computer Science or Equivalent Degree) Proficiency with Python and experience with one of the following languages: Java Golang C# Proficiency working with Bash or PowerShell programmatically Familiarity with public cloud platforms (AWS or Azure preferred) Experience troubleshooting Java and .NET applications Experience troubleshooting network and storage infrastructure issues Experience working with core Linux distributions (Debian, RHEL, SUSE, Slackware). Experience working with Windows. Experience working with one or more: SQL Server, PostgreSQL, Redis, Kafka, MongoDB, Elasticsearch, or similar Ability to configure and fine tune at least one: HA Proxy, Apache, Nginx, IIS, or similar Ability to configure: New Relic, DataDog, Splunk, or similar monitoring tools Familiarity with container orchestration technologies (AWS EKS or Azure AKS preferred) Experience with deployment pipeline tools such as Ansible, Jenkins, and/or GitHub Actions Proficiency working and developing Infrastructure as Code (IaC) A desire to adopt and implement emergent technologies and best practices Strong verbal and written communication skills in English for the purposes of global collaboration ‘Nice-to-haves’ Include Prior experience as a Site Reliability Engineer or DevOps Engineer Certificates in one or more of the following categories, or demonstrated certificate-equivalent knowledge: Cloud Development and architecture Kubernetes Administration Linux Administration Software engineering disciplines Experience with compliance frameworks such as SOC 2 Type 2, ISO-27001, FedRAMP, or IRAP and privacy regulations such as GDPR and PIPEDA Roadmap for Success 90 Days Onboarding and role-training is complete You're building foundational knowledge of the SRE-run product portfolio You hold general knowledge of how SRE manages our SaaS environments You've gotten to know the team and are building relationships with SRE peer teams 6 Months Self-sufficiency in core job functions and existing processes Participating in SRE on-call rotations Contributing to handling SRE tickets to fulfillment and responsible for individual SRE tasks Active participation in SRE stability discussions with direct interaction with SRE peers 1 Year Contribute independently to improve reliability and compliance in our SaaS environments Demonstrate ownership of SRE ticket management including triage and resolution Lead one or more well-defined projects under guidance from Senior SRE members Identify areas where performance, scalability, security, and reliability can be improved in production systems and environments",,,"Python, SQL",
4255439934,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4249544592,Data Engineer,Tata Consultancy Services,"Kolkata, West Bengal, India (On-site)",On-site,Full-time,,"About the job Greetings from Tata Consultancy Services Join the Walk-in Drive on 21st June 2025 and Pave your path to value with TCS AI Cloud Team We are Hiring for Below Skills Exp : 4 yrs to 12 yrs Azure Data Engineer Required:Implementation, and operations of OLTP, OLAP, DW technologies such as Azure SQL, Azure SQL DW",,,SQL,
4213684918,Python Machine learning Engineer,Infosys,"Bengaluru East, Karnataka, India (On-site)",On-site,Full-time,,"About the job Technical knowledge- has expertise in cloud technologies, specifically MS Azure, and services with hands on coding to – Python Programming - Expert and Experienced - 4 -5 years DevOps Working knowledge with implementation experience - 1 or 2 projects a minimum Hands-On MS Azure Cloud knowledge Understand and take requirements on Operationalization of ML Models from Data Scientist Help team with ML Pipelines from creation to execution List Azure services required for deployment, Azure Data bricks and Azure DevOps Setup Assist team to coding standards (flake8 etc) Guide team to debug on issues with pipeline failures Engage with Business / Stakeholders with status update on progress of development and issue fix Automation, Technology and Process Improvement for the deployed projects Setup Standards related to Coding, Pipelines and Documentation Adhere to KPI / SLA for Pipeline Run, Execution Research on new topics, services and enhancements in Cloud Technologies Responsible for successful delivery of MLOps solutions and services in client consulting environments; Define key business problems to be solved; formulate high level solution approaches and identify data to solve those problems, develop, analyze/draw conclusions and present to client. Assist clients with operationalization metrics to track performance of ML Models Agile trained to manage team effort and track through JIRA High Impact Communication- Assesses the target audience need, prepares and practices a logical flow, answers audience questions appropriately and sticks to timeline. Master’s degree in Computer Science Engineering, with Relevant experience in the field of MLOps / Cloud Domain experience in Capital Markets, Banking, Risk and Compliance etc. Exposure to US/ overseas markets is preferred Azure Certified – DP100, AZ/AI900 Domain / Technical / Tools Knowledge: Object oriented programming, coding standards, architecture & design patterns, Config management, Package Management, Logging, documentation Experience in Test Driven Development and experience in using Pytest frameworks, git version control, Rest APIs Azure ML best practices in environment management, run time configurations (Azure ML & Databricks clusters), alerts. Experience designing and implementing ML Systems & pipelines, MLOps practices Exposure to event driven orchestration, Online Model deployment Contribute towards establishing best practices in MLOps Systems development Proficiency with data analysis tools (e.g., SQL, R & Python) High level understanding of database concepts/reporting & Data Science concepts Hands on experience in working with client IT/Business teams in gathering business requirement and converting into requirement for development team Experience in managing client relationship and developing business cases for opportunities Azure AZ-900 Certification with Azure Architecture understanding is a plus",,,"Python, SQL, R, Data Analysis",
4218109131,"Software Development Engineer, Analytics & Data Management, Advertising Core Services",Amazon,"Bengaluru, Karnataka, India",,Full-time,,"About the job Description Would you like to build highly available, scalable and distributed microservices for the Advertising Data Lake? Does Petabyte scale excite you? The Spektr team owns the central data lake for Advertising, with services for data ingestion, analysis, cataloging and infrastructure. Spektr provides customers with self-serve tools to analyze Petabytes of data such as campaigns, ad-serving, billing, clicks, impressions and more generated across the Ads pipeline. This enables engineers, business analysts, ML engineers, research scientists, economists and data experts to perform analysis, measurement and reporting decisions over high quality data. Spektr Datalake team is building the next version of its core platform for 5x growth. An SDE on this team has a unique opportunity to design the core infra services to scale for Petabytes of data per day with 99.9% uptime, minimal error rates and low operational footprint. Services built by you will utilize technologies such as Java, AWS Lambda, Kinesis, Spark, Redis, EMR, Athena and more to build highly distributed data processing frameworks. Your work will create value that materially impacts the speed and quality of decision making across the organization resulting in tangible business growth. Key job responsibilities Engage with key decision makers such as Product & Program Managers to understand customer requirements and brainstorm on solutions Design, code and deploy components and micro-services for the core job management pipeline Ensure testability, maintanability and low operational footprint for your code Participate in operational responsibilities with your team Innovate on AWS technology to improve latency, reduce cost and operations A day in the life Focus on core engineering opportunities to guarantee system availability that matches our data growth Work with a skilled team of engineers, managers and decision makers to consistently meet customer demand Automate monitoring of data availability, quality and usability via simplified metrics and drive innovations to improve guarantees for our customers Build frugal solutions that will help make Spektr data lake cost wise leanest datalake in Amazon About The Team The mission of the Spektr Datalake team is to provide data that helps the advertising organization make informed analyses and decisions for our customers and to determine and deploy investments for future growth via a set of central and unified products and services. Our team focuses on simplicity, usability, speed, compliance, cost efficiency and enabling high-velocity decision making so our customers can generate high quality insights faster. We are a global team with presence across IN and NA. Basic Qualifications 3+ years of non-internship professional software development experience 2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience Experience programming with at least one software programming language Preferred Qualifications 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience Bachelor's degree in computer science or equivalent Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI - Karnataka Job ID: A2966503",Manager,,,
4256416515,Application Developer-SAP ABAP HANA,IBM,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology. As an Application Developer, you will lead IBM into the future by translating system requirements into the design and development of customized systems in an agile environment. The success of IBM is in your hands as you transform vital business needs into code and drive innovation. Your work will power IBM and its clients globally, collaborating and integrating code into enterprise systems. You will have access to the latest education, tools and technology, and a limitless career path with the world’s technology leader. Come to IBM and make a global impact! Your Role And Responsibilities Responsible to design, develop and/or re-engineer highly complex application components and integrate software packages, programs and reusable objects residing on multiple platforms. Responsible to Designs, development of applications in one or more of the areas like SAP Portal, SAP Fiori, SAP UI5, SAP Mobile Platform (SMP), SAP Cloud Platform Mobile Services (SCPMs). Customization to standard application in case required. Experience in working in Implementation, Upgrade, Maintenance and Postproduction support projects would be an advantage. Practitioner must willing to travel to client location for the Project duration Ability to create Screens, Controllers, OData DPC and MPC. Hands-on HTML5, JS, CSS3 coding experience. SAP Web IDE, SAP Frontend Server Experience. Preferred Education Master's Degree Required Technical And Professional Expertise BE / B Tech in any stream, M.Sc. (Computer Science/IT) / M.C.A, Min. 2-4 years of work experience in SAP Portal, SAP Fiori, SAP UI5, SAP Mobile Platform (SMP), SAP Cloud Platform Mobile Services (SCPMs Experience in Business Application Programming Interface and XI (Exchange Infrastructure) and Extensive experience in SAPUI5 application development Experience in MVC framework for UI, SAPUI5, HTML5, and JavaScript and Expertise in SAPUI5 controls and Fiori Design patterns Understanding of SAP functional requirement, conversion into technical design and development using ABAP Language for Report, Interface, Conversion, Enhancement and Forms in implementation or support project: Minimum 3-4 implementation experience Expertise in Fiori application and system architecture and Exposure in SAP Fiori Launchpad configuration and app integration Preferred Technical And Professional Experience Cement industry business knowledge is preferable. Knowledge and experience on SAP Workflow and Good experience in OData. Understanding of SAP functional requirement, conversion into technical design and development using ABAP Language for Report, Interface, Conversion, Enhancement and Forms in implementation or support project: Minimum 3-4 implementation experience",,,,
4259095858,HTML CSS Developer Intern,Innovate Solutions,India (Remote),Remote,Full-time,,"About the job Job Title: HTML/CSS Developer Trainee Location: Remote Job Type: Internship (Full-Time) Duration: 1–3 Months Stipend: ₹25,000/month Department: Web Development / UI Engineering Job Summary: We are looking for a passionate and detail-focused HTML/CSS Developer Trainee to join our remote development team. This internship is ideal for individuals who have a strong interest in creating visually appealing and responsive web interfaces using HTML and CSS. You will gain hands-on experience by working on real-world UI development projects. Key Responsibilities: Convert design mockups (Figma, Adobe XD, etc.) into clean, responsive HTML/CSS code Maintain and improve front-end code across web projects Ensure cross-browser compatibility and mobile responsiveness Collaborate with designers and developers to implement pixel-perfect UI components Help maintain UI consistency and styling across multiple projects Learn and apply modern HTML5 and CSS3 standards and best practices Qualifications: Bachelor's degree (or final-year student) in Computer Science, IT, or a related field Strong understanding of HTML5 and CSS3 Knowledge of responsive design principles and frameworks (e.g., Bootstrap, Tailwind) Attention to detail and an eye for design consistency Ability to work independently in a remote environment Eagerness to learn and grow as a front-end/UI developer Preferred Skills (Nice to Have): Familiarity with version control tools (e.g., Git, GitHub) Exposure to JavaScript or front-end frameworks (e.g., React, Vue) Basic understanding of accessibility and web standards Experience working with design tools like Figma or Adobe XD What We Offer: Monthly stipend of ₹25,000 100% remote internship Opportunity to work on real web development projects Mentorship from experienced UI/UX professionals Certificate of Completion Potential for full-time employment based on performance",,,,
4256756299,"Software Engineer, AI (Python)",G2i Inc.,India (Remote),Remote,Contract,,"About the job Software Engineer, AI — Code Evaluation & Training (Remote) Help train large-language models (LLMs) to write production-grade code across a wide range of programming languages: Compare & rank multiple code snippets , explaining which is best and why. Repair & refactor AI-generated code for correctness, efficiency, and style. Inject feedback (ratings, edits, test results) into the RLHF pipeline and keep it running smoothly. End result: the model learns to propose, critique, and improve code the way you do. RLHF in one line Generate code ➜ expert engineers rank, edit, and justify ➜ convert that feedback into reward signals ➜ reinforcement learning tunes the model toward code you’d actually ship. What You’ll Need 4+ years of professional software engineering experience in Python (Constraint programming experience is a bonus, but not required) Strong code-review instincts —you can spot logic errors, performance traps, and security issues quickly. Extreme attention to detail and excellent written communication skills. Much of this role involves explaining why one approach is better than another. This cannot be overstated. You enjoy reading documentation and language specs and thrive in an asynchronous, low-oversight environment. What You Don’t Need No prior RLHF (Reinforcement Learning with Human Feedback) or AI training experience. No deep machine learning knowledge. If you can review and critique code clearly, we’ll teach you the rest. Tech Stack We are looking for engineers with a strong command of Python . Logistics Location: Fully remote — work from anywhere Compensation: From $30/hr to $70/hr, depending on location and seniority Hours: Minimum 15 hrs/week, up to 40 hrs/week available Engagement: 1099 contract Straightforward impact, zero fluff. If this sounds like a fit, apply here!",,,"Python, Machine Learning",
4259091983,Software Development Engineer - II (React Native),AEREO,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Aereo is actively looking for self-driven and process-oriented individuals who would be interested in joining Team Aereo in this fascinating growth journey and be an early contributor to the drone ecosystem of the country, which is growing at an extremely exciting and fast pace. The role pertains to the Platform Team in Aereo, whose charter is to build and maintain our cloud-based enterprise SaaS platform, Aereo Cloud. Aereo Cloud is a powerful platform that enables organizations to store, manage, visualize, and analyze their drone-based geospatial data at PB-scale and generate critical and actionable business insights based on this data. Responsibilities Building UIs to manage data processing and visualization for PWA. Designing the UI Architecture based on system requirements. Deployment and management of apps and services on our cloud infrastructure. Stay updated with the latest trends in IONIC, React, and mobile app development, proposing improvements and innovations. Working cohesively with developers in the team, guiding best practices, code reviews, and technical decision-making. Ensure code quality and best practices in terms of unit testing, integration testing, and continuous integration/continuous deployment (CI/CD). Troubleshoot and resolve complex issues related to IONIC integration within React, ensuring the highest standards of performance and user experience. Requirements 2-3+ years of professional experience in software development with a focus on IONIC or React. Strong experience in React-based applications and Mobile app development. Proficient in JavaScript/TypeScript, HTML5 and CSS3 Experience in architecting mobile and web applications, with a focus on scalability, performance, and security. Familiarity with RESTful APIs and backend integration. Strong understanding of Git, version control, and CI/CD pipelines. Knowledge of Redux or other state management libraries. You Are Awesome If You Are Familiarity with native modules in mobile development. Prior experience in leading or managing a team of developers. Prior familiarity with GIS and Aereo Products. Familiar with CI/CD tools and practices. Desired Skills: HTML, CSS, JavaScript, IONIC, React, AWS, Docker, and Redux. Strong experience in integrating IONIC components into React-based applications. Desired Skills: HTML, CSS, JavaScript, React Native, Ionic, AWS, Docker, Redux. This job was posted by Deepak Td from Aereo. Desired Skills and Experience Hybrid Apps,Ionic,React Native",,,,
4259095677,SDE 2 - Backend,Saathi,"Delhi, Delhi, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More We are looking for high-performing and curious Senior Software Engineers who thrive in a fast-paced environment and want to be part of building robust, scalable systems. You'll work on core services powering our platform and solve meaningful technical problems that impact real users every day. Responsibilities Design, build, and maintain efficient, reusable, and reliable backend services. Collaborate cross-functionally to deliver new features, ensuring stability and performance. Write well-structured code following OOP principles and design patterns. Work with REST APIs, background workers, and message queues (Kafka or similar). Manage database design and queries, understanding schema optimization and performance tuning. Contribute to system architecture discussions and participate in peer code reviews. Troubleshoot and debug production issues in a time-critical environment. Requirements 3-5 years of professional software development experience. Solid knowledge of at least one core backend language, such as Node.js or Java. Strong understanding of data structures, algorithms, and object-oriented programming (OOP). A good grasp of software design principles and design patterns (e. g., factory, singleton, observer, etc. ). Experience with databases, relational or NoSQL (MongoDB is a plus). Comfort with version control (Git) and working with RESTful APIs. Bonus Points Experience with MongoDB, Kafka, or Elasticsearch is a plus. Exposure to microservices architecture, distributed systems, and caching strategies. Experience in agile teams and startups, and willingness to take end-to-end ownership. Familiarity with CI/CD pipelines, containerization tools like Docker, and cloud deployment on AWS. This job was posted by Shabina Khan from Saathi. Desired Skills and Experience Java,Node.js",,,,
4228843476,Senior AI Engineer - REMOTE,Uplers,"Ranchi, Jharkhand, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4253211258,Lead AI Engineer – Machine Learning,BlockTXM Inc,India (Remote),Remote,Contract,,"About the job We are looking for a visionary and technically skilled Lead AI Engineer – Machine Learning to spearhead the design, development, and deployment of advanced machine learning solutions. In this leadership role, you will guide a team of AI/ML engineers, contribute hands-on to critical technical challenges, and collaborate with cross-functional teams to deliver impactful AI products. This role is ideal for someone who thrives at the intersection of innovation, engineering rigor, and business value. Key Responsibilities Technical Leadership : Lead the architecture, development, and deployment of machine learning models and AI systems across a range of use cases. Model Development : Design, train, and optimize supervised, unsupervised, and deep learning models using frameworks like PyTorch, TensorFlow, and XGBoost. Mentorship : Coach and mentor a team of ML engineers and data scientists; foster a culture of innovation, ownership, and continuous learning. Project Management : Drive planning, execution, and delivery of AI/ML projects, ensuring alignment with business objectives and technical feasibility. System Design : Architect scalable, secure, and high-performance ML pipelines and services using cloud-native tools and MLOps best practices. Collaboration : Work closely with product managers, data engineers, and DevOps teams to translate business problems into AI-driven solutions. Code Quality & Governance : Establish standards for model quality, reproducibility, documentation, versioning, and monitoring. Innovation : Stay current with research and industry trends in ML/AI, evaluate new tools, and introduce state-of-the-art solutions where applicable. Required Skills and Experience Education : Bachelor’s or Master’s in Computer Science, Machine Learning, Data Science, or related technical field Experience : 6–10+ years of experience in software engineering or AI/ML, with at least 2+ years in a technical leadership role Technical Expertise : o Strong programming skills in Python and experience with ML libraries such as Scikit-learn, TensorFlow, PyTorch, Hugging Face o Deep understanding of ML fundamentals: feature engineering, model evaluation, optimization, and deployment o Proficiency in designing and building data pipelines, real-time processing, and model inference systems o Experience with cloud platforms (AWS, GCP, or Azure), containerization (Docker, Kubernetes), and CI/CD pipelines o Familiarity with MLOps tools (e.g., MLflow, DVC, Airflow, SageMaker) and vector databases (e.g., FAISS, Pinecone) Preferred Qualifications Hands-on experience with LLMs, RAG pipelines, or generative AI applications Familiarity with agentic AI frameworks (LangChain, CrewAI, AutoGPT) Domain expertise in fintech, healthtech, HR tech, or industrial automation Contributions to open-source AI/ML projects or published research Knowledge of responsible AI practices, explainability (XAI), and model governance Soft Skills Strong leadership and team-building skills Clear and persuasive communication with both technical and non-technical stakeholders Strategic thinker with attention to detail and a bias for action",manager,,"Python, Machine Learning",
4246064492,Cognite Data Engineer,Virtusa,"Chennai, Tamil Nadu, India (Hybrid)",Hybrid,Full-time,,"About the job Job Description We are looking to onboard a strong offshore Data Engineer for the Asset Twin project, with specialized expertise in Cognite. The candidate should have hands-on experience in: Cognite Data Fusion (CDF) - specifically in data loading, modelling, and contextualization In addition to Cognite expertise, it would be advantageous if the candidate also has skills in: SnapLogic Snowflake Python Desired Skills and Experience Snowflake design",,,Python,
4255441821,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4255973661,Azure AI/ML Engineer,Tata Consultancy Services,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,About the job Job Title: Azure AI/ML Engineer Location: Pan India Experience : 5 + Yrs Job Type : Full time ----- Job Summary: We’re looking for a hands-on Azure AI/ML Architect to build and support AI and machine learning solutions using Microsoft Azure. This is a technical role—no managerial experience needed. What You’ll Do: Design and build AI/ML solutions using Azure tools. Work with Azure OpenAI and Generative AI models. Use Azure Cognitive Services to build smart features. Write code in Python to create and deploy models. Use Azure integration tools like Logic Apps and Service Bus. Help with automation and deployment using Azure DevOps. What You Should Know: Strong experience with Azure AI/ML and OpenAI tools. Good understanding of Generative AI and Cognitive Services. Skilled in Python programming. Experience with Azure integration services. Familiar with DevOps and CI/CD in Azure. Microsoft Certified or other certifications / education on AI and ML will be a plus. Strong problem-solving and communication skills. Note: This is a purely technical role—please don’t apply if your experience is mostly managerial.,manager,,"Python, Machine Learning",
4259203120,Php Developer Trainee,Innovate Solutions,India (Remote),Remote,Full-time,,"About the job Job Title: PHP Developer Trainee Location: Remote Job Type: Full-Time Stipend: ₹25,000 per month (Fixed) About the Role: We are looking for a motivated and enthusiastic PHP Developer Trainee to join our development team. This is a great opportunity for freshers or recent graduates who are passionate about web development and eager to learn in a real-world environment. You will be working alongside experienced developers on live projects, gaining hands-on experience in backend development, databases, and modern frameworks. Key Responsibilities: Assist in developing and maintaining web applications using PHP. Write clean, scalable, and well-documented code. Support the team in troubleshooting, testing, and debugging applications. Collaborate with front-end developers, designers, and other team members. Stay updated with the latest trends and best practices in web development. Requirements: Basic understanding of PHP, MySQL, HTML, CSS, and JavaScript. Familiarity with Object-Oriented Programming (OOP). Knowledge of any PHP framework (like Laravel or CodeIgniter) is a plus. Good problem-solving and analytical skills. Ability to work in a team and follow instructions. Bachelor's degree in Computer Science, IT, or a related field (or currently pursuing final year). What We Offer: Fixed monthly stipend of ₹25,000. Real-world project exposure and mentorship. Opportunity for full-time employment based on performance. Collaborative and growth-focused work environment.",,,,
4252669947,FS-RC- EY Comply and RVS-AI Engineer-Senior,EY,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. Position: Senior - AI Engineer Job Summary: As an AI Engineer, you will be responsible for designing, developing, and implementing AI models and algorithms that solve complex problems and enhance our products and services. You will work closely with software engineers, business users and product managers to create intelligent systems that leverage machine learning and artificial intelligence. Responsibilities: Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions. Proficiency in Generative AI: Strong understanding of GPT architecture, prompt engineering, embeddings , efficient token usage and agentic AI solutions (example async, batching, caching, piping solutions etc ). Hands-on Experience with Model Training: Demonstrated ability to train and fine-tune AI/ML models, particularly in natural language processing (NLP). Expertise in Deep Learning Frameworks: Familiarity with popular deep learning libraries such as TensorFlow, PyTorch, or similar tools. NLP Techniques: Experience with various NLP techniques, namely using AI to extract the contents from unstructured complex PDF documents. Knowledge of deep learning techniques and neural networks. Strong communication skills to convey complex technical concepts to non-technical stakeholders. Skills requirement: 4 – 6 years of hands on experience developing AI solutions. Strong programming skills in languages such as Python. Strong experience with SQL, RESTful API, JSON Experience with Azure Cloud resources is preferable. Familiarity with DevOps practices and tools. Exposure to any noSQL Databases (MongoDB, Cosmos DB and etc) is a plus EY | Building a better working world EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets. Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate. Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",manager,,"Python, SQL, Machine Learning",
4244340399,"Lead Machine Learning Engineer – MLOps, VertexAI, LLMs, GenAI, ML Model Management",UPS,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Avant de postuler à un emploi, sélectionnez votre langue de préférence parmi les options disponibles en haut à droite de cette page. Découvrez votre prochaine opportunité au sein d'une organisation qui compte parmi les 500 plus importantes entreprises mondiales. Envisagez des opportunités innovantes, découvrez notre culture enrichissante et travaillez avec des équipes talentueuses qui vous poussent à vous développer chaque jour. Nous savons ce qu’il faut faire pour diriger UPS vers l'avenir : des personnes passionnées dotées d’une combinaison unique de compétences. Si vous avez les qualités, de la motivation, de l'autonomie ou le leadership pour diriger des équipes, il existe des postes adaptés à vos aspirations et à vos compétences d'aujourd'hui et de demain. Role Overview Fiche de poste : UPS Data Science and Machine Learning team is seeking a highly skilled and experienced Lead Machine Learning Engineer to manage our AI, ML, GenAI application focused on Cross Border logistics. This position leverages continuous integration and deployment of the best practices, including test automation and monitoring, to ensure successful deployment of optimal ML models and analytical systems. You will be responsible for the end-to-end lifecycle of AI models, from experimentation and fine-tuning to deployment and management in production. A strong background in prompt engineering and practical experience with either Google Cloud's Vertex AI platform is essential for this role. You will also provide technical leadership and mentorship to other members of the AI/ML team. Key Responsibilities Lead the development and deployment of generative AI solutions utilizing LLMs, SLMs, and FMs for various applications (e.g., content generation, chatbots, summarization, code generation, etc.). Architect and implement robust and scalable infrastructure for training, fine-tuning, and serving large-scale AI models, leveraging either Vertex AI. Drive the fine-tuning and adaptation of pre-trained models using proprietary data to achieve state-of-the-art performance on specific tasks. Develop and implement effective prompt engineering strategies to elicit desired outputs and control the behavior of generative models. Manage the lifecycle of deployed models, production support, including monitoring performance, identifying areas for improvement, and implementing necessary updates or retraining. Collaborate closely with cross-functional teams (e.g., product, engineering, research) to understand business requirements and translate them into technical solutions. Provide technical leadership and mentorship to junior machine learning engineers, fostering a culture of learning and innovation. Ensure the responsible and ethical development and deployment of AI models, considering factors such as bias, fairness, and privacy. Stay up to date with latest advancements in generative AI, LLMs, and related technologies, and evaluate their potential application within the company. Document technical designs, implementation details, and deployment processes. Troubleshoot and resolve issues related to model performance and deployment. Required Skills And Experience Bachelor's or Master's degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field. Minimum of 5-8 years of hands-on experience in building, deploying, and managing machine learning models in a production environment. Demonstrable experience in managing, deploying, and fine-tuning large language models (LLMs), small language models (SLMs), and foundation models (FMs). Significant hands-on experience with prompt engineering techniques for various generative AI tasks. Proven experience working with either Google Cloud's Vertex AI platform platform. including experience with their respective model registries, deployment tools, and MLOps features. Strong programming skills in Python and experience with relevant machine learning libraries (e.g., TensorFlow, PyTorch, Transformers). Experience with cloud computing platforms (beyond Vertex AI is a plus, e.g. Azure). Solid understanding of machine learning principles, deep learning architectures, and evaluation metrics. Excellent problem-solving, analytical, and communication skills. Ability to work independently and as part of a collaborative team. Experience with MLOps practices and tools for continuous integration and continuous delivery (CI/CD) of ML models is highly desirable. Experience with version control systems (e.g., Git). Bonus Points Experience with model governance frameworks and implementing ethical AI practices. Experience with specific generative AI use cases relevant to Logistics industry. Publications or contributions to open-source projects, technical blogs, or industry conferences are considered a plus Familiarity with data engineering pipelines and tools. Familiarity with emerging trends in generative AI, reinforcement learning from human feedback (RLHF), and federated learning approaches. Type De Contrat en CDI Chez UPS, égalité des chances, traitement équitable et environnement de travail inclusif sont des valeurs clefs auxquelles nous sommes attachés.",,,"Python, Machine Learning",
4259094664,Fullstack Developer - Java,CodeVyasa,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More Responsibilities Develop, implement, and maintain Java-based applications. Design and develop front-end and back-end solutions using Java/J2EE and Angular/React frameworks. Build RESTful APIs and integrate with existing systems. Collaborate with cross-functional teams to define, design, and ship new features. Ensure code quality through unit testing and continuous integration. Deploy applications on DevOps platforms and manage containerized environments. Requirements Proficiency in Java 8 and Java/J2EE frameworks. Experience with Angular or React for front-end development. Strong knowledge of JavaScript, HTML, and CSS. Hands-on experience in developing and consuming RESTful APIs. Familiarity with DevOps practices for continuous integration and deployment. Bachelor's degree in Computer Science or related field. Excellent problem-solving and analytical skills. Ability to work independently and as part of a team. Strong communication skills and a proactive approach to learning. Knowledge of MongoDB and SQL databases. Understanding of cloud platforms like AWS or Azure. This job was posted by Taranpreet Kaur from CodeVyasa. Desired Skills and Experience Angular,DevOps,J2EE,Java,JavaScript",,,SQL,
4240530645,Dainik Bhaskar - Principal Machine Learning Engineer,Dainik Bhaskar,"Noida, Uttar Pradesh, India",,Full-time,,"About the job This job is sourced from a job board. Learn More Job Description We're building the most personalized and intelligent news experiences for Indias next 750 million digital users. As our Principal Machine Learning (ML) / Personalization Engineer, you will : Architect and deploy ML-based personalization systems for our suite of digital news products, including recommender systems for content ranking, homepage personalization, push notification targeting, and audience segmentation. Collaborate closely with editors, product managers, and analysts to integrate machine learning into the editorial workflowmaking content creation, packaging, and distribution smarter and audience-aware. Analyze user behavior and content consumption patterns using large-scale datasets to build user understanding models and inform personalization strategies. Own the end-to-end ML pipeline: from data acquisition, feature engineering, model training & evaluation, to deployment and real-time inference. Drive experimentation culture: lead A/B testing and iterative optimization of recommendation and ranking models. Stay on top of global trends in personalization, news AI, large language models (LLMs), and recommendation systems, and bring best-in-class solutions to our stack. Who You Need To Be Bachelors or Masters degree in Computer Science, Data Science, Statistics, or a related field. 812 years of experience in machine learning, ideally in recommendation systems, personalization, or search relevance. Strong experience with Python and ML frameworks like TensorFlow, PyTorch, or Scikit-learn. Hands-on with recommendation engines (collaborative filtering, content-based, hybrid models) and vector similarity models. Experience with real-time data processing frameworks and deploying models in production. Solid understanding of SQL and data platforms (e.g., Snowflake, BigQuery, or Redshift). Exposure to BI tools (Metabase, Looker, Tableau) is a plus. Comfortable navigating ambiguous, fast-paced environments and leading cross-functional initiatives. Excellent communication and collaboration skillsable to explain complex ML concepts to non-technical stakeholders. (ref:hirist.tech)",manager,,"Python, SQL, Tableau, Machine Learning",
4248378940,Evoort Solutions - MLOps Engineer,Evoort Solutions,"Delhi, Delhi, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More We are seeking a highly skilled MLOps Engineer with experience in Healthcare domain to join our team. The Engineer will be responsible for ensuring the accuracy, performance, and stability of ML models. This role includes continuous monitoring, maintenance, and improvement of ML pipelines, Docker images, and data synchronization processes. Key Responsibilities Model Accuracy & Performance : Perform in-depth analysis of model accuracy. Identify and diagnose issues affecting model accuracy. Collaborate with data scientists to address and rectify model shortcomings. Regularly compare model performance against previous results to identify trends and improvement & Infrastructure Maintenance: Design and implement cloud solutions for MLOps (AWS, Azure, or GCP). Build and maintain CI/CD pipelines using GitLab CI, GitHub Actions, Circle CI, Airflow, or similar tools. Maintain production pipelines and Docker images with the latest model code. Ensure stability and alignment between development and production environments. Model Deployment & Monitoring Manage containerization, deployment, versioning, and monitoring of ML models. Implement automated testing, validation, and quality checks for data science models. Troubleshoot and resolve bugs related to model deployment and data synchronization. Data Synchronization & Reporting Maintain consistent data synchronization across systems. Export and format monthly results for reporting and analysis. Upload and process monthly CSV data into databases. Implement and improve event logic for data insights. Stakeholder Collaboration Provide insights and explanations for model predictions to stakeholders. Collaborate with affiliate teams to address their needs related to predictions and model outputs. Conduct deep-dive analyses on model performance, including feature importance and model : 4+ years of experience as MLOps Engineer. Minimum 2 years experience supporting Healthcare business as MLOps Engineer. Proven experience in designing and implementing cloud-based MLOps solutions (AWS, Azure, GCP). Proficiency in CI/CD pipeline orchestration tools (GitLab CI, GitHub Actions, Circle CI, Airflow). Strong programming skills in Python, Go, Ruby, or Bash. Solid understanding of Linux environments. Hands-on experience with machine learning frameworks (scikit-learn, Keras, PyTorch, TensorFlow). Familiarity with Agile project delivery processes. Strong analytical and problem-solving skills with a quality control mindset. Excellent written and verbal communication skills for effective team coordination. Consulting experience with creativity, critical thinking, project planning, and attention to detail. Knowledge of the US/Europe pharmaceutical market and experience with pharmaceutical data is a plus. Number of Positions : 2. Job Type : Full-Time. Experience Required : 4+ Years (Mandatory: Healthcare Domain experience of 2 years). Location : Gurgaon. Work Mode : Onsite. Shift : UK Shift. (ref:hirist.tech)",,2 years experience,"Python, Machine Learning",
4226972663,Job For Trainer(Online N.Shift) (Data Science / Data Engineer) Opening,Onjob Group,"Noida, Uttar Pradesh, India",,Full-time,,"About the job This job is sourced from a job board. Learn More Hi, Job Description Role Responsibilities: Provide expert job support or on-the-job training in Data Science, Data Engineering, AWS, ML, AI more. Assist professionals in solving real-time project challenges. Work hourly at your convenience without affecting your full-time job. Preferred Candidate Profile 10+ years of experience in relevant technology, Data Science, Data Engineering, AWS, ML, AI more.. Strong Troubleshooting Mentoring Skills. Comfortable with flexible, hourly-based job support (WFH), Its remote job. Perks Benefits Earn 1L - 3L per month for extra 2 hours to 4 hours. Work on your scheduling commitment, no impact on your current job. Get paid hourly for your expertise. Interested? Apply Now Start Earning Extra! Contact: Bala (+91 82960 46895) and Email to bala@onjob.in This job is provided by Shine.com",,,,
4256415448,Power BI Developer Intern,Lead India,India (Remote),Remote,Full-time,,"About the job Job Title: Power BI Developer Intern Location: Remote Job Type: Internship (Full-Time) Duration: 1–3 Months Stipend: ₹25,000/month About the Role We are looking for a motivated and detail-oriented Power BI Developer Intern to join our team for a 1–3 month internship. As a Power BI intern, you will work closely with our data and business teams to design, develop, and maintain interactive dashboards and reports that provide key business insights. Key Responsibilities Assist in developing Power BI dashboards, reports, and visualizations. Transform raw data into meaningful insights using DAX and Power Query. Collaborate with cross-functional teams to gather requirements and define KPIs. Ensure data accuracy, performance, and visual storytelling in reports. Troubleshoot issues related to report performance or data inconsistencies. Document report logic, data sources, and user guides as needed. Requirements Currently pursuing or recently completed a degree in Computer Science, Data Science, Engineering, or a related field. Strong knowledge of Power BI and its components (Power Query, DAX, etc.). Familiarity with data modeling, data transformation, and visualization best practices. Basic understanding of SQL and relational databases. Strong analytical and problem-solving skills. Good communication and collaboration skills. Preferred Qualifications Experience with Excel, SQL Server, or other BI tools is a plus. Prior experience in creating dashboards for academic or personal projects. Understanding of business metrics and KPIs. What You’ll Gain Hands-on experience in real-world BI projects. Opportunity to work with experienced professionals in a fast-paced environment. Certificate of Internship upon successful completion. A chance to showcase your work and potentially transition to a full-time role.",,,"SQL, Excel, Power BI",
4228838863,Senior AI Engineer - REMOTE,Uplers,"Madurai, Tamil Nadu, India (Remote)",Save Senior AI Engineer - REMOTE at Uplers,Full-time,,"About the job Experience : 3.00 + years Salary : INR 2500000.00 / year (based on experience) Expected Notice Period : 30 Days Shift : (GMT+11:00) Australia/Melbourne (AEDT) Opportunity Type : Remote Placement Type : Full Time Indefinite Contract(40 hrs a week/160 hrs a month) (*Note: This is a requirement for one of Uplers' client - Okkular) What do you need for this opportunity? Must have skills required: Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python Okkular is Looking for: About The Job Company Description: We are a leading provider of fashion e-commerce solutions, leveraging generative AI to empower teams with innovative tools for merchandising and product discovery. Our mission is to enhance every product page with engaging customer-centric narratives, propelling accelerated growth and revenue generation. Join us in shaping the future of online fashion retail through cutting-edge technology and unparalleled creativity within the Greater Melbourne Area. Role Description: This is a full-time remote working position in India as a Senior AI Engineer . The Senior AI Engineer will be responsible for pattern recognition, neural network development, software development, and natural language processing tasks on a daily basis. Qualifications: Proficiency in sklearn, PyTorch, and fastai for implementing algorithms and training/improving models. Familiarity with Docker, AWS cloud services like Lambda, SageMaker, Bedrock. Familiarity with Streamlit. Knowledge of LangChain, LlamaIndex, Ollama, OpenRouter, and other relevant technologies. Expertise in pattern recognition and neural networks. Experience in Agentic AI development. Strong background in Computer Science and Software Development. Knowledge of Natural Language Processing (NLP). Ability to work effectively in a fast-paced environment and collaborate with cross-functional teams. Strong problem-solving skills and attention to detail. Master’s or PhD in Computer Science, AI, or a related field is preferred, but not mandatory. Strong experience in the field is sufficient alternative. Prior experience in fashion e-commerce is advantageous. Languages: Python, Golang Engagement Type: Direct-hire Job Type : Permanent Location : Remote Working time: 2:30 PM IST to 11:30 PM IST How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience Communication Skills, problem-solvers, Agentic AI, AWS services (Lambda, FastAI, LangChain, Large Language Model (LLM), Natural Language Processing (NLP), PyTorch, Sagemaker, Step Functions), Go Lang, Python",,,Python,
4207718668,ML Developer,Virtusa,"Andhra Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job JD:ML Developers to build prod-ready models that will help with content extraction and classification from images and text based sources. Should have worked on projects related to Intelligent document processing using open source models. Work with business and transformation teams to understand & formulate application specific design. Collaborative with product managers, technical teams. Create, test and iterate new and existing products and features. Design and Build Python/ML/OCR-based components. Completes applications development by coordinating requirements, schedules, and activities; contributing to team meetings, troubleshooting development and production problems across multiple environments and operating platforms. Should be able to troubleshoot development and production problems across multiple environments and operating platforms. Desired Skills and Experience ML Ops",manager,,Python,
4255445114,AI / ML Engineer,Accenture in India,"Chennai, Tamil Nadu, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Large Language Models Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: As an AI / ML Engineer, you will engage in the development of applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve designing and implementing production-ready solutions, ensuring that they meet quality standards. You will work with various AI models, including generative AI, and may also explore deep learning, neural networks, chatbots, and image processing technologies. Collaboration with cross-functional teams will be essential to integrate these solutions effectively into existing systems and workflows. Roles & Responsibilities: - Expected to be an SME. - Collaborate and manage the team to perform. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Provide solutions to problems for their immediate team and across multiple teams. - Facilitate knowledge sharing and training sessions to enhance team capabilities. - Monitor project progress and ensure alignment with strategic goals. Professional & Technical Skills: - Must To Have Skills: Proficiency in Large Language Models. - Good To Have Skills: Experience with cloud-based AI services. - Strong understanding of deep learning frameworks such as TensorFlow or PyTorch. - Familiarity with natural language processing techniques and tools. - Experience in developing and deploying chatbots and conversational agents. Additional Information: - The candidate should have minimum 5 years of experience in Large Language Models. - This position is based in Chennai. - A 15 years full time education is required. 15 years full time education",,,,
4233878447,Crest Infosystems - Machine Learning Engineer,Crest Infosystems Pvt. Ltd.,"Surat, Gujarat, India",,Full-time,,"About the job This job is sourced from a job board. Learn More Job Description We are looking for a skilled Machine Learning Engineer or AI Model Developer with at least 5 years of hands-on experience in building, training, and deploying custom AI models. The ideal candidate will have practical experience in developing and fine-tuning machine learning models rather than integrating pre-built models via APIs. Natural Abilities Smart, self-motivated, responsible, and out of the box thinker. Detailed oriented and powerful analyzer. Great writing communication skills. Requirements 5+ years of hands-on experience in building custom machine learning models (not just using APIs or pre-built models). Proficiency in machine learning frameworks such as TensorFlow, PyTorch, Keras, or similar. Strong programming skills in Python, with experience in libraries such as NumPy, pandas, scikit-learn, and others. Experience in training and fine-tuning machine learning models using real datasets. Knowledge of machine learning algorithms, model evaluation, and feature engineering. Hands-on experience with data preprocessing, model optimization, and hyperparameter tuning. Experience with cloud-based machine learning tools (AWS, GCP, or Azure) is a plus. Responsibilities Design, develop, and implement custom machine learning models tailored to specific business problems. Train, optimize, and validate machine learning models using real-world datasets and advanced techniques. Collaborate with cross-functional teams to understand requirements and deliver AI-driven solutions. Build and maintain end-to-end machine learning pipelines from data preprocessing to model deployment. Continuously improve the performance, scalability, and reliability of AI models in production environments. Perform model evaluations and select the best-performing models for real-world applications. Ensure proper documentation of model development processes and results. Stay current with industry trends, algorithms, and new technologies related to machine learning and AI. (ref:hirist.tech)",,,"Python, Machine Learning",
4226972661,Job For Trainer(Online N.Shift) (Data Science / Data Engineer) Opening,Onjob Group,"Gurugram, Haryana, India",,Full-time,,"About the job This job is sourced from a job board. Learn More Hi, Job Description Role Responsibilities: Provide expert job support or on-the-job training in Data Science, Data Engineering, AWS, ML, AI more. Assist professionals in solving real-time project challenges. Work hourly at your convenience without affecting your full-time job. Preferred Candidate Profile 10+ years of experience in relevant technology, Data Science, Data Engineering, AWS, ML, AI more.. Strong Troubleshooting Mentoring Skills. Comfortable with flexible, hourly-based job support (WFH), Its remote job. Perks Benefits Earn 1L - 3L per month for extra 2 hours to 4 hours. Work on your scheduling commitment, no impact on your current job. Get paid hourly for your expertise. Interested? Apply Now Start Earning Extra! Contact: Bala (+91 82960 46895) and Email to bala@onjob.in This job is provided by Shine.com",,,,
4248024771,AI Prompt Engineer – Finance Domain Expert (PhD/Masters),TELUS Digital AI Data Solutions,"Surat, Gujarat, India (Remote)",Remote,Part-time,,"About the job We are seeking a highly skilled Finance Specialists who possess a PhD/Masters to join our AI team as a Prompt Engineer. In this role, you will develop complex user prompts that incorporate pairs of mathematical skills in a non-trivial manner. Your work will contribute to cutting-edge approaches in AI data development and help illuminate the limitations of modern AI models. Key Responsibilities Develop intricate, domain-specific mathematical questions to probe AI model capabilities Create content that combine multiple mathematical concepts in innovative ways. You will create and review model responses to contribute to the improvement of AI model performance in mathematical reasoning. Project Details Duration: March to June 2025 Work Schedule: 3-4 hours per day in a freelance capacity. Location: Remote India residents only Mandatory: As part of your application you must have your CV and relevant qualifications uploaded in your application as it will impact your ability to undertake work with us if not provided. Payment rate The payment rate is in USD. If you are a holder of a PhD Degree USD 30 If you hold a Master Degree USD 20 This is an Independent Contractor opportunity. Payments will be issued through our TELUS Digital AI Community Platform. Qualification path Requirements PhD or Master's Degree in Finance, Business, Economics or a related field Strong background in advanced mathematics Excellent analytical and problem-solving skills Ability to think creatively and develop challenging mathematical scenarios Familiarity with AI and machine learning concepts (preferred) Strong written communication skills in English Desktop or Laptop Stable Internet Connection for the duration of the task If interested, please apply here: https://www.telusinternational.ai/cmp/contributor/jobs/available/126437?utm_source=Linkedin&utm_medium=Ads&utm_campaign=SHTArianne_APAC_Paid+Site_Linkedin_Ads_126437 Once you’ve completed your application through the link, kindly notify us by emailing tip_ai_crowdsourcing_apac@telusinternational.com so we can assist in tracking the progress of your application.",,,Machine Learning,
4253720223,"AI Developer -Product, Data & Technology - Tools India",SAP,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job We help the world run better At SAP, we enable you to bring out your best. Our company culture is focused on collaboration and a shared passion to help the world run better. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from. AI Developer –Product, Data & Technology - Tools India What you'll do Responsibilities As an AI Developer, you will play a key role in building innovative AI-powered applications to solve complex business challenges. Your responsibilities will include: Developing AI-powered applications leveraging Large Language Models (LLMs), AI agents, Model Context Protocol (MCP), Agent-to-Agent (A2A) protocol. Development, testing, performance, security and user experience of AI applications from prototyping to production. Collaborating with cross-functional teams to integrate AI capabilities into existing applications and workflows. What You Bring Bachelor’s or Master's degree in Computer Science, Artificial Intelligence, or a related field. 6+ years of IT experience. Must Have Skills Excellent programming skills in Python Experience with developing AI-powered applications Large Language Models (e.g., OpenAI, Hugging Face, LangChain, LLaMA) Agentic AI concepts and protocols (Model Context Protocol, Agent-to-Agent protocol) Nice to have skills Machine Learning frameworks (e.g., TensorFlow, PyTorch, scikit-learn) Lifecycle management for AI models (training, validation, deployment, and monitoring) DevOps / AIOps practices Meet your team Product, Data & Technology - Tools India is responsible for defining, designing & developing applications that support product development at SAP. We are the team responsible for several innovative applications including: Hyperspace (SAP’s official internal development platform) SAP Jira (SAP’s official backlog management tool with over 100,000 end-users) Lucid Capacity (simplified capacity management for development) SAP Transformation Navigator (provides guidance to SAP customers on charting their path to an intelligent enterprise. Winner of the 2017 Hasso Plattner Award) AI Pair Programming with GitHub Copilot We aim for excellence in our work and prioritize developing strong professional relationships and having fun at work. With teams in Walldorf, Palo Alto, Sofia, Paris and Bangalore, we offer an open, collaborative and international environment for continuous learning and career development! Bring out your best SAP innovations help more than four hundred thousand customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with two hundred million users and more than one hundred thousand employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, you can bring out your best. We win with inclusion SAP’s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world. SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy . Specific conditions may apply for roles in Vocational Training. EOE AA M/F/Vet/Disability Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability. Successful candidates might be required to undergo a background verification with an external vendor. Requisition ID: 423243 | Work Area: Software-Design and Development | Expected Travel: 0 - 10% | Career Status: Professional | Employment Type: Regular Full Time | Additional Locations: .",,,"Python, Machine Learning",
4169463083,AI-ML Tech Engineer [1 month NP MAX],Luxoft,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,,"About the job Project Description: New settlements and confirmation system for FX trades. Responsibilities We are seeking an AI-ML Tech Engineer who has a minimum of 8+ years of strong background in machine learning, data science, and software engineering. As a Machine Learning Engineer, you will develop and deploy machine learning models, work with large datasets, and collaborate with cross-functional teams to solve real-world problems. Mandatory Skills: • Proficient in building ML (Machine Learning) & NLP (Natural Language Processing) solutions using common ML libraries and frameworks. • Proficient with Python language and worked on various ML toolkits like TensorFlow, PyTorch, Keras, Scikit Learn. • Theoretical understanding of statistical models such as regression, clustering, and ML algorithms such as decision trees, Random Forests, neural networks, etc. • Strong understanding of cloud computing and cloud AI services. • Experience in deploying AI/ML models in production environments. • Experience in data analytics, feature creation, model selection and ensemble methods, performance metrics and visualization. • Experience working with large datasets and distributed computing systems. • Experience in fine-tuning DL models including LLMs, SLMs. • Knowledge of large language models from OpenAI such as GPT 3.5,GPT 4,C odex etc. • Experience with Vector Stores and RAG pipelines. • Proficient with Data-Modelling Tools. • Proficient with multiple ML deployment strategies including static and dynamic. • Excellent knowledge of CI, CD Pipelines for ML algorithms, training, prediction pipelines. • Experience in translating ML-based outcomes to business-digestible insights. • Excellent communication skills and experience in managing stakeholders at various levels. Nice-to-Have Skills: • Knowledge of ML Ops like continuous integration, continuous deployment. • Knowledge of full stack development. • Knowledge of Databricks, Data Mesh. • Knowledge of ETL (Extract, Transform, Load) pipeline. • Familiarity with agile methodologies, such as Scrum or Kanban, and project management tools such as JIRA/GITLAB. • Experience with frameworks like flask/Django. • Knowledge of Docker containers.",,,"Python, Machine Learning",
4256299345,Senior AI Engineer,Total-TECH Co,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Total Tech is looking for ""Senior AI Engineer"" for one of our mega clients. Location: Jeddah, KSA (full-time, on-site). Develop AI Models: Research and analyze data to identify trends and insights. Design and implement machine learning algorithms. Test and validate model performance against benchmarks. Must have hand-on experience with RAG and LLMs development 2.Collaborate with Teams Work with cross-functional teams to gather requirements. Present AI solutions and findings to stakeholders. Provide technical guidance to team members. 3.Data Management Collect, clean, and preprocess data for model training. Ensure data quality and compliance with regulations. Maintain data pipelines for ongoing model updates. Main Contacts: Data Science Team Product Management IT Department External AI Vendors Years of experience: 5:9 years with AI. Skills required: Machine Learning, Python, Data Analysis, Neural Networks, SQL . Main Contacts . Main Contacts . Main Contacts",,,"Python, SQL, Machine Learning, Data Analysis",
4205944595,Synaptic AI Engineer,Millennium,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job Description We are a high-impact and fast-paced infrastructure team, looking for an experienced AI Engineer to focus on building and enhancing our next-generation AI platform. Our mission is to create products that leverage cutting-edge AI technologies to significantly boost the productivity of our users. You'll be responsible for designing, implementing, and optimizing the core AI systems that power our platform, working with large language models, agent frameworks, and ensuring high performance and reliability of our AI services. Key Responsibilities Design and implement scalable back-end systems for AI applications (Python) Develop and optimize AI agent systems and workflows using modern agent frameworks Collaborate with ML engineers and front-end developers to create seamless AI experiences Work with other internal teams to integrate automations and other functionality into our core platform Build robust APIs and services that power our AI features Implement and maintain efficient data pipelines for AI model training and inference Ensure system reliability, performance, and security Contribute to technical architecture decisions and best practices Work within an agile team environment to deliver features on schedule Required Qualifications 5-7 years of professional software engineering experience Strong proficiency in Python (Golang and Java considered as well) Experience building and deploying production-grade back-end services Knowledge of RESTful APIs and microservice architectures Understanding of AI/ML concepts and integration patterns Experience with version control systems (Git) and CI/CD pipelines Strong problem-solving skills and attention to detail Excellent communication and collaboration skills Preferred Qualifications Experience with AI agent frameworks such as LangGraph, smolagents, or Autogen Familiarity with Model Context Protocol (MCP) Experience working with large language models and generative AI Understanding of vector databases and retrieval systems Experience with FastAPI or other async/middleware driven python web frameworks Knowledge of cloud platforms (AWS, GCP, or Azure) Experience with containerization and orchestration (Docker, Kubernetes) Proficiency in performance optimization and scaling of AI applications Background in distributed systems or high-availability architectures",,,Python,
4246251523,Computer Scientist - I,Adobe,"Noida, Uttar Pradesh, India",,Full-time,,"About the job Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! Adobe Illustrator is the industry-leading graphic design tool for people who love art, illustration and designing. It offers creative tools to design anything you can imagine – from logos and icons to graphics, typography and illustrations – and customize it with professional-level precision across desktop, mobile and web. The Adobe Illustrator team is looking for a passionate, hardworking and highly motivated engineer and technical problem solver to help build scalable, responsive, next-generation vector editing application that makes vector drawing ubiquitous. Responsibilities Desired Skills and Experience As a developer for Adobe Creative Cloud – Illustrator, you will work with a team of hardworking developers. You and your team will add features in products that are strategic to Adobe’s growth. Partner with Product Manager, fellow engineers, and other partners in defining the roadmap, scope, and work for releases. Lead your features end-to-end starting from gathering requirements, design, implementation, and instrumenting unit and automation test cases. Maintain existing features and constantly strive toward optimizing memory and processing footprint. Should be a proactive self-starter who can develop methods, techniques and evaluation criterion for obtaining results. You would be an expert on one or more platforms and knowledgeable of cross-platform issues, competitive products, and customer requirements. You would contribute significantly towards the development and application of advanced concepts, technologies and expertise within the team. This role involves addressing architecture and design issues for future products, providing strategic direction in evaluating new technologies. Must have Bachelors or Master’s degree in Computer Science or related from a premier institute 6+ years of hands on design / development experience Deep experience in modern C++, object-oriented programming, debugging, and profiling Expertise in writing highly performant native code on platforms like macOS, Windows, Web. Should have excellent computer science fundamentals and a good understanding of architecture, design and performance. Exceptional problem-solving skills Excellent interpersonal skills, written and verbal communication skills Must be familiar with working in a fast paced global environment Good to have Experience in C++/React programming language. Experience with GenAI, ML, Diffusion, LLM, LoRa models. Experience working with SQL database, In-memory cache. Experience with GPU, WebGL, Skia rendering. Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more about our vision here. Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.",Manager,,SQL,
4259094707,Backend Engineer - L2,Botsync,"Bengaluru, Karnataka, India (On-site)",On-site,Full-time,,"About the job This job is sourced from a job board. Learn More We are seeking a young and analytical thinking Full Stack Software Developer Engineer to join our Bangalore team. In this role, you will design, develop, and maintain Botsync's syncOS fleet manager software and focus mostly on the backend side of the web app. The ideal candidate should have an excellent command of Python, JavaScript programming languages and frameworks (Django-React Framework), a problem-solving attitude, and prior experience with full-stack development. Responsibilities Design, develop, and maintain Botsync's syncOS Fleet Manager software. Develop and maintain the back end of the web app. Develop and maintain, and share standard deployment configurations in Docker, podman, and Kubernetes for the web app. Configure and design the application for load balancing and redundancy. Design and develop REST APIs and Websocket endpoints to allow for third-party integrations. Make updates to the user interface in React.js . Ensure cross-platform optimization. Requirements Bachelor's degree or higher qualification in Computer Science Engineering, Information Technology, or related fields. Understanding of key design principles. Excellent knowledge of the Python Programming language. Good knowledge of the JavaScript programming language and React.js framework. Working knowledge of the Django framework and Redis. Excellent understanding of SQL and NoSQL databases. Keen understanding of backend system design, data flow, architecture diagrams, and likewise. Excellent understanding of REST APIs and Websockets. Good understanding of real-time communication applications. Excellent problem-solving skills. Excellent verbal and written communication skills. Ability to think and work independently. Skills: Python | Javascript | Linux OS | Django-React Framework | REST API and websockets | SQL and NoSQL DB| DSA | OOPS | Standard MS Office offerings - Excel, Powerpoint, Word | Excellent Communication abilities. This job was posted by Sonali Adity from Botsync. Desired Skills and Experience Java,Python,Django",manager,,"Python, SQL, Excel",
4247343534,Pune || AI/ML Engineer IRC260167,GlobalLogic,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Description Allvue Requirements Role Summary: The AI/ML Engineers will be responsible for developing, testing, and deploying machine learning models and AI algorithms that can be integrated into the product suite. The ideal candidate will have expertise in integrating large language models (LLMs) with external knowledge bases, fine-tuning model architectures for specific tasks, and optimizing retrieval strategies to improve the accuracy and relevance of generated content. Required Experience: 4 – 6 years of hands-on experience in machine learning model development and deployment. Hands-on experience in developing and fine-tuning Generative AI models, specifically focusing on Retrieval-Augmented Generation (RAG) systems. Experience with frameworks such as Hugging Face, OpenAI, or other GenAI platforms, along with proficiency in data preprocessing and model evaluation, is required Proficiency in Python, TensorFlow, Keras, PyTorch, or other AI/ML frameworks. Experience with model deployment and monitoring in production environments. Strong problem-solving skills and experience with cloud computing platforms (AWS, GCP, Azure). Familiarity with containerization and orchestration tools (e.g., Docker, Kubernetes). Job responsibilities Key Responsibilities: Implement and optimize AI/ML algorithms for product integration. Collaborate with data scientists to deploy models and integrate them with software products. Design scalable solutions for AI/ML applications. Develop automated pipelines for continuous model training and updates. Work with engineering teams to ensure smooth integration and operation of AI models in production. Monitor and troubleshoot AI/ML models to ensure reliability and performance. What we offer Culture of caring. At GlobalLogic, we prioritize a culture of caring. Across every region and department, at every level, we consistently put people first. From day one, you’ll experience an inclusive culture of acceptance and belonging, where you’ll have the chance to build meaningful connections with collaborative teammates, supportive managers, and compassionate leaders. Learning and development. We are committed to your continuous learning and development. You’ll learn and grow daily in an environment with many opportunities to try new things, sharpen your skills, and advance your career at GlobalLogic. With our Career Navigator tool as just one example, GlobalLogic offers a rich array of programs, training curricula, and hands-on opportunities to grow personally and professionally. Interesting & meaningful work. GlobalLogic is known for engineering impact for and with clients around the world. As part of our team, you’ll have the chance to work on projects that matter. Each is a unique opportunity to engage your curiosity and creative problem-solving skills as you help clients reimagine what’s possible and bring new solutions to market. In the process, you’ll have the privilege of working on some of the most cutting-edge and impactful solutions shaping the world today. Balance and flexibility. We believe in the importance of balance and flexibility. With many functional career areas, roles, and work arrangements, you can explore ways of achieving the perfect balance between your work and life. Your life extends beyond the office, and we always do our best to help you integrate and balance the best of work and life, having fun along the way! High-trust organization. We are a high-trust organization where integrity is key. By joining GlobalLogic, you’re placing your trust in a safe, reliable, and ethical global company. Integrity and trust are a cornerstone of our value proposition to our employees and clients. You will find truthfulness, candor, and integrity in everything we do. About GlobalLogic GlobalLogic, a Hitachi Group Company, is a trusted digital engineering partner to the world’s largest and most forward-thinking companies. Since 2000, we’ve been at the forefront of the digital revolution – helping create some of the most innovative and widely used digital products and experiences. Today we continue to collaborate with clients in transforming businesses and redefining industries through intelligent products, platforms, and services.",manager,,"Python, Machine Learning",
4256413984,Python Developer Remote Intern,Lead India,India (Remote),Save Python Developer Remote Intern at Lead India,Full-time,,"About the job Job Title: Python Developer Trainee Location: Remote Job Type: Internship (Full-Time) Duration: 1–3 Months Stipend: ₹25,000/month Department: Software Development / Engineering About the Internship: We are looking for passionate and driven individuals to join our team as Python Developer Trainees . This internship is an excellent opportunity to gain hands-on experience in Python programming, software development practices, and collaborative project work in a professional setting. You will work on live projects under the guidance of experienced developers and mentors. Key Responsibilities: Develop, test, and maintain Python-based applications and scripts. Assist in building RESTful APIs, data pipelines, or backend components. Write clean, efficient, and maintainable code following best practices. Debug and resolve issues in existing codebases. Collaborate with team members to deliver high-quality solutions. Learn and apply new technologies and tools as needed. Document development processes and code functionalities. Requirements: Basic understanding of Python programming and core concepts (data types, loops, functions, OOPs). Familiarity with any web framework like Flask or Django is a plus. Understanding of database systems like MySQL, PostgreSQL, or MongoDB is desirable. Strong analytical and problem-solving skills. Good communication and teamwork skills. Ability to work independently and manage time effectively in a remote environment. What You’ll Gain: ₹25,000/month stipend. Real-world development experience and exposure to live projects. Professional mentorship and code reviews from experienced developers. Internship completion certificate. Chance for a pre-placement offer (PPO) based on performance.",,,Python,
4239498153,Senior Generative AI Engineer,August Infotech,"Chorasi, Gujarat, India",,Full-time,,"About the job This job is sourced from a job board. Learn More Job Description This is a remote position. Introduction: Join August Infotech, an IT services and outsourcing leader, and make a significant impact through Generative AI. We're seeking a Senior Generative AI Engineer with a minimum of 3 years experience and a knack for leadership to join our team. This role involves developing advanced GenAI-based applications, managing projects, and leading teams. A Typical Day for a Senior Generative AI Engineer at August Infotech: Morning Routine: Check emails, messages, and project-related notifications. Plan the day, prioritize tasks, and review the progress of ongoing projects. Project Management: Review pending tasks from the previous day and prioritize them. Review the project roadmap, tasks, and goals for ongoing projects. Discuss new requirements, changes, or challenges with the project team. Coordinate with backend developers, front-end developers, and other stakeholders. Development and Code Review: Review code written by junior/intermediate developers for quality, security, and adherence to best practices. Address bugs, issues, or technical debt. Develop and customize Python applications, mainly using frameworks like Django or Flask. Create API endpoints, optimize database queries, or implement new features using Python. Client Communication: Communicate with clients to provide project updates, discuss requirements, and address questions or concerns. Testing and Debugging: Perform thorough testing of new features or changes to ensure functionality, performance, and compatibility. Debug and resolve issues or inconsistencies that arise during testing. Project Management Tools: Update project management tools or task boards to reflect the progress and completion of tasks. Estimate the time required for upcoming tasks and plan accordingly. End-of-Day Routine: Wrap up ongoing tasks, commit code changes, and ensure a clean and organized workspace. Reflect on the day's accomplishments, challenges, and areas for improvement. Architectural Design and Problem-Solving: Work on architectural design tasks, discussing and planning software components to meet project requirements and scalability needs. Solve complex technical challenges during development. Optimize code to improve application performance, scalability, and load times. Mentorship: Mentor junior/intermediate developers, providing guidance and support to help them grow and improve their skills. Requirements Skills and Qualifications: Bachelor's or Master's degree in Computer Science, Engineering, or a related field. Minimum three years of software development experience, focusing on Azure AI Services, Generative AI and Python. Minimum six months of hands-on experience with Generative AI technologies. Proficient in Python frameworks such as Django or Flask. Experience with Azure cloud services. Strong understanding of machine learning principles and techniques. Familiarity with natural language processing (NLP) and computer vision. Proficient in using libraries and tools such as TensorFlow, PyTorch, or similar. Strong problem-solving skills and ability to think critically. Excellent communication and collaboration skills. Experience with version control systems like Git. Nice To Have Skills: Experience with other cloud platforms such as Azure or Google Cloud. Knowledge of additional programming languages such as C#, R, Java, or Scala. Proficiency in database management systems, including SQL and NoSQL databases. Familiarity with software development best practices and methodologies. Understanding of microservices architecture and containerization technologies like Docker or Kubernetes. Enhanced presentation skills for effectively conveying complex findings. Benefits Permanent Remote 5 Days Working Technical Growth Certification Culture Monthly Performance Review Requirements Technical Requirements - Generative AI - Python",,3 years experience,"Python, SQL, R, Machine Learning",
4257562506,Unreal Engine Developer,Mihira Visual Labs,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job About Mihira Visual Labs Mihira Visual Labs is a research-driven CGI and VFX studio redefining filmmaking through AI- and ML-powered workflows. We specialize in the development and production of full-length animated films, empowering creators with cutting-edge tools to accelerate high-quality storytelling and IP creation. Our mission is to make world-class storytelling faster, more efficient, and more cost-effective — where human imagination is the only true differentiator. Role Overview We are looking for an Unreal Engine Developer with a strong foundation in Blueprints and UMG to help us build real-time cinematic and interactive experiences. In this role, you will work closely with our creative and technical teams to prototype, implement, and optimize real-time content. This is a hands-on development role with the opportunity to work at the forefront of VFX, animation, and virtual production technologies. Key Responsibilities Develop and implement real-time features using Unreal Engine Blueprints and/or C++ Design and build responsive, performant UI systems using UMG Collaborate closely with creative, technical, and production teams to support in-engine visualization and animation workflows Optimize and deploy Unreal Engine projects across multiple platforms, including iOS and Android Maintain clean, scalable, and well-documented code Qualifications & Skills Strong experience with Unreal Engine (Blueprints and/or C++) Bachelor’s degree in Computer Science, Game Development, Interactive Media, Animation Technology, or a related field. (Equivalent practical experience will also be considered) Proficient in UMG for UI/UX design and development Solid understanding of best practices for real-time graphics and performance optimization Nice To Have Experience with Sequencer workflows and timeline-based animations Familiarity with Cine Camera Actors and cinematic tools in UE Knowledge of Live Link and Remote Control API for real-time device integration Hands-on experience deploying projects to mobile platforms (iOS/Android) Exposure to Virtual Production pipelines and tools Python scripting experience within the Unreal Engine Editor",,,Python,
4212854972,Celonis Data Engineer/Consultant,Infosys,"Bengaluru East, Karnataka, India (On-site)",On-site,Full-time,,"About the job Celonis You have 2+ years of relevant work experience in process and data modelling. You have worked with data from ERP systems like SAP. You have a proven track record in using SQL and Python. You are a team player and can communicate data structural concepts and ideas to both technical and non-technical stakeholders. You have strong analytical skills and have an affinity with business concepts. Celonis Data Engineer/Implementation Professional certification will be an advantage. Celonis project experience will be a big plus. You will be part of an innovative team that drives our Celonis initiatives and to dive into business processes to determine root causes, quantify potential, and establish and drive improvement initiatives that make businesses more efficient. You will set up and maintain data models that will be the basis of the analyses and work together closely with the business analysts to generate the customized set of analytics that serve as a single source of truth for business performance measurement as well as data-driven decision making. You are responsible for setting data dictionary and maintaining data governance on the created structure. You identify the best possible strategy for data collection, ensure the data quality and work together with the stakeholders responsible for the data input to ensure we can correctly measure and track all necessary information. Collaborate with source system experts to ensure the source systems are set up correctly to gather all relevant information and support the most effective data structures. Create and maintain comprehensive documentation for data models, processes, and systems to facilitate knowledge sharing.",,,"Python, SQL",
4247343534,Pune || AI/ML Engineer IRC260167,GlobalLogic,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Description Allvue Requirements Role Summary: The AI/ML Engineers will be responsible for developing, testing, and deploying machine learning models and AI algorithms that can be integrated into the product suite. The ideal candidate will have expertise in integrating large language models (LLMs) with external knowledge bases, fine-tuning model architectures for specific tasks, and optimizing retrieval strategies to improve the accuracy and relevance of generated content. Required Experience: 4 – 6 years of hands-on experience in machine learning model development and deployment. Hands-on experience in developing and fine-tuning Generative AI models, specifically focusing on Retrieval-Augmented Generation (RAG) systems. Experience with frameworks such as Hugging Face, OpenAI, or other GenAI platforms, along with proficiency in data preprocessing and model evaluation, is required Proficiency in Python, TensorFlow, Keras, PyTorch, or other AI/ML frameworks. Experience with model deployment and monitoring in production environments. Strong problem-solving skills and experience with cloud computing platforms (AWS, GCP, Azure). Familiarity with containerization and orchestration tools (e.g., Docker, Kubernetes). Job responsibilities Key Responsibilities: Implement and optimize AI/ML algorithms for product integration. Collaborate with data scientists to deploy models and integrate them with software products. Design scalable solutions for AI/ML applications. Develop automated pipelines for continuous model training and updates. Work with engineering teams to ensure smooth integration and operation of AI models in production. Monitor and troubleshoot AI/ML models to ensure reliability and performance. What we offer Culture of caring. At GlobalLogic, we prioritize a culture of caring. Across every region and department, at every level, we consistently put people first. From day one, you’ll experience an inclusive culture of acceptance and belonging, where you’ll have the chance to build meaningful connections with collaborative teammates, supportive managers, and compassionate leaders. Learning and development. We are committed to your continuous learning and development. You’ll learn and grow daily in an environment with many opportunities to try new things, sharpen your skills, and advance your career at GlobalLogic. With our Career Navigator tool as just one example, GlobalLogic offers a rich array of programs, training curricula, and hands-on opportunities to grow personally and professionally. Interesting & meaningful work. GlobalLogic is known for engineering impact for and with clients around the world. As part of our team, you’ll have the chance to work on projects that matter. Each is a unique opportunity to engage your curiosity and creative problem-solving skills as you help clients reimagine what’s possible and bring new solutions to market. In the process, you’ll have the privilege of working on some of the most cutting-edge and impactful solutions shaping the world today. Balance and flexibility. We believe in the importance of balance and flexibility. With many functional career areas, roles, and work arrangements, you can explore ways of achieving the perfect balance between your work and life. Your life extends beyond the office, and we always do our best to help you integrate and balance the best of work and life, having fun along the way! High-trust organization. We are a high-trust organization where integrity is key. By joining GlobalLogic, you’re placing your trust in a safe, reliable, and ethical global company. Integrity and trust are a cornerstone of our value proposition to our employees and clients. You will find truthfulness, candor, and integrity in everything we do. About GlobalLogic GlobalLogic, a Hitachi Group Company, is a trusted digital engineering partner to the world’s largest and most forward-thinking companies. Since 2000, we’ve been at the forefront of the digital revolution – helping create some of the most innovative and widely used digital products and experiences. Today we continue to collaborate with clients in transforming businesses and redefining industries through intelligent products, platforms, and services.",manager,,"Python, Machine Learning",
4256294645,Site Reliability Engineer,Altysys,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Site Reliability Engineer – Resiliency Focus Experience: 4+ Years (Mandatory)- Budget -As per the Market . Key Areas of Expertise Required: Fault Tolerance: Systems should function despite component failures (e.g., redundant servers, fallback mechanisms) Graceful Degradation: Systems should reduce functionality/performance instead of failing completely Auto-Recovery: Self-healing infrastructure, auto-scaling capabilities Redundancy: Implementation of backups and failovers (e.g., multi-region deployments) Monitoring & Alerting: Ability to detect and act on issues proactively Chaos Engineering: Simulate failures to test resiliency strategies Disaster Recovery: Experience with planning and executing RTO/RPO strategies",Associate,,,
4221373274,Data Engineer_Hyd/Noida (2025),Arrise Solutions (India) Pvt. Ltd.,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Data Engineer Department: Engineering Type of Position: Full Time About us: Arrise Solutions (India) Pvt. Ltd. is a leading content provider to the iGaming and Betting Industry, offering a multi-product portfolio that is innovative, regulated and mobile-focused. We strive to create the most engaging and evocative experience for customers globally across a range of products, including slots, live casino, sports betting, virtual sports and bingo. We are seeking a talented and experienced Data Engineer that will work in a global team of Data Scientists delivering their pipelines into production in the most efficient way possible. You will also implement monitoring and alert systems. The ideal candidate should have in-depth knowledge and experience of Python, Azure/AWS, data storage, Data Pipelines. Key Responsibilities Create and manage ETL workflows using Python and relevant libraries (e.g., Pandas, NumPy) for high-volume data processing Monitor and optimize data workflows to reduce latency, maximize throughput, and ensure high-quality data availability. Develop REST API integrations and Python scripts to automate data exchanges with internal systems and BI dashboards. Implement validation processes and address anomalies or performance bottlenecks in real time. Design, develop and maintain Data Engineering pipelines for Machine Learning projects, ensuring high reliability and scalability. Collaborate with cross-functional teams across data Science and engineering to come up with solutions to complex problem statements. Automate existing workflows within Data Science team Required Skills And Qualifications Bachelor’s or master’s degree in computer science, Engineering, or a related field. Advanced Python proficiency with data libraries (Pandas, NumPy, etc.). Deep understanding of ETL / Reporting / Cloud (Azure) / DS technologies 3–5 years of professional experience in data engineering, ETL development, or similar roles. Experience in Azure Data Factory, Databricks, Azure data lake and Azure SQL Server. Configuration and Deployment of ADF packages. Experience working with SQL databases (e.g., MySQL, PostgreSQL) and NoSQL solutions (e.g., MongoDB). Experience with version control (Git) and continuous integration practices. Prior experience in handling very large datasets across different business functions. Excellent problem-solving, analytical, and communication skills. PREFERRED QUALIFICATIONS: Extensive experience with Azure ecosystem, particularly Azure Data Engineering and Machine Learning. Experience developing computer vision, text, audio, and/or tabular data models. Strong proficiency in Gitlab CI, Jenkins, Grafana, Docker. Excellent software engineering skills in API design and development, and concurrency design skills. If you are a skilled Data Engineer who has passion to work in a fast-paced environment, have an eye for details and ready to experiment new things, we encourage you to apply and be part of our dynamic and innovative team and organization. What We Offer Competitive compensation depending on experience Opportunities for professional and personal development Opportunities to progress within a dynamic team. Chance to work with close and collaborative colleagues Comprehensive health coverage OUR VALUES PERSISTENCE We never give up and are determined to be the best at what we do. RESPECT We value and respect our clients, their players, and our team members; promoting professionalism, integrity and fairness without compromise. OWNERSHIP We take ownership of our work and consistently deliver in a reliable manner; always providing the highest level of quality.",,,"Python, SQL, Machine Learning",
4186996419,Python Data Engineer,WIN Home Inspection,Greater Delhi Area (Remote),Remote,Full-time,,"About the job ABOUT THE PYTHON DATA ENGINEER ROLE: We are looking for a skilled Python Data Engineer to join our team and work on building high-performance applications and scalable data solutions. In this role, you will be responsible for designing, developing, and maintaining robust Python-based applications, optimizing data pipelines, and integrating various APIs and databases. This is more than just a coding role—it requires strategic thinking, creativity, and a passion for data-driven decision-making to drive results and innovation. KEY RESPONSIBILITIES: Develop, test, and maintain efficient Python applications. Design, develop, and maintain ETL pipelines for efficient data extraction, transformation, and loading. Implement and integrate APIs, web scraping techniques, and database queries to extract data from various sources. Design and implement algorithms for data processing, transformation, and analysis. Write optimized SQL queries and work with relational databases to manage and analyse large datasets. Collaborate with cross-functional teams to understand technical requirements and deliver high-quality solutions. Ensure code quality, performance, and scalability through best practices and code reviews. Stay updated with the latest advancements in Python, data engineering, and backend development. REQUIRED QUALIFICATIONS: Bachelor’s/Master’s degree in Computer Science, Engineering, or a related field. 3–5+ years of hands-on experience as Data Engineer using Python Proficiency in Python frameworks and libraries such as Pandas, NumPy, and Scrapy. Experience with Data Visualization tools such as Power BI, Tableau Strong understanding of relational databases and SQL. Experience working with cloud platforms such as AWS Strong problem-solving skills with an analytical mindset. Excellent communication skills and the ability to work in a collaborative team environment. WHY JOIN US? Highly inclusive and collaborative culture built on mutual respect. Focus on core values, initiative, leadership, and adaptability. Strong emphasis on personal and professional development. Flexibility to work remotely and/or hybrid indefinitely. ABOUT WIN: Founded in 1993, WIN is a highly innovative proptech company revolutionizing the real estate industry with cutting-edge software platforms and products. With the stability and reputation of a 30-year legacy paired with the curiosity and agility of a start-up, we’ve been recognized as an Entrepreneur 500 company, one of the Fastest Growing Companies, and the Most Innovative Home Services Company. OUR CULTURE: Our colleagues are driven by curiosity and tinkering and a desire to make an impact. They enjoy a culture of high energy and collaboration where we listen to each other with empathy, experience personal and professional growth, and celebrate small victories and big accomplishments. Click here to learn more about our company and culture: https://www.linkedin.com/company/winhomeinspection/life",,,"Python, SQL, Tableau, Power BI",
4252682082,"Staff, Software Engineer, Machine Learning Engineer – Conversational AI",Walmart Global Tech India,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Position Summary... Drives the execution of multiple business plans and projects by identifying customer and operational needs; developing and communicating business plans and priorities; removing barriers and obstacles that impact performance; providing resources; identifying performance standards; measuring progress and adjusting performance accordingly; developing contingency plans; and demonstrating adaptability and supporting continuous learning. Provides supervision and development opportunities for associates by selecting and training; mentoring; assigning duties; building a team-based work environment; establishing performance expectations and conducting regular performance evaluations; providing recognition and rewards; coaching for success and improvement; and ensuring culture of belongingawareness. Promotes and supports company policies, procedures, mission, values, and standards of ethics and integrity by training and providing direction to others in their use and application; ensuring compliance with them; and utilizing and supporting the Open Door Policy. Ensures business needs are being met by evaluating the ongoing effectiveness of current plans, programs, and initiatives; consulting with business partners, managers, co-workers, or other key stakeholders; soliciting, evaluating, and applying suggestions for improving efficiency and cost-effectiveness; and participating in and supporting community outreach events. What you'll do... Job Ad Description Job Summary About The Team As the Conversational AI team we are building completely new capabilities to allow our customers to shop, by seamlessly interacting with their connected devices using spoken and written language. This team is part of the Emerging tech organization and will build new voice experiences both in-house and in collaboration with strategic partners. Voice as a medium for shopping is still in its infancy and as part of this team you will get to work on industry leading solutions and be at the forefront of this emerging platform. What You'll Do As a Staff Machine Learning Engineer for Walmart, you'll have the opportunity to Partner with key business stakeholders and be a thought leader in the Conversational AI space for driving the development and planning of POCs and production AI solutions. Lead the design, development and deployment of complex machine learning solutions that drive business results and impact millions of customers worldwide. Collaborate with other engineers and data scientists to integrate machine learning models into products and services. Uphold ML engineering best practices - enforcing high standard for quality, reliability, and security in deployed machine learning solutions. Stay up to date with the latest AI/ML technologies and trend - acting as a thought leader for ML Engineering within the organization and in the broader technical community. Enhance current Deployment Solutions to make it cost as well as time efficient. Provide technical leadership, guidance and mentorship to a small group of highly skilled and motivated engineers. Lead innovation and efficiency through the complete problem-solving cycle, from approach to methods to development and results. Partner and engage with associates in other regions for delivering the best services to customers around the globe. Proactively participate in the external community to strengthen Walmart';s brand and gain insights into industry practices. Lead multiple initiatives within the platform, with focus on efficiency, innovation, and leverage. What You'll Bring Bachelors with 10; years or Masters with 8; years of relevant experience. Educational qualifications should be in Computer Science or related fields 7; year experience in deploying and scaling AI/ML systems for real-time inferencing and streaming applications. 7; year of experience with MLE technologies: Python, TensorFlow/Pytorch, Numpy, scikit-learn, Unix, Docker, CPU and GPU architectures, LangChain, Vector DB, etc. Have experience in designing the pipelines with different orchestration methods like Airflow, Kubernetes, Job Scheduler etc. 3; year experience in deep learning and generative AI technologies, with focus on optimised model deployments. 6; year experience with big data stack and relational/no-SQL databases: BigQuery, Spark, HDFC, MySQL, Cassandra, etc. 4; years of experience working with Kafka, ActiveMQ, Caches such as Redis or memcached, Elastic Search. 4; year of software engineering experience in developing services using Java/C;; Experience using managed servicing public cloud platforms such as Azure, GCP or AWS Usage of Model Deployment Framework like Triton Server, Seldon Core, Vertex AI is a plus. Extensive experience in working with large datasets and building batch data processing pipelines Advanced knowledge of performance, scalability, and system architecture with an eye toward avoiding and reducing technical debt Good problem-solving attitude and analytical skills Strong communication skills with inclination to high ownership and commitment About Walmart Global Tech Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. Thats what we do at Walmart Global Tech. Were a team of software engineers, data scientists, cybersecurity expert';s and service professionals within the worlds leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail. Flexible, hybrid work We use a hybrid way of working with primary in office presence coupled with an optimal mix of virtual presence. We use our campuses to collaborate and be together in person, as business needs require and for development and networking opportunities. This approach helps us make quicker decisions, remove location barriers across our global team, be more flexible in our personal lives. Benefits Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include a host of best-in-class benefits maternity and parental leave, PTO, health benefits, and much more. Belonging We aim to create a culture where every associate feels valued for who they are, rooted in respect for the individual. Our goal is to foster a sense of belonging, to create opportunities for all our associates, customers and suppliers, and to be a Walmart for everyone. At Walmart, our vision is ''everyone included.'' By fostering a workplace culture where everyone isâ€”and feelsâ€”included, everyone wins. Our associates and customers reflect the makeup of all 19 countries where we operate. By making Walmart a welcoming place where all people feel like they belong, were able to engage associates, strengthen our business, improve our ability to serve customers, and support the communities where we operate. Equal Opportunity Employer Walmart, Inc., is an Equal Opportunities Employer â€“ By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions â€“ while being welcoming of all people. Minimum Qualifications... Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications. Minimum Qualifications:Option 1: Bachelor's degree in computer science, computer engineering, computer information systems, software engineering, or related area and 4 years’ experience in software engineering or related area.Option 2: 6 years’ experience in software engineering or related area. Preferred Qualifications... Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications. Master’s degree in Computer Science, Computer Engineering, Computer Information Systems, Software Engineering, or related area and 2 years' experience in software engineering or related area Primary Location... 4,5,6, 7 Floor, Building 10, Sez, Cessna Business Park, Kadubeesanahalli Village, Varthur Hobli , India R-2165016",associate,,"Python, SQL, R, Machine Learning",
4169463083,AI-ML Tech Engineer [1 month NP MAX],Luxoft,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,,"About the job Project Description: New settlements and confirmation system for FX trades. Responsibilities We are seeking an AI-ML Tech Engineer who has a minimum of 8+ years of strong background in machine learning, data science, and software engineering. As a Machine Learning Engineer, you will develop and deploy machine learning models, work with large datasets, and collaborate with cross-functional teams to solve real-world problems. Mandatory Skills: • Proficient in building ML (Machine Learning) & NLP (Natural Language Processing) solutions using common ML libraries and frameworks. • Proficient with Python language and worked on various ML toolkits like TensorFlow, PyTorch, Keras, Scikit Learn. • Theoretical understanding of statistical models such as regression, clustering, and ML algorithms such as decision trees, Random Forests, neural networks, etc. • Strong understanding of cloud computing and cloud AI services. • Experience in deploying AI/ML models in production environments. • Experience in data analytics, feature creation, model selection and ensemble methods, performance metrics and visualization. • Experience working with large datasets and distributed computing systems. • Experience in fine-tuning DL models including LLMs, SLMs. • Knowledge of large language models from OpenAI such as GPT 3.5,GPT 4,C odex etc. • Experience with Vector Stores and RAG pipelines. • Proficient with Data-Modelling Tools. • Proficient with multiple ML deployment strategies including static and dynamic. • Excellent knowledge of CI, CD Pipelines for ML algorithms, training, prediction pipelines. • Experience in translating ML-based outcomes to business-digestible insights. • Excellent communication skills and experience in managing stakeholders at various levels. Nice-to-Have Skills: • Knowledge of ML Ops like continuous integration, continuous deployment. • Knowledge of full stack development. • Knowledge of Databricks, Data Mesh. • Knowledge of ETL (Extract, Transform, Load) pipeline. • Familiarity with agile methodologies, such as Scrum or Kanban, and project management tools such as JIRA/GITLAB. • Experience with frameworks like flask/Django. • Knowledge of Docker containers.",,,"Python, Machine Learning",
4240087820,AI Enabled Devops Engineer,IBM,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction As a Hardware Developer at IBM, you’ll get to work on the systems that are driving the quantum revolution and the AI era. Join an elite team of engineering professionals who enable IBM customers to make better decisions quicker on the most trusted hardware platform in today’s market. Your Role And Responsibilities We are part of a world-class development team that pioneers industry-leading hardware for IBM POWER Systems servers including Storage, Quantum, and IBM Research systems. Responsibilities Provide technical programming and automation support across all aspects of hardware development for our server products. Developing and maintaining custom software tools, integrating AI and machine learning capabilities into engineering workflows, supporting CI/CD pipelines, and managing development and validation environments. Partner with teams including electrical, mechanical, thermal, socket, module, and system development, as well as supporting areas such as project management, tools, and profit engineering. Preferred Education Bachelor's Degree Required Technical And Professional Expertise Demonstrated experience (3+ years) in programming languages such as Python, JavaScript, or similar scripting languages Strong understanding of Windows and Unix/Linux operating systems, including file systems, basic networking, and scripting environments Troubleshooting skills to diagnose and resolve technical issues related to automation, development environments, and tool support Strong interpersonal skills to effectively work across a wide range of engineering teams with varying technical backgrounds and cultures Must be effective working independently as well as in a highly collaborative, fast-paced team environment Self-starter with the ability to prioritize tasks, independently drive solutions, and deliver results with minimal supervision Strong analytical and problem-solving skills with high attention to detail, especially in identifying root causes and optimizing workflows Preferred Technical And Professional Experience Experience with AI/ML frameworks (such as TensorFlow, PyTorch, or OpenAI API) and integrating AI-based solutions into engineering workflows Familiarity with DevOps practices such as Continuous Integration/Continuous Deployment (CI/CD) and version control systems like Git Exposure to hardware development environments (electrical, mechanical, thermal, module, or manufacturing support) Experience developing or supporting engineering automation tools, dashboards, or data visualization system. Knowledge of server hardware, PCB design processes, mechanical design, or manufacturing workflows is a plus",,,"Python, Machine Learning",
4241889319,Data Engineer,Virtusa,"Andhra Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job Responsibilities Design and Develop Scalable Data Pipelines: Build and maintain robust data pipelines using Python to process, transform, and integrate large-scale data from diverse sources. Orchestration and Automation: Implement and manage workflows using orchestration tools such as Apache Airflow to ensure reliable and efficient data operations. Data Warehouse Management: Work extensively with Snowflake to design and optimize data models, schemas, and queries for analytics and reporting. Queueing Systems: Leverage message queues like Kafka, SQS, or similar tools to enable real-time or batch data processing in distributed environments. Collaboration: Partner with Data Science, Product, and Engineering teams to understand data requirements and deliver solutions that align with business objectives. Performance Optimization: Optimize the performance of data pipelines and queries to handle large scales of data efficiently. Data Governance and Security: Ensure compliance with data governance and security standards to maintain data integrity and privacy. Documentation: Create and maintain clear, detailed documentation for data solutions, pipelines, and workflows. Qualifications Required Skills: 5+ years of experience in data engineering roles with a focus on building scalable data solutions. Proficiency in Python for ETL, data manipulation, and scripting. Hands-on experience with Snowflake or equivalent cloud-based data warehouses. Strong knowledge of orchestration tools such as Apache Airflow or similar. Expertise in implementing and managing messaging queues like Kafka, AWS SQS, or similar. Demonstrated ability to build and optimize data pipelines at scale, processing terabytes of data. Experience in data modeling, data warehousing, and database design. Proficiency in working with cloud platforms like AWS, Azure, or GCP. Strong understanding of CI/CD pipelines for data engineering workflows. Experience working in an Agile development environment, collaborating with cross-functional teams. Preferred Skills Familiarity with other programming languages like Scala or Java for data engineering tasks. Knowledge of containerization and orchestration technologies (Docker, Kubernetes). Experience with stream processing frameworks like Apache Flink. Experience with Apache Iceberg for data lake optimization and management. Exposure to machine learning workflows and integration with data pipelines. Soft Skills Strong problem-solving skills with a passion for solving complex data challenges. Excellent communication and collaboration skills to work with cross-functional teams. Ability to thrive in a fast-paced, innovative environment. Desired Skills and Experience CI & CD, ETL",,,"Python, Machine Learning",
4259201929,Sr Associate IS Security Engineer - Veeva Vault,Amgen,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,"Experience in building configured and custom solutions on Veeva Vault Platform. Experience in managing systems, implementing and validating projects in GxP regulated environments. Extensive expertise in SDLC, including requirements, design, testing, data analysis, creating and managing change controls. Proficiency in programming languages such as Python, JavaScript etc. Good understanding of software development methodologies, including Agile and Scrum. Experience with version control systems such as Git. Good-to-Have Skills: Familiarity with relational databases (such as MySQL, SQL server, PostgreSQL etc.) Proficiency in programming languages such as Python, JavaScript or other programming languages Outstanding written and verbal communication skills, and ability to translate technical concepts for non-technical audiences. Experience with ETL Tools (Informatica, Databricks). Experience with API integrations such as MuleSoft. Solid understanding & Proficiency in writing SQL queries. Hands on experience on reporting tools such as Tableau, Spotfire & Power BI. Professional Certifications: Veeva Vault Platform Administrator or Equivalent Vault Certification (Mandatory) SAFe for Teams (Preferred) Soft Skills: Excellent analytical and troubleshooting skills. Strong verbal and written communication skills. Ability to work effectively with global, virtual teams. Team-oriented, with a focus on achieving team goals. Strong presentation and public speaking skills. Shift Information: This position requires you to work a later shift and may be assigned a second or third shift schedule. Candidates must be willing and able to work during evening or night shifts, as required based on business requirements. What You Can Expect Of Us As we work to develop treatments that take care of others, we also work to care for your professional and personal growth and well-being. From our competitive benefits to our collaborative culture, we’ll support your journey every step of the way. In addition to the base salary, Amgen offers competitive and comprehensive Total Rewards Plans that are aligned with local industry standards. Apply now and make a lasting impact with the Amgen team. careers.amgen.com As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other and live the Amgen values to continue advancing science to serve patients. Together, we compete in the fight against serious disease. Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other basis protected by applicable law. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company Amgen 1,422,303 followers Follow Biotechnology Research 10,001+ employees 34,623 on LinkedIn Amgen harnesses the best of biology and technology to fight the world’s toughest diseases, and make people’s lives easier, fuller and longer. We helped establish the biotechnology industry, and we remain on the cutting-edge of innovation, using technology and human genetic data to push beyond what’s known today. Our investment in research and development has yielded a robust pipeline that builds on our existing portfolio of medicines to treat cancer, heart disease, osteoporosis, inflammatory diseases and rare diseases. Amgen is one of 30 companies comprising the Dow Jones Industrial Average®, and part of the Nasdaq-100 Index®. In 2024, Amgen was named one of the “World’s Most Innovative Companies” by Fast Company and one of “America’s Best Large Employers” by Forbes. For more information, visit Amgen.com and follow us on X, LinkedIn, Instagram, TikTok, YouTube and Threads. 🔗 Community Guidelines: https://wwwext.amgen.com/community-guidelines 🔗Global Privacy Statement Directory: www.amgen.com/dp Special Advisory: Please be cautious of scam recruitment offers claiming to be from Amgen. Such scams may come from various sources, including fake websites and/or unsolicited emails and seek to obtain personal data or payment from victims by offering jobs that do not exist. Please be advised that Amgen would never ask for payment to progress a job application. When in doubt, please check to see if the position in question is posted on this website before applying. Additionally, please report any suspicious recruiting activity to https://complaint.ic3.gov/ and thank you for your assistance. … show more Interested in working with us in the future? Members who share that they’re interested in a company may be 2x as likely to get a message from a recruiter than those who don’t. Learn more Learn more about Interested in working for our company I’m interested Trending employee content Page 1 of 4 Previous Next Show more","About the job Join Amgen’s Mission of Serving Patients At Amgen, if you feel like you’re part of something bigger, it’s because you are. Our shared mission—to serve patients living with serious illnesses—drives all that we do. Since 1980, we’ve helped pioneer the world of biotech in our fight against the world’s toughest diseases. With our focus on four therapeutic areas –Oncology, Inflammation, General Medicine, and Rare Disease– we reach millions of patients each year. As a member of the Amgen team, you’ll help make a lasting impact on the lives of patients as we research, manufacture, and deliver innovative medicines to help people live longer, fuller happier lives. Our award-winning culture is collaborative, innovative, and science based. If you have a passion for challenges and the opportunities that lay within them, you’ll thrive as part of the Amgen team. Join us and transform the lives of patients while transforming your career. [POSITION TITLE] What You Will Do Let’s do this. Let’s change the world. In this vital role you will In this vital role in the Veeva Vault team you will be responsible for designing, developing, and maintaining security solutions that meet business needs. This role involves working closely with product managers, designers, and other engineers to create high-quality, scalable software solutions and automating operations, monitoring system health, and responding to incidents to minimize downtime. Roles & Responsibilities: Solid understanding of Veeva Basic and Atomic security configuration. Ensure compliance with relevant regulations and maintain current certification status against various standards. Identifying control gaps, advising teams on how to address them, and collecting, organizing, and reviewing evidence for Veeva products. They also play a crucial role in planning and managing audits, interacting with external auditors, and advising management on risk and control issues. Lead day to day operations and maintenance of Amgen’s R&D Veeva Vaults and hosted applications. Possesses strong rapid prototyping skills and can quickly translate concepts into working code. Stay updated with the latest trends, advancements and standard process for Veeva Vault Platform ecosystem. Design, develop, and implement applications and modules, including custom reports, SDKs, interfaces, and enhancements. Analyze and understand the functional & technical requirements of applications, solutions and systems, translate them into software architecture and design specifications. Develop and execute unit tests, integration tests, and other testing strategies to ensure the quality of the software following IS change control and GxP Validation process while exhibiting expertise in Risk Based Validation methodology. Work closely with multi-functional teams, including product management, design, and QA, to deliver high-quality software on time. Maintain detailed documentation of software designs, code, and development processes. Work on integrating with other systems and platforms to ensure seamless data flow and functionality. Stay up to date on Veeva Vault Features, new releases and best practices around Veeva Platform Governance. Basic Qualifications and Experience: Master’s degree and 5 to 7years of Computer Science, IT or related field experience OR Bachelor’s degree and 7 to 9 years of Computer Science, IT or related field experience Functional Skills: Must-Have Skills: Experience with Veeva Vault Platform and Products, including Veeva configuration settings and custom builds. Strong knowledge of information systems and network technologies. 6-8 years of experience working in global pharmaceutical Industry Experience in building configured and custom solutions on Veeva Vault Platform. Experience in managing systems, implementing and validating projects in GxP regulated environments. Extensive expertise in SDLC, including requirements, design, testing, data analysis, creating and managing change controls. Proficiency in programming languages such as Python, JavaScript etc. Good understanding of software development methodologies, including Agile and Scrum. Experience with version control systems such as Git. Good-to-Have Skills: Familiarity with relational databases (such as MySQL, SQL server, PostgreSQL etc.) Proficiency in programming languages such as Python, JavaScript or other programming languages Outstanding written and verbal communication skills, and ability to translate technical concepts for non-technical audiences. Experience with ETL Tools (Informatica, Databricks). Experience with API integrations such as MuleSoft. Solid understanding & Proficiency in writing SQL queries. Hands on experience on reporting tools such as Tableau, Spotfire & Power BI. Professional Certifications: Veeva Vault Platform Administrator or Equivalent Vault Certification (Mandatory) SAFe for Teams (Preferred) Soft Skills: Excellent analytical and troubleshooting skills. Strong verbal and written communication skills. Ability to work effectively with global, virtual teams. Team-oriented, with a focus on achieving team goals. Strong presentation and public speaking skills. Shift Information: This position requires you to work a later shift and may be assigned a second or third shift schedule. Candidates must be willing and able to work during evening or night shifts, as required based on business requirements. What You Can Expect Of Us As we work to develop treatments that take care of others, we also work to care for your professional and personal growth and well-being. From our competitive benefits to our collaborative culture, we’ll support your journey every step of the way. In addition to the base salary, Amgen offers competitive and comprehensive Total Rewards Plans that are aligned with local industry standards. Apply now and make a lasting impact with the Amgen team. careers.amgen.com As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other and live the Amgen values to continue advancing science to serve patients. Together, we compete in the fight against serious disease. Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other basis protected by applicable law. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",Associate,,"Python, SQL, Tableau, Power BI, R, Data Analysis",
4249778357,Snaplogic Data Engineer,Ideagen,"Hyderabad, Telangana, India (On-site)",On-site,Part-time,,"About the job About Us Location - Hyderabad, India Department - Product R&D Level - Professional Working Pattern - Work from office. Benefits - Benefits At Ideagen DEI - DEI strategy Salary - this will be discussed at the next stage of the process, if you do have any questions, please feel free to reach out! We are seeking an experienced Snaplogic Data Engineer who is having strong problem solving and analytical skills, high attention to detail, passion for analytics, real-time data, and monitoring and critical Thinking and collaboration skills. The candidate should be a self-starter and a quick learner, ready to learn new technologies and tools that the job demands. Responsibilities Building automated pipelines and solutions for data migration/data import or other operations requiring data ETL. Performing analysis on core products to support migration planning and development. Working closely with the Team Lead and collaborating with other stakeholders to gather requirements and build well architected data solutions. Produce supporting documentation, such as specifications, data models, relation between data and others, required for the effective development, usage and communication of the data operations solutions with different stakeholders. Competencies, Characteristics And Traits Mandatory Skills - Total Experience - 5 years, of which a Minimum 3 years of Experience with SnapLogic pipeline development and a minimum of 2 years in building ETL/ELT Pipelines, is needed. Experience working with databases on-premises and/or cloud-based environments such as MSSQL, MySQL, PostgreSQL, AzureSQL, Aurora MySQL & PostgreSQL, AWS RDS etc. Experience working with API sources and destinations. Essential Skills and Experience Strong experience working with databases on-premises and/or cloud-based environments such as MSSQL, MySQL, PostgreSQL, AzureSQL, Aurora MySQL & PostgreSQL, AWS RDS etc Strong knowledge of databases, data modeling and data life cycle Proficient in understanding data and writing complex SQL Mandatory Skills - Total Experience - 5 years, of which a Minimum 3 years of Experience with SnapLogic pipeline development and a minimum 2 years in building ETL/ELT Pipelines, is needed. Experience working with REST API in data pipelines Strong problem solving and high attention to detail Passion for analytics, real-time data, and monitoring Critical Thinking, good communication and collaboration skills Focus on high performance and quality delivery Highly self-motivated and continuous learner Desirable Experience working with no-SQL databases like MongoDB Experience with Snaplogic administration is preferable Experience working with Microsoft Power Platform (PowerAutomate and PowerApps) or any similar automation / RPA tool Experience with cloud data platforms like snowflake, data bricks, AWS, Azure etc Awareness of emerging ETL and Cloud concepts such as Amazon AWS or Microsoft Azure Experience working with Scripting languages, such as Python, R, JavaScript, etc. About Ideagen Ideagen is the invisible force behind many things we rely on every day - from keeping airplanes soaring in the sky, to ensuring the food on our tables is safe, to helping doctors and nurses care for the sick. So, when you think of Ideagen, think of it as the silent teammate that's always working behind the scenes to help those people who make our lives safer and better. Everyday millions of people are kept safe using Ideagen software. We have offices all over the world including America, Australia, Malaysia and India with people doing lots of different and exciting jobs. What is next? If your application meets the requirements for this role, our Talent Acquisition team will be in touch to guide you through the next steps. To ensure a flexible and inclusive process, please let us know if you require any reasonable adjustments by contacting us at recruitment@ideagen.com. All matters will be treated with strict confidence. At Ideagen, we value the importance of work-life balance and welcome candidates seeking flexible or part-time working arrangements. If this is something you are interested in, please let us know during the application process. Enhance your career and make the world a safer place!",,,"Python, SQL, R",
4259099578,SQL Developer Trainee,Innovate Solutions,India (Remote),Remote,Full-time,,"About the job Job Title: SQL Developer Trainee Location: Remote Job Type: Internship (Full-Time) Duration: 1–3 Months Stipend: ₹25,000/month Department: Data & Engineering Job Summary: We are seeking a detail-oriented and motivated SQL Developer Trainee to join our team remotely. This internship is designed for recent graduates or students who want to gain practical experience in database development, writing SQL queries, and working with data in real-world applications. Key Responsibilities: Write, test, and optimize SQL queries for data extraction and reporting Assist in designing and maintaining database structures (tables, views, indexes, etc.) Help ensure data integrity, accuracy, and security across systems Support the team in troubleshooting and debugging database-related issues Collaborate with developers and analysts to fulfill data requirements for projects Document query logic and database-related processes Qualifications: Bachelor’s degree (or final year student) in Computer Science, Information Technology, or related field Strong understanding of SQL and relational databases (e.g., MySQL, PostgreSQL, SQL Server) Familiarity with database design and normalization Analytical mindset with good problem-solving skills Ability to work independently in a remote setting Eagerness to learn and grow in a data-driven environment Preferred Skills (Nice to Have): Experience with procedures, triggers, or functions in SQL Exposure to BI/reporting tools (Power BI, Tableau, etc.) Understanding of data warehousing concepts Familiarity with cloud-based databases or platforms What We Offer: Monthly stipend of ₹25,000 Remote work opportunity Hands-on experience with real-world datasets and projects Mentorship and structured learning sessions Certificate of Completion Potential for full-time employment based on performance",,,"SQL, Tableau, Power BI",
4217270562,Machine Learning Engineer (Remote),Uplers,"Amritsar, Punjab, India (Remote)",Save Machine Learning Engineer (Remote) at Uplers,Full-time,,"About the job Experience : 5.00 + years Salary : INR 5000000.00 / year (based on experience) Expected Notice Period : 15 Days Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full Time Permanent position(Payroll and Compliance to be managed by: Precanto) (*Note: This is a requirement for one of Uplers' client - A fast-growing, VC-backed B2B SaaS platform revolutionizing financial planning and analysis for modern finance teams.) What do you need for this opportunity? Must have skills required: async workflows, MLOps, Ray Tune, Data Engineering, MLFlow, Supervised Learning, Time-Series Forecasting, Docker, machine_learning, NLP, Python, SQL A fast-growing, VC-backed B2B SaaS platform revolutionizing financial planning and analysis for modern finance teams. is Looking for: We are a fast-moving startup building AI-driven solutions to the financial planning workflow. We’re looking for a versatile Machine Learning Engineer to join our team and take ownership of building, deploying, and scaling intelligent systems that power our core product. Job Description- Full-time Team: Data & ML Engineering We’re looking for 5+ years of experience as a Machine Learning or Data Engineer (startup experience is a plus) What You Will Do- Build and optimize machine learning models — from regression to time-series forecasting Work with data pipelines and orchestrate training/inference jobs using Ray, Airflow, and Docker Train, tune, and evaluate models using tools like Ray Tune, MLflow, and scikit-learn Design and deploy LLM-powered features and workflows Collaborate closely with product managers to turn ideas into experiments and production-ready solutions Partner with Software and DevOps engineers to build robust ML pipelines and integrate them with the broader platform Basic Skills Proven ability to work creatively and analytically in a problem-solving environment Excellent communication (written and oral) and interpersonal skills Strong understanding of supervised learning and time-series modeling Experience deploying ML models and building automated training/inference pipelines Ability to work cross-functionally in a collaborative and fast-paced environment Comfortable wearing many hats and owning projects end-to-end Write clean, tested, and scalable Python and SQL code Leverage async workflows and cloud-native infrastructure (S3, Docker, etc.) for high-throughput data processing. Advanced Skills Familiarity with MLOps best practices Prior experience with LLM-based features or production-level NLP Experience with LLMs, vector stores, or prompt engineering Contributions to open-source ML or data tools TECH STACK Languages: Python, SQL Frameworks & Tools: scikit-learn, Prophet, pyts, MLflow, Ray, Ray Tune, Jupyter Infra: Docker, Airflow, S3, asyncio, Pydantic How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience async workflows, MLOps, Ray Tune, Data Engineering, MLFlow, Supervised Learning, Time-Series Forecasting, Docker, machine_learning, NLP, Python, SQL",manager,,"Python, SQL, Machine Learning",
4255441809,AI / ML Engineer,Accenture in India,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Large Language Models Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: As an AI / ML Engineer, you will engage in the development of applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve designing and implementing production-ready solutions, ensuring that they meet quality standards. You will work with various AI models, including generative AI, deep learning, and neural networks, while also exploring innovative applications such as chatbots and image processing. Collaboration with cross-functional teams will be essential to integrate these advanced technologies effectively into existing systems and workflows. Roles & Responsibilities: - Expected to be an SME. - Collaborate and manage the team to perform. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Provide solutions to problems for their immediate team and across multiple teams. - Facilitate knowledge sharing sessions to enhance team capabilities. - Monitor project progress and ensure alignment with strategic goals. Professional & Technical Skills: - Must To Have Skills: Proficiency in Large Language Models. - Good To Have Skills: Experience with cloud-based AI services. - Strong understanding of deep learning frameworks such as TensorFlow or PyTorch. - Familiarity with natural language processing techniques. - Experience in developing and deploying chatbots and conversational agents. Additional Information: - The candidate should have minimum 5 years of experience in Large Language Models. - This position is based at our Noida office. - A 15 years full time education is required. 15 years full time education",,,,
4251748013,Senior Machine Learning Engineer,Balancehero India,"Gurugram, Haryana, India (On-site)",On-site,Full-time,,"About the job About Balancehero India Balancehero India Pvt. Ltd. (BHI), the wholly-owned subsidiary of Balancehero Co. Ltd., Korea which runs and operates the mobile app “True Balance”- a one-stop destination for financial services.” Founded by Charlie Lee in Korea in 2014, Balancehero started its operations in India in the year 2016. It started off as a balance check application and the company has expanded its business model to financial services. The company aims to build a financial platform for the next billion which set the context for loans, utility services, pay later services, and commerce services. The Company's wholly-owned subsidiary True Credits Private Limited, is a licensed NBFC that aims to bridge the financial gap in India by making Finance available for all. True Credits lends through the True Balance mobile application. About True Balance Owned and operated by BalanceHero Group, True Balance is an RBI authorized Prepaid Payment Instrument (PPI) issuing entity. It offers loans through its subsidiary and RBI licensed Non-Banking Financial Company - True Credits Private Limited and other RBI licensed partners. Founded in 2016, as a mobile app for users in India to efficiently manage their phone calls and data usage, True Balance is now India’s one of the top financial services platforms providing solutions to all the financial needs of its users - from obtaining instant loans, paying utility bills to do prepaid recharges seamlessly. To date, True Balance has raised more than US$84 million in equity funding from marquee global investors like Softbank, Naver, and Line to name a few. The company aims to become the go-to financial services platform for the next billion people in India, playing a key role in the nationwide push towards the goal of Digital India and advancing financial inclusion amongst the unbanked and underbanked people. Balancehero India | LinkedIn About True Credits Established in 2019, True Credits is the RBI licensed NBFC that provides innovative financial services to empower the next billion unbanked users. They cater to the personal and business needs of consumers by providing fast and hassle-free finance. True Credits is focused towards unbanked users who have created a huge demand for instant credit services in India. Job Description: About the Role : BalanceHero's ML Engineer builds and operates training/serving systems and data pipelines for ML/LLM powered applications related to marketing/review/recovery of loan products. About the Responsibilities Building and operating data pipelines and feature stores for training and serving ML/LLM models Building and operating ML/LLM model serving systems Building and operating monitoring systems for ML/LLM powered applications Managing and deploying ML/LLM model versions Requirements Fluent in Python Experience on designing and building data pipelines for large-scale data using Hadoop Ecosystem in a cloud environment Experience on managing model versions and deployments while continuously updating one or more ML-powered applications Experience on operating ML Products that provide real-time prediction services Experience on open source (Triton, torchserve, BentoML, ONNX, etc.) and cloud solutions (AWS Sagemaker Endpoint, GCP Vertex AI, etc.) for model serving Experience on monitoring data shift and consistency while maintaining ML/LLM powered applications Preferred qualification Experience on Pyspark and Polars in large scale project Experience on AWS ML-related services (EMR, Glue, Sagemaker, Athena, etc.) Experience optimizing high-performance models using GPU Roles and responsibilities: About the Role: BalanceHero's ML Engineer builds and operates training/serving systems and data pipelines for ML/LLM powered applications related to marketing/review/recovery of loan products. About the Responsibilities Building and operating data pipelines and feature stores for training and serving ML/LLM models Building and operating ML/LLM model serving systems Building and operating monitoring systems for ML/LLM powered applications Managing and deploying ML/LLM model versions . Required Experience : Fluent in Python Experience on designing and building data pipelines for large-scale data using Hadoop Ecosystem in a cloud environment Experience on managing model versions and deployments while continuously updating one or more ML-powered applications Experience on operating ML Products that provide real-time prediction services Experience on open source (Triton, torchserve, BentoML, ONNX, etc.) and cloud solutions (AWS Sagemaker Endpoint, GCP Vertex AI, etc.) for model serving Experience on monitoring data shift and consistency while maintaining ML/LLM powered applications",Executive,,Python,
4196581485,Machine Learning Engineer - AI,Egnyte,India (Remote),Remote,Full-time,,"About the job Description Title: ML Engineer Location: India, Remote EGNYTE YOUR CAREER. SPARK YOUR PASSION. Role Egnyte is a place where we spark opportunities for amazing people. We believe that every role has meaning, and every Egnyter should be respected. With 17,000 customers worldwide and growing, you can make an impact by protecting their valuable data. When joining Egnyte, you’re not just landing a new career, you become part of a team of Egnyters who doers, thinkers, and collaborators are who embrace and live by our values: Invested Relationships Fiscal Prudence Candid Conversations About Egnyte Egnyte is the secure multi-cloud platform for content security and governance that enables organizations to better protect and collaborate on their most valuable content. Established in 2008, Egnyte has democratized cloud content security for more than 22,000 organizations, helping customers improve data security, maintain compliance, prevent and detect ransomware threats, and boost employee productivity on any app, any cloud, anywhere. For more information, visit www.egnyte.com . The Opportunity We are looking for an experienced engineer who will help us to design, develop, and deploy machine learning & deep learning models in production, with a strong focus on NLP solutions. The core of the work will be focused on providing technical leadership for the development of NLP projects. Besides tasks associated with developing models into production, an important part of the work concerns the development of appropriate approaches and tools to ensure the professional management of our models in production. Finally, transferring knowledge, providing technical expertise to the team members, and helping shape up the team is an integral part of the job. Your Day-to-day At Egnyte Supervising the full development of machine learning & deep learning projects, from design to deployment and maintenance Providing technical leadership for the development of NLP projects Reviewing state-of-the-art machine learning & deep learning technologies/models with a strong focus on NLP Evaluating potential ML solutions and choosing the most appropriate ones depending on technical and business needs, in close collaboration with our Product team Defining the architecture of machine learning-based projects, including integrations with other Egnyte products Supporting the whole lifecycle of our machine learning models, including gathering data for (re)training, A/B testing, deployment, monitoring, retraining, and redeployments Working closely within a distributed team to analyze and apply innovative solutions over billions of documents Communicating your approach and results to a wider audience through articles and presentations About You Documented technical excellence in NLP Demonstrated success with machine learning & deep learning in a SaaS or Cloud environment, with hands–on knowledge of model creation and deployments in production at scale Advanced communication skills, especially with regards to knowledge transfer Ability to provide mentorship and team support Fluency in at least one deep learning framework: PyTorch, TensorFlow / Keras Advanced knowledge of the HuggingFace libraries (transformers and tokenizers) or the Fairseq library Fluency in Python, Docker, Kubernetes, Helm Solid English skills to effectively communicate with other team members Bonus Skills Experience with large datasets and distributed computing, especially with the Google Cloud Platform Good understanding of advanced analytical modeling and statistical forecasting techniques Knowledge of Java, Scala or Go-Lang programming languages Familiarity with Kubeflow Experience with OpenCV Names containing “BERT” are very welcomed ;-) Benefits Competitive salaries Medical insurance and healthcare benefits for you and your family Fully paid premiums for life insurance Flexible hours and PTO Mental wellness platform subscription Gym reimbursement Childcare reimbursement Group term life insurance Commitment To Diversity, Equity, And Inclusion At Egnyte, we celebrate our differences and thrive on our diversity for our employees, our products, our customers, our investors, and our communities. Egnyters are encouraged to bring their whole selves to work and to appreciate the many differences that collectively make Egnyte a higher-performing company and a great place to be.",associate,,"Python, Machine Learning",
4256419165,SQL Developer Intern,Lead India,India (Remote),Remote,Full-time,,"About the job About Lead India: Lead India is a forward-thinking IT company offering end-to-end digital solutions, software development, and data-driven services. We believe in nurturing fresh talent and giving them the opportunity to work on meaningful, real-world projects in a supportive remote environment. Internship Overview: We are seeking a motivated and detail-oriented SQL Developer Intern to join our team. In this role, you’ll be working with databases, writing and optimizing SQL queries, and contributing to the development and maintenance of our data systems. Key Responsibilities: Write, test, and optimize SQL queries and stored procedures Assist in the design and maintenance of database schemas Perform data extraction, transformation, and loading (ETL) tasks Collaborate with the data and development teams to troubleshoot and improve database performance Document database processes and ensure data accuracy and integrity Support reporting needs with custom queries and data exports Required Skills: Good understanding of SQL and relational databases (MySQL, PostgreSQL, SQL Server, etc.) Basic knowledge of database design and normalization Familiarity with tools like MySQL Workbench, SSMS, or pgAdmin Strong problem-solving and analytical skills Attention to detail and ability to work independently in a remote setup Nice to Have: Exposure to ETL tools or processes Basic knowledge of performance tuning and query optimization Understanding of data warehousing concepts Experience with scripting languages (Python, Shell) for automation What You’ll Gain: Practical experience working on real SQL/database projects Guidance from experienced developers and mentors Remote work flexibility Internship certificate and Letter of Recommendation Opportunity for a full-time role or pre-placement offer (based on performance) You will get salary upto 25,000/- per month.",,,"Python, SQL",
4190955006,Machine Learning Engineer 5,Adobe,"Bengaluru, Karnataka, India",,Full-time,,"About the job Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! Adobe Advertising Cloud Adobe Advertising is a combination of a ‘Demand Side Platform (DSP)’ and a ‘Spend Optimizer’ that helps customers plan, buy, measure, and optimize their digital media (across CTV, Online Video, Display, Search, Social, and Retail Media Networks). We help the largest global advertisers maximize the impact of their paid media budgets by delivering connected and personalized experiences to their consumers. The Opportunity This opportunity is with the Spend Optimizer group. In collaboration with a team of highly motivated data scientists and engineers, you will apply reinforcement learning, time series analysis, bayesian modeling, Gen AI frameworks to optimize ad spends. What you'll Do Technically lead and guide team of skilled machine learning engineers to design and implement ML algorithms/models Collaborate with multi-functional teams to determine technical requirements Develop and deploy scalable machine learning solutions that optimize Adobe’s products and services, deliver value to clients and drive customer adoption Drive innovation through research and experimentation, encouraging an environment where new ideas can thrive Monitor and evaluate the performance of ML models, making vital adjustments to compete at the highest level What you need to succeed Outstanding knowledge of machine learning frameworks and tools such as PyTorch, Tensorflow, Scikit-learn, with strong programming skills in Python Solid understanding of core machine learning and statistics, including Bayesian Modeling, Time Series Analysis, Reinforcement Learning, and Optimization Experience in developing, deploying and maintaining ML models in a production environment Ability to thrive in a collaborative, inclusive, and diverse workplace, embracing different perspectives and ideas Ideal Candidate Profile: A total of 10+ years of experience in an applied Machine Learning setting, delivering cloud-scale, data-driven products, and services PhD or master’s in Computer Science/ Applied Math/Statistics/ related field. Experience and domain expertise in Digital ad technologies is desirable. Comfort with ambiguity, adaptability to evolving priorities, and an ability to influence technical and non-technical collaborators Adobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more. Adobe aims to make Adobe.com accessible to all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015. Adobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other’s employees. Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more about our vision here. Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.",,,"Python, Machine Learning",
4227617554,Data Engineer,Acuity Knowledge Partners,"Gurugram, Haryana, India (On-site)",On-site,Full-time,,"About the job We're seeking a skilled Software Engineer with expertise in Python and it would be nice to have experience of working on Large Language Models (LLM) to join our team. Essential skills Minimum of a bachelor’s degree in a technical or quantitative field with strong academic background Demonstrated ability to implement data engineering pipelines and real-time applications in python (C++ is a plus) Proficiency with object oriented programming in python is a must Experience with Linux/Unix shell/ scripting languages and Git is a must Experience with python based tools like Jupyter notebook, coding standards like pep8 is a plus Strong problem-solving skills and understanding of data structures and algorithms Experience with large-scale data processing and pipeline development Understanding of various LLM frameworks and experience with prompt engineering using Python or other scripting languages Nice to have Knowledge of natural language processing (NLP) concepts, familiarity with integrating and leveraging LLM APIs for various applications Key Responsibilities Design, develop, and maintain projects using Python along with operational support Transform a wide range of structured and unstructured data into standardized outputs for quantitative analysis and financial engineering Participate in code reviews, ensure coding standards, and contribute to the improvement of the codebase Develop the utility tools that can further automate the software development, testing and deployment workflow Collaborate with internal and external cross-functional teams",Executive,,Python,
4234988250,Data Engineer,Virtusa,"Andhra Pradesh, India (Hybrid)",Hybrid,Full-time,,"About the job This role will be instrumental in building and maintaining robust, scalable, and reliable data pipelines using Confluent Kafka, ksqlDB, Kafka Connect, and Apache Flink. The ideal candidate will have a strong understanding of data streaming concepts, experience with real-time data processing, and a passion for building high-performance data solutions. This role requires excellent analytical skills, attention to detail, and the ability to work collaboratively in a fast-paced environment. Essential Responsibilities Design & develop data pipelines for real time and batch data ingestion and processing using Confluent Kafka, ksqlDB, Kafka Connect, and Apache Flink. Build and configure Kafka Connectors to ingest data from various sources (databases, APIs, message queues, etc.) into Kafka. Develop Flink applications for complex event processing, stream enrichment, and real-time analytics. Develop and optimize ksqlDB queries for real-time data transformations, aggregations, and filtering. Implement data quality checks and monitoring to ensure data accuracy and reliability throughout the pipeline. Monitor and troubleshoot data pipeline performance, identify bottlenecks, and implement optimizations. Automate data pipeline deployment, monitoring, and maintenance tasks. Stay up-to-date with the latest advancements in data streaming technologies and best practices. Contribute to the development of data engineering standards and best practices within the organization. Participate in code reviews and contribute to a collaborative and supportive team environment. Work closely with other architects and tech leads in India & US and create POCs and MVPs Provide regular updates on the tasks, status and risks to project manager The experience we are looking to add to our team Required Bachelors degree or higher from a reputed university 8 to 10 years total experience with majority of that experience related to ETL/ELT, big data, Kafka etc. Proficiency in developing Flink applications for stream processing and real-time analytics. Strong understanding of data streaming concepts and architectures. Extensive experience with Confluent Kafka, including Kafka Brokers, Producers, Consumers, and Schema Registry. Hands-on experience with ksqlDB for real-time data transformations and stream processing. Experience with Kafka Connect and building custom connectors. Extensive experience in implementing large scale data ingestion and curation solutions Good hands on experience in big data technology stack with any cloud platform - Excellent problemsolving, analytical, and communication skills. Ability to work independently and as part of a team Good to have Experience in Google Cloud Healthcare industry experience Experience in Agile Desired Skills and Experience AWS Native Data Services, CI/CD, Hive, Kafka, Scala, PySpark",manager,,,
4240091064,Data Engineer-Enterprise Content Management,IBM,"Hyderabad, Telangana, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology Your Role And Responsibilities Design and Development of ECM Solutions FileNet API Integration Configure and manage Events, Subscriptions, and Triggers in the Content Engine to support business process automation. Define and enforce security policies, including Access Control Lists (ACLs), role-based access control (RBAC), and document-level security configurations Preferred Education Master's Degree Required Technical And Professional Expertise FileNet Developer with IBM FileNet P8 platform. The ideal candidate will be responsible for designing, developing, implementing, and supporting enterprise content management solutions using FileNet, including customization of IBM Content Navigator (ICN), working with FileNet APIs, managing Records Manager configurations, and executing large-scale content migrations. Required Skills and Experience: Experience in IBM FileNet P8 platform (5.2/5.5 or higher). Strong hands-on experience with FileNet Java APIs (CE/PE APIs) Understanding, configuration and management of Event, Triggers in Content Engine to automate business logic. Implement and maintain FileNet security, including ACLs, role-based access control (RBAC), and document-level security Good communication skills and ability to work independently or as part of a team Preferred Technical And Professional Experience IBM FileNet certification (e.g., IBM Certified Specialist - FileNet Content Manager). Experience with workflow design using FileNet BPM/Case Manager. Experience integrating FileNet with other enterprise systems via REST/SOAP APIs",Manager,,,
4217268791,Machine Learning Engineer (Remote),Uplers,"Guwahati, Assam, India (Remote)",Save Machine Learning Engineer (Remote) at Uplers,Full-time,,"About the job Experience : 5.00 + years Salary : INR 5000000.00 / year (based on experience) Expected Notice Period : 15 Days Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full Time Permanent position(Payroll and Compliance to be managed by: Precanto) (*Note: This is a requirement for one of Uplers' client - A fast-growing, VC-backed B2B SaaS platform revolutionizing financial planning and analysis for modern finance teams.) What do you need for this opportunity? Must have skills required: async workflows, MLOps, Ray Tune, Data Engineering, MLFlow, Supervised Learning, Time-Series Forecasting, Docker, machine_learning, NLP, Python, SQL A fast-growing, VC-backed B2B SaaS platform revolutionizing financial planning and analysis for modern finance teams. is Looking for: We are a fast-moving startup building AI-driven solutions to the financial planning workflow. We’re looking for a versatile Machine Learning Engineer to join our team and take ownership of building, deploying, and scaling intelligent systems that power our core product. Job Description- Full-time Team: Data & ML Engineering We’re looking for 5+ years of experience as a Machine Learning or Data Engineer (startup experience is a plus) What You Will Do- Build and optimize machine learning models — from regression to time-series forecasting Work with data pipelines and orchestrate training/inference jobs using Ray, Airflow, and Docker Train, tune, and evaluate models using tools like Ray Tune, MLflow, and scikit-learn Design and deploy LLM-powered features and workflows Collaborate closely with product managers to turn ideas into experiments and production-ready solutions Partner with Software and DevOps engineers to build robust ML pipelines and integrate them with the broader platform Basic Skills Proven ability to work creatively and analytically in a problem-solving environment Excellent communication (written and oral) and interpersonal skills Strong understanding of supervised learning and time-series modeling Experience deploying ML models and building automated training/inference pipelines Ability to work cross-functionally in a collaborative and fast-paced environment Comfortable wearing many hats and owning projects end-to-end Write clean, tested, and scalable Python and SQL code Leverage async workflows and cloud-native infrastructure (S3, Docker, etc.) for high-throughput data processing. Advanced Skills Familiarity with MLOps best practices Prior experience with LLM-based features or production-level NLP Experience with LLMs, vector stores, or prompt engineering Contributions to open-source ML or data tools TECH STACK Languages: Python, SQL Frameworks & Tools: scikit-learn, Prophet, pyts, MLflow, Ray, Ray Tune, Jupyter Infra: Docker, Airflow, S3, asyncio, Pydantic How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience async workflows, MLOps, Ray Tune, Data Engineering, MLFlow, Supervised Learning, Time-Series Forecasting, Docker, machine_learning, NLP, Python, SQL",manager,,"Python, SQL, Machine Learning",
4256421167,SQL Developer Trainee,Lead India,India (Remote),Remote,Full-time,,"About the job SQL Developer Internship (Remote) Type: Full-Time Stipend: ₹25,000/month Location: Remote About the Internship We are looking for a detail-oriented SQL Developer Intern to support our data and backend teams. This full-time remote internship offers hands-on experience working with real-world data, query optimization, and database management in a collaborative environment. Key Responsibilities Write and optimize SQL queries for data extraction, reporting, and analysis Assist in database design, maintenance, and performance tuning Work with large datasets to identify patterns, trends, and anomalies Support data migration, integration, and validation activities Document query logic, workflows, and database changes Eligibility & Requirements Strong knowledge of SQL and relational database concepts Familiarity with database systems like MySQL, PostgreSQL, or MS SQL Server Understanding of indexing, joins, stored procedures, and query optimization Experience with data analysis or BI tools is a plus Self-motivated and reliable in a remote working environment Good communication and problem-solving skills Perks Fixed stipend of ₹25,000 for the internship period Flexible remote working environment Internship certificate upon successful completion Mentorship and exposure to production-level data systems",,,"SQL, Data Analysis",
4255465356,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Large Language Models Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: As an AI / ML Engineer, you will engage in the development of applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve designing and implementing production-ready solutions, ensuring that they meet quality standards. You will work with various AI models, including generative AI, deep learning, and neural networks, while collaborating with cross-functional teams to integrate these technologies into existing systems. Your role will also require you to stay updated with the latest advancements in AI and machine learning, applying this knowledge to enhance the functionality and efficiency of the applications you develop. Roles & Responsibilities: - Expected to be an SME. - Collaborate and manage the team to perform. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Provide solutions to problems for their immediate team and across multiple teams. - Mentor junior team members to foster their professional growth. - Continuously evaluate and improve existing AI models and applications. Professional & Technical Skills: - Must To Have Skills: Proficiency in Large Language Models. - Strong understanding of deep learning frameworks such as TensorFlow or PyTorch. - Experience with cloud platforms like AWS, Azure, or Google Cloud for deploying AI solutions. - Familiarity with natural language processing techniques and tools. - Ability to design and implement scalable AI applications. Additional Information: - The candidate should have minimum 5 years of experience in Large Language Models. - This position is based at our Hyderabad office. - A 15 years full time education is required. 15 years full time education",,,Machine Learning,
4231455531,Machine Learning Engineer 4,Adobe,"Noida, Uttar Pradesh, India",,Full-time,,"About the job Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! The Challenge: Search, Discovery, and Content AI (SDC) is a cornerstone of Adobe’s ecosystem, enabling creative professionals and everyday users to access, discover, and demonstrate a wide array of digital assets and creative content, including images, videos, documents, vector graphics and more. With increasing demand for intuitive search, contextual discovery, and seamless content interactions across Adobe products like Express, Lightroom, and Adobe Stock, SDC is evolving into a generative AI powerhouse. This team develops innovative solutions for intent understanding, personalized recommendations, and action orchestration to transform how users interact with content. Working with extensive datasets and pioneering technologies, you will help redefine the discovery experience and drive user success. If working at the intersection of machine learning, generative AI, and real-time systems excites you, we’d love to have you join us. Responsibilities: As a Machine Learning Engineer on the SDC team, you will develop and optimize machine learning models and algorithms for search, recommendation, and content understanding across diverse content types. You will build and deploy scalable generative AI solutions to enable intelligent content discovery and contextual recommendations within Adobe products. Collaborating with multi-functional teams, you will integrate ML models into production systems, ensuring high performance, reliability, and user impact. Your role will involve researching, designing, and implementing pioneering techniques in natural language understanding, computer vision, and multimodal learning for content and asset discovery. You will also contribute to the end-to-end ML pipeline, including data preprocessing, model training, evaluation, deployment, and monitoring, while pushing the boundaries of computational efficiency to meet the needs of real-time, large-scale applications. Partnering with product teams, identify customer needs and translate them into innovative solutions that prioritize usability and performance. Additionally, you will mentor and provide technical guidance to junior engineers and multi-functional collaborators, driving excellence and innovation within the team. What You’ll Need to Succeed: Bachelor’s or equivalent experience, advanced degree such as a Ph.D. in Computer Science, Machine Learning, Data Science, or a related field. 6–9 years of industry experience building and deploying machine learning systems at scale. Proficiency in programming languages such as Python (for ML/AI) and Java (for production-grade systems). Strong expertise in machine learning frameworks and tools (e.g., TensorFlow, PyTorch). Solid understanding of mathematics and ML fundamentals: linear algebra, statistics, optimization, and numerical methods. Experience with deep learning techniques for computer vision (e.g., CNNs, transformers), natural language understanding (e.g., BERT, GPT), or multimodal AI. Consistent track record of delivering ML solutions to production environments, optimizing performance, and ensuring reliability. Knowledge of large-scale distributed systems and frameworks (e.g., Kubernetes, Spark, Hadoop). Strong problem-solving skills and the ability to innovate new solutions for complex challenges. Excellent communication and collaboration skills to work efficiently in a fast-paced, multi-functional environment. Nice-to-Haves: Experience with generative AI (e.g., Stable Diffusion, DALL·E, MidJourney) and its application in content creation or discovery. Knowledge of computational geometry, 3D modeling, or animation pipelines. Familiarity with real-time recommendation systems or search indexing. Publications in peer-reviewed journals or conferences in relevant fields. Why Join Us? Be part of a dynamic, innovative team shaping the future of AI-powered creative tools. Work on impactful, large-scale projects that touch millions of users daily. Enjoy the benefits and resources of a leading global company with the agility of a startup environment. Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more about our vision here. Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.",,,"Python, Machine Learning",
4259202810,Release Train Engineer,Amgen,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Let’s do this. Let’s change the world. In this vital role you will work with product and platform teams in the implementation of 3DEXPERIENCE PLM solutions across the organization. They will interact with the organization’s Product Teams (5 teams), Portfolio Management and Communities of Practice to continuously improve standards, processes, and automation enablers that accelerate staff and team SAFe maturity and overall business agility. This role will also facilitate the ongoing coordination across the program, enable and guide the scrum masters, and also act as a Scrum Master. This role requires deep understanding of Agile principles and frameworks like SAFe, Scrum practices, along with excellent leadership and communication skills. Roles & Responsibilities: Lead the implementation and adoption of the Scaled Agile Framework (SAFe) across the Product Teams. Assess current states of Agile maturity, identify areas for improvement, and guide the organization in aligning with SAFe principles and practices. Work closely with multi-functional teams to ensure alignment and effective communication. Facilitate collaboration between business and technical teams to achieve common goals. Communicate progress, challenges, and successes to customers at all levels. Collaborate with stakeholders to establish and track KPIs related to SAFe implementation. Support the Scaled Agile transformation efforts within the organization, including the adoption of SAFe principles, practices, and mindset. Assess the current state of Agile maturity and develop a roadmap for improvement. Provide guidance and support to teams and leaders in transitioning to Agile methodologies. Mentor Agile teams to improve their performance, collaboration, and delivery capabilities. Provide coaching to Scrum Masters, RTEs, Product Owners, and team members to enhance their Agile skills. Provide training and workshops on SAFe principles and practices to teams and collaborators. Foster a culture of continuous improvement and learning within the organization. Conduct regular assessments of current processes and identify areas for improvement. Implement standard methodologies and tools to streamline workflows and enhance productivity. Monitor and measure the effectiveness of process changes and make necessary adjustments. Act as a change agent, promoting the benefits of SAFe and driving organizational transformation. They collaborate with teams, leaders, and collaborators to create a shared understanding of SAFe and its value and help overcome resistance to change. Leverage agile tools such as Jira / Jira Align, Smartsheet’s and Confluence Act as a change agent, promoting the benefits of SAFe and driving organizational transformation. Collaborate with teams, leaders, and collaborators to create a shared understanding of SAFe and its value and help overcome resistance to change. What We Expect Of You We are all different, yet we all use our unique contributions to serve patients. The [vital attribute] professional we seek is a [type of person] with these qualifications. Basic Qualifications: Doctorate degree / Master's degree / Bachelor's degree and 8 to 13 years of experience in SAFe implementations and delivery Preferred Qualifications: Functional Skills: Must-Have Skills: Strong knowledge of SAFe methodologies and practices Prior experience with Agile project management tools, such as Jira Software, Confluence, and Jira Align Hands on experience in guiding teams and Agile Release Trains through SAFe events and ensuring consistency to SAFe practices and behaviors Must demonstrate proactiveness in understanding the product team’s backlog, dependencies, risks and influence the team to progress through sprints, product increments and releases. Must conduct PI planning event with the product team Excellent problem-solving skills and a passion for tackling complex challenges Collaborative spirit and effective communication skills to work seamlessly in a multi-functional team Good-to-Have Skills: Experiences with agile transformations in larger enterprises and legacy systems Jira Align experience Workshop facilitation and training development experience Knowledge of Product Lifecycle Management with software such as 3DEXPERIENCE, Windchill, Oracle Fusion Cloud or Teamcenter Professional Certifications: Certified SAFe Scrum Master, Release Train Engineer or equivalent Soft Skills: Excellent people and project management skills Ability to work collaboratively with cross-functional teams Ability to manage multiple priorities successfully High degree of initiative and self-motivation Team-oriented, with a focus on achieving team goals What You Can Expect Of Us As we work to develop treatments that take care of others, we also work to care for your professional and personal growth and well-being. From our competitive benefits to our collaborative culture, we’ll support your journey every step of the way. In addition to the base salary, Amgen offers competitive and comprehensive Total Rewards Plans that are aligned with local industry standards. Apply now and make a lasting impact with the Amgen team. careers.amgen.com",Associate,,,
4247771998,Artificial Intelligence Engineer,Tata Consultancy Services,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Greetings from TCS. TCS is Hiring For AI Engineer Experience: 9-14 years Relevant Experience: 9-14 years WORK Location: PAN India Job Description- Must Have 9- 14 years of IT experience Strong programming skills in Python Expertise in machine learning is a must. In depth knowledge of various machine learning models and techniques; deep learning, supervised and unsupervised learning, natural language processing, and reinforcement learning. Expertise in data analysis and visualization to extract insights from large datasets and transmit them virtually. Good knowledge on data mining, statistical methods, data wrangling, and visualization tools like Power BI, Tableau and matplotlib. Hands on skills in Data Manipulation Language. Expertise in various machine learning frameworks - TensorFlow, Scikit-Learn and PyTorch. Good to Have - Gen AI Certification Experience in Containers (Docker), Kubernetes, Kafka (or other messaging platform), Apache Camel, RabbitMQ, Active MQ, Storage / RDBMS and No-SQL databases etc..",,,"Python, SQL, Tableau, Power BI, Machine Learning, Data Analysis",
4253712747,GenAI MLOps Engineer,NielsenIQ,Pune/Pimpri-Chinchwad Area,,Full-time,,"About the job Company Description NIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. Job Description About the Role As a GenAI MLOps Engineer on our AI Engineering team, you’ll build, deploy, and maintain the core infrastructure that powers our generative-AI products. You’ll partner closely with data scientists and software engineers to productionize LLM-based models, automate workflows, and keep services reliable and cost-effective. Core Responsibilities (Must-Have) Pipeline & CI/CD Design, build, and operate repeatable ML pipelines (data prep → training → evaluation → deploy) using tools such as Airflow, Prefect, or cloud-native solutions Author automated CI/CD workflows (GitHub Actions, Azure DevOps, or Jenkins) for model code, pipelines, and container builds, including linting and automated tests Model Deployment & Serving Containerize models with Docker; deploy to Kubernetes (AKS/EKS/GKE) or serverless (Cloud Run, Azure Functions) Implement safe rollout patterns (canary, blue/green) to minimize risk when updating model versions Monitoring & Alerting Instrument inference endpoints and pipelines with key metrics (latency, throughput) and logs Create dashboards and alerts (Prometheus/Grafana or cloud-native alternatives) to detect errors, drift, and performance regressions Cloud & Infrastructure Operate core compute resources on one major cloud platform (Azure Databricks, AWS SageMaker, or GCP Vertex AI) Write and maintain basic Infrastructure-as-Code (Terraform, or CloudFormation) for provisioning clusters and managed services GenAI Orchestration & Vector Retrieval Use orchestration framework (e.g., LangGraph, Langfuse etc) to automate GenAI workflows Support embedding-based retrieval pipelines: collaborate on vector index maintenance and refresh processes Collaboration & Documentation Work with data science to integrate new models into production Produce clear runbooks, architecture diagrams, and “on-call” guides Qualifications 5 years in DevOps/MLOps roles, including at least 3 years supporting ML or deep-learning systems Hands-on with one major cloud (Azure/AWS/GCP) and experience provisioning compute for training/inference Strong skills in Docker and Kubernetes or serverless deployments Proven ability to author CI/CD pipelines and IaC Experience with monitoring stacks (Prometheus/Grafana, Datadog, or cloud-native tools) Familiarity with a prompt-orchestration framework (e.g., LangChain) and core vector-retrieval concepts Soft Skills Effective communicator who can translate technical details to cross-functional teams Strong problem-solver who can troubleshoot across data, model, and infrastructure layers Eager to learn new tools and iterate rapidly in a fast-paced environment Additional Information Growth & Nice-to-Have Security & Compliance: Basic API auth (OAuth/JWT), secrets management (Key Vault, AWS KMS), and data encryption Testing & Validation: Data-quality checks (e.g., Great Expectations), adversarial testing, and automated model-quality gates Scalability & Cost Optimization: Capacity planning, load testing (Locust, JMeter), spot-instance usage, and caching strategies (Redis) Reliability Engineering: Participation in on-call rotations, post-mortems, and error-budget SLOs; chaos-testing fundamentals Experimentation Lifecycle: Tracking experiments and hyperparameter sweeps (MLflow, Optuna), and supporting A/B tests Tooling Flexibility: Familiarity with alternative MLOps frameworks (Kubeflow, TFX) or observability stacks (OpenTelemetry) Our Benefits Flexible working environment Volunteer time off LinkedIn Learning Employee-Assistance-Program (EAP) About NIQ NIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population. For more information, visit NIQ.com Want to keep up with our latest updates? Follow us on: LinkedIn | Instagram | Twitter | Facebook Our commitment to Diversity, Equity, and Inclusion NIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Manager,,,
4237257502,Algorithm Developer,Applied Materials,"Bengaluru, Karnataka, India",,Full-time,,"About the job Who We Are Applied Materials is the global leader in materials engineering solutions used to produce virtually every new chip and advanced display in the world. We design, build and service cutting-edge equipment that helps our customers manufacture display and semiconductor chips – the brains of devices we use every day. As the foundation of the global electronics industry, Applied enables the exciting technologies that literally connect our world – like AI and IoT. If you want to work beyond the cutting-edge, continuously pushing the boundaries of science and engineering to make possible the next generations of technology, join us to Make Possible® a Better Future. What We Offer Location: Bangalore,IND At Applied, we prioritize the well-being of you and your family and encourage you to bring your best self to work. Your happiness, health, and resiliency are at the core of our benefits and wellness programs. Our robust total rewards package makes it easier to take care of your whole self and your whole family. We’re committed to providing programs and support that encourage personal and professional growth and care for you at work, at home, or wherever you may go. Learn more about our benefits . You’ll also benefit from a supportive work culture that encourages you to learn, develop and grow your career as you take on challenges and drive innovative solutions for our customers. We empower our team to push the boundaries of what is possible—while learning every day in a supportive leading global company. Visit our Careers website to learn more about careers at Applied. Key Responsibilities Develop or improve an algorithmic feature or a Matlab (system or product) feature, including research, design, development and implementation & proliferation accompanying in accordance with project budgets and time schedules. Perform algorithmic C&F for an algorithmic feature, including problem analysis, data gathering, literature review, concept selection and evaluation and implementation constrains Provide information needed for construction of work plans for his own features Document algorithmic development, take part in planning and accompany implementation, integration and testing of an algorithmic module Interact with internal and external customers to assist in gap analysis, activity definitions, data collection and accompany integration, testing and proliferation of algorithmic solutions Understand system and applicative environment regarding own feature, take part in system definitions Functional Knowledge Demonstrates expanded conceptual knowledge in own discipline and broadens capabilities Business Expertise Understands key business drivers; uses this understanding to accomplish own work Leadership No supervisory responsibilities but provides informal guidance to new team members Problem Solving Solves problems in straightforward situations; analyzes possible solutions using technical experience and judgment and precedents Impact Impacts quality of own work and the work of others on the team; works within guidelines and policies Interpersonal Skills Explains complex information to others in straightforward situations Additional Information Time Type: Full time Employee Type: Assignee / Regular Travel: Not Specified Relocation Eligible: Yes Applied Materials is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, national origin, citizenship, ancestry, religion, creed, sex, sexual orientation, gender identity, age, disability, veteran or military status, or any other basis prohibited by law.",,,,
4256117728,"Engineer, Staff -Machine Learning",Qualcomm,"Hyderabad, Telangana, India",,Full-time,,"About the job Company Qualcomm India Private Limited Job Area Engineering Group, Engineering Group > Software Engineering General Summary As a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Software Engineer, you will design, develop, create, modify, and validate embedded and cloud edge software, applications, and/or specialized utility programs that launch cutting-edge, world class products that meet and exceed customer needs. Qualcomm Software Engineers collaborate with systems, hardware, architecture, test engineers, and other teams to design system-level software solutions and obtain information on performance requirements and interfaces. Minimum Qualifications Bachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Engineering or related work experience. OR Master's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience. OR PhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience. 2+ years of work experience with Programming Language such as C, C++, Java, Python, etc. Machine Learning Engineer Job Location: Hyderabad More Details Below Join a new and growing team at Qualcomm focused on advancing state-of-the-art in Machine Learning. The team uses Qualcomm chips’ extensive heterogeneous computing capabilities. See your work directly impact billions of mobile devices around the world. In this position, you will be responsible for the development and commercialization of ML solutions like Snapdragon Neural Processing Engine (SNPE) and AI Model Efficiency Toolkit (AIMET) on Qualcomm SoCs. You will have expert knowledge of design, improvement, and maintenance of large AI software stacks using best practices. Work Experience 8-12 years of relevant work experience in software development Live and breathe quality software development with excellent analytical and debugging skills. Strong understanding of Deep Learning and Machine learning theory and practice. Experience with Deep learning model development. Data transformations, model training, model design, model optimization. Familiarity with various deep learning architectures and problem domains like Computer Vision, Speech recognition, NLP etc. Strong development skills in Python and C++. Experience with at least one machine learning framework like TensorFlow, ONNX, Pytorch, etc. Understanding of software development and debugging in embedded environments. Excellent communication skills (verbal, presentation, written) Ability to collaborate across a globally diverse team and multiple interests. Preferred Qualifications Familiarity with neural network operators and model formats including PyTorch, ONNX, and Tensorflow. Familiarity with neural network optimization techniques like graph optimization, quantization, pruning, knowledge distillation, network architecture search etc. Strong understanding about embedded systems, system design fundamentals. Well versed in version control tools like git Experience with machine learning accelerators, optimizing algorithms for hardware acceleration cores, working with heterogeneous or parallel computing systems. Educational Requirements Bachelor's/Master’s/PhD in Computer Science, Computer Engineering, or Electrical Engineering Applicants : Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here . Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries). Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law. To all Staffing and Recruiting Agencies : Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications. If you would like more information about this role, please contact Qualcomm Careers . 3072732",,,"Python, Machine Learning",
4253252092,Data Research Engineer-AI/ML,Uplers,"Gurugram, Haryana, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - Forbes Advisor) What do you need for this opportunity? Must have skills required: TensorFlow, PyTorch, rag, LangChain Forbes Advisor is Looking for: Location - Remote (For candidate's from Chennai or Mumbai it's hybrid) Forbes Advisor is a new initiative for consumers under the Forbes Marketplace umbrella that provides journalist- and expert-written insights, news and reviews on all things personal finance, health, business, and everyday life decisions. We do this by providing consumers with the knowledge and research they need to make informed decisions they can feel confident in, so they can get back to doing the things they care about most. At Marketplace, our mission is to help readers turn their aspirations into reality. We arm people with trusted advice and guidance, so they can make informed decisions they feel confident in and get back to doing the things they care about most. We are an experienced team of industry experts dedicated to helping readers make smart decisions and choose the right products with ease. Marketplace boasts decades of experience across dozens of geographies and teams, including Content, SEO, Business Intelligence, Finance, HR, Marketing, Production, Technology and Sales. The team brings rich industry knowledge to Marketplace’s global coverage of consumer credit, debt, health, home improvement, banking, investing, credit cards, small business, education, insurance, loans, real estate and travel. The Data Extraction Team is a brand-new team who plays a crucial role in our organization by designing, implementing, and overseeing advanced web scraping frameworks. Their core function involves creating and refining tools and methodologies to efficiently gather precise and meaningful data from a diverse range of digital platforms. Additionally, this team is tasked with constructing robust data pipelines and implementing Extract, Transform, Load (ETL) processes. These processes are essential for seamlessly transferring the harvested data into our data storage systems, ensuring its ready availability for analysis and utilization. A typical day in the life of a Data Research Engineer will involve coming up with ideas regarding how the company/team can best harness the power of AI/LLM, and use it not only simplify operations within the team, but also to streamline the work of the research team in gathering/retrieving large sets of data. The role is that of a leader who sets a vision for the future of AI/LLM’s use within the team and the company. They think outside the box and are proactive in engaging with new technologies and developing new ideas for the team to move forward in the AI/LLM field. The candidate should also at least be willing to acquire some basic skills in scraping and data pipelining. Responsibilities: Develop methods to leverage the potential of LLM and AI within the team. Proactive at finding new solutions to engage the team with AI/LLM, and streamline processes in the team. Be a visionary with AI/LLM tools and predict how the use of future technologies could be harnessed early on so that when these technologies come out, the team is ahead of the game regarding how it could be used. Assist in acquiring and integrating data from various sources, including web crawling and API integration. Stay updated with emerging technologies and industry trends. Explore third-party technologies as alternatives to legacy approaches for efficient data pipelines. Contribute to cross-functional teams in understanding data requirements. Assume accountability for achieving development milestones. Prioritize tasks to ensure timely delivery, in a fast-paced environment with rapidly changing priorities. Collaborate with and assist fellow members of the Data Research Engineering Team as required. Leverage online resources effectively like StackOverflow, ChatGPT, Bard, etc., while considering their capabilities and limitations. Skills And Experience Bachelor's degree in Computer Science, Data Science, or a related field. Higher qualifications is a plus. Think proactively and creatively regarding the next AI/LLM technologies and how to use them to the team’s and company’s benefits. “Think outside the box” mentality. Experience prompting LLMs in a streamlined way, taking into account how the LLM can potentially “hallucinate” and return wrong information. Experience building agentic AI platforms with modular capabilities and autonomous task execution. (crewai, lagchain, etc.) Proficient in implementing Retrieval-Augmented Generation (RAG) pipelines for dynamic knowledge integration. (chromadb, pinecone, etc) Experience managing a team of AI/LLM experts is a plus: this includes setting up goals and objectives for the team and fine-tuning complex models. Strong proficiency in Python programming Proficiency in SQL and data querying is a plus. Familiarity with web crawling techniques and API integration is a plus but not a must. Experience in AI/ML engineering and data extraction Experience with LLMs, NLP frameworks (spaCy, NLTK, Hugging Face, etc.) Strong understanding of machine learning frameworks (TensorFlow, PyTorch) Design and build AI models using LLMs Integrate LLM solutions with existing systems via APIs Collaborate with the team to implement and optimize AI solutions Monitor and improve model performance and accuracy Familiarity with Agile development methodologies is a plus. Strong problem-solving and analytical skills with attention to detail. Creative and critical thinking. Ability to work collaboratively in a team environment. Good and effective communication skills. Experience with version control systems, such as Git, for collaborative development. Ability to thrive in a fast-paced environment with rapidly changing priorities. Comfortable with autonomy and ability to work independently. Perks: Day off on the 3rd Friday of every month (one long weekend each month) Monthly Wellness Reimbursement Program to promote health well-being Monthly Office Commutation Reimbursement Program Paid paternity and maternity leaves How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience TensorFlow, PyTorch, rag, LangChain",,,"Python, SQL, Machine Learning",
4256826176,"Software Development Engineer-Finance AI and ML Dev, PXT Finance - ML Forecasting and Core Engineering",Amazon,"Bengaluru, Karnataka, India",,Full-time,,"About the job Description Amazon Finance Tech team leads innovation to combine data-driven finance with the AI approach driving accuracy, next gen forecasting capabilities, speed, efficiency, and reliability by exploring new techniques in ML and GenAI and building full stack services in AWS. This AI-First Finance builders team will lead AI Application Architecture, designs for predicting outcomes, forecasting values with high degree of automation and ML Ops for existing science pipelines and frameworks. Key job responsibilities As an software engineer on the team, you will own components of an integrated system. You will design and develop these components using AI builder tools, AWS and serverless infrastructure in the cloud that will need to be deployed for use by our financial stakeholders. You will work on a secured data management service that will allow the storage and usage of financial data with the highest standard of privacy. You will create a system that will allow the team to monitor the efficiencies of the designs. You will utilize GenAI-assisted software development on a daily basis that integrates with artificial intelligence tools like Amazon Q Developer into builder workflows to generate & optimize code, build tests, explain unfamiliar code, and learn new languages or APIs, effectively boosting your team’s productivity and code quality. Throughout the software development lifecycle, you will deploy AI tools, agents, use Model Context Protocol (MCP) and large language models (LLMs) to assist in multiple phases - from requirements analysis to coding and testing. You will be execute AI tools on Claude and Nova models for vibe coding and testing. We are looking for individuals who thrive in a collaborative environment where they will have a high level of independence, autonomy, and ownership in what they deliver. The right candidate will wear many hats and work in a highly collaborative environment that is more startup than big company. You will work on cutting edge technology not legacy. As a Software Development Engineer, you will work with a team of talented engineers to build low-latency solutions for frontend, middle tier and backend as well as identify and evaluate new technology options for the challenges we are trying to solve. You will work with a variety of core languages, microservices, and technologies including Java, Javascript, Python, Dynamo DB, Lambda, SQS, SNS and many other AWS services. We are looking for a smart engineer who can effectively deal with ambiguity and work independently to clarify requirements, build prototypes and deliver results quickly. Come join a team in which builders build software and delight customers! You will learn, have fun, and make a positive impact for our customers. A day in the life You Will Design and develop scalable financial systems using distributed computing technologies while collaborating with cross-functional teams Write and review high-quality code for mission-critical applications that process millions of transactions and impact customers globally Participate in daily agile ceremonies including stand-ups, sprint planning, and retrospectives while managing rapid development cycles Debug, optimize, and maintain complex distributed systems to ensure fault tolerance, performance, and reliability at massive scale Create and contribute to technical documentation, architecture designs, and implementation strategies while mentoring junior team members and participating in code reviews Partner closely with customers, product leaders, and stakeholders to understand business requirements, influence product roadmap decisions, and deliver innovative solutions that drive business value Basic Qualifications 3+ years of non-internship professional software development experience 2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience 3+ years of computer science fundamentals (object-oriented design, data structures, algorithm design, problem solving and complexity analysis) experience Experience programming with at least one software programming language Preferred Qualifications 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience Bachelor's degree in computer science or equivalent Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI - Karnataka Job ID: A3017207",,,Python,
4256417808,Ruby on Rails Developer,Velotio Technologies,"Pune, Maharashtra, India (On-site)",On-site,Full-time,,"About the job Velotio Technologies is a product engineering company working with innovative startups and enterprises. We are a certified Great Place to Work® and recognized as one of the best companies to work for in India. We have provided full-stack product development for 325+ startups across the globe building products in the cloud-native, data engineering, B2B SaaS, IoT & Machine Learning space. Our team of 400+ elite software engineers solves hard technical problems while transforming customer ideas into successful products. We are looking for a versatile Backend developer with proficiency in Web frameworks like Ruby on Rails, Elixir/Phoenix and/or Django/Python. You will get to design, architect and develop complex enterprise software and SaaS web applications leveraging modern web stack. Requirements Design & build highly scalable, high performance, responsive web applications. Take full ownership and responsibility for building, shipping, and maintaining core product features, end to end. Help out in building the backend & front-end infrastructure. Translation of requirements, designs and wireframes into high quality code. Collaborate closely with designers, engineers, founders and product managers. Mentor team members and review their work. You will enjoy this role if you ... Are a geek with a desire to stay ahead of the curve. Like building beautiful well-architected software products with millions of users. Work collaboratively as part of a close-knit team of geeks, architects and leads. Desired Skills & Experience: 7+ years of production experience with modern web frameworks - Ruby on Rails.. Should have sound experience in developing scalable / distributed SaaS apps. Should have good knowledge and work experience in REST API implementations, JSON format handling, caching, sessions, multi-threading, etc. Should be comfortable with database schema design and leveraging SQL & NoSQL (PostgreSQL, MySQL, Redis, Elasticsearch, DynamoDB). Experience developing, consuming and transforming internal and 3rd party API's (REST and GraphQL). Experience with code quality and reusability practices (CI/CD for back-end & front-end repos). Solid foundation in data structures, algorithms, distributed systems, design patterns. Strong understanding of software engineering best practices, including unit testing, code reviews, design documentation, debugging, troubleshooting, and agile development. Communication : You like discussing a plan upfront, welcome collaboration, and are an excellent verbal and written communicator. Bachelor’s degree in Computer Science or equivalent experience. Bonus points if you... Exposure to front-end technologies like React, Javascript/Typescript. Cloud native development on AWS or GCP. Experience with implementation of container technologies like Docker, Kubernetes. Knowledge of continuous integration, continuous delivery and enterprise DevOps concepts Our Culture : We have an autonomous and empowered work culture encouraging individuals to take ownership and grow quickly. Flat hierarchy with fast decision making and a startup-oriented “get things done” culture. A strong, fun & positive environment with regular celebrations of our success. We pride ourselves in creating an inclusive, diverse & authentic environment. We want to hire smart, curious, and ambitious folks, so please reach out even if you do not have all of the requisite experience. We are looking for engineers with the potential to grow! At Velotio, we embrace diversity. Inclusion is a priority for us, and we are eager to foster an environment where everyone feels valued. We welcome applications regardless of ethnicity or cultural background, age, gender, nationality, religion, disability or sexual orientation.",manager,,"Python, SQL, Machine Learning",
4256419293,Qlik sense Developer,Virtusa,"Chennai, Tamil Nadu, India (Hybrid)",Hybrid,Full-time,,"About the job Hands on design & development experience in Reporting following the process. Deeloping visual reports, dashboards and KPI scorecards using Qliksense Connecting to data sources, importing data and transforming data for Business Intelligence. Excellent in analytical thinking for translating data into informative visuals and reports. Building Analysis Services reporting models. Communicate effectively with both business, technical stakeholders Preparing complete documentation for the dashboard/Model developed. Analyze and optimize performance of the models/Dashboards. Ability to work independently to implement a solution with minimal guidance. Qualifications / Experience 4+ years Information Technology and Demonstrate experience with Agile (Scrum) and DevOps software development methodologies.Good Knowledge in SDLC life cycle and processes followed. Demonstrated Experience With The Following Developing dashboards in Qliksense Job Scheduling/Procedure Analysis Performance tuning Data source types: Oracle,PostGres RDBMS concepts and principles with advanced PL/SQL skills Bachelor of Science or equivalent in Computer Science, Computer / Electronics Engineering. Skills Demonstrated experience implementing Reporting Capabilies Qliksense Strong SQL skills and ability to analyse and backtrack for related issues. Results driven, with strong analytical and problem-solving skills Work Independently with minimal guidance. Excellent Communications skills Desired Skills and Experience Database Concepts",,,SQL,
4255470110,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Large Language Models Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: As an AI / ML Engineer, you will engage in the development of applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve designing and implementing production-ready solutions, ensuring that they meet quality standards. You will work with various AI models, including generative AI, deep learning, and neural networks, while collaborating with cross-functional teams to integrate these technologies into existing systems. Your role will also require you to stay updated with the latest advancements in AI and machine learning, applying this knowledge to enhance the functionality and efficiency of the applications you develop. Roles & Responsibilities: - Expected to be an SME. - Collaborate and manage the team to perform. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Provide solutions to problems for their immediate team and across multiple teams. - Mentor junior team members to foster their professional growth. - Continuously evaluate and improve existing AI models and applications. Professional & Technical Skills: - Must To Have Skills: Proficiency in Large Language Models. - Strong understanding of deep learning frameworks such as TensorFlow or PyTorch. - Experience with cloud platforms like AWS, Azure, or Google Cloud for deploying AI solutions. - Familiarity with natural language processing techniques and tools. - Ability to design and implement scalable AI applications. Additional Information: - The candidate should have minimum 5 years of experience in Large Language Models. - This position is based at our Hyderabad office. - A 15 years full time education is required. 15 years full time education",,,Machine Learning,
4165255644,Machine Learning Platform Engineer,Tower Research Capital,"Gurgaon, Haryana, India (Hybrid)",Hybrid,Full-time,,"About the job Tower Research Capital is a leading quantitative trading firm founded in 1998. Tower has built its business on a high-performance platform and independent trading teams. We have a 25+ year track record of innovation and a reputation for discovering unique market opportunities. Tower is home to some of the world’s best systematic trading and engineering talent. We empower portfolio managers to build their teams and strategies independently while providing the economies of scale that come from a large, global organization. Engineers thrive at Tower while developing electronic trading infrastructure at a world class level. Our engineers solve challenging problems in the realms of low-latency programming, FPGA technology, hardware acceleration and machine learning. Our ongoing investment in top engineering talent and technology ensures our platform remains unmatched in terms of functionality, scalability and performance. At Tower, every employee plays a role in our success. Our Business Support teams are essential to building and maintaining the platform that powers everything we do — combining market access, data, compute, and research infrastructure with risk management, compliance, and a full suite of business services. Our Business Support teams enable our trading and engineering teams to perform at their best. At Tower, employees will find a stimulating, results-oriented environment where highly intelligent and motivated colleagues inspire each other to reach their greatest potential. Responsibilities: Working on our next gen platform empowering quant researchers to easily compose custom modeling workflows, with an emphasis on: Reliability, transparency and observability of the system Interoperability across on-prem and multi-cloud infrastructure Working side by side with our researchers and HPC infrastructure team to solve problems in a scalable manner Taking a lead in identifying efficiency and throughput optimizations Continuously enhance the platform to handle ever-increasing data volumes and incorporate cutting-edge machine learning techniques Working in a fast-paced, close-knit and dynamic environment, implementing fixes / features at short notice when needed Qualifications: 4-5 years' experience designing large distributed systems, with passion for performance and high availability at scale Proficient in Python Experience with managing applications on linux HPC clusters and/or cloud platforms Knowledge of GPUs, related technologies and/or machine learning frameworks is a strong plus Strong troubleshooting and problem-solving skills Motivated to learn new technologies and able to work independently Benefits: Tower’s headquarters are in the historic Equitable Building, right in the heart of NYC’s Financial District and our impact is global, with over a dozen offices around the world. At Tower, we believe work should be both challenging and enjoyable. That is why we foster a culture where smart, driven people thrive – without the egos. Our open concept workplace, casual dress code, and well-stocked kitchens reflect the value we place on a friendly, collaborative environment where everyone is respected, and great ideas win. Our benefits include: Generous paid time off policies Savings plans and other financial wellness tools available in each region Hybrid working opportunities Free breakfast, lunch and snacks daily In-office wellness experiences and reimbursement for select wellness expenses (e.g., gym, personal training and more) Volunteer opportunities and charitable giving Social events, happy hours, treats and celebrations throughout the year Workshops and continuous learning opportunities At Tower, you’ll find a collaborative and welcoming culture, a diverse team and a workplace that values both performance and enjoyment. No unnecessary hierarchy. No ego. Just great people doing great work – together. Tower Research Capital is an equal opportunity employer.",manager,,"Python, Machine Learning",
4211379376,Python AI/ML Developer,Virtusa,"Pune, Maharashtra, India (Hybrid)",Hybrid,Full-time,,"About the job P1,C2,STS 6+years of Strong hands-on experience in Machine Learning. Experience in Python coding, Data pre-processing , Data Modelling Good experience in Cloud Platfom, Kuberenetes Experience in SQL queries, Snowflake Should be able to perform an Individual role. Skills Machine Learning Data Modelling and Analysis SQL Kubernetes Desired Skills and Experience SQL, Machine Learning",,,"Python, SQL, Machine Learning",
4249900574,AI Engineer,IBM,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction Software Developers at IBM are the backbone of our strategic initiatives to design, code, test, and provide industry-leading solutions that make the world run today - planes and trains take off on time, bank transactions complete in the blink of an eye and the world remains safe because of the work our software developers do. Whether you are working on projects internally or for a client, software development is critical to the success of IBM and our clients worldwide. At IBM, you will use the latest software development tools, techniques and approaches and work with leading minds in the industry to build solutions you can be proud of. Your Role And Responsibilities As a Watson AI Developer, you would be responsible for developing and deploying challenging AI /Chatbot solutions using IBM Watson suite of products with flair knowledge on Python/Java. Be a trusted Advisor of the Customer for AI / Conversational use cases. Work for smooth delivery of assigned projects Research and implement appropriate Watson AI algorithms and tools Design and solutioning of new requirements Develop machine learning applications according to requirements Ability to work independently and as part of a team in a fast-paced, dynamic development environment. Mentor / lead team in the engagements Be a hands-on person and deliver. Will be involved in product installation/ configurations, troubleshooting (performance, 3rd party integrations, security) Based on customer requirements, deliver the deployment Work across timezones based on customer requirements Preferred Education Bachelor's Degree Required Technical And Professional Expertise 10+ years’ experience of overall experience 4+ years Experience in AI and ML technology Knowledge on Generative AI Watson Assistant, Watson Discovery, Watson Studio, Watsonx.ai ETL Databand Soul Machines Digital Avatar Integrations Any courses on Cloud, IBM products from coursera, Udemy, IBM cognitive etc Quick Learner, willingness to learn, hardworking and explore/pick-up the skills on their own. Working knowledge on Linux (RHEL, CoreOS, Ubuntu) Deploying software’s on top of Linux and troubleshoot linux related issues. Good hands-on Shell scripting, Python, Ansible, Java Working knowledge with Git, eclipse, docker/podman, kubernets, Jenkins. Knowledge on Dev/ops & Monitoring. Preferred Technical And Professional Experience NA",,4+ years Experience,"Python, Machine Learning",
4239944068,Machine Learning Engineer - AI Foundation - Image domain,Adobe,"Noida, Uttar Pradesh, India",,Full-time,,"About the job Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! The Opportunity Develop ML models, platforms, and services for Adobe Express, covering the entire ML lifecycle. About The Team The AI Foundation Team at Adobe Express aims to develop a groundbreaking AI stack using internal and external technologies to improve feature speed and quality. Develop ML models and services, collaborate with teams, improve user experience at Adobe Express. What You'll Do Research, design, and implement advanced ML models and pipelines for training and inference at scale, including techniques in computer vision, NLP, deep learning, and generative AI. Integrate Large Language Models (LLMs) and agent-based frameworks to support multimodal creative workflows, enabling rich, context-aware content generation and dynamic user experiences. Collaborate with multi-functional teams to translate product requirements into ML solutions, iterating from proof-of-concept to fully productionized services. Develop robust platforms for continuous model training, experimentation, A/B testing, and monitoring, ensuring that model quality and relevance remain consistently high. Leverage distributed computing technologies and cloud infrastructures to handle large-scale data processing, feature engineering, and real-time inference, optimizing for performance and cost-efficiency. Implement reliable APIs and microservices that serve ML models to end users, ensuring alignment to standard methodologies in security, compliance, scalability, and maintainability. Stay ahead of emerging ML research, tools, and frameworks, evaluating and integrating new technologies such as sophisticated LLMs, reinforcement learning-based agents, and innovative inference optimization techniques. In the near future, we will expand the model coverage to include more creative tasks. We will also improve the model architectures to achieve better latency and accuracy. Additionally, we will integrate federated learning or domain adaptation strategies to reach diverse audiences. Basic Qualifications: PhD or Master’s or Bachelor’s in Computer Science or equivalent experience, ML, Applied Mathematics, Data Science, or a related technical field. 14+years of industry experience. Proficiency in Python and Java for ML model development and systems integration. Hands-on experience with deep learning frameworks, including TensorFlow and PyTorch. Demonstrated experience working with LLMs and agent frameworks to develop advanced AI-based experiences. Proficiency in computer vision and NLP techniques for multimodal content understanding and generation. Work experience in Creative Domains, Imaging Domains will be highly useful. Experience in developing and deploying RESTful web services and microservices architectures for applications involving ML. Proficiency with UNIX environments, Git for version control, and Jenkins for CI/CD processes. Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more about our vision here. Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.",,,Python,
4258459153,AI Engineer-PA2025062002,SS&C Technologies,Mumbai Metropolitan Region,,Full-time,,"About the job As a leading financial services and healthcare technology company based on revenue, SS&C is headquartered in Windsor, Connecticut, and has 27,000+ employees in 35 countries. Some 20,000 financial services and healthcare organizations, from the world's largest companies to small and mid-market firms, rely on SS&C for expertise, scale, and technology. Job Description Job Summary: We are seeking an experienced AI Developer with expertise in Python , Generative AI (GenAI) with Retrieval-Augmented Generation (RAG) , Robotic Process Automation (RPA) , and advanced document intelligence using OCR and LLMs . This role involves designing AI-powered solutions that extract meaningful insights from complex documents—both digital and scanned—using tools like Tesseract, Hugging Face Transformers or similar. You will work on end-to-end automation and AI integration for intelligent document processing, enabling smarter decisions and workflow efficiencies across the organization. Key Responsibilities: Build and deploy GenAI solutions with RAG pipelines to enable intelligent querying and summarization over document repositories. Extract and structure data from complex documents (PDFs, Images etc) using a combination of OCR engines (e.g., Tesseract) and AI-based document and vision language models(DiNO, SmolVLM etc). Integrate OCR+LLM pipelines into business applications to process scanned forms, contracts, and other unstructured documents. Automate repetitive, document-intensive tasks using RPA tools (e.g., Blue Prism etc). Design and maintain Python-based workflows to orchestrate document ingestion, extraction, and LLM-powered processing. Work cross-functionally with product, data, and operations teams to deliver scalable, AI-enhanced document automation solutions. Ensure model performance, compliance, and audit readiness for all document-handling workflows. Required Qualifications: 4+ years of hands-on programming experience with Python. Strong experience building RAG-based GenAI applications using tools like LangChain, LlamaIndex, or equivalent. Proficient in OCR tools (e.g., Tesseract, PaddleOCR) and transformer-based document models. Experience working with LLMs for document understanding, summarization, and Q&A. Proficiency in RPA development using platforms like Blueprism etc. Knowledge of vector databases (e.g., FAISS, Pinecone) and embeddings for semantic retrieval. Strong understanding of REST APIs, JSON, and data integration workflows. Unless explicitly requested or approached by SS&C Technologies, Inc. or any of its affiliated companies, the company will not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. SS&C Technologies is an Equal Employment Opportunity employer and does not discriminate against any applicant for employment or employee on the basis of race, color, religious creed, gender, age, marital status, sexual orientation, national origin, disability, veteran status or any other classification protected by applicable discrimination laws.",,,Python,
4245293505,GCP Data Engineer,TELUS Digital,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job About Us : At TELUS Digital, we enable customer experience innovation through spirited teamwork, agile thinking, and a caring culture that puts customers first. TELUS Digital is the global arm of TELUS Corporation, one of the largest telecommunications service providers in Canada. We deliver contact center and business process outsourcing (BPO) solutions to some of the world's largest corporations in the consumer electronics, finance, telecommunications and utilities sectors. With global call center delivery capabilities, our multi-shore, multi-language programs offer safe, secure infrastructure, value-based pricing, skills-based resources and exceptional customer service - all backed by TELUS, our multi-billion dollar telecommunications parent. Required Skills: Design, develop, and support data pipelines and related data products and platforms. Design and build data extraction, loading, and transformation pipelines and data products across on-prem and cloud platforms. Perform application impact assessments, requirements reviews, and develop work estimates. Develop test strategies and site reliability engineering measures for data products and solutions. Participate in agile development ""scrums"" and solution reviews. Mentor junior Data Engineers. Lead the resolution of critical operations issues, including post-implementation reviews. Perform technical data stewardship tasks, including metadata management, security, and privacy by design. Design and build data extraction, loading, and transformation pipelines using Python and other GCP Data Technologies Demonstrate SQL and database proficiency in various data engineering tasks. Automate data workflows by setting up DAGs in tools like Control-M, Apache Airflow, and Prefect. Develop Unix scripts to support various data operations. Model data to support business intelligence and analytics initiatives. Utilize infrastructure-as-code tools such as Terraform, Puppet, and Ansible for deployment automation. Expertise in GCP data warehousing technologies, including BigQuery, Cloud SQL, Dataflow, Data Catalog, Cloud Composer, Google Cloud Storage, IAM, Compute Engine, Cloud Data Fusion and Dataproc (good to have). Qualifications: Bachelor's degree in Software Engineering, Computer Science, Business, Mathematics, or related field. 4+ years of data engineering experience. 2 years of data solution architecture and design experience. GCP Certified Data Engineer (preferred).",,,"Python, SQL",
4250533963,Data Flow Engineer I,Clearwater Analytics,"Noida, Uttar Pradesh, India",,Full-time,,"About the job Job Summary: The Data Flow Engineer's primary role is to create and manage data connections, perform validations, and execute transformations. Their work is integral to the ongoing process of iterative improvement, with a particular focus on enhancing auto-reconciliation within the system through advanced technology. Responsibilities: Import and validate file delivery for new clients. Automate daily process monitoring and reporting. Establish connections through external APIs and FTPs. Ensure timely and dependable consumption of external portfolio data. Normalize external datasets into a standardized Clearwater format facilitating the in-take process. Mine data from existing feeds to identify, design, and implement solutions to improve auto-reconciliation. Execute improvements requested from Operations and Development groups. Apply acquired skills, procedures, and decision-making best practices to complete various issues, such as normalizing new feeds and improving automation. Understand and reference or explain the general workflow, tools, and Clearwater value proposition. Use critical thinking to address issues and offer solutions for both internal and external parties, ensuring best practices are employed. Clearly and effectively communicate the technical aspects of Clearwater systems and our best practices with non-technical internal and external stakeholders. Engage in light on-call duties. Required Skills: Securities, accounting, and financial experience. Strong understanding of SQL and relational database principles. Experience with scripting programming languages like Groovy, Perl or Python. Experience with industry-standard data transmission protocols preferred. Securities, accounting, and financial experience preferred. Strong computer skills, including proficiency in Microsoft Office. Excellent attention to detail and strong documentation skills. Outstanding verbal and written communication skills. Strong organizational and interpersonal skills. Exceptional problem-solving abilities. Education and Experience: Bachelor's degree in Math, Computer Information Systems, or other relevant degrees. 1+ years of relevant experience. Experience with industry-standard data transmission protocols.",manager,,"Python, SQL",
4171844453,"Business Intelligence Engineer, DSP Analytics",Amazon,"Hyderabad, Telangana, India",,Full-time,,"About the job Description Do you enjoy diving deep into data, building data models and developing business metrics to generate actionable insights? Are you looking for an opportunity to define end to end analytics roadmap, work with cross functional teams and leverage cutting edge modern technologies and cloud solutions to develop analytics products. DSP Analytics team has an exciting opportunity for a Business Intelligence Engineer (BIE) to improve Amazon’s Delivery Service Partner (DSP) program through impactful data solutions. The goal of Amazon’s DSP organization is to exceed the expectations of our customers by ensuring that their orders, no matter how large or small, are delivered as quickly, accurately, and cost effectively as possible. To meet this goal, Amazon is continually striving to innovate and provide best in class delivery experience through the introduction of pioneering new products and services in the last mile delivery space. We are looking for an innovative, highly-motivated and experienced BIE who can think holistically about problems to understand how systems work together to identify and execute both tactical and strategic projects. You will work closely with engineering teams, product managers, program managers and org leaders to deliver end-to-end data solutions aimed at continuously enhancing overall DSP performance and delivery quality. The business coverage is broad, and you will identify and prioritize what matters most for the business, quantify what is (or is not) working, invent and simplify the current process and develop self-serve data and reporting solutions. You should have excellent business and communication skills to be able to work with business owners to define roadmap, develop milestones, define key business questions, and build data-sets that answers those questions. The ideal candidate should have hands-on SQL and scripting language experience and excel in designing, implementing, and operating stable, scalable, low-cost solutions to flow data from production systems into the data warehouse and into end-user facing applications. Key job responsibilities Lead the design, implementation, and delivery of BI solutions for the Sub-Same Day (SSD) DSP Performance. Manage and execute entire projects from start to finish including stakeholder management, data gathering and manipulation, modeling, problem solving, and communication of insights and recommendations. Extract, transform, and load data from many data sources using SQL, Scripting and other ETL tools. Design, build, and maintain automated reporting, dashboards, and ongoing analysis to enable data driven decisions across our team and with partner teams. Report key insight trends using statistical rigor to simplify and inform the larger team of noteworthy trends that impact the business. Retrieve and analyze data using a broad set of Amazon’s data technologies (ex. Redshift, AWS S3, Amazon Internal Platforms/Solutions) and resources, knowing how, when, and which to use. Earn the trust of your customers and stakeholders by continuing to constantly obsess over their business use cases and data needs, and helping them solve their problems by leveraging technology. Work closely with business stakeholders and senior leadership team to review roadmap and contributing to business strategy and how they can leverage analytics for success. About The Team We are the core Amazon DSP BI team with the vision to enable data, insights and science driven decision-making. We have exceptionally talented and fun loving team members. In our team, you will have the opportunity to dive deep into complex business and data problems, drive large scale technical solutions and raise the bar for operational excellence. We love to share ideas and learning with each other. We are a relatively new team and do not carry legacy operational burden. We believe in promoting and using ideas to disrupt the status quo. Per the internal transfers guidelines, please reach out to the hiring manager for an informational through the ""Request Informational"" button on the job page. Basic Qualifications 3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience Experience with data modeling, warehousing and building ETL pipelines Experience with data visualization using Tableau, Quicksight, or similar tools Experience writing complex SQL queries Experience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling Experience in Statistical Analysis packages such as R, SAS and Matlab Preferred Qualifications Experience with AWS solutions such as EC2, DynamoDB, S3, and Redshift Experience in data mining, ETL, etc. and using databases in a business environment with large-scale, complex datasets Experience developing and presenting recommendations of new metrics allowing better understanding of the performance of the business Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - Amazon Dev Center India - Hyderabad Job ID: A2915502",manager,,"Python, SQL, Excel, Tableau, R",
4253248673,Data Research Engineer-AI/ML,Uplers,"Kolkata, West Bengal, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - Forbes Advisor) What do you need for this opportunity? Must have skills required: TensorFlow, PyTorch, rag, LangChain Forbes Advisor is Looking for: Location - Remote (For candidate's from Chennai or Mumbai it's hybrid) Forbes Advisor is a new initiative for consumers under the Forbes Marketplace umbrella that provides journalist- and expert-written insights, news and reviews on all things personal finance, health, business, and everyday life decisions. We do this by providing consumers with the knowledge and research they need to make informed decisions they can feel confident in, so they can get back to doing the things they care about most. At Marketplace, our mission is to help readers turn their aspirations into reality. We arm people with trusted advice and guidance, so they can make informed decisions they feel confident in and get back to doing the things they care about most. We are an experienced team of industry experts dedicated to helping readers make smart decisions and choose the right products with ease. Marketplace boasts decades of experience across dozens of geographies and teams, including Content, SEO, Business Intelligence, Finance, HR, Marketing, Production, Technology and Sales. The team brings rich industry knowledge to Marketplace’s global coverage of consumer credit, debt, health, home improvement, banking, investing, credit cards, small business, education, insurance, loans, real estate and travel. The Data Extraction Team is a brand-new team who plays a crucial role in our organization by designing, implementing, and overseeing advanced web scraping frameworks. Their core function involves creating and refining tools and methodologies to efficiently gather precise and meaningful data from a diverse range of digital platforms. Additionally, this team is tasked with constructing robust data pipelines and implementing Extract, Transform, Load (ETL) processes. These processes are essential for seamlessly transferring the harvested data into our data storage systems, ensuring its ready availability for analysis and utilization. A typical day in the life of a Data Research Engineer will involve coming up with ideas regarding how the company/team can best harness the power of AI/LLM, and use it not only simplify operations within the team, but also to streamline the work of the research team in gathering/retrieving large sets of data. The role is that of a leader who sets a vision for the future of AI/LLM’s use within the team and the company. They think outside the box and are proactive in engaging with new technologies and developing new ideas for the team to move forward in the AI/LLM field. The candidate should also at least be willing to acquire some basic skills in scraping and data pipelining. Responsibilities: Develop methods to leverage the potential of LLM and AI within the team. Proactive at finding new solutions to engage the team with AI/LLM, and streamline processes in the team. Be a visionary with AI/LLM tools and predict how the use of future technologies could be harnessed early on so that when these technologies come out, the team is ahead of the game regarding how it could be used. Assist in acquiring and integrating data from various sources, including web crawling and API integration. Stay updated with emerging technologies and industry trends. Explore third-party technologies as alternatives to legacy approaches for efficient data pipelines. Contribute to cross-functional teams in understanding data requirements. Assume accountability for achieving development milestones. Prioritize tasks to ensure timely delivery, in a fast-paced environment with rapidly changing priorities. Collaborate with and assist fellow members of the Data Research Engineering Team as required. Leverage online resources effectively like StackOverflow, ChatGPT, Bard, etc., while considering their capabilities and limitations. Skills And Experience Bachelor's degree in Computer Science, Data Science, or a related field. Higher qualifications is a plus. Think proactively and creatively regarding the next AI/LLM technologies and how to use them to the team’s and company’s benefits. “Think outside the box” mentality. Experience prompting LLMs in a streamlined way, taking into account how the LLM can potentially “hallucinate” and return wrong information. Experience building agentic AI platforms with modular capabilities and autonomous task execution. (crewai, lagchain, etc.) Proficient in implementing Retrieval-Augmented Generation (RAG) pipelines for dynamic knowledge integration. (chromadb, pinecone, etc) Experience managing a team of AI/LLM experts is a plus: this includes setting up goals and objectives for the team and fine-tuning complex models. Strong proficiency in Python programming Proficiency in SQL and data querying is a plus. Familiarity with web crawling techniques and API integration is a plus but not a must. Experience in AI/ML engineering and data extraction Experience with LLMs, NLP frameworks (spaCy, NLTK, Hugging Face, etc.) Strong understanding of machine learning frameworks (TensorFlow, PyTorch) Design and build AI models using LLMs Integrate LLM solutions with existing systems via APIs Collaborate with the team to implement and optimize AI solutions Monitor and improve model performance and accuracy Familiarity with Agile development methodologies is a plus. Strong problem-solving and analytical skills with attention to detail. Creative and critical thinking. Ability to work collaboratively in a team environment. Good and effective communication skills. Experience with version control systems, such as Git, for collaborative development. Ability to thrive in a fast-paced environment with rapidly changing priorities. Comfortable with autonomy and ability to work independently. Perks: Day off on the 3rd Friday of every month (one long weekend each month) Monthly Wellness Reimbursement Program to promote health well-being Monthly Office Commutation Reimbursement Program Paid paternity and maternity leaves How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience TensorFlow, PyTorch, rag, LangChain",,,"Python, SQL, Machine Learning",
4257564985,JAVA DEVELOPER,Tata Consultancy Services,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Hi {fullName} There is an opportunity for Senior Java Developer IN NOIDA (Experience 5-10 years only) for which WALKIN interview is there on 12th JULY 25 between 9:30 AM TO 12:30 PM PLS SHARE below details to mamidi.p@tcs.com with subject line as Senior Java Developer 12 th JULY 25 if you are interested Email id: Contact no: Total EXP: Preferred Location: CURRENT CTC: EXPECTED CTC: NOTICE PERIOD: CURRENT ORGANIZATION: HIGHEST QUALIFICATION THAT IS FULL TIME : HIGHEST QUALIFICATION UNIVERSITY: ANY GAP IN EDUCATION OR EMPLOYMENT: IF YES HOW MANY YEARS AND REASON FOR GAP: ARE U AVAILABLE FOR WALKIN INTERVIEW AT NOIDA ON 12TH JULY 25(YES/NO): We will share a mail to you by tom Night if you are shortlisted. PLS FIND JD Senior Java Developer Java 8, J2EE, Spring, Hibernate/JPA, Micro Services, REST APIs Java 8 or 11. Strong fundamentals with work experience Multithreading concepts and experience Spring boot, Spring reactive / React paradigm Exp developing high throughput, high performance, and zero downtime systems. Experience in performance tuning of the applications including JVM tuning, memory profiling, deadlocks and heap analysis Experience with Micro Services, Hibernate, Spring, Spring Batch, Spring Data, Spring MVC Experience with RESTful Web Services REST APIs AWS Knowledge Fast APIs Thanks & Regards Priyanka Talent Acquisition Group Tata Consultancy Services",,,,
4255441822,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4249172017,Engineer II - Data Engg & AI,Anblicks,"Hyderabad, Telangana, India",,Full-time,,"About the job Summary We are seeking a motivated and detail-oriented Data Quality Engineer to join our team and contribute to ensuring the accuracy, completeness, and reliability of our data. In this role, you will be responsible for implementing data quality checks, monitoring data quality, and identifying and resolving data quality issues. Experience with SODA (or similar data quality frameworks) is preferred. Responsibilities Implement and maintain data quality checks and validations using various tools and techniques. Develop and execute data quality test plans and test cases. Automate data quality processes, including data profiling, data quality checks, and reporting. Contribute to the implementation and maintenance of data quality frameworks and tools. (Preferred) Utilize SODA (or similar frameworks) to define data quality checks, configure data sources, and generate data quality reports. Collaborate with data engineers, data analysts, and other stakeholders to ensure data quality requirements are met. Communicate data quality issues and findings to relevant stakeholders. Investigate and analyze data quality problems to determine root causes.",,,,
4252461376,GEN AI Senior Developer,Virtusa,"Chennai, Tamil Nadu, India (Hybrid)",Hybrid,Full-time,,"About the job We are seeking an experienced and innovative Generative AI Developer to join our AWAC team. In this role, you will lead the design and development of GenAI and Agentic AI applications using state of the art LLMs and AWS native services. You will work on both R&D focused proofof concepts and production grade implementations, collaborating with cross-functional teams to bring intelligent, scalable solutions to life. Key Responsibilities Design, develop, and deploy Generative AI and Agentic AI applications using LLMs such as Claude, Cohere, Titan, and others. Lead the development of proof of concept (PoC) solutions to explore new use cases and validate AI driven innovations. Architect and implement retrieval augmented generation (RAG) pipelines using LangChain and Vector Databases like OpenSearch. Integrate with AWS services including Bedrock API, SageMaker, SageMaker JumpStart, Lambda, EKS/ECS, Amazon Connect, Amazon Q. Apply few shot, one shot, and zero shot learning techniques to fine tune and prompt LLMs effectively. Collaborate with data scientists, ML engineers, and business stakeholders to translate complex requirements into scalable AI solutions. Implement CI/CD pipelines, infrastructure as code using Terraform, and follow DevOps best practices. Optimize performance, cost, and reliability of AI applications in production environments. Document architecture, workflows, and best practices to support knowledge sharing and onboarding. Required Skills & Technologies Experience in Python development, with at least 2 years in AI/ML or GenAI projects. Strong hands on experience with LLMs and Generative AI frameworks. Proficiency in LangChain, Vector DBs (e.g OpenSearch), and prompt engineering. Deep understanding of AWS AI/ML ecosystem: Bedrock, SageMaker, Lambda, EKS/ECS. Experience with serverless architectures, containerization, and cloud native development. Familiarity with DevOps tools: Git, CI/CD, Terraform. Strong debugging, performance tuning, and problem solving skills. Preferred Qualifications Experience with Amazon Q, Amazon Connect, or Amazon Titan. Familiarity with Claude, Cohere, or other foundation models. Bachelors or Master s degree in Computer Science, AI/ML, or a related field. Experience in building agentic workflows and multi agent orchestration is a plus. Desired Skills and Experience DevOps, AI/ML, Terraform, Amazon Elastic Kubernetes Service (EKS), Amazon Elastic Container Service (ECS), Amazon Q",,,"Python, R",
4247912113,Data Engineer-Data Modeling,IBM,"Kochi, Kerala, India (Hybrid)",Hybrid,Full-time,,"About the job Introduction In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology. Your Role And Responsibilities As an Data Engineer at IBM you will harness the power of data to unveil captivating stories and intricate patterns. You'll contribute to data gathering, storage, and both batch and real-time processing. Collaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis. As a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets. In this role, your responsibilities may include: Implementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques Designing and implementing various enterprise search applications such as Elasticsearch and Splunk for client requirements Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviours. Build teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modelling results Preferred Education Master's Degree Required Technical And Professional Expertise 4+ years of experience in data modelling, data architecture. Proficiency in data modelling tools ERwin, IBM Infosphere Data Architect and database management systems Familiarity with different data models like relational, dimensional and NoSQl databases. Understanding of business processes and how data supports business decision making. Strong understanding of database design principles, data warehousing concepts, and data governance practices Preferred Technical And Professional Experience Excellent analytical and problem-solving skills with a keen attention to detail. Ability to work collaboratively in a team environment and manage multiple projects simultaneously. Knowledge of programming languages such as SQL",,,"SQL, Machine Learning",
4241255242,ML Lead Engineer,Nerve Solutions,"Mumbai, Maharashtra, India (On-site)",On-site,Full-time,,"About the job As Lead Machine Learning Engineer you will spearhead the design, development, and deployment of advanced ML models and systems. You will work closely with the engineering team and product team to build solutions focussed on financial markets. Key Responsibilities Collaborate with cross-functional teams to integrate ML solutions into products Drive innovation by researching and applying the latest ML techniques and technologies Lead the development of end-to-end ML workflows, with a focus on LLM-based architectures and applications Fine-tune and optimize open-source and proprietary LLMs for real-world use cases Apply techniques like retrieval-augmented generation (RAG), prompt engineering, and model compression to improve performance and efficiency Work with product and engineering teams to integrate LLMs into customer-facing applications Guide data collection, training pipeline setup, and deployment infrastructure Stay current with advances in the LLM and generative AI space and assess their relevance to our work Requirements Strong expertise in Python, ML frameworks (TensorFlow, PyTorch, etc.), and cloud platforms (AWS/GCP/Azure) Strong ML/NLP background with a proven track record in developing and shipping LLM-powered products Deep familiarity with tools like Hugging Face Transformers, LangChain, OpenAI/Anthropic APIs, vector databases (e.g., Pinecone, Weaviate), and orchestration frameworks Solid understanding of model evaluation, performance tuning, and responsible AI principles Comfortable working in fast-paced, cross-functional environments Knowledge and exposure to financial markets will be a huge plus",,,"Python, Machine Learning",
4259075776,Artificial Intelligence,Workassist,"Kolkata, West Bengal, India (On-site)",On-site,Full-time,"Type : Packaging & Containers Function : Automation Engineer Key Skills : Python,Pipeline Automation,Design,Artificial Intelligence (AI),API Integration Education : Other Education Other: Btech Note: This is a requirement for one of the Workassist Hiring Partner Key Responsibilities:  Research and implement AI tools for artwork QC, mockup comparison, and prepress automation.  Integrate automation workflows using platforms like n8n, Zapier, Enfocus Switch, or custom scripts.  Collaborate with the design, prepress, and production teams to identify automation opportunities.  Help develop AI-based systems for OCR validation, print-to-proof checks, and mockup camera verification.  Manage databases, file flows, and folder automation across departments.  Evaluate and test AI design tools for packaging prototyping and assist in pilot deployments.  Prepare documentation and tutorials for adopted tools and workflows.  Continuously stay updated on the latest AI/ML trends in creative and print tech industries.  Familiarity with AI tools like ChatGPT, Midjourney, Runway, or Adobe Firefly.  Experience with automation tools like n8n, Make, Zapier, or Enfocus Switch.  Understanding of design files and formats (AI, PDF) or exposure to the printing industry. Company Description Workassist is an online recruitment and employment solution platform based in Lucknow, India. We provide relevant profiles to employers and connect job seekers with the best opportunities across various industries. With a network of over 10,000+ recruiters, we help employers recruit talented individuals from sectors such as Banking & Finance, Consulting, Sales & Marketing, HR, IT, Operations, and Legal. We have adapted to the new normal and strive to provide a seamless job search experience for job seekers worldwide. Our goal is to enhance the job seeking experience by leveraging technology and matching job seekers with the right employers. For a seamless job search experience, visit our website: https://bit.ly/3QBfBU2 (Note: There are many more opportunities apart from this on the portal. Depending on the skills, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Put your best foot forward with your application Put your best foot forward with your application Hire a resume writer Hire a resume writer Get a resume review About the company Workassist 77,978 followers Follow Staffing and Recruiting 51-200 employees 59 on LinkedIn Workassist is an online recruitment and employment solution providing a platform in India. Workassist provides relevant profiles to employers and relevant jobs to job seekers across different industries and with varying levels of experience leveraging the technology through e-recruitment. Workassist has quickly adapted to the new normal and assists job seekers with the best opportunities and employers with the best talent from all over the world. Get in touch to enhance the job seeking experience as we work with Recruiters from sectors such as Banking & Finance, Consulting, Sales & Marketing, Healthcare, IT and Operations and legal to help them recruit great emerging talents. >>>>For a seamless job search experience, >>>>Visit: https://bit.ly/3ztaKSi … show more Show more","About the job Work Level : Middle Management Core : Self Motivated Leadership : Articulate Industry Type : Packaging & Containers Function : Automation Engineer Key Skills : Python,Pipeline Automation,Design,Artificial Intelligence (AI),API Integration Education : Other Education Other: Btech Note: This is a requirement for one of the Workassist Hiring Partner Key Responsibilities:  Research and implement AI tools for artwork QC, mockup comparison, and prepress automation.  Integrate automation workflows using platforms like n8n, Zapier, Enfocus Switch, or custom scripts.  Collaborate with the design, prepress, and production teams to identify automation opportunities.  Help develop AI-based systems for OCR validation, print-to-proof checks, and mockup camera verification.  Manage databases, file flows, and folder automation across departments.  Evaluate and test AI design tools for packaging prototyping and assist in pilot deployments.  Prepare documentation and tutorials for adopted tools and workflows.  Continuously stay updated on the latest AI/ML trends in creative and print tech industries.  Familiarity with AI tools like ChatGPT, Midjourney, Runway, or Adobe Firefly.  Experience with automation tools like n8n, Make, Zapier, or Enfocus Switch.  Understanding of design files and formats (AI, PDF) or exposure to the printing industry. Company Description Workassist is an online recruitment and employment solution platform based in Lucknow, India. We provide relevant profiles to employers and connect job seekers with the best opportunities across various industries. With a network of over 10,000+ recruiters, we help employers recruit talented individuals from sectors such as Banking & Finance, Consulting, Sales & Marketing, HR, IT, Operations, and Legal. We have adapted to the new normal and strive to provide a seamless job search experience for job seekers worldwide. Our goal is to enhance the job seeking experience by leveraging technology and matching job seekers with the right employers. For a seamless job search experience, visit our website: https://bit.ly/3QBfBU2 (Note: There are many more opportunities apart from this on the portal. Depending on the skills, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",,,Python,
4247343534,Pune || AI/ML Engineer IRC260167,GlobalLogic,"Noida, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Description Allvue Requirements Role Summary: The AI/ML Engineers will be responsible for developing, testing, and deploying machine learning models and AI algorithms that can be integrated into the product suite. The ideal candidate will have expertise in integrating large language models (LLMs) with external knowledge bases, fine-tuning model architectures for specific tasks, and optimizing retrieval strategies to improve the accuracy and relevance of generated content. Required Experience: 4 – 6 years of hands-on experience in machine learning model development and deployment. Hands-on experience in developing and fine-tuning Generative AI models, specifically focusing on Retrieval-Augmented Generation (RAG) systems. Experience with frameworks such as Hugging Face, OpenAI, or other GenAI platforms, along with proficiency in data preprocessing and model evaluation, is required Proficiency in Python, TensorFlow, Keras, PyTorch, or other AI/ML frameworks. Experience with model deployment and monitoring in production environments. Strong problem-solving skills and experience with cloud computing platforms (AWS, GCP, Azure). Familiarity with containerization and orchestration tools (e.g., Docker, Kubernetes). Job responsibilities Key Responsibilities: Implement and optimize AI/ML algorithms for product integration. Collaborate with data scientists to deploy models and integrate them with software products. Design scalable solutions for AI/ML applications. Develop automated pipelines for continuous model training and updates. Work with engineering teams to ensure smooth integration and operation of AI models in production. Monitor and troubleshoot AI/ML models to ensure reliability and performance. What we offer Culture of caring. At GlobalLogic, we prioritize a culture of caring. Across every region and department, at every level, we consistently put people first. From day one, you’ll experience an inclusive culture of acceptance and belonging, where you’ll have the chance to build meaningful connections with collaborative teammates, supportive managers, and compassionate leaders. Learning and development. We are committed to your continuous learning and development. You’ll learn and grow daily in an environment with many opportunities to try new things, sharpen your skills, and advance your career at GlobalLogic. With our Career Navigator tool as just one example, GlobalLogic offers a rich array of programs, training curricula, and hands-on opportunities to grow personally and professionally. Interesting & meaningful work. GlobalLogic is known for engineering impact for and with clients around the world. As part of our team, you’ll have the chance to work on projects that matter. Each is a unique opportunity to engage your curiosity and creative problem-solving skills as you help clients reimagine what’s possible and bring new solutions to market. In the process, you’ll have the privilege of working on some of the most cutting-edge and impactful solutions shaping the world today. Balance and flexibility. We believe in the importance of balance and flexibility. With many functional career areas, roles, and work arrangements, you can explore ways of achieving the perfect balance between your work and life. Your life extends beyond the office, and we always do our best to help you integrate and balance the best of work and life, having fun along the way! High-trust organization. We are a high-trust organization where integrity is key. By joining GlobalLogic, you’re placing your trust in a safe, reliable, and ethical global company. Integrity and trust are a cornerstone of our value proposition to our employees and clients. You will find truthfulness, candor, and integrity in everything we do. About GlobalLogic GlobalLogic, a Hitachi Group Company, is a trusted digital engineering partner to the world’s largest and most forward-thinking companies. Since 2000, we’ve been at the forefront of the digital revolution – helping create some of the most innovative and widely used digital products and experiences. Today we continue to collaborate with clients in transforming businesses and redefining industries through intelligent products, platforms, and services.",manager,,"Python, Machine Learning",
4218055475,Computer Scientist - I,Adobe,"Noida, Uttar Pradesh, India",,Full-time,,"About the job Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! The Opportunity Adobe is looking for an experienced cloud software engineer to join the Adobe Experience platform team. We’re seeking candidates to help us design, build and run high traffic, critically important back end services that drive business for the world’s top brands. You will build and own critical parts of the services and deliver to production. We are looking for a passionate Cloud Software Engineer with high potential, eager to learn new technologies and to help us design, build and operate our industry leader platform at scale. What You Will Do Responsible for multiple phases of engineering - from early specs, design/architecture, technology choice, development, unit-testing/integration automation, and deployment. Collaborate with architects, product management and other engineering teams to build the technical vision, and road map for the team. Build technical specifications, prototypes and presentations to communicate your ideas. Be proficient in emerging industry technologies and trends, and have the ability to communicate that knowledge to the team and use it to influence product direction. Apply innovation and creativity to solve engineering and coding problems using new and emerging tech like GenAI. What You Need To Succeed B.Tech / M.Tech in Computer Science & Engineering or a related field. 4-6 years of experience in software development and automation. Skilled and experienced in Java / ReactJava with the ability to produce clean, performant and maintainable Object oriented code. Strong computer science fundamentals, OOPS, Data Structures, Algorithms and performance optimization. Excellent understanding of the SDLC, Agile Development, Microservice design, CI/CD processes etc. Knowledge of Azure, AWS, JavaScript and familiarity with RESTful APIs, Docker, Jenkins, Splunk, Git etc. Knowledge of GenAI tools and technology would be a bonus. Should be able to quickly adapt to new programming paradigms, languages, tools, and problem areas. Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more about our vision here. Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.",,,,
4250884153,Senior Machine Learning Engineer,Autodesk,"Bengaluru, Karnataka, India (Hybrid)",Hybrid,Full-time,,"About the job Job Requisition ID # 25WD89404 Position Overview As a Senior ML Engineer on the team, you will be responsible for leading/contributing to the design, analysis, and delivery of data-driven solutions to significant business challenges across dedicated RAG programs of work. Your expertise in Information Retrieval as a theoretical discipline and in OpenSearch/ElasticSearch as the enabling tool will drive end-to-end planning, POC-building, offline and online evaluation and features into the hands of users. The Senior MLE will work to deliver ML-driven technical solutions to customer needs in our platform. Sr MLEs help in coordinating delivery as part of multi-disciplinary stakeholder teams. This role is hands-on, focusing on technical problem solving with the latest in NLP and ML technology.Our team culture is built on collaboration, mutual support, and continuous learning. As a Senior MLE, you will provide technical guidance and expertise for the team, and with other stakeholders. We emphasize an agile, hands-on, and technical approach at all levels of the team. As a group, we want to continuously improve our Machine Learning as well as our knowledge of trends and techniques relevant to our areas. Our team strives for excellence in the theory and practice of Machine Learning. We encourage personal development and knowledge sharing. Responsibilities Design and implement Machine Learning capabilities that improve Autodesk’s RAG platforms Perform statistical and data analysis and exploration to generate datasets for model training and development Collaborate with other members of the team to reach better solutions, and to position our team at the cutting edge of technology and ML practice Provide technical leadership and mentorship for less-experienced members of the team to deliver key ML-powered features for our Digital Customer Platform. Partner with stakeholders, to solve important business objectives across a range of problems Translate business requirements and objectives into problems that can be solved with a combination of Data, Statistics, and Machine Learning Minimum Qualifications MS/M.Tech/M.Math/ or PhD in Computer Science, Statistics, Mathematics, Physics, Engineering, Economics, Computational Linguistics or related field. 3+ years of applicable work experience in ML Hands-on experience working with OpenSearch/ElasticSearch/Lucene/Solr on large text data Hands-on experience of NLU and integrating traditional search techniques into RAG Proficiency with the Python Machine Learning stack, e.g. Pandas, etc Knowledge of experimental design and analysis of results Demonstrate expertise with applying Machine Learning, including both Deep Learning (PyTorch) and Classical ML (Scikit-Learn) Demonstrate experience with leading Machine Learning teams in deploying and improving ML features in production Demonstrate experience working in cross-functional teams to deliver ML solutions in production Learn More About Autodesk Welcome to Autodesk! Amazing things are created every day with our software – from the greenest buildings and cleanest cars to the smartest factories and biggest hit movies. We help innovators turn their ideas into reality, transforming not only how things are made, but what can be made. We take great pride in our culture here at Autodesk – our Culture Code is at the core of everything we do. Our values and ways of working help our people thrive and realize their potential, which leads to even better outcomes for our customers. When you’re an Autodesker, you can be your whole, authentic self and do meaningful work that helps build a better future for all. Ready to shape the world and your future? Join us! Salary transparency Salary is one part of Autodesk’s competitive compensation package. Offers are based on the candidate’s experience and geographic location. In addition to base salaries, we also have a significant emphasis on discretionary annual cash bonuses, commissions for sales roles, stock or long-term incentive cash grants, and a comprehensive benefits package. Diversity & Belonging We take pride in cultivating a culture of belonging and an equitable workplace where everyone can thrive. Learn more here: https://www.autodesk.com/company/diversity-and-belonging Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site).",director,,"Python, Machine Learning, Data Analysis",
4211353335,"Data Scientist , AI Engineer-Manager",PwC Acceleration Centers in India,"Bengaluru, Karnataka, India",,Full-time,,"About the job At PwC, our people in data and analytics focus on leveraging data to drive insights and make informed business decisions. They utilise advanced analytics techniques to help clients optimise their operations and achieve their strategic goals. In data analysis at PwC, you will focus on utilising advanced analytical techniques to extract insights from large datasets and drive data-driven decision-making. You will leverage skills in data manipulation, visualisation, and statistical modelling to support clients in solving complex business problems. Years of Experience: Candidates with 8+ years of hands on experience Position: Manager Required Skills: Successful candidates will have demonstrated the following skills and characteristics: Must Have Strong expertise in machine learning, deep learning, and advanced statistical modeling. Experience delivering AI-driven solutions in areas such as forecasting, recommendation systems, NLP, computer vision, and optimization. Strong programming skills in Python, PySpark, and SQL, with a solid understanding of software engineering practices. Practical knowledge of the AI model lifecycle, from data preparation to deployment and monitoring. Proficient with ML frameworks like TensorFlow, PyTorch, scikit-learn, XGBoost, and H2O. Hands-on experience in designing and deploying AI pipelines using ML engineering tools such as MLflow, DVC, Kubeflow, and Airflow. Experience in REST API development, NoSQL database design, and RDBMS design and optimizations. Ability to work with big data platforms and tools like Apache Spark, Hive, and Delta Lake for scalable model development. Proficiency in data visualization tools such as Tableau, Power BI, Looker, and Streamlit. Programming skills in Python and either Scala or R, with experience using Flask and FastAPI. Experience with software engineering practices, including the use of GitHub, CI/CD, code testing, and analysis. Skilled in using Apache Spark, including PySpark and Databricks, for big data processing. Strong understanding of foundational data science concepts, including statistics, linear algebra, and machine learning principles. Knowledgeable in integrating DevOps, MLOps, and DataOps practices to enhance operational efficiency and model deployment. Experience with cloud infrastructure services like Azure and GCP. Proficiency in containerization technologies such as Docker and Kubernetes. Familiarity with observability and monitoring tools like Prometheus and the ELK stack, adhering to SRE principles and techniques. Cloud or Data Engineering certifications or specialization certifications (e.g. Google Professional Machine Learning Engineer, Microsoft Certified: Azure AI Engineer Associate – Exam AI-102, AWS Certified Machine Learning – Specialty (MLS-C01), Databricks Certified Machine Learning) Nice To Have Experience in deploying models to production using CI/CD pipelines and MLOps practices Exposure to cloud platforms like Azure, AWS, or GCP, including AI/ML services (e.g., Vertex AI, SageMaker, Azure ML) Familiarity with API development for AI applications and containerization tools (Docker, Kubernetes) Strong business acumen and ability to communicate technical solutions to non-technical stakeholders Roles And Responsibilities Lead and manage AI and data science projects from design to deployment, ensuring high-quality and scalable delivery. Translate complex business problems into AI-driven solutions, leveraging predictive modeling, optimization, or generative AI. Architect and oversee the development of AI pipelines and data workflows, incorporating best practices for reproducibility and monitoring. Guide project teams on data engineering, model development, validation, and operationalization. Communicate technical solutions effectively to business stakeholders through presentations, dashboards, and storyboards. Foster strong client relationships by acting as a strategic advisor and aligning AI solutions with business goals. Mentor junior team members and build a culture of innovation, learning, and collaboration. Drive knowledge sharing, intellectual property creation, and support pre-sales activities through thought leadership and solution development. Partner effectively with cross-functional teams, including data scientists, data managers, analysts, and infrastructure engineers, to develop, operationalize, integrate, and scale new algorithmic products. Develop code, CI/CD, and MLOps pipelines, including automated tests, and deploy models to cloud compute endpoints. Manage cloud resources and build accelerators to enable other engineers, demonstrating practical experience across modern software and AI engineering stacks. Work autonomously with a successful track record of building multiple large-scale production-grade AI products for large organizations, with experience in two hyperscale clouds, and effectively communicate while coaching and leading junior engineers. Professional And Educational Background BE / B.Tech / MCA / M.Sc / M.E / M.Tech /Master’s Degree /MBA from reputed institute",Manager,,"Python, SQL, Tableau, Power BI, R, Machine Learning, Data Analysis",
4216781981,bluCursor Infotech - Python/Machine Learning Engineer,bluCursor Infotech Pvt Ltd,"Indore, Madhya Pradesh, India",,Full-time,,"About the job This job is sourced from a job board. Learn More Responsibilities Develop Python applications and software solutions based on business requirements and technical specifications, with a focus on integrating AI/ML capabilities. Write well-designed, efficient, and reusable code adhering to best practices and coding standards. Participate in code reviews to ensure adherence to coding standards, maintainability, and scalability. Debug and troubleshoot issues in existing software applications, providing timely resolutions. Optimize application performance and ensure scalability by implementing efficient algorithms and data structures, especially for AI/ML models. Integrate Python applications with databases, APIs, and other third-party services as required, including data pipelines for AI/ML processes. Stay updated with the latest industry trends, tools, and technologies related to Python development and AI/ML applications. Continuously improve software development processes and practices to enhance productivity and quality. Collaborate with cross-functional teams, including product managers, designers, and quality assurance engineers, to ensure timely delivery of high-quality software products. Continuously discover, evaluate, and implement new technologies. Test products in controlled, real situations before going live, ensuring AI/ML functionalities perform as expected. Design, initiate, and handle technical designs and complex application features, integrating AI/ML components. Design databases that meet all requirements for data entry and reporting, maintaining integrity and quality, and planning for future needs. Understand client requirements and functional specifications, translating them into technical : Bachelors degree in Technology (B.Tech/BE) in CS/TI/EC or a related field, or MCA. Minimum of 2 years of experience as Python/ML Engineer. Strong programming skills, with a focus on Python. Proficiency in Python, including a solid understanding of its core principles and libraries. Experience in developing and maintaining Python applications using frameworks such as Django, Flask, or Pyramid. Familiarity with front-end technologies like HTML, CSS, and JavaScript is desirable. Knowledge of relational databases such as MySQL, PostgreSQL, or Oracle. Proficiency in software engineering tools and methodologies. Experience or interest in AI/ML technologies, including frameworks such as TensorFlow, PyTorch, or scikit-learn. Strong verbal and written communication skills (ref:hirist.tech)",manager,,Python,
4253247956,Data Research Engineer-AI/ML,Uplers,"Noida, Uttar Pradesh, India (Remote)",Remote,Full-time,,"About the job Experience : 4.00 + years Salary : Confidential (based on experience) Shift : (GMT+05:30) Asia/Kolkata (IST) Opportunity Type : Remote Placement Type : Full time Permanent Position (*Note: This is a requirement for one of Uplers' client - Forbes Advisor) What do you need for this opportunity? Must have skills required: TensorFlow, PyTorch, rag, LangChain Forbes Advisor is Looking for: Location - Remote (For candidate's from Chennai or Mumbai it's hybrid) Forbes Advisor is a new initiative for consumers under the Forbes Marketplace umbrella that provides journalist- and expert-written insights, news and reviews on all things personal finance, health, business, and everyday life decisions. We do this by providing consumers with the knowledge and research they need to make informed decisions they can feel confident in, so they can get back to doing the things they care about most. At Marketplace, our mission is to help readers turn their aspirations into reality. We arm people with trusted advice and guidance, so they can make informed decisions they feel confident in and get back to doing the things they care about most. We are an experienced team of industry experts dedicated to helping readers make smart decisions and choose the right products with ease. Marketplace boasts decades of experience across dozens of geographies and teams, including Content, SEO, Business Intelligence, Finance, HR, Marketing, Production, Technology and Sales. The team brings rich industry knowledge to Marketplace’s global coverage of consumer credit, debt, health, home improvement, banking, investing, credit cards, small business, education, insurance, loans, real estate and travel. The Data Extraction Team is a brand-new team who plays a crucial role in our organization by designing, implementing, and overseeing advanced web scraping frameworks. Their core function involves creating and refining tools and methodologies to efficiently gather precise and meaningful data from a diverse range of digital platforms. Additionally, this team is tasked with constructing robust data pipelines and implementing Extract, Transform, Load (ETL) processes. These processes are essential for seamlessly transferring the harvested data into our data storage systems, ensuring its ready availability for analysis and utilization. A typical day in the life of a Data Research Engineer will involve coming up with ideas regarding how the company/team can best harness the power of AI/LLM, and use it not only simplify operations within the team, but also to streamline the work of the research team in gathering/retrieving large sets of data. The role is that of a leader who sets a vision for the future of AI/LLM’s use within the team and the company. They think outside the box and are proactive in engaging with new technologies and developing new ideas for the team to move forward in the AI/LLM field. The candidate should also at least be willing to acquire some basic skills in scraping and data pipelining. Responsibilities: Develop methods to leverage the potential of LLM and AI within the team. Proactive at finding new solutions to engage the team with AI/LLM, and streamline processes in the team. Be a visionary with AI/LLM tools and predict how the use of future technologies could be harnessed early on so that when these technologies come out, the team is ahead of the game regarding how it could be used. Assist in acquiring and integrating data from various sources, including web crawling and API integration. Stay updated with emerging technologies and industry trends. Explore third-party technologies as alternatives to legacy approaches for efficient data pipelines. Contribute to cross-functional teams in understanding data requirements. Assume accountability for achieving development milestones. Prioritize tasks to ensure timely delivery, in a fast-paced environment with rapidly changing priorities. Collaborate with and assist fellow members of the Data Research Engineering Team as required. Leverage online resources effectively like StackOverflow, ChatGPT, Bard, etc., while considering their capabilities and limitations. Skills And Experience Bachelor's degree in Computer Science, Data Science, or a related field. Higher qualifications is a plus. Think proactively and creatively regarding the next AI/LLM technologies and how to use them to the team’s and company’s benefits. “Think outside the box” mentality. Experience prompting LLMs in a streamlined way, taking into account how the LLM can potentially “hallucinate” and return wrong information. Experience building agentic AI platforms with modular capabilities and autonomous task execution. (crewai, lagchain, etc.) Proficient in implementing Retrieval-Augmented Generation (RAG) pipelines for dynamic knowledge integration. (chromadb, pinecone, etc) Experience managing a team of AI/LLM experts is a plus: this includes setting up goals and objectives for the team and fine-tuning complex models. Strong proficiency in Python programming Proficiency in SQL and data querying is a plus. Familiarity with web crawling techniques and API integration is a plus but not a must. Experience in AI/ML engineering and data extraction Experience with LLMs, NLP frameworks (spaCy, NLTK, Hugging Face, etc.) Strong understanding of machine learning frameworks (TensorFlow, PyTorch) Design and build AI models using LLMs Integrate LLM solutions with existing systems via APIs Collaborate with the team to implement and optimize AI solutions Monitor and improve model performance and accuracy Familiarity with Agile development methodologies is a plus. Strong problem-solving and analytical skills with attention to detail. Creative and critical thinking. Ability to work collaboratively in a team environment. Good and effective communication skills. Experience with version control systems, such as Git, for collaborative development. Ability to thrive in a fast-paced environment with rapidly changing priorities. Comfortable with autonomy and ability to work independently. Perks: Day off on the 3rd Friday of every month (one long weekend each month) Monthly Wellness Reimbursement Program to promote health well-being Monthly Office Commutation Reimbursement Program Paid paternity and maternity leaves How to apply for this opportunity? Step 1: Click On Apply! And Register or Login on our portal. Step 2: Complete the Screening Form & Upload updated Resume Step 3: Increase your chances to get shortlisted & meet the client for the Interview! About Uplers: Our goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement. (Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well). So, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you! Desired Skills and Experience TensorFlow, PyTorch, rag, LangChain",,,"Python, SQL, Machine Learning",
4255446048,AI / ML Engineer,Accenture in India,"Hyderabad, Telangana, India (On-site)",On-site,Full-time,,"About the job Project Role : AI / ML Engineer Project Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing. Must have skills : Machine Learning Good to have skills : NA Minimum 5 Year(s) Of Experience Is Required Educational Qualification : 15 years full time education Summary: These roles have many overlapping skills with GENAI Engineers and architects. Description may scaleup/scale down based on expected seniority. Roles & Responsibilities: -Implement generative AI models, identify insights that can be used to drive business decisions. Work closely with multi-functional teams to understand business problems, develop hypotheses, and test those hypotheses with data, collaborating with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals. -Conducting research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques and identify opportunities to integrate them into our products and services. -Optimizing existing generative AI models for improved performance, scalability, and efficiency. -Ensure data quality and accuracy -Leading the design and development of prompt engineering strategies and techniques to optimize the performance and output of our GenAI models. -Implementing cutting-edge NLP techniques and prompt engineering methodologies to enhance the capabilities and efficiency of our GenAI models. -Determining the most effective prompt generation processes and approaches to drive innovation and excellence in the field of AI technology, collaborating with AI researchers and developers -Experience working with cloud based platforms (example: AWS, Azure or related) -Strong problem-solving and analytical skills -Proficiency in handling various data formats and sources through Omni Channel for Speech and voice applications, part of conversational AI -Prior statistical modelling experience -Demonstrable experience with deep learning algorithms and neural networks -Developing clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. -Contributing to the establishment of best practices and standards for generative AI development within the organization. Professional & Technical Skills: -Must have solid experience developing and implementing generative AI models, with a strong understanding of deep learning techniques such as GPT, VAE, and GANs. -Must be proficient in Python and have experience with machine learning libraries and frameworks such as TensorFlow, PyTorch, or Keras. -Must have strong knowledge of data structures, algorithms, and software engineering principles. -Must be familiar with cloud-based platforms and services, such as AWS, GCP, or Azure. -Need to have experience with natural language processing (NLP) techniques and tools, such as SpaCy, NLTK, or Hugging Face. -Must be familiar with data visualization tools and libraries, such as Matplotlib, Seaborn, or Plotly. -Need to have knowledge of software development methodologies, such as Agile or Scrum. -Possess excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. Additional Information: -Must have a degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. A Ph.D. is highly desirable. -strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. -You possess a proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment. 15 years full time education",,,"Python, Machine Learning",
4254398607,Senior Associate - AI ML Engineer,Acuity Knowledge Partners,"Gurugram, Haryana, India (On-site)",On-site,Full-time,,"About the job Job Purpose We are looking for a passionate candidate in the application of advanced analytics and data science to address varied business problems. You will need to have a strong grounding in python and have experience of leading value delivery through product development and AI/ML modelling. You will operate in teams on a wide range of projects using agile ways of working collaboratively with other colleagues and partners from the wider Biostatistics, Data Science and R&D community. Desired Skills And Experience  Bachelor’s or master’s degree in computer science, Engineering, Mathematics, or a related field.  5+ years of hands-on experience in machine learning, deep learning, or AI engineering roles.  Proficiency in Python and ML frameworks such as TensorFlow, PyTorch, or Scikit-learn.  Experience with cloud platforms (AWS, GCP, Azure [Preferred]) and deploying ML models in production.  Strong software engineering skills, including version control (Git), containerization (Docker), and CI/CD pipelines.  Solid understanding of data structures, algorithms, and system design.  Experience with data preprocessing, feature engineering, and model evaluation.  Excellent problem-solving, analytical, and communication skills.  Ability to work independently and as part of a collaborative team. Key Responsibilities  Design, develop, and deploy scalable machine learning models and AI-driven solutions for real-world business problems.  Collaborate with data scientists, software engineers, and product managers to define requirements and deliver impactful solutions.  Lead the end-to-end machine learning lifecycle: data preprocessing, feature engineering, model selection, training, evaluation, and deployment.  Implement and maintain ML Ops pipelines for continuous integration, delivery, monitoring, and retraining of models.  Optimize models for performance, scalability, and efficiency in production environments.  Stay current with the latest AI/ML research, tools, and best practices; evaluate and implement new technologies as appropriate.  Document processes, models, and code to ensure reproducibility and knowledge sharing.  Mentor and guide junior engineers and team members.  Ensure compliance with data privacy, security, and ethical standards in all AI/ML initiatives.",Associate,,"Python, R, Machine Learning",
4256586175,Machine Learning Engineer Expert,Infosys,"Bengaluru East, Karnataka, India",,Full-time,"trends Education and Experience: Overall, 6 to 8 years of experience in Data driven software engineering with 3-5 years of experience designing, building and deploying enterprise AI or ML applications with at least 2 years of experience implementing full lifecycle ML automation using MLOps(scalable development to deployment of complex data science workflows) Bachelors or Master’s degree in Computer Science Engineering or equivalent Domain experience in Retail, CPG and Logistics etc. Azure Certified – DP100, AZ/AI900 Logical thinking and problem solving skills along with an ability to collaborate Two or three industry domain knowledge Understanding of the financial processes for various types of projects and the various pricing models available Client Interfacing skills Knowledge of SDLC and agile methodologies Project and Team management Job search faster with Premium Access company insights like strategic priorities, headcount trends, and more Hitesh and millions of other members use Premium Reactivate Premium: 50% Off Cancel anytime. No hidden fees. About the company Infosys 10,092,675 followers Follow IT Services and IT Consulting 10,001+ employees 349,063 on LinkedIn Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over three decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem. Visit www.infosys.com to see how Infosys (NYSE: INFY) can help your enterprise navigate your next. … show more Interested in working with us in the future? Members who share that they’re interested in a company may be 2x as likely to get a message from a recruiter than those who don’t. Learn more Learn more about Interested in working for our company I’m interested Company photos Page 1 of 7 Previous Next February 6, 2023 February 6, 2023 December 29, 2022 Show more","About the job Primary skills:Technology->OpenSystem->Python - OpenSystem Responsible for successful delivery of MLOps solutions and services in client consulting environments; Define key business problems to be solved; formulate high level solution approaches and identify data to solve those problems, develop, analyze/draw conclusions and present to client. Assist clients with operationalization metrics to track performance of ML Models Agile trained to manage team effort and track through JIRA High Impact Communication- Assesses the target audience need, prepares and practices a logical flow, answers audience questions appropriately and sticks to timeline. Technical knowledge- has expertise in cloud technologies, specifically MS Azure, and services with hands on coding to – Expertise in Object Oriented Python Programming with 6 -8 years’ experience. DevOps Working knowledge with implementation experience - 1 or 2 projects a minimum Hands-On MS Azure Cloud knowledge Understand and take requirements on Operationalization of ML Models from Data Scientist Help team with ML Pipelines from creation to execution List Azure services required for deployment, Azure Data bricks and Azure DevOps Setup Assist team to coding standards (flake8 etc) Guide team to debug on issues with pipeline failures Engage with Business / Stakeholders with status update on progress of development and issue fix Automation, Technology and Process Improvement for the deployed projects Setup Standards related to Coding, Pipelines and Documentation Adhere to KPI / SLA for Pipeline Run, Execution Research on new topics, services and enhancements in Cloud Technologies Domain / Technical / Tools Knowledge: Object oriented programming, coding standards, architecture & design patterns, Config management, Package Management, Logging, documentation Experience in Test Driven Development and experience in using Pytest frameworks, git version control, Rest APIs Python programming with OOPs concept, SQL, XML, YAML, Bash, JSON, Pydantic models, Class based frameworks, Dependency injections FastAPI, Flask, Streamlit, Python, Azure API management, API Gateways, Traffic Manager, Load Balancers Nginx, Uvicorn, Gunicorn, Azure ML best practices in environment management, run time configurations (Azure ML & Databricks clusters), alerts. Experience designing and implementing ML Systems & pipelines, MLOps practices and tools such a MLFlow, Kubernetes, etc. Exposure to event driven orchestration, Online Model deployment Contribute towards establishing best practices in MLOps Systems development Proficiency with data analysis tools (e.g., SQL, R & Python) High level understanding of database concepts/reporting & Data Science concepts Hands on experience in working with client IT/Business teams in gathering business requirement and converting into requirement for development team Experience in managing client relationship and developing business cases for opportunities Azure AZ-900 Certification with Azure Architect Good knowledge on software configuration management systems Strong business acumen, strategy and cross-industry thought leadership Awareness of latest technologies and Industry trends Education and Experience: Overall, 6 to 8 years of experience in Data driven software engineering with 3-5 years of experience designing, building and deploying enterprise AI or ML applications with at least 2 years of experience implementing full lifecycle ML automation using MLOps(scalable development to deployment of complex data science workflows) Bachelors or Master’s degree in Computer Science Engineering or equivalent Domain experience in Retail, CPG and Logistics etc. Azure Certified – DP100, AZ/AI900 Logical thinking and problem solving skills along with an ability to collaborate Two or three industry domain knowledge Understanding of the financial processes for various types of projects and the various pricing models available Client Interfacing skills Knowledge of SDLC and agile methodologies Project and Team management",Manager,,"Python, SQL, R, Data Analysis",
4204050699,Data Engineer (PySpark),Virtusa,"Chennai, Tamil Nadu, India (Hybrid)",Hybrid,Full-time,,"About the job About The Role We are seeking a highly skilled Data Engineer with deep expertise in PySpark and the Cloudera Data Platform (CDP) to join our data engineering team. As a Data Engineer, you will be responsible for designing, developing, and maintaining scalable data pipelines that ensure high data quality and availability across the organization. This role requires a strong background in big data ecosystems, cloud-native tools, and advanced data processing techniques. The ideal candidate has hands-on experience with data ingestion, transformation, and optimization on the Cloudera Data Platform, along with a proven track record of implementing data engineering best practices. You will work closely with other data engineers to build solutions that drive impactful business insights. Responsibilities Data Pipeline Development: Design, develop, and maintain highly scalable and optimized ETL pipelines using PySpark on the Cloudera Data Platform, ensuring data integrity and accuracy. Data Ingestion: Implement and manage data ingestion processes from a variety of sources (e.g., relational databases, APIs, file systems) to the data lake or data warehouse on CDP. Data Transformation and Processing: Use PySpark to process, cleanse, and transform large datasets into meaningful formats that support analytical needs and business requirements. Performance Optimization: Conduct performance tuning of PySpark code and Cloudera components, optimizing resource utilization and reducing runtime of ETL processes. Data Quality and Validation: Implement data quality checks, monitoring, and validation routines to ensure data accuracy and reliability throughout the pipeline. Automation and Orchestration: Automate data workflows using tools like Apache Oozie, Airflow, or similar orchestration tools within the Cloudera ecosystem. Education and Experience Bachelors or Masters degree in Computer Science, Data Engineering, Information Systems, or a related field. 3+ years of experience as a Data Engineer, with a strong focus on PySpark and the Cloudera Data Platform. Technical Skills PySpark: Advanced proficiency in PySpark, including working with RDDs, DataFrames, and optimization techniques. Cloudera Data Platform: Strong experience with Cloudera Data Platform (CDP) components, including Cloudera Manager, Hive, Impala, HDFS, and HBase. Data Warehousing: Knowledge of data warehousing concepts, ETL best practices, and experience with SQL-based tools (e.g., Hive, Impala). Big Data Technologies: Familiarity with Hadoop, Kafka, and other distributed computing tools. Orchestration and Scheduling: Experience with Apache Oozie, Airflow, or similar orchestration frameworks. Scripting and Automation: Strong scripting skills in Linux. Desired Skills and Experience Operations Management",Manager,,SQL,
4220651924,"Data Engineer, AFT BI Content",Amazon,"Hyderabad, Telangana, India",,Full-time,,"About the job Description Have you ever ordered a product from Amazon and been amazed at how fast it gets to you? Every day Amazon engineers are relentlessly working to decrease the time between Click to Deliver for your products. The Amazon Fulfillment Technologies (AFT) team owns all of the software and infrastructure which powers Amazon's world-class fulfillment engine. Our team is building complex, massive data systems to capture data during every step in the automated pipeline and use that data to proactively predict efficiency and cost improvements to deliver the packages fast to our customers. As an Amazon.com Big Data Engineer you will be working in one of the world's largest and most complex data warehouse environments. You should be skilled in the architecture of DW solutions for the Enterprise using multiple platforms (RDBMS, Columnar, Cloud). You should have experience in the design, creation, management, and business use of extremely large data-sets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all, you should be passionate about working with huge data sets and someone who loves to bring data-sets together to answer business questions and drive change. As a Big Data Engineer in this role, you will develop new data engineering patterns that leverage a new cloud architecture, and will extend or migrate our existing data pipelines to this architecture as needed. You will also be assisting with integrating the Redshift platform as our primary processing platform to create the curated Amazon.com data model for the enterprise to leverage. You will be part of a team that builds the next generation data warehouse platform and to drive the adoption of new technologies and new practices in existing implementations. You will be responsible for designing and implementing the complex ETL pipelines in data warehouse platform and other BI solutions to support the rapidly growing and dynamic business demand for data, and use it to deliver the data as service which will have an immediate influence on day-to-day decision-making at Amazon.com. About The Team Amazon Fulfillment Technologies (AFT) powers Amazon’s global fulfillment network. We invent and deliver software, hardware, and data science solutions that orchestrate processes, robots, machines, and people. We harmonize the physical and virtual world so Amazon customers can get what they want, when they want it. Basic Qualifications 3+ years of data engineering experience 4+ years of SQL experience Experience with data modeling, warehousing and building ETL pipelines Preferred Qualifications Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases) Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner. Company - ADCI HYD 13 SEZ Job ID: A2971024",,,SQL,
4247511751,Senior Machine Learning Engineer #7405,New Relic,"Hyderabad, Telangana, India",,Full-time,,"About the job Your opportunity As a crucial member of our team, you'll play a pivotal role across the entire machine learning lifecycle, contributing to our conversational AI bots, RAG system and traditional ML problem solving for our observability platform. Your tasks will encompass both operational and engineering aspects, including building production-ready inference pipelines, deploying and versioning models, and implementing continuous validation processes. On the LLM side you'll fine-tune generative AI models, design agentic language chains, and prototype recommender system experiments. What You'll Do In this role, you'll have the opportunity to contribute significantly to our machine learning initiatives, shaping the future of AI-driven solutions in various domains. If you're passionate about pushing the boundaries of what's possible in machine learning and ready to take on diverse challenges, we encourage you to apply and join us in our journey towards innovation. This role requires Proficiency in software engineering design practices. Experience working with transformer models and text embeddings. Proven track record of deploying and managing ML models in production environments. Familiarity with common ML/NLP libraries such as PyTorch, Tensorflow, HuggingFace Transformers, and SpaCy. 5+ years of developing production-grade applications in Python. Proficiency in Kubernetes and containers. Familiarity with concepts/libraries such as sklearn, kubeflow, argo, and seldon. Expertise in Python, C++, Kotlin, or similar programming languages. Experience designing, developing, and testing scalable distributed systems. Familiarity with message broker systems (e.g., Kafka, RabbitMQ). Knowledge of application instrumentation and monitoring practices. Experience with ML workflow management, like AirFlow, Sagemaker, etc. Fine-tuning generative AI models to enhance performance. Designing AI Agents for conversational AI applications. Experimenting with new techniques to develop models for observability use cases Building and maintaining inference pipelines for efficient model deployment. Managing deployment and model versioning pipelines for seamless updates. Developing tooling to continuously validate models in production environments. Bonus points if you have Familiarity with the AWS ecosystem. Past projects involving the construction of agentic language chains Please note that visa sponsorship is not available for this position. Fostering a diverse, welcoming and inclusive environment is important to us. We work hard to make everyone feel comfortable bringing their best, most authentic selves to work every day. We celebrate our talented Relics’ different backgrounds and abilities, and recognize the different paths they took to reach us – including nontraditional ones. Their experiences and perspectives inspire us to make our products and company the best they can be. We’re looking for people who feel connected to our mission and values, not just candidates who check off all the boxes. If you require a reasonable accommodation to complete any part of the application or recruiting process, please reach out to resume@newrelic.com. We believe in empowering all Relics to achieve professional and business success through a flexible workforce model. This model allows us to work in a variety of workplaces that best support our success, including fully office-based, fully remote, or hybrid. Our hiring process In compliance with applicable law, all persons hired will be required to verify identity and eligibility to work and to complete employment eligibility verification. Note: Our stewardship of the data of thousands of customers’ means that a criminal background check is required to join New Relic. We will consider qualified applicants with arrest and conviction records based on individual circumstances and in accordance with applicable law including, but not limited to, the San Francisco Fair Chance Ordinance . Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. New Relic does not accept unsolicited headhunter and agency resumes, and will not pay fees to any third-party agency or company that does not have a signed agreement with New Relic. Candidates are evaluated based on qualifications, regardless of race, religion, ethnicity, national origin, sex, sexual orientation, gender expression or identity, age, disability, neurodiversity, veteran or marital status, political viewpoint, or other legally protected characteristics. Review our Applicant Privacy Notice at https://newrelic.com/termsandconditions/applicant-privacy-policy",manager,,"Python, Machine Learning",
4217589656,Data Engineer - India GDC (Gurugram),ERM,"New Delhi, Delhi, India (On-site)",On-site,Full-time,,"About the job Who is ERM? ERM is a leading global sustainability consulting firm, committed for nearly 50 years to helping organizations navigate complex environmental, social, and governance (ESG) challenges. We bring together a diverse and inclusive community of experts across regions and disciplines, providing a truly multicultural environment that fosters collaboration, professional growth, and meaningful global exposure. As a people-first organization, ERM values well-being, career development, and the power of collective expertise to drive sustainable impact for our clients—and the planet. Introducing our new Global Delivery Centre (GDC) Our Global Delivery Centre (GDC) in India is a unified platform designed to deliver high-value services and solutions to ERM’s global clientele. By centralizing key business and consulting functions, we streamline operations, optimize service delivery, and enable our teams to focus on what matters most—advising clients on sustainability challenges with agility and innovation. Through the GDC, you will collaborate with international teams, leverage emerging technologies, and further enhance ERM’s commitment to excellence—amplifying our shared mission to make a lasting, positive impact. Job Objective The objective of the Data Engineer role is to help our consultants upskill in the use of new technology and tools, especially AI tools. The Data Engineer will work with project teams to demonstrate and showcase capabilities using ERM's technology and AI tools, and impart that knowledge to the project teams so they can undertake these tasks themselves. Additionally, the role involves creating tools and resources for project teams to independently achieve their goals. The overall objective is to facilitate the growth of capabilities within our consulting ranks. Key Accountabilities & Responsibilities Work directly with project teams to solve their problems using available tools, ensuring that project teams can independently and autonomously solve these problems in the future. Identify generic forms of requests to build tools and applications that consultants can use off the shelf for similar purposes in the future. Understand requirements and own the execution of tasks while collaborating across the business. Demonstrate and showcase capabilities using ERM's technology and AI tools, such as Microsoft Fabric and Copilot. Create tools and resources to support project teams in achieving their goals independently. Influence And Decision Making Authority Influence: The Data Engineer will have significant influence over the adoption and implementation of new technologies and AI tools within project teams. They will guide and mentor consultants, helping them to upskill and become proficient in using these tools independently. Decision Making Authority: The Data Engineer will have the authority to make decisions regarding the design and development of tools and resources that will be used by project teams. They will also be responsible for identifying common problems and creating reusable solutions that can be applied across different projects. Additionally, they will collaborate with various departments to ensure that the tools and solutions developed align with the overall business strategy and objectives. Job Requirements & Capabilities Qualifications: Bachelors degree qualified in science, engineering or mathematics Job specific capabilities/skills: Skills in data engineering and working with databases. Experience in data science and coding in Python is favorable. Experience with Microsoft Fabric highly regarded. Experience with large language models (LLMs) or other natural language processing tools. Ability to work with non-technical specialists to upskill or train them. Strong communication skills and the ability to articulate complex scenarios effectively. Ability to work in a complex, global, dynamic organization and be effective within matrixed reporting environments and multi-partner contexts. Problem-solving skills and the ability to make decisions by assessing situations and selecting appropriate courses of action.",,,Python,
4258414353,Sr. Engineer - Artificial Intelligence,Jubilant Pharmova Limited,"Sadar, Uttar Pradesh, India (On-site)",On-site,Full-time,,"About the job Jubilant Bhartia Group Jubilant Bhartia Group is a global conglomerate founded by Mr. Shyam S Bhartia and Mr. Hari S Bhartia with strong presence in diverse sectors like Pharmaceuticals, Contract Research and Development Services, Proprietary Novel Drugs, Life Science Ingredients, Agri Products, Performance Polymers, Food Service (QSR), Food, Auto, Consulting in Aerospace and Oilfield Services. Jubilant Bhartia Group has four flagships Companies- Jubilant Pharmova Limited, Jubilant Ingrevia Limited, Jubilant FoodWorks Limited and Jubilant Industries Limited. Currently the group has a global workforce of around 43,000 employees. Jubilant Pharmova Limited Jubilant Pharmova Limited (formerly Jubilant Life Sciences Limited) is a company with global presence that is involved in Radiopharma, Allergy Immunotherapy, CDMO Sterile Injectables, Contract Research Development and Manufacturing Organisation (CRDMO), Generics and Proprietary Novel Drugs businesses . In the Radiopharma business , the Company is involved in manufacturing and supply of Radiopharmaceuticals with a network of 46 radio-pharmacies in the US. The Company’s Allergy Immunotherapy business is involved in the manufacturing and supply of allergic extracts and venom products in the US and in some other markets such as Canada, Europe and Australia. Jubilant through its CDMO Sterile Injectables business offers manufacturing services including sterile fill and finish injectables (both liquid and lyophilization), full-service ophthalmic offer (liquids, ointments & creams) and ampoules. The CRDMO business of the Company includes the Drug Discovery Services business that provides contract research and development services through two world-class research centres in Bangalore and Noida in India and the CDMO-API business that is involved in the manufacturing of Active Pharmaceutical Ingredients. Jubilant Therapeutics is involved in Proprietary Novel Drugs business and is an innovative biopharmaceutical company developing breakthrough therapies in the area of oncology and autoimmune disorders. The company operates six manufacturing facilities that cater to all the regulated market including USA, Europe and other geographies. Find out more about us at www.jubilantpharmova.com The Position Organization : - Jubilant Pharmova Limited Designation : - Sr. Engineer - Artificial Intelligence Location : - Greater Noida Job Summary: - The incumbent will Work on real-world projects, helping design, develop, and deploy AI models and data-driven solutions. You will play a crucial role in helping businesses make informed decisions by collaborating with stakeholders, designing data models, creating algorithms, and sharing meaningful insights to drive use case success. Key Responsibilities AI Solution Development : Design, train, fine-tune, and evaluate generative models (e.g., GPT, LLaMA, Stable Diffusion, DALL·E, etc.), Collaborate with cross-functional teams including product, research, and engineering to integrate GenAI capabilities into products. Develop a platform approach, optimize models for performance, latency, and cost in production environments Model Integration : Integrate foundational models and retrieval-augmented generation (RAG) techniques Backend Development : Implement backend services and API endpoints to support AI solutions. Frontend Integration : Develop or adapt frontend interfaces for user interaction. Mentor junior engineers and contribute to best practices in model development and deployment. Ensure ethical and responsible AI practices in model design and usage Person Profile Qualification: - Bachelor’s or Master’s degree in Computer Science, Machine Learning, Mathematics / Statistics or related field Experience/Must Have :- 3 -5+ years of experience in machine learning, with at least 2 years focused on generative AI. Preferably with GenAI use cases in Chemical, Pharma, or Manufacturing industries. We are looking for a highly agile individuals who would like to make an impact in a global set up. Proficiency in Python for data handling and AI-related scripting. Familiarity with data pipeline development, ETL processes, and data preprocessing techniques. Knowledge of testing frameworks and tools to ensure model robustness, as well as experience with automated testing for QA processes. Familiarity with Retrieval-Augmented Generation techniques and their applications. Knowledge of prompt engineering techniques to optimize generative AI models for specific tasks and enhance output relevance. Experience in predictive modeling areas, such as traditional supervised and unsupervised learning, Basic familiarity with foundational generative AI models and Natural Language Processing (NLP) Jubilant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, colour, gender identity or expression, genetic information, marital status, medical condition, national origin, political affiliation, race, ethnicity, religion or any other characteristic protected by applicable local laws, regulations and ordinances",,,"Python, Machine Learning",
4187890615,Senior Computer Vision Engineer,Mercer,"Gurugram, Haryana, India (Hybrid)",Hybrid,Full-time,,"About the job About the Role: We are based in Gurgaon and looking for a Senior Computer Vision Engineer to join our team and help our team to improve and create new technologies. You'll work on projects which makes online assessment more secure and cheating proof. If you're a seasoned computer vision expert with a passion for innovation and a track record of delivering impactful solutions, we would be happy to meet you. Role : Senior Computer Vision Engineer Functional Area : AI Educational Qualification: BTech/MS/MTech/PhD in Computer Science/Computer vision/Signal Processing/Deep Learning or equivalent. Should have worked in an academic or professional setting in the field of computer vision/signal processing. Experience: 2-5 years Location : Gurgaon Key Responsibilities: Develop and optimize advanced computer vision algorithms for image and video analysis tasks. Design, implement and train deep learning models for object detection, face processing, activity recognition and other related tasks. Test and refine models and systems based on real-world data and feedback. Evaluate project requirements, plan and manage the roadmap of a project. Present findings and insights in a clear and concise manner to stakeholders. Collaborate and help to integrate and deploy computer vision systems into broader product architecture. Conduct research to stay updated on emerging computer vision technologies and trends. Automate data preprocessing and annotation processes to streamline workflow efficiency. Maintain comprehensive documentation for algorithms, implementations, and evaluations. Mentor junior engineers and provide strategic guidance on project development. Requirements and skills: Proficiency in Python and knowledge of C++, Java and JS is plus. Solid understanding of neural networks, especially convolutional neural networks (CNNs). Knowledge of RCNN’s and vision transformers. Proficient in understanding, designing and implementing deep learning models using frameworks such as TensorFlow, PyTorch and Keras. Understanding of fundamental image processing techniques like image filtering, edge detection, image segmentation and image augmentation. Experience in evaluating computer vision models using relevant metrics and performance indicators. Familiarity with GPU and related technologies which is utilized for improved computational efficiency such as CUDA, CUDNN, tensorRT etc. Familiarity with Python libraries such as OpenCV, NumPy, Pandas and scikit-learn etc. Basic knowledge of linear algebra, calculus, and statistics. Strong critical thinking, analytical, and problem-solving skills Self-motivated, quick learner and strong team player with ability to work with minimal supervision. Mercer, a business of Marsh McLennan (NYSE: MMC), is a global leader in helping clients realize their investment objectives, shape the future of work and enhance health and retirement outcomes for their people. Marsh McLennan is a global leader in risk, strategy and people, advising clients in 130 countries across four businesses: Marsh, Guy Carpenter, Mercer and Oliver Wyman. With annual revenue of $24 billion and more than 90,000 colleagues, Marsh McLennan helps build the confidence to thrive through the power of perspective. For more information, visit mercer.com, or follow on LinkedIn and X. Marsh McLennan is committed to embracing a diverse, inclusive and flexible work environment. We aim to attract and retain the best people and embrace diversity of age, background, caste, disability, ethnic origin, family duties, gender orientation or expression, gender reassignment, marital status, nationality, parental status, personal or social status, political affiliation, race, religion and beliefs, sex/gender, sexual orientation or expression, skin color, or any other characteristic protected by applicable law. Marsh McLennan is committed to hybrid work, which includes the flexibility of working remotely and the collaboration, connections and professional development benefits of working together in the office. All Marsh McLennan colleagues are expected to be in their local office or working onsite with clients at least three days per week. Office-based teams will identify at least one “anchor day” per week on which their full team will be together in person. R_288254",,,Python,
